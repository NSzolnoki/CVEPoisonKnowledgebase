diff --git a/.gitignore b/.gitignore
index 24afdb80df..60fb346c0f 100644
--- a/.gitignore
+++ b/.gitignore
@@ -38,4 +38,10 @@ guava-rpm-maker/\.project
 src-main
 src-test
 plugin_test.jar
-/bin/
+bin/
+
+#Docker
+tools/docker/libs
+tools/docker/*.jar
+tools/docker/logback.xml
+tools/docker/opentsdb.conf
diff --git a/.travis.yml b/.travis.yml
index 35b57e08a5..fccf400e41 100644
--- a/.travis.yml
+++ b/.travis.yml
@@ -6,5 +6,6 @@ addons:
 jdk:
   - oraclejdk7
   - openjdk6
+  - oraclejdk8
 notifications:
     email: false
diff --git a/AUTHORS b/AUTHORS
index f52737fcdf..828a00bfd9 100644
--- a/AUTHORS
+++ b/AUTHORS
@@ -24,5 +24,6 @@ Chris Larsen <clarsen575@gmail.com>
 David Bainbridge <dbainbridge@zenoss.com>
 Geoffrey Anderson <geoff@geoffreyanderson.net>
 Ion Savin <comp_@gmx.net>
+Jonathan Creasy <jonathan@ghostlab.net>
 Nicholas Whitehead <whitehead.nicholas@gmail.com>
 Will Moss <wmoss@bu.mp>
diff --git a/Makefile.am b/Makefile.am
index 9963574c64..ab2a3fa505 100644
--- a/Makefile.am
+++ b/Makefile.am
@@ -68,18 +68,55 @@ tsdb_SRC := \
 	src/core/TSQuery.java	\
 	src/core/TSSubQuery.java	\
 	src/core/WritableDataPoints.java	\
+	src/core/WriteableDataPointFilterPlugin.java	\
 	src/graph/Plot.java	\
 	src/meta/Annotation.java	\
+	src/meta/MetaDataCache.java	\
 	src/meta/TSMeta.java	\
 	src/meta/TSUIDQuery.java	\
 	src/meta/UIDMeta.java	\
 	src/query/QueryUtil.java	\
+	src/query/expression/Absolute.java	\
+	src/query/expression/Alias.java	\
+	src/query/expression/DiffSeries.java	\
+	src/query/expression/DivideSeries.java	\
+	src/query/expression/EDPtoDPS.java	\
+	src/query/expression/Expression.java	\
+	src/query/expression/ExpressionDataPoint.java	\
+	src/query/expression/ExpressionFactory.java	\
+	src/query/expression/ExpressionIterator.java	\
+	src/query/expression/ExpressionReader.java	\
+	src/query/expression/Expressions.java	\
+	src/query/expression/ExpressionTree.java	\
+	src/query/expression/HighestCurrent.java	\
+	src/query/expression/HighestMax.java	\
+	src/query/expression/IntersectionIterator.java	\
+	src/query/expression/ITimeSyncedIterator.java	\
+	src/query/expression/NumericFillPolicy.java	\
+	src/query/expression/MovingAverage.java	\
+	src/query/expression/MultiplySeries.java	\
+	src/query/expression/PostAggregatedDataPoints.java	\
+	src/query/expression/Scale.java	\
+	src/query/expression/SumSeries.java	\
+	src/query/expression/TimeShift.java \
+	src/query/expression/TimeSyncedIterator.java	\
+	src/query/expression/UnionIterator.java	\
+	src/query/expression/VariableIterator.java	\
 	src/query/filter/TagVFilter.java	\
 	src/query/filter/TagVLiteralOrFilter.java	\
 	src/query/filter/TagVNotKeyFilter.java	\
 	src/query/filter/TagVNotLiteralOrFilter.java	\
 	src/query/filter/TagVRegexFilter.java	\
 	src/query/filter/TagVWildcardFilter.java	\
+	src/query/pojo/Downsampler.java	\
+	src/query/pojo/Expression.java	\
+	src/query/pojo/Filter.java	\
+	src/query/pojo/Join.java	\
+	src/query/pojo/Metric.java	\
+	src/query/pojo/Output.java	\
+	src/query/pojo/Query.java	\
+	src/query/pojo/Timespan.java	\
+	src/query/pojo/Validatable.java	\
 	src/search/SearchPlugin.java	\
 	src/search/SearchQuery.java	\
 	src/search/TimeSeriesLookup.java	\
@@ -96,6 +133,7 @@ tsdb_SRC := \
 	src/tools/MetaPurge.java	\
 	src/tools/MetaSync.java	\
 	src/tools/Search.java	\
+	src/tools/StartupPlugin.java \
 	src/tools/TSDMain.java	\
 	src/tools/TextImporter.java	\
 	src/tools/TreeSync.java	\
@@ -109,6 +147,7 @@ tsdb_SRC := \
 	src/tsd/AnnotationRpc.java	\
 	src/tsd/BadRequestException.java	\
 	src/tsd/ConnectionManager.java	\
+	src/tsd/DropCachesRpc.java \
 	src/tsd/GnuplotException.java	\
 	src/tsd/GraphHandler.java	\
 	src/tsd/HttpJsonSerializer.java	\
@@ -121,10 +160,12 @@ tsdb_SRC := \
 	src/tsd/LogsRpc.java	\
 	src/tsd/PipelineFactory.java	\
 	src/tsd/PutDataPointRpc.java	\
+	src/tsd/QueryExecutor.java	\
 	src/tsd/QueryRpc.java	\
 	src/tsd/RpcHandler.java	\
 	src/tsd/RpcPlugin.java	\
 	src/tsd/RpcManager.java	\
+	src/tsd/RpcUtil.java \
 	src/tsd/RTPublisher.java	\
 	src/tsd/SearchRpc.java	\
 	src/tsd/StaticFileRpc.java	\
@@ -140,8 +181,10 @@ tsdb_SRC := \
 	src/uid/NoSuchUniqueName.java	\
 	src/uid/RandomUniqueId.java	\
 	src/uid/UniqueId.java	\
+	src/uid/UniqueIdFilterPlugin.java \
 	src/uid/UniqueIdInterface.java \
 	src/utils/ByteArrayPair.java \
+	src/utils/ByteSet.java \
 	src/utils/Config.java \
 	src/utils/DateTime.java \
 	src/utils/Exceptions.java \
@@ -153,7 +196,7 @@ tsdb_SRC := \
 	src/utils/Threads.java
 
 tsdb_DEPS = \
-	$(ASYNCHBASE)	\
+	$(COMMONS_LOGGING)	\
 	$(GUAVA)	\
 	$(LOG4J_OVER_SLF4J)	\
 	$(LOGBACK_CLASSIC)	\
@@ -161,13 +204,39 @@ tsdb_DEPS = \
 	$(JACKSON_ANNOTATIONS)	\
 	$(JACKSON_CORE)	\
 	$(JACKSON_DATABIND)	\
+	$(JAVACC)	\
+	$(JEXL)	\
+	$(JGRAPHT)	\
 	$(NETTY)	\
-	$(PROTOBUF)	\
 	$(SLF4J_API)	\
 	$(SUASYNC)	\
-	$(ZOOKEEPER) \
 	$(APACHE_MATH)
 
+if BIGTABLE
+tsdb_DEPS += \
+	$(ALPN_BOOT)	\
+	$(ASYNCBIGTABLE)
+maven_profile_bigtable := true
+maven_profile_hbase := false
+maven_profile_cassandra := false
+else
+if CASSANDRA
+tsdb_DEPS += \
+	$(ASYNCCASSANDRA)
+maven_profile_bigtable := false
+maven_profile_hbase := false
+maven_profile_cassandra := true
+else
+tsdb_DEPS += \
+	$(ASYNCHBASE) \
+	$(PROTOBUF) \
+	$(ZOOKEEPER)
+maven_profile_bigtable := false
+maven_profile_hbase := true
+maven_profile_cassandra := false
+endif
+endif
+
 test_SRC := \
 	test/core/SeekableViewsForTest.java \
 	test/core/BaseTsdbTest.java \
@@ -190,6 +259,7 @@ test_SRC := \
 	test/core/TestSpanGroup.java	\
 	test/core/TestTags.java	\
 	test/core/TestTSDB.java	\
+	test/core/TestTSDBAddPoint.java	\
 	test/core/TestTsdbQueryDownsample.java	\
 	test/core/TestTsdbQueryDownsampleSalted.java	\
 	test/core/TestTsdbQuery.java	\
@@ -206,12 +276,41 @@ test_SRC := \
 	test/meta/TestTSMeta.java	\
 	test/meta/TestTSUIDQuery.java	\
 	test/meta/TestUIDMeta.java	\
+	test/query/expression/BaseTimeSyncedIteratorTest.java	\
+	test/query/expression/TestAbsolute.java	\
+	test/query/expression/TestAlias.java	\
+	test/query/expression/TestDiffSeries.java	\
+	test/query/expression/TestDivideSeries.java	\
+	test/query/expression/TestExpressionFactory.java	\
+	test/query/expression/TestExpressionIterator.java	\
+	test/query/expression/TestExpressionReader.java	\
+	test/query/expression/TestExpressions.java	\
+	test/query/expression/TestExpressionTree.java	\
+	test/query/expression/TestHighestCurrent.java	\
+	test/query/expression/TestHighestMax.java	\
+	test/query/expression/TestIntersectionIterator.java	\
+	test/query/expression/TestNumericFillPolicy.java	\
+	test/query/expression/TestMovingAverage.java	\
+	test/query/expression/TestMultiplySeries.java	\
+	test/query/expression/TestPostAggregatedDataPoints.java	\
+	test/query/expression/TestScale.java	\
+	test/query/expression/TestSumSeries.java	\
+	test/query/expression/TestTimeSyncedIterator.java	\
+	test/query/expression/TestUnionIterator.java	\
 	test/query/filter/TestTagVFilter.java	\
 	test/query/filter/TestTagVLiteralOrFilter.java	\
 	test/query/filter/TestTagVNotKeyFilter.java	\
 	test/query/filter/TestTagVNotLiteralOrFilter.java	\
 	test/query/filter/TestTagVRegexFilter.java	\
 	test/query/filter/TestTagVWildcardFilter.java	\
+	test/query/pojo/TestDownsampler.java	\
+	test/query/pojo/TestExpression.java	\
+	test/query/pojo/TestFilter.java	\
+	test/query/pojo/TestJoin.java	\
+	test/query/pojo/TestMetric.java	\
+	test/query/pojo/TestOutput.java	\
+	test/query/pojo/TestQuery.java	\
+	test/query/pojo/TestTimeSpan.java	\
 	test/search/TestSearchPlugin.java	\
 	test/search/TestSearchQuery.java	\
 	test/search/TestTimeSeriesLookup.java	\
@@ -237,6 +336,7 @@ test_SRC := \
 	test/tsd/TestHttpQuery.java	\
 	test/tsd/TestHttpRpcPluginQuery.java	\
 	test/tsd/TestPutRpc.java	\
+	test/tsd/TestQueryExecutor.java	\
 	test/tsd/TestQueryRpc.java	\
 	test/tsd/TestQueryRpcLastDataPoint.java	\
 	test/tsd/TestRpcHandler.java	\
@@ -252,6 +352,7 @@ test_SRC := \
 	test/uid/TestRandomUniqueId.java	\
 	test/uid/TestUniqueId.java \
 	test/utils/TestByteArrayPair.java \
+	test/utils/TestByteSet.java \
 	test/utils/TestConfig.java \
 	test/utils/TestDateTime.java \
 	test/utils/TestExceptions.java \
@@ -286,11 +387,11 @@ test_DEPS = \
 	$(tsdb_DEPS) \
 	$(JAVASSIST)	\
 	$(JUNIT)	\
-        $(HAMCREST)	\
+	$(HAMCREST)	\
 	$(MOCKITO)	\
-        $(OBJENESIS)	\
+	$(OBJENESIS)	\
 	$(POWERMOCK_MOCKITO)	\
-        $(jar)
+	$(jar)
 
 httpui_SRC := \
 	src/tsd/client/DateTimeBox.java	\
@@ -304,12 +405,18 @@ httpui_SRC := \
 
 httpui_DEPS = src/tsd/QueryUi.gwt.xml
 
+# TODO(CL) - There is likely a MUCH better way to compile and add the expression sources and jars.
+expr_grammar = $(srcdir)/src/parser.jj
+expr_package = net/opentsdb/query/expression/parser
+expr_src_dir = $(builddir)/src/$(expr_package)
+get_expr_classes = `classes=''; for f in $(packagedir)$(expr_package)/*.class; do classes="$$classes $$f"; done; echo $$classes;`
+
 #dist_pkgdata_DATA = src/logback.xml
 dist_static_DATA = \
 	src/tsd/static/favicon.ico	\
 	src/tsd/static/opentsdb_header.jpg
 
-EXTRA_DIST = tsdb.in $(tsdb_SRC) $(test_SRC) \
+EXTRA_DIST = tsdb.in $(tsdb_SRC) $(test_SRC) $(expr_grammar) \
         $(test_plugin_SRC) $(test_plugin_MF) $(test_plugin_SVCS:%=test/%) \
         $(THIRD_PARTY) $(THIRD_PARTY:=.md5) \
         $(httpui_SRC) $(httpui_DEPS) \
@@ -379,6 +486,9 @@ filter_src = \
      src="$$src $$i";; \
    esac; \
  done; \
+ for f in $(expr_src_dir)/*.java; do \
+   src="$$src $$f"; \
+ done; \
  test -n "$$src" || exit 0
 # Touches all the targets if any of the dependencies are newer.
 # This is useful to force-recompile all files if one of the
@@ -395,7 +505,7 @@ $(tsdb_SRC): $(tsdb_DEPS)
 
 find_jar = test -f "$$jar" && echo "$$jar" || echo "$(srcdir)/$$jar"
 get_dep_classpath = `for jar in $(tsdb_DEPS); do $(find_jar); done | tr '\n' ':'`
-.javac-stamp: $(tsdb_SRC) $(builddata_SRC)
+.javac-stamp: $(tsdb_SRC) $(builddata_SRC) runjavacc
 	@$(filter_src); cp=$(get_dep_classpath); \
           echo "$(JAVA_COMPILE) -cp $$cp $$src"; \
                 $(JAVA_COMPILE) -cp $$cp $$src
@@ -611,8 +721,8 @@ manifest: .javac-stamp .git/HEAD
           echo "Implementation-Version: $(git_version)"; \
           echo "Implementation-Vendor: $(spec_vendor)"; } >"$@"
 
-$(jar): manifest .javac-stamp $(classes)
-	$(JAR) cfm `basename $(jar)` manifest $(classes_with_nested_classes) \
+$(jar): manifest .javac-stamp
+	$(JAR) cfm `basename $(jar)` manifest $(classes_with_nested_classes) $(get_expr_classes) \
          || { rv=$$? && rm -f `basename $(jar)` && exit $$rv; }
 #                       ^^^^^^^^^^^^^^^^^^^^^^^
 # I've seen cases where `jar' exits with an error but leaves a partially built .jar file!
@@ -636,6 +746,9 @@ $(JAVADOC_DIR)/index.html: $(tsdb_SRC)
           -link $(JDK_JAVADOC) -link $(NETTY_JAVADOC) -link $(SUASYNC_JAVADOC) \
           $? $(builddata_SRC)
 
+runjavacc:
+	$(JAVA) -cp $(JAVACC) javacc -OUTPUT_DIRECTORY:$(expr_src_dir) $(expr_grammar); echo PWD: `pwd`;
+
 dist-hook:
 	$(mkdir_p) $(distdir)/.git
 	echo $(git_version) >$(distdir)/.git/HEAD
@@ -666,6 +779,8 @@ pom.xml: pom.xml.in Makefile
 	  echo '<!-- Generated by Makefile on '`date`' -->'; \
 	  sed <$< \
 	    -e 's/@ASYNCHBASE_VERSION@/$(ASYNCHBASE_VERSION)/' \
+	    -e 's/@ASYNCBIGTABLE_VERSION@/$(ASYNCBIGTABLE_VERSION)/' \
+	    -e 's/@ASYNCCASSANDRA_VERSION@/$(ASYNCCASSANDRA_VERSION)/' \
 	    -e 's/@GUAVA_VERSION@/$(GUAVA_VERSION)/' \
 	    -e 's/@GWT_VERSION@/$(GWT_VERSION)/' \
 	    -e 's/@GWT_THEME_VERSION@/$(GWT_THEME_VERSION)/' \
@@ -684,9 +799,14 @@ pom.xml: pom.xml.in Makefile
 	    -e 's/@SUASYNC_VERSION@/$(SUASYNC_VERSION)/' \
 	    -e 's/@ZOOKEEPER_VERSION@/$(ZOOKEEPER_VERSION)/' \
 	    -e 's/@APACHE_MATH_VERSION@/$(APACHE_MATH_VERSION)/' \
+	    -e 's/@JEXL_VERSION@/$(JEXL_VERSION)/' \
+	    -e 's/@JGRAPHT_VERSION@/$(JGRAPHT_VERSION)/' \
 	    -e 's/@spec_title@/$(spec_title)/' \
 	    -e 's/@spec_vendor@/$(spec_vendor)/' \
 	    -e 's/@spec_version@/$(PACKAGE_VERSION)/' \
+	    -e 's/@maven_profile_hbase@/$(maven_profile_hbase)/' \
+	    -e 's/@maven_profile_bigtable@/$(maven_profile_bigtable)/' \
+	    -e 's/@maven_profile_cassandrae@/$(maven_profile_cassandra)/' \
 	    ; \
 	} >$@-t
 	mv $@-t ../$@
@@ -741,7 +861,7 @@ debian: dist staticroot
 	cp -r gwt/queryui/* $(distdir)/debian/usr/share/opentsdb/static
 	`for dep_jar in $(tsdb_DEPS); do cp $$dep_jar \
 	     $(distdir)/debian/usr/share/opentsdb/lib; done;`
-	cp $(top_srcdir)/tools/* $(distdir)/debian/usr/share/opentsdb/tools
+	cp -r $(top_srcdir)/tools/* $(distdir)/debian/usr/share/opentsdb/tools
 	dpkg -b $(distdir)/debian $(distdir)/opentsdb-$(PACKAGE_VERSION)_all.deb
 
 .PHONY: jar doc check gwtc gwtdev printdeps staticroot gwttsd rpm
diff --git a/NEWS b/NEWS
index 799715d529..e2e4426532 100644
--- a/NEWS
+++ b/NEWS
@@ -1,5 +1,17 @@
 OpenTSDB - User visible changes.
 
+
+* Version 2.3.0 (2016-12-31)
+
+Noteworthy Changes:
+  - Release of 2.3.0.
+  - Add example classes for using the Java API.
+
+Bug Fixes:
+  - Same fixes as in 2.2.2
+  - Fix a null UID check on decoding metric names from row keys.
+  - Fix unit tests for JDK 8 and later.
+
 * Version 2.2.2 (2016-12-29)
 
 Bug Fixes:
@@ -11,6 +23,27 @@ Bug Fixes:
   - Fix a concurrent modification issue where salt scanners were not synchronized on the
     annotation map and could cause spinning threads.
 
+* Version 2.3.0 RC2 (2016-10-08)
+
+Noteworthy Changes:
+  - Added a docker file and tool to build TSD docker containers (#871).
+  - Log X-Forwarded-For addresses when handling HTTP requests.
+  - Expand aggregator options in the Nagios check script.
+  - Allow enabling or disabling the HTTP API or UI.
+  - TSD will now exit when an unrecognized CLI param is passed.
+  
+Bug Fixes:
+  - Improved ALPN version detection when using Google Bigtable.
+  - Fix the DumpSeries class to support appended data point types.
+  - Fix queries where groupby is set to false on all filters.
+  - Fix a missing attribute in the Nagios check script (#728).
+  - Fix a major security bug where requesting a PNG with certain URI params could execute code
+    on the host (#793, #781).
+  - Return a proper error code when dropping caches with the DELETE HTTP verb (#830).
+  - Fix backwards compatibility with HBase 0.94 when using explicit tags by removing the
+    fuzzy filter (#837).
+  - Fix an RPM build issue when creating the GWT directory.s
+
 * Version 2.2.1 (2016-10-08)
 
 Noteworthy Changes
@@ -38,6 +71,38 @@ Bug Fixes:
   - Change the static file path for the HTTP API to be relative (#857).
   - Fix an issue where the GUI could flicker when two or more tag filters were set (#708).
 
+* Version 2.3.0 RC1 (2016-05-02)
+
+Noteworthy Changes:
+  - Introduced option --max-connection/tsd.core.connections.limit to set the maximum number
+    of connection a TSD will accept (#638)
+  - 'tsdb import' can now read from stdin (#580)
+  - Added datapoints counter (#369)
+  - Improved metadata storage performance (#699)
+  - added checkbox for showing global annotations in UI (#736)
+  - Added startup plugins, can be used for Service Discovery or other integration (#719)
+  - Added MetaDataCache plugin api
+  - Added timeshift() function (#175)
+  - Now align downsampling to Gregorian Calendar (#548, #657)
+  - Added None aggregator to fetch raw data along with first and last aggregators to 
+    fetch only the first or last data points when downsampling.
+  - Added script to build OpenTSDB/HBase on OSX (#674)
+  - Add cross-series expressions with mathematical operators using Jexl
+  - Added query epxressions (alias(), scale(), absolute(), movingAverage(), highestCurrent(),
+    highestMax(), timeShift(), divide(), sum(), difference(), multiply()) (#625)
+  - Add a Unique ID assignment filter API for enforcing UID assignment naming conventions.
+  - Add a whitelist regular expression based UID assignment filter
+  - Add a time series storage filter plugin API that allows processing time series data
+    and determining if it should be stored or not.
+  - Allow using OpenTSDB with Google's Bigtable cloud platform or with Apache Cassandra
+    
+Bug Fixes:
+  - Some improperly formatted timestamps were allowed (#724)
+  - Removed stdout logging from packaged logback.xml files (#715)
+  - Restore the ability to create TSMeta objects via URI
+  - Restore raw data points (along with post-filtered data points) in query stats
+  - Built in UI will now properly display global annotations when the query string is passed
+
 * Version 2.2.0 (2016-02-14)
 
 Noteworthy Changes
diff --git a/THANKS b/THANKS
index 9493ba58e1..e7262c951e 100644
--- a/THANKS
+++ b/THANKS
@@ -13,11 +13,17 @@ Adrien Mogenet <adrien.mogenet@gmail.com>
 Alex Ioffe <deusaquilus@gmail.com>
 Andre Pech
 Andrey Stepachev <octo47@gmail.com>
+Andy Flury
+Anna Claiborne
 Aravind Gottipati <aravind.gottipati@gmail.com>
 Arvind Jayaprakash <work@anomalizer.net>
 Berk D. Demir <bdd@mindcast.org>
 Bikrant Neupane
+Bryan Hernandez <bryan4887@gmail.com>
 Bryan Zubrod <bzubrod@adknowledge.com>
+Camden Narzt
+Can Zhang
+Carlos Devoto
 Chris McClymont <chris@mcclymont.it>
 Cristian Sechel 
 Christophe Furmaniak
@@ -28,10 +34,12 @@ Ethan Wang
 Filippo Giunchedi <fgiunchedi@gmail.com>
 Gabriel Nicolas Avellaneda
 Guenther Schmuelling <schmuell@pepperdata.com>
+Haiyang Jiang
 Hari Krishna Dara
 Hong Dai Thanh
 Hugo M Fernandes
 Hugo Trippaers <opensource@strocamp.net>
+Isaiah Choe
 Ivan Babrou
 Jacek Masiulaniec <jacek.masiulaniec@gmail.com>
 Jari Takkala <jari.takkala@betfair.com>
@@ -46,6 +54,7 @@ Johannes Meixner
 Jonathan Works <jonathan.works@threattrack.com>
 Josh Thomas <josh@kickbackpoints.com>
 Kevin Bowling
+Kevin Landreth
 Kieren Hynd <kieren.hynd@ticketmaster.co.uk>
 Kimoon Kim <kimoon@pepperdata.com>
 Kris Beevers <beevek@gmail.com>
@@ -61,6 +70,7 @@ Matt Schallert <mattschallert@gmail.com>
 Marc Tamsky
 Mark Smith <mark@dreamwidth.org>
 Martin Jansen <martin@divbyzero.net>
+Max Meng
 Michal Kimle
 Mike Bryant <mike@mikebryant.me.uk>
 Mike Kobyakov <mkobyakov@cyngn.com>
@@ -71,6 +81,8 @@ Nitin Aggarwal
 Paula Keezer <paula.keezer@gmail.com>
 Peter Edwards
 Peter Gotz <peter.s.goetz@googlemail.com>
+Peter Edwards
+Ping Yong
 Pradeep Chhetri <pradeep.chhetri89@gmail.com>
 Rajesh G
 Ryan Berdeen <ryan@ryanberdeen.com>
diff --git a/build-aux/deb/logback.xml b/build-aux/deb/logback.xml
index 7ae2c3fcfc..9c32b2ecbe 100644
--- a/build-aux/deb/logback.xml
+++ b/build-aux/deb/logback.xml
@@ -67,7 +67,7 @@
   
   <!-- Fallthrough root logger and router -->
   <root level="INFO">
-    <appender-ref ref="STDOUT"/>
+    <!-- <appender-ref ref="STDOUT"/> -->
     <appender-ref ref="CYCLIC"/>
     <appender-ref ref="FILE"/>
   </root>
diff --git a/build-aux/gen_build_data.sh b/build-aux/gen_build_data.sh
index 927f2e63b1..4f211efbbc 100755
--- a/build-aux/gen_build_data.sh
+++ b/build-aux/gen_build_data.sh
@@ -39,6 +39,7 @@ eval "$sh"  # Sets the timestamp and date variables.
 user=`whoami`
 host=`hostname`
 repo=`pwd`
+branch=`git branch | grep -h '\*.*' | awk '{print $2}'`
 
 sh=`git rev-list --pretty=format:%h HEAD --max-count=1 \
     | sed '1s/commit /full_rev=/;2s/^/short_rev=/'`
@@ -92,6 +93,8 @@ public final class $CLASS {
   public static final String host = "$host";
   /** Path to the repository in which this package was built. */
   public static final String repo = "$repo";
+  /** Git branch */
+  public static final String branch = "$branch";
 
   /** Human readable string describing the revision of this package. */
   public static final String revisionString() {
diff --git a/build-aux/rpm/logback.xml b/build-aux/rpm/logback.xml
index 7ae2c3fcfc..9c32b2ecbe 100644
--- a/build-aux/rpm/logback.xml
+++ b/build-aux/rpm/logback.xml
@@ -67,7 +67,7 @@
   
   <!-- Fallthrough root logger and router -->
   <root level="INFO">
-    <appender-ref ref="STDOUT"/>
+    <!-- <appender-ref ref="STDOUT"/> -->
     <appender-ref ref="CYCLIC"/>
     <appender-ref ref="FILE"/>
   </root>
diff --git a/build-bigtable.sh b/build-bigtable.sh
new file mode 100644
index 0000000000..1076da2f8e
--- /dev/null
+++ b/build-bigtable.sh
@@ -0,0 +1,9 @@
+#!/usr/bin/env bash
+set -xe
+test -f configure || ./bootstrap
+test -d build || mkdir build
+cd build
+test -f Makefile || ../configure --with-bigtable "$@"
+MAKE=make
+[ `uname -s` = "FreeBSD" ] && MAKE=gmake
+exec ${MAKE} "$@"
\ No newline at end of file
diff --git a/build-cassandra.sh b/build-cassandra.sh
new file mode 100644
index 0000000000..a29a383e34
--- /dev/null
+++ b/build-cassandra.sh
@@ -0,0 +1,9 @@
+#!/usr/bin/env bash
+set -xe
+test -f configure || ./bootstrap
+test -d build || mkdir build
+cd build
+test -f Makefile || ../configure --with-cassandra "$@"
+MAKE=make
+[ `uname -s` = "FreeBSD" ] && MAKE=gmake
+exec ${MAKE} "$@"
\ No newline at end of file
diff --git a/configure.ac b/configure.ac
index dd50581898..5efc9c1da5 100644
--- a/configure.ac
+++ b/configure.ac
@@ -1,4 +1,4 @@
-# Copyright (C) 2011-2012  The OpenTSDB Authors.
+# Copyright (C) 2011-2016  The OpenTSDB Authors.
 #
 # This library is free software: you can redistribute it and/or modify it
 # under the terms of the GNU Lesser General Public License as published
@@ -14,7 +14,7 @@
 # along with this library.  If not, see <http://www.gnu.org/licenses/>.
 
 # Semantic Versioning (see http://semver.org/).
-AC_INIT([opentsdb], [2.2.2], [opentsdb@googlegroups.com])
+AC_INIT([opentsdb], [2.3.0], [opentsdb@googlegroups.com])
 AC_CONFIG_AUX_DIR([build-aux])
 AM_INIT_AUTOMAKE([foreign])
 
@@ -24,6 +24,26 @@ AC_CONFIG_FILES([
 AC_CONFIG_FILES([opentsdb.spec])
 AC_CONFIG_FILES([build-aux/fetchdep.sh], [chmod +x build-aux/fetchdep.sh])
 
+AC_ARG_WITH([bigtable],
+            [AS_HELP_STRING([--with-bigtable], [Enable Google's Bigtable backend])],
+            [with_bigtable=yes],
+            [with_bigtable=no])
+
+AS_IF([test "x$with_bigtable" = "xyes"],
+  [AM_CONDITIONAL(BIGTABLE, true)],
+  [AM_CONDITIONAL(BIGTABLE, false)]
+)
+
+AC_ARG_WITH([cassandra],
+            [AS_HELP_STRING([--with-cassandra], [Enable Cassandra backend])],
+            [with_cassandra=yes],
+            [with_cassandra=no])
+
+AS_IF([test "x$with_cassandra" = "xyes"],
+  [AM_CONDITIONAL(CASSANDRA, true)],
+  [AM_CONDITIONAL(CASSANDRA, false)]
+)
+
 TSDB_FIND_PROG([md5], [md5sum md5 gmd5sum digest])
 if test x`basename "$MD5"` = x'digest'; then
   MD5='digest -a md5'
diff --git a/pom.xml.in b/pom.xml.in
index e18845d6cd..c44b692ff9 100644
--- a/pom.xml.in
+++ b/pom.xml.in
@@ -314,6 +314,28 @@
         </configuration>
       </plugin>
 
+      <plugin>
+        <groupId>com.helger.maven</groupId>
+        <artifactId>ph-javacc-maven-plugin</artifactId>
+        <version>2.8.0</version>
+        <executions>
+          <execution>
+            <id>jjc</id>
+            <phase>generate-sources</phase>
+            <goals>
+              <goal>javacc</goal>
+            </goals>
+            <configuration>
+              <jdkVersion>1.6</jdkVersion>
+              <javadocFriendlyComments>true</javadocFriendlyComments>
+              <packageName>net.opentsdb.query.expression.parser</packageName>
+              <sourceDirectory>${basedir}/src/</sourceDirectory>
+              <outputDirectory>${project.build.directory}/generated-sources/</outputDirectory>
+            </configuration>
+          </execution>
+        </executions>
+      </plugin>
+      
     </plugins>
   </build>
 
@@ -355,47 +377,29 @@
       <version>@SUASYNC_VERSION@</version>
     </dependency>
 
-    <dependency>
-      <groupId>org.apache.zookeeper</groupId>
-      <artifactId>zookeeper</artifactId>
-      <version>@ZOOKEEPER_VERSION@</version>
-      <exclusions>
-        <exclusion>
-          <groupId>log4j</groupId>
-          <artifactId>log4j</artifactId>
-        </exclusion>
-        <exclusion>
-          <groupId>org.slf4j</groupId>
-          <artifactId>slf4j-log4j12</artifactId>
-        </exclusion>
-        <exclusion>
-          <groupId>jline</groupId>
-          <artifactId>jline</artifactId>
-        </exclusion>
-        <exclusion>
-          <groupId>junit</groupId>
-          <artifactId>junit</artifactId>
-        </exclusion>
-      </exclusions>
-    </dependency>
-
     <dependency>
       <groupId>org.slf4j</groupId>
       <artifactId>slf4j-api</artifactId>
       <version>@SLF4J_API_VERSION@</version>
     </dependency>
 
-    <dependency>
-      <groupId>org.hbase</groupId>
-      <artifactId>asynchbase</artifactId>
-      <version>@ASYNCHBASE_VERSION@</version>
-    </dependency>
-
     <dependency>
       <groupId>org.apache.commons</groupId>
       <artifactId>commons-math3</artifactId>
       <version>@APACHE_MATH_VERSION@</version>
     </dependency>
+    
+    <dependency>
+      <groupId>org.apache.commons</groupId>
+      <artifactId>commons-jexl</artifactId>
+      <version>@JEXL_VERSION@</version>
+    </dependency>
+    
+    <dependency>
+      <groupId>org.jgrapht</groupId>
+      <artifactId>jgrapht-core</artifactId>
+      <version>@JGRAPHT_VERSION@</version>
+    </dependency>
 
     <!-- runtime dependencies -->
 
@@ -487,7 +491,85 @@
   <properties>
     <project.build.sourceEncoding>UTF-8</project.build.sourceEncoding>
   </properties>
-
+  
+  <profiles>
+    <profile>
+      <!-- Build for Apache HBase backend -->
+      <id>hbase</id>
+      <activation>
+        <activeByDefault>@maven_profile_hbase@</activeByDefault>
+      </activation>
+
+      <dependencies>
+        <dependency>
+          <groupId>org.hbase</groupId>
+          <artifactId>asynchbase</artifactId>
+          <version>@ASYNCHBASE_VERSION@</version>
+        </dependency>
+
+        <dependency>
+          <groupId>org.apache.zookeeper</groupId>
+          <artifactId>zookeeper</artifactId>
+          <version>@ZOOKEEPER_VERSION@</version>
+          <exclusions>
+            <exclusion>
+              <groupId>log4j</groupId>
+              <artifactId>log4j</artifactId>
+            </exclusion>
+            <exclusion>
+              <groupId>org.slf4j</groupId>
+              <artifactId>slf4j-log4j12</artifactId>
+            </exclusion>
+            <exclusion>
+              <groupId>jline</groupId>
+              <artifactId>jline</artifactId>
+            </exclusion>
+            <exclusion>
+              <groupId>junit</groupId>
+              <artifactId>junit</artifactId>
+            </exclusion>
+          </exclusions>
+        </dependency>
+      </dependencies>
+    </profile>
+
+    <profile>
+      <!-- Build for Google Bigtable backend -->
+      <id>bigtable</id>
+      <activation>
+        <activeByDefault>@maven_profile_bigtable@</activeByDefault>
+      </activation>
+
+      <dependencies>
+        <dependency>
+          <groupId>com.pythian.opentsdb</groupId>
+          <artifactId>asyncbigtable</artifactId>
+          <version>@ASYNCBIGTABLE_VERSION@</version>
+          <classifier>jar-with-dependencies</classifier>
+        </dependency>
+      </dependencies>
+
+    </profile>
+    
+    <profile>
+      <!-- Build for Apache Cassandra backend -->
+      <id>cassandra</id>
+      <activation>
+        <activeByDefault>@maven_profile_cassandra@</activeByDefault>
+      </activation>
+
+      <dependencies>
+        <dependency>
+          <groupId>net.opentsdb</groupId>
+          <artifactId>asynccassandra</artifactId>
+          <version>@ASYNCCASSANDRA_VERSION@</version>
+          <classifier>jar-with-dependencies</classifier>
+        </dependency>
+      </dependencies>
+
+    </profile>
+  </profiles>
+  
   <parent>
     <groupId>org.sonatype.oss</groupId>
     <artifactId>oss-parent</artifactId>
diff --git a/src/META-INF/MANIFEST.MF b/src/META-INF/MANIFEST.MF
new file mode 100644
index 0000000000..348f1bdd38
--- /dev/null
+++ b/src/META-INF/MANIFEST.MF
@@ -0,0 +1 @@
+Manifest-Version: 1.0
\ No newline at end of file
diff --git a/src/META-INF/services/net.opentsdb.uid.UniqueIdFilterPlugin b/src/META-INF/services/net.opentsdb.uid.UniqueIdFilterPlugin
new file mode 100644
index 0000000000..010e95484c
--- /dev/null
+++ b/src/META-INF/services/net.opentsdb.uid.UniqueIdFilterPlugin
@@ -0,0 +1 @@
+net.opentsdb.uid.UniqueIdWhitelistFilter
\ No newline at end of file
diff --git a/src/core/AggregationIterator.java b/src/core/AggregationIterator.java
index 28d77b9939..4c4a917c3d 100644
--- a/src/core/AggregationIterator.java
+++ b/src/core/AggregationIterator.java
@@ -115,7 +115,7 @@
  * to a special, really large value (too large to be a valid timestamp).
  * <p>
  */
-final class AggregationIterator implements SeekableView, DataPoint,
+public class AggregationIterator implements SeekableView, DataPoint,
                                            Aggregator.Longs, Aggregator.Doubles {
 
   private static final Logger LOG =
@@ -129,7 +129,7 @@ final class AggregationIterator implements SeekableView, DataPoint,
    * possibly store, provided that the most significant bit is reserved by
    * FLAG_FLOAT.
    */
-  private static final long TIME_MASK  = 0x7FFFFFFFFFFFFFFFL;
+  protected static final long TIME_MASK  = 0x7FFFFFFFFFFFFFFFL;
 
   /** Aggregator to use to aggregate data points from different Spans. */
   private final Aggregator aggregator;
@@ -148,13 +148,13 @@ final class AggregationIterator implements SeekableView, DataPoint,
    * Once we reach the end of a Span, we'll null out its iterator from this
    * array.
    */
-  private final SeekableView[] iterators;
+  protected final SeekableView[] iterators;
 
   /** Start time (UNIX timestamp in seconds or ms) on 32 bits ("unsigned" int). */
-  private final long start_time;
+  protected final long start_time;
 
   /** End time (UNIX timestamp in seconds or ms) on 32 bits ("unsigned" int). */
-  private final long end_time;
+  protected final long end_time;
 
   /**
    * The current and previous timestamps for the data points being used.
@@ -178,7 +178,7 @@ final class AggregationIterator implements SeekableView, DataPoint,
    * linear interpolation anymore.</li>
    * </ul>
    */
-  private final long[] timestamps; // 32 bit unsigned + flag
+  protected final long[] timestamps; // 32 bit unsigned + flag
 
   /**
    * The current and next values for the data points being used.
@@ -186,7 +186,7 @@ final class AggregationIterator implements SeekableView, DataPoint,
    * This array is also used to store floating point values, in which case
    * their binary representation just happens to be stored in a {@code long}.
    */
-  private final long[] values;
+  protected final long[] values;
 
   /** The index in {@link #iterators} of the current Span being used. */
   private int current;
@@ -277,6 +277,55 @@ public static AggregationIterator create(final List<Span> spans,
                                    method, rate);
   }
 
+  /**
+   * Creates a new iterator for a {@link SpanGroup}.
+   * @param spans Spans in a group.
+   * @param start_time Any data point strictly before this timestamp will be
+   * ignored.
+   * @param end_time Any data point strictly after this timestamp will be
+   * ignored.
+   * @param aggregator The aggregation function to use.
+   * @param method Interpolation method to use when aggregating time series
+   * @param downsampler The downsampling specifier to use (cannot be null)
+   * @param query_start Start of the actual query
+   * @param query_end End of the actual query
+   * @param rate If {@code true}, the rate of the series will be used instead
+   * of the actual values.
+   * @param rate_options Specifies the optional additional rate calculation
+   * options.
+   * @return an AggregationIterator
+   * @since 2.3
+   */
+  public static AggregationIterator create(final List<Span> spans,
+      final long start_time,
+      final long end_time,
+      final Aggregator aggregator,
+      final Interpolation method,
+      final DownsamplingSpecification downsampler,
+      final long query_start,
+      final long query_end,
+      final boolean rate,
+      final RateOptions rate_options) {
+    final int size = spans.size();
+    final SeekableView[] iterators = new SeekableView[size];
+    for (int i = 0; i < size; i++) {
+      SeekableView it;
+      if (downsampler == null || 
+          downsampler == DownsamplingSpecification.NO_DOWNSAMPLER) {
+        it = spans.get(i).spanIterator();
+      } else {
+        it = spans.get(i).downsampler(start_time, end_time, downsampler, 
+            query_start, query_end);
+      }
+      if (rate) {
+        it = new RateSpan(it, rate_options);
+      }
+      iterators[i] = it;
+    }
+    return new AggregationIterator(iterators, start_time, end_time, aggregator,
+    method, rate);  
+  }
+  
   /**
    * Creates an aggregation iterator for a group of data point iterators.
    * @param iterators An array of Seekable views of spans in a group. Ignored
@@ -290,7 +339,7 @@ public static AggregationIterator create(final List<Span> spans,
    * @param rate If {@code true}, the rate of the series will be used instead
    * of the actual values.
    */
-  private AggregationIterator(final SeekableView[] iterators,
+  public AggregationIterator(final SeekableView[] iterators,
                               final long start_time,
                               final long end_time,
                               final Aggregator aggregator,
diff --git a/src/core/Aggregator.java b/src/core/Aggregator.java
index baf1721b62..0b6a1a7818 100644
--- a/src/core/Aggregator.java
+++ b/src/core/Aggregator.java
@@ -92,14 +92,14 @@ public interface Doubles {
    * @param values The sequence to aggregate.
    * @return The aggregated value.
    */
-  abstract long runLong(Longs values);
+  public abstract long runLong(Longs values);
 
   /**
    * Aggregates a sequence of {@code double}s.
    * @param values The sequence to aggregate.
    * @return The aggregated value.
    */
-  abstract double runDouble(Doubles values);
+  public abstract double runDouble(Doubles values);
 
   /** 
    * Returns the interpolation method to use when working with data points
diff --git a/src/core/Aggregators.java b/src/core/Aggregators.java
index 5edb598aa7..ef1371bc68 100644
--- a/src/core/Aggregators.java
+++ b/src/core/Aggregators.java
@@ -15,6 +15,8 @@
 import java.util.HashMap;
 import java.util.NoSuchElementException;
 import java.util.Set;
+import java.util.Iterator;
+import java.util.LinkedList;
 
 import org.apache.commons.math3.stat.descriptive.rank.Percentile;
 import org.apache.commons.math3.stat.descriptive.rank.Percentile.EstimationType;
@@ -53,6 +55,14 @@ public enum Interpolation {
   public static final Aggregator AVG = new Avg(
       Interpolation.LERP, "avg");
 
+  /** Aggregator that skips aggregation/interpolation and/or downsampling. */
+  public static final Aggregator NONE = new None(Interpolation.ZIM, "raw");
+  
+  /** Return the product of two time series 
+   * @since 2.3 */
+  public static final Aggregator MULTIPLY = new Multiply(
+      Interpolation.LERP, "multiply");
+  
   /** Aggregator that returns the Standard Deviation of the data points. */
   public static final Aggregator DEV = new StdDev(
       Interpolation.LERP, "dev");
@@ -71,7 +81,7 @@ public enum Interpolation {
    * if timestamps don't line up instead of interpolating. */
   public static final Aggregator MIMMAX = new Max(
       Interpolation.MIN, "mimmax");
-  
+
   /** Aggregator that returns the number of data points.
    * WARNING: This currently interpolates with zero-if-missing. In this case 
    * counts will be off when counting multiple time series. Only use this when
@@ -79,6 +89,12 @@ public enum Interpolation {
    * @since 2.2 */
   public static final Aggregator COUNT = new Count(Interpolation.ZIM, "count");
 
+  /** Aggregator that returns the first data point. */
+  public static final Aggregator FIRST = new First(Interpolation.ZIM, "first");
+
+  /** Aggregator that returns the first data point. */
+  public static final Aggregator LAST = new Last(Interpolation.ZIM, "last");
+  
   /** Maps an aggregator name to its instance. */
   private static final HashMap<String, Aggregator> aggregators;
 
@@ -139,11 +155,15 @@ public enum Interpolation {
     aggregators.put("min", MIN);
     aggregators.put("max", MAX);
     aggregators.put("avg", AVG);
+    aggregators.put("none", NONE);
+    aggregators.put("mult", MULTIPLY);
     aggregators.put("dev", DEV);
     aggregators.put("count", COUNT);
     aggregators.put("zimsum", ZIMSUM);
     aggregators.put("mimmin", MIMMIN);
     aggregators.put("mimmax", MIMMAX);
+    aggregators.put("first", FIRST);
+    aggregators.put("last", LAST);
 
     PercentileAgg[] percentiles = {
        p999, p99, p95, p90, p75, p50, 
@@ -313,6 +333,62 @@ public double runDouble(final Doubles values) {
    
   }
 
+  /**
+   * An aggregator that isn't meant for aggregation. Paradoxical!!
+   * Really it's used as a flag to indicate that, during sorting and iteration,
+   * that the pipeline should not perform any aggregation and should emit 
+   * raw time series.
+   */
+  private static final class None extends Aggregator {
+    public None(final Interpolation method, final String name) {
+      super(method, name);
+    }
+    
+    @Override
+    public long runLong(final Longs values) {
+      final long v = values.nextLongValue();
+      if (values.hasNextValue()) {
+        throw new IllegalDataException("More than one value in aggregator " + values);
+      }
+      return v;
+    }
+    
+    @Override
+    public double runDouble(final Doubles values) {
+      final double v = values.nextDoubleValue();
+      if (values.hasNextValue()) {
+        throw new IllegalDataException("More than one value in aggregator " + values);
+      }
+      return v;
+    }
+  }
+  
+  private static final class Multiply extends Aggregator {
+    
+    public Multiply(final Interpolation method, final String name) {
+      super(method, name);
+    }
+
+    @Override
+    public long runLong(Longs values) {
+      long result = values.nextLongValue();
+      while (values.hasNextValue()) {
+        result *= values.nextLongValue();
+      }
+      return result;
+    }
+
+    @Override
+    public double runDouble(Doubles values) {
+      double result = values.nextDoubleValue();
+      while (values.hasNextValue()) {
+        result *= values.nextDoubleValue();
+      }
+      return result;
+    }
+    
+  }
+  
   /**
    * Standard Deviation aggregator.
    * Can compute without storing all of the data points in memory at the same
@@ -486,4 +562,148 @@ public double runDouble(final Doubles values) {
     }
 
   }
+  public static final class MovingAverage extends Aggregator {
+    private LinkedList<SumPoint> list = new LinkedList<SumPoint>();
+    private final long numPoints;
+    private final boolean isTimeUnit;
+
+    public MovingAverage(final Interpolation method, final String name, long numPoints, boolean isTimeUnit) {
+      super(method, name);
+      this.numPoints = numPoints;
+      this.isTimeUnit = isTimeUnit;
+    }
+
+    public long runLong(final Longs values) {
+      long sum = values.nextLongValue();
+      while (values.hasNextValue()) {
+        sum += values.nextLongValue();
+      }
+
+      if (values instanceof DataPoint) {
+        long ts = ((DataPoint) values).timestamp();
+        list.addFirst(new SumPoint(ts, sum));
+      }
+
+      long result = 0;
+      int count = 0;
+
+      Iterator<SumPoint> iter = list.iterator();
+      SumPoint first = iter.next();
+      boolean conditionMet = false;
+
+      // now sum up the preceeding points
+      while (iter.hasNext()) {
+        SumPoint next = iter.next();
+        result += (Long) next.val;
+        count++;
+        if (!isTimeUnit && count >= numPoints) {
+          conditionMet = true;
+          break;
+        } else if (isTimeUnit && ((first.ts - next.ts) > numPoints)) {
+          conditionMet = true;
+          break;
+        }
+      }
+
+      if (!conditionMet || count == 0) {
+        return 0;
+      }
+
+      return result / count;
+    }
+
+    @Override
+    public double runDouble(Doubles values) {
+      double sum = values.nextDoubleValue();
+      while (values.hasNextValue()) {
+        sum += values.nextDoubleValue();
+      }
+
+      if (values instanceof DataPoint) {
+        long ts = ((DataPoint) values).timestamp();
+        list.addFirst(new SumPoint(ts, sum));
+      }
+
+      double result = 0;
+      int count = 0;
+
+      Iterator<SumPoint> iter = list.iterator();
+      SumPoint first = iter.next();
+      boolean conditionMet = false;
+
+      // now sum up the preceeding points
+      while (iter.hasNext()) {
+        SumPoint next = iter.next();
+        result += (Double) next.val;
+        count++;
+        if (!isTimeUnit && count >= numPoints) {
+          conditionMet = true;
+          break;
+        } else if (isTimeUnit && ((first.ts - next.ts) > numPoints)) {
+          conditionMet = true;
+          break;
+        }
+      }
+
+      if (!conditionMet || count == 0) {
+        return 0;
+      }
+
+      return result / count;
+    }
+  
+    class SumPoint {
+      long ts;
+      Object val;
+
+      public SumPoint(long ts, Object val) {
+        this.ts = ts;
+        this.val = val;
+      }
+    }
+  }
+  
+  private static final class First extends Aggregator {
+    public First(final Interpolation method, final String name) {
+      super(method, name);
+    }
+    
+    public long runLong(final Longs values) {
+      long val = values.nextLongValue();
+      while (values.hasNextValue()) {
+    	  values.nextLongValue();
+      }
+      return val;
+    }
+
+    public double runDouble(final Doubles values) {
+      double val = values.nextDoubleValue();
+      while (values.hasNextValue()) {
+    	  values.nextDoubleValue();
+      }
+      return val;
+    }
+  }
+  
+  private static final class Last extends Aggregator {
+    public Last(final Interpolation method, final String name) {
+      super(method, name);
+    }
+    
+    public long runLong(final Longs values) {
+      long val = values.nextLongValue();
+      while (values.hasNextValue()) {
+        val = values.nextLongValue();
+      }
+      return val;
+    }
+
+    public double runDouble(final Doubles values) {
+      double val = values.nextDoubleValue();
+      while (values.hasNextValue()) {
+        val = values.nextDoubleValue();
+      }
+      return val;
+    }
+  }
 }
diff --git a/src/core/AppendDataPoints.java b/src/core/AppendDataPoints.java
index 8081a507c3..4647ff4b23 100644
--- a/src/core/AppendDataPoints.java
+++ b/src/core/AppendDataPoints.java
@@ -252,4 +252,9 @@ public byte[] value() {
   public Deferred<Object> repairedDeferred() {
     return repaired_deferred;
   }
+ 
+  /** @return whether or not a qualifier of AppendDataPoints */
+  public static boolean isAppendDataPoints(byte[] qualifier) {
+    return qualifier != null && qualifier.length == 3 && qualifier[0] == APPEND_COLUMN_PREFIX;
+  }
 }
diff --git a/src/core/BatchedDataPoints.java b/src/core/BatchedDataPoints.java
index c56143f234..e399802345 100644
--- a/src/core/BatchedDataPoints.java
+++ b/src/core/BatchedDataPoints.java
@@ -39,8 +39,8 @@ final class BatchedDataPoints implements WritableDataPoints {
   private final TSDB tsdb;
 
   /**
-   * The row key. 3 bytes for the metric name, 4 bytes for the base timestamp, 
-   * 6 bytes per tag (3 for the name, 3 for the value).
+   * The row key. Optional salt + 3 bytes for the metric name, 4 bytes for the 
+   * base timestamp, 6 bytes per tag (3 for the name, 3 for the value).
    */
   private byte[] row_key;
 
@@ -309,6 +309,12 @@ public Deferred<String> metricNameAsync() {
     return tsdb.metrics.getNameAsync(id);
   }
 
+  @Override
+  public byte[] metricUID() {
+    return Arrays.copyOfRange(row_key, Const.SALT_WIDTH(), 
+        Const.SALT_WIDTH() + TSDB.metrics_width());
+  }
+  
   @Override
   public Map<String, String> getTags() {
     try {
@@ -343,6 +349,11 @@ public Deferred<List<String>> getAggregatedTagsAsync() {
     return Deferred.fromResult(empty);
   }
 
+  @Override
+  public List<byte[]> getAggregatedTagUids() {
+    return Collections.emptyList();
+  }
+  
   @Override
   public List<String> getTSUIDs() {
     return Collections.emptyList();
diff --git a/src/core/Const.java b/src/core/Const.java
index d9f97c2aab..6369589354 100644
--- a/src/core/Const.java
+++ b/src/core/Const.java
@@ -12,6 +12,9 @@
 // see <http://www.gnu.org/licenses/>.
 package net.opentsdb.core;
 
+import java.nio.charset.Charset;
+import java.util.TimeZone;
+
 /** Constants used in various places.  */
 public final class Const {
 
@@ -38,7 +41,19 @@ static void setMaxNumTags(final short tags) {
     }
     MAX_NUM_TAGS = tags;
   }
-
+  
+  /** The default ASCII character set for encoding tables and qualifiers that
+   * don't depend on user input that may be encoded with UTF.
+   * Charset to use with our server-side row-filter.
+   * We use this one because it preserves every possible byte unchanged.
+   */
+  public static final Charset ASCII_CHARSET = Charset.forName("ISO-8859-1");
+  
+  /** Used for metrics, tags names and tag values */
+  public static final Charset UTF8_CHARSET = Charset.forName("UTF8");
+  
+  /** The UTC timezone used for rollup and calendar conversions */
+  public static final TimeZone UTC_TZ = TimeZone.getTimeZone("UTC");
 
   /** Number of LSBs in time_deltas reserved for flags.  */
   public static final short FLAG_BITS = 4;
diff --git a/src/core/DataPoints.java b/src/core/DataPoints.java
index cef3c69790..c9a4930992 100644
--- a/src/core/DataPoints.java
+++ b/src/core/DataPoints.java
@@ -38,6 +38,12 @@ public interface DataPoints extends Iterable<DataPoint> {
    * @since 1.2
    */
   Deferred<String> metricNameAsync();
+  
+  /**
+   * @return the metric UID
+   * @since 2.3
+   */
+  byte[] metricUID();
 
   /**
    * Returns the tags associated with these data points.
@@ -93,6 +99,13 @@ public interface DataPoints extends Iterable<DataPoint> {
    */
   Deferred<List<String>> getAggregatedTagsAsync();
 
+  /**
+   * Returns the tagk UIDs associated with some but not all of the data points. 
+   * @return a non-{@code null} list of tagk UIDs.
+   * @since 2.3
+   */
+  List<byte[]> getAggregatedTagUids();
+  
   /**
    * Returns a list of unique TSUIDs contained in the results
    * @return an empty list if there were no results, otherwise a list of TSUIDs
diff --git a/src/core/Downsampler.java b/src/core/Downsampler.java
index d4d56ff51d..004e768e33 100644
--- a/src/core/Downsampler.java
+++ b/src/core/Downsampler.java
@@ -12,34 +12,112 @@
 // see <http://www.gnu.org/licenses/>.
 package net.opentsdb.core;
 
+import java.util.Calendar;
 import java.util.NoSuchElementException;
 
+import net.opentsdb.utils.DateTime;
+
 /**
  * Iterator that downsamples data points using an {@link Aggregator}.
  */
 public class Downsampler implements SeekableView, DataPoint {
-
-  /** Function to use for downsampling. */
-  protected final Aggregator downsampler;
+  
+  /** Matches the weekly downsampler as it requires special handling. */
+  protected final static int WEEK_UNIT = DateTime.unitsToCalendarType("w");
+  protected final static int DAY_UNIT = DateTime.unitsToCalendarType("d");
+  protected final static int WEEK_LENGTH = 7;
+  
+  /** The downsampling specification when provided */
+  protected final DownsamplingSpecification specification;
+  
+  /** The start timestamp of the actual query for use with "all" */
+  protected final long query_start;
+  
+  /** The end timestamp of the actual query for use with "all" */
+  protected final long query_end;
+  
+  /** The data source */
+  protected final SeekableView source;
+  
   /** Iterator to iterate the values of the current interval. */
   protected final ValuesInInterval values_in_interval;
+  
   /** Last normalized timestamp */ 
   protected long timestamp;
+  
   /** Last value as a double */
   protected double value;
   
+  /** Whether or not to merge all DPs in the source into one vaalue */
+  protected final boolean run_all;
+  
+  /** The interval to use with a calendar */
+  protected final int interval;
+  
+  /** The unit to use with a calendar as a Calendar integer */
+  protected final int unit;
+  
   /**
    * Ctor.
    * @param source The iterator to access the underlying data.
    * @param interval_ms The interval in milli seconds wanted between each data
    * point.
    * @param downsampler The downsampling function to use.
+   * @deprecated as of 2.3
    */
   Downsampler(final SeekableView source,
               final long interval_ms,
               final Aggregator downsampler) {
-    this.values_in_interval = new ValuesInInterval(source, interval_ms);
-    this.downsampler = downsampler;
+    this.source = source;
+    if (downsampler == Aggregators.NONE) {
+      throw new IllegalArgumentException("cannot use the NONE "
+          + "aggregator for downsampling");
+    }
+    specification = new DownsamplingSpecification(interval_ms, downsampler, 
+        DownsamplingSpecification.DEFAULT_FILL_POLICY);
+    values_in_interval = new ValuesInInterval();
+    query_start = 0;
+    query_end = 0;
+    interval = unit = 0;
+    run_all = false;
+  }
+  
+  /**
+   * Ctor.
+   * @param source The iterator to access the underlying data.
+   * @param specification The downsampling spec to use
+   * @param query_start The start timestamp of the actual query for use with "all"
+   * @param query_end The end timestamp of the actual query for use with "all"
+   * @since 2.3
+   */
+  Downsampler(final SeekableView source,
+              final DownsamplingSpecification specification,
+              final long query_start,
+              final long query_end
+      ) {
+    this.source = source;
+    this.specification = specification;
+    values_in_interval = new ValuesInInterval();
+    this.query_start = query_start;
+    this.query_end = query_end;
+    
+    final String s = specification.getStringInterval();
+    if (s != null && s.toLowerCase().contains("all")) {
+      run_all = true;
+      interval = unit = 0;
+    } else if (s != null && specification.useCalendar()) {
+      if (s.toLowerCase().contains("ms")) {
+        interval = Integer.parseInt(s.substring(0, s.length() - 2));
+        unit = DateTime.unitsToCalendarType(s.substring(s.length() - 2));
+      } else {
+        interval = Integer.parseInt(s.substring(0, s.length() - 1));
+        unit = DateTime.unitsToCalendarType(s.substring(s.length() - 1));
+      }
+      run_all = false;
+    } else {
+      run_all = false;
+      interval = unit = 0;
+    }
   }
 
   // ------------------ //
@@ -57,7 +135,7 @@ public boolean hasNext() {
   @Override
   public DataPoint next() {
     if (hasNext()) {
-      value = downsampler.runDouble(values_in_interval);
+      value = specification.getFunction().runDouble(values_in_interval);
       timestamp = values_in_interval.getIntervalTimestamp();
       values_in_interval.moveToNextInterval();
       return this;
@@ -85,6 +163,9 @@ public void seek(final long timestamp) {
 
   @Override
   public long timestamp() {
+    if (run_all) {
+      return query_start;
+    }
     return timestamp;
   }
 
@@ -112,8 +193,10 @@ public double toDouble() {
   public String toString() {
     final StringBuilder buf = new StringBuilder();
     buf.append("Downsampler: ")
-       .append("interval_ms=").append(values_in_interval.interval_ms)
-       .append(", downsampler=").append(downsampler)
+       .append(", downsampler=").append(specification)
+       .append(", queryStart=").append(query_start)
+       .append(", queryEnd=").append(query_end)
+       .append(", runAll=").append(run_all)
        .append(", current data=(timestamp=").append(timestamp)
        .append(", value=").append(value)
        .append("), values_in_interval=").append(values_in_interval);
@@ -121,16 +204,20 @@ public String toString() {
   }
 
   /** Iterates source values for an interval. */
-  protected static class ValuesInInterval implements Aggregator.Doubles {
+  protected class ValuesInInterval implements Aggregator.Doubles {
 
-    /** The iterator of original source values. */
-    private final SeekableView source;
-    /** The sampling interval in milliseconds. */
-    protected final long interval_ms;
+    /** An optional calendar set to the current timestamp for the data point */
+    private Calendar previous_calendar;
+    
+    /** An optional calendar set to the end of the interval timestamp */
+    private Calendar next_calendar;
+    
     /** The end of the current interval. */
     private long timestamp_end_interval = Long.MIN_VALUE;
+    
     /** True if the last value was successfully extracted from the source. */
     private boolean has_next_value_from_source = false;
+    
     /** The last data point extracted from the source. */
     private DataPoint next_dp = null;
 
@@ -139,13 +226,13 @@ protected static class ValuesInInterval implements Aggregator.Doubles {
 
     /**
      * Constructor.
-     * @param source The iterator to access the underlying data.
-     * @param interval_ms Downsampling interval.
      */
-    ValuesInInterval(final SeekableView source, final long interval_ms) {
-      this.source = source;
-      this.interval_ms = interval_ms;
-      this.timestamp_end_interval = interval_ms;
+    protected ValuesInInterval() {
+      if (run_all) {
+        timestamp_end_interval = query_end;
+      } else if (!specification.useCalendar()) {
+        timestamp_end_interval = specification.getInterval();
+      }
     }
 
     /** Initializes to iterate intervals. */
@@ -155,8 +242,26 @@ protected void initializeIfNotDone() {
       // performance penalty by accessing the unnecessary first data of a span.
       if (!initialized) {
         initialized = true;
-        moveToNextValue();
-        resetEndOfInterval();
+        if (source.hasNext()) {
+          moveToNextValue();
+          if (!run_all) {
+            if (specification.useCalendar()) {
+              previous_calendar = DateTime.previousInterval(next_dp.timestamp(), 
+                  interval, unit, specification.getTimezone());
+              next_calendar = DateTime.previousInterval(next_dp.timestamp(), 
+                  interval, unit, specification.getTimezone());
+              if (unit == WEEK_UNIT) {
+                next_calendar.add(DAY_UNIT, interval * WEEK_LENGTH);
+              } else {
+                next_calendar.add(unit, interval);
+              }
+              timestamp_end_interval = next_calendar.getTimeInMillis();
+            } else {
+              timestamp_end_interval = alignTimestamp(next_dp.timestamp()) + 
+                  specification.getInterval();
+            }
+          }
+        }
       }
     }
 
@@ -164,7 +269,25 @@ protected void initializeIfNotDone() {
     private void moveToNextValue() {
       if (source.hasNext()) {
         has_next_value_from_source = true;
-        next_dp = source.next();
+        // filter out dps that don't match start and end for run_alls
+        if (run_all) {
+          while (source.hasNext()) {
+            next_dp = source.next();
+            if (next_dp.timestamp() < query_start) {
+              next_dp = null;
+              continue;
+            }
+            if (next_dp.timestamp() >= query_end) {
+              has_next_value_from_source = false;
+            }
+            break;
+          }
+          if (next_dp == null) {
+            has_next_value_from_source = false;
+          }
+        } else {
+          next_dp = source.next();
+        }
       } else {
         has_next_value_from_source = false;
       }
@@ -175,10 +298,22 @@ private void moveToNextValue() {
      * the next value read from source. It is the first value of the next
      * interval. */
     private void resetEndOfInterval() {
-      if (has_next_value_from_source) {
-        // Sets the end of the interval of the timestamp.
-        timestamp_end_interval = alignTimestamp(next_dp.timestamp()) + 
-            interval_ms;
+      if (has_next_value_from_source && !run_all) {
+        if (specification.useCalendar()) {
+          while (next_dp.timestamp() >= timestamp_end_interval) {
+            if (unit == WEEK_UNIT) {
+              previous_calendar.add(DAY_UNIT, interval * WEEK_LENGTH);
+              next_calendar.add(DAY_UNIT, interval * WEEK_LENGTH);
+            } else {
+              previous_calendar.add(unit, interval);
+              next_calendar.add(unit, interval);
+            }
+            timestamp_end_interval = next_calendar.getTimeInMillis();
+          }
+        } else {
+          timestamp_end_interval = alignTimestamp(next_dp.timestamp()) + 
+              specification.getInterval();
+        }
       }
     }
 
@@ -194,7 +329,22 @@ void seekInterval(final long timestamp) {
       // rounds up the seeking timestamp to the smallest timestamp that is
       // a multiple of the interval and is greater than or equal to the given
       // timestamp..
-      source.seek(alignTimestamp(timestamp + interval_ms - 1));
+      if (run_all) {
+        source.seek(timestamp);
+      } else if (specification.useCalendar()) {
+        final Calendar seek_calendar = DateTime.previousInterval(
+            timestamp, interval, unit, specification.getTimezone());
+        if (timestamp > seek_calendar.getTimeInMillis()) {
+          if (unit == WEEK_UNIT) {
+            seek_calendar.add(DAY_UNIT, interval * WEEK_LENGTH);
+          } else {
+            seek_calendar.add(unit, interval);
+          }
+        }
+        source.seek(seek_calendar.getTimeInMillis());
+      } else {
+        source.seek(alignTimestamp(timestamp + specification.getInterval() - 1));
+      }
       initialized = false;
     }
 
@@ -203,14 +353,21 @@ protected long getIntervalTimestamp() {
       // NOTE: It is well-known practice taking the start time of
       // a downsample interval as a representative timestamp of it. It also
       // provides the correct context for seek.
-      return alignTimestamp(timestamp_end_interval - interval_ms);
+      if (run_all) {
+        return timestamp_end_interval;
+      } else if (specification.useCalendar()) {
+        return previous_calendar.getTimeInMillis();
+      } else {
+        return alignTimestamp(timestamp_end_interval - 
+            specification.getInterval());
+      }
     }
 
     /** Returns timestamp aligned by interval. */
     protected long alignTimestamp(final long timestamp) {
-      return timestamp - (timestamp % interval_ms);
+      return timestamp - (timestamp % specification.getInterval());
     }
-
+    
     // ---------------------- //
     // Doubles interface //
     // ---------------------- //
@@ -218,6 +375,9 @@ protected long alignTimestamp(final long timestamp) {
     @Override
     public boolean hasNextValue() {
       initializeIfNotDone();
+      if (run_all) {
+        return has_next_value_from_source;
+      }
       return has_next_value_from_source &&
           next_dp.timestamp() < timestamp_end_interval;
     }
@@ -237,10 +397,13 @@ public double nextDoubleValue() {
     public String toString() {
       final StringBuilder buf = new StringBuilder();
       buf.append("ValuesInInterval: ")
-         .append("interval_ms=").append(interval_ms)
          .append(", timestamp_end_interval=").append(timestamp_end_interval)
          .append(", has_next_value_from_source=")
-         .append(has_next_value_from_source);
+         .append(has_next_value_from_source)
+         .append(", previousCalendar=")
+         .append(previous_calendar == null ? "null" : previous_calendar)
+         .append(", nextCalendar=")
+         .append(next_calendar == null ? "null" : next_calendar);
       if (has_next_value_from_source) {
         buf.append(", nextValue=(").append(next_dp).append(')');
       }
diff --git a/src/core/DownsamplingSpecification.java b/src/core/DownsamplingSpecification.java
index 3f590d20f0..b64cceb157 100644
--- a/src/core/DownsamplingSpecification.java
+++ b/src/core/DownsamplingSpecification.java
@@ -13,6 +13,7 @@
 package net.opentsdb.core;
 
 import java.util.NoSuchElementException;
+import java.util.TimeZone;
 
 import com.google.common.base.MoreObjects;
 import net.opentsdb.utils.DateTime;
@@ -37,12 +38,21 @@ public final class DownsamplingSpecification {
 
   // Parsed downsample interval.
   private final long interval;
-
+  
+  //The string interval, e.g. 1h, 30d, etc
+  private final String string_interval;
+  
   // Parsed downsampler function.
   private final Aggregator function;
   
   // Parsed fill policy: whether to interpolate or to fill.
   private final FillPolicy fill_policy;
+  
+  // Whether or not to use the calendar for intervals
+  private boolean use_calendar;
+ 
+  // The user provided timezone for calendar alignment (defaults to UTC)
+  private TimeZone timezone;
 
   /**
    * A specification indicating no downsampling is requested.
@@ -51,6 +61,9 @@ private DownsamplingSpecification() {
     interval = NO_INTERVAL;
     function = NO_FUNCTION;
     fill_policy = DEFAULT_FILL_POLICY;
+    string_interval = null;
+    use_calendar = false;
+    timezone = DateTime.timezones.get(DateTime.UTC_ID);
   }
 
   /**
@@ -59,6 +72,7 @@ private DownsamplingSpecification() {
    * @param function The downsampling function.
    * @param fill_policy The policy specifying how to deal with missing data.
    * @throws IllegalArgumentException if any argument is invalid.
+   * @deprecated since 2.3
    */
   public DownsamplingSpecification(final long interval,
       final Aggregator function, final FillPolicy fill_policy) {
@@ -71,16 +85,25 @@ public DownsamplingSpecification(final long interval,
     if (null == fill_policy) {
       throw new IllegalArgumentException("fill policy cannot be null");
     }
+    if (function == Aggregators.NONE) {
+      throw new IllegalArgumentException("cannot use the NONE "
+          + "aggregator for downsampling");
+    }
 
     this.interval = interval;
     this.function = function;
     this.fill_policy = fill_policy;
+    string_interval = null;
+    use_calendar = false;
+    timezone = DateTime.timezones.get(DateTime.UTC_ID);
   }
 
   /**
    * C-tor for string representations.
    * The argument to this c-tor should have the following format:
    * {@code interval-function[-fill_policy]}.
+   * This ctor supports the "all" flag to downsample to a single value as well
+   * as units suffixed with 'c' to use the calendar for downsample alignment.
    * @param specification String representation of a downsample specifier.
    * @throws IllegalArgumentException if the specification is null or invalid.
    */
@@ -106,7 +129,20 @@ public DownsamplingSpecification(final String specification) {
 
     // INTERVAL.
     // This will throw if interval is invalid.
-    interval = DateTime.parseDuration(parts[0]);
+    if (parts[0].contains("all")) {
+      interval = NO_INTERVAL;
+      use_calendar = false;
+      string_interval = parts[0];
+    } else if (parts[0].charAt(parts[0].length() - 1) == 'c') {
+      final String duration = parts[0].substring(0, parts[0].length() - 1);
+      interval = DateTime.parseDuration(duration);
+      string_interval = duration;
+      use_calendar = true;
+    } else {
+      interval = DateTime.parseDuration(parts[0]);
+      use_calendar = false;
+      string_interval = parts[0];
+    }
 
     // FUNCTION.
     try {
@@ -115,6 +151,10 @@ public DownsamplingSpecification(final String specification) {
       throw new IllegalArgumentException("No such downsampling function: " +
         parts[1]);
     }
+    if (function == Aggregators.NONE) {
+      throw new IllegalArgumentException("cannot use the NONE "
+          + "aggregator for downsampling");
+    }
 
     // FILL POLICY.
     if (3 == parts.length) {
@@ -135,8 +175,25 @@ public DownsamplingSpecification(final String specification) {
       // Default to linear interpolation.
       fill_policy = FillPolicy.NONE;
     }
+    timezone = DateTime.timezones.get(DateTime.UTC_ID);
   }
 
+  /** @param use_calendar Whether or not to use the calendar when downsampling 
+   * @since 2.3 */
+  public void setUseCalendar(final boolean use_calendar) {
+    this.use_calendar = use_calendar;
+  }
+  
+  /** @param timezone The timezone to use when downsampling on calendar 
+   * boundaries.
+   * @since 2.3 */
+  public void setTimezone(final TimeZone timezone) {
+    if (timezone == null) {
+      throw new IllegalArgumentException("Timezone cannot be null");
+    }
+    this.timezone = timezone;
+  }
+  
   /**
    * Get the downsampling interval, in milliseconds.
    * @return the downsampling interval, in milliseconds.
@@ -145,6 +202,12 @@ public long getInterval() {
     return interval;
   }
 
+  /** @return The string interval from the user (without the 'c' if given) 
+   * @since 2.3 */
+  public String getStringInterval() {
+    return string_interval;
+  }
+  
   /**
    * Get the downsampling function.
    * @return the downsampling function.
@@ -161,12 +224,27 @@ public FillPolicy getFillPolicy() {
     return fill_policy;
   }
 
+  /** @return Whether or not to use the calendar when downsampling 
+   * @since 2.3 */
+  public boolean useCalendar() {
+    return use_calendar;
+  }
+  
+  /** @return The timezone to use when downsampling on calendar boundaries.
+   * @since 2.3 */
+  public TimeZone getTimezone() {
+    return timezone;
+  }
+  
   @Override
   public String toString() {
     return MoreObjects.toStringHelper(this)
       .add("interval", getInterval())
       .add("function", getFunction())
       .add("fillPolicy", getFillPolicy())
+      .add("stringInterval", string_interval)
+      .add("useCalendar", useCalendar())
+      .add("timeZone", getTimezone() != null ? getTimezone().getID() : null)
       .toString();
   }
 }
diff --git a/src/core/FillPolicy.java b/src/core/FillPolicy.java
index 7cba9bc5d9..09c145f284 100644
--- a/src/core/FillPolicy.java
+++ b/src/core/FillPolicy.java
@@ -12,6 +12,9 @@
 // see <http://www.gnu.org/licenses/>.
 package net.opentsdb.core;
 
+import com.fasterxml.jackson.annotation.JsonCreator;
+import com.fasterxml.jackson.annotation.JsonValue;
+
 /**
  * Specification of how to deal with missing intervals when downsampling.
  * @since 2.2
@@ -20,7 +23,8 @@ public enum FillPolicy {
   NONE("none"),
   ZERO("zero"),
   NOT_A_NUMBER("nan"),
-  NULL("null");
+  NULL("null"),
+  SCALAR("scalar");
 
   // The user-friendly name of this policy.
   private final String name;
@@ -33,6 +37,7 @@ public enum FillPolicy {
    * Get this fill policy's user-friendly name.
    * @return this fill policy's user-friendly name.
    */
+  @JsonValue
   public String getName() {
     return name;
   }
@@ -42,7 +47,9 @@ public String getName() {
    * @param name The user-friendly name of a fill policy.
    * @return an instance of {@link FillPolicy}, or {@code null} if the name
    * does not match any instance.
+   * @throws IllegalArgumentException if the name doesn't match a policy
    */
+  @JsonCreator
   public static FillPolicy fromString(final String name) {
     for (final FillPolicy policy : FillPolicy.values()) {
       if (policy.name.equalsIgnoreCase(name)) {
@@ -50,7 +57,7 @@ public static FillPolicy fromString(final String name) {
       }
     }
 
-    return null;
+    throw new IllegalArgumentException("Unrecognized fill policy: " + name);
   }
 }
 
diff --git a/src/core/FillingDownsampler.java b/src/core/FillingDownsampler.java
index 0e4d77ad10..bd47205bf8 100644
--- a/src/core/FillingDownsampler.java
+++ b/src/core/FillingDownsampler.java
@@ -12,8 +12,11 @@
 // see <http://www.gnu.org/licenses/>.
 package net.opentsdb.core;
 
+import java.util.Calendar;
 import java.util.NoSuchElementException;
 
+import net.opentsdb.utils.DateTime;
+
 /**
  * A specialized downsampler that returns special values, based on the fill
  * policy, for intervals for which no data could be found. The default
@@ -25,9 +28,12 @@
 public class FillingDownsampler extends Downsampler {
   /** Track when the downsampled data should end. */
   protected long end_timestamp;
-
-  /** Downsampling fill policy. */
-  protected final FillPolicy fill_policy;
+  
+  /** An optional calendar set to the current timestamp for the data point */
+  private final Calendar previous_calendar;
+  
+  /** An optional calendar set to the end of the interval timestamp */
+  private final Calendar next_calendar;
 
   /** 
    * Create a new nulling downsampler.
@@ -40,24 +46,75 @@ public class FillingDownsampler extends Downsampler {
    * @param fill_policy Policy specifying whether to interpolate or to fill
    * missing intervals with special values.
    * @throws IllegalArgumentException if fill_policy is interpolation.
+   * @deprecated as of 2.3
    */
   FillingDownsampler(final SeekableView source, final long start_time,
       final long end_time, final long interval_ms,
       final Aggregator downsampler, final FillPolicy fill_policy) {
+    this(source, start_time, end_time, 
+        new DownsamplingSpecification(interval_ms, downsampler, fill_policy)
+        , 0, 0);
+  }
+  
+  /** 
+   * Create a new filling downsampler.
+   * @param source The iterator to access the underlying data.
+   * @param start_time The time in milliseconds at which the data begins.
+   * @param end_time The time in milliseconds at which the data ends.
+   * @param specification The downsampling spec to use
+   * @param query_start The start timestamp of the actual query for use with "all"
+   * @param query_end The end timestamp of the actual query for use with "all"
+   * @throws IllegalArgumentException if fill_policy is interpolation.
+   * @since 2.3
+   */
+  FillingDownsampler(final SeekableView source, final long start_time,
+      final long end_time, final DownsamplingSpecification specification, 
+      final long query_start, final long end_start) {
     // Lean on the superclass implementation.
-    super(source, interval_ms, downsampler);
+    super(source, specification, query_start, end_start);
 
     // Ensure we aren't given a bogus fill policy.
-    if (FillPolicy.NONE == fill_policy) {
+    if (FillPolicy.NONE == specification.getFillPolicy()) {
       throw new IllegalArgumentException("Cannot instantiate this class with" +
         " linear-interpolation fill policy");
     }
-    this.fill_policy = fill_policy;
-
+    
     // Use the values-in-interval object to align the timestamps at which we
     // expect data to arrive for the first and last intervals.
-    this.timestamp = values_in_interval.alignTimestamp(start_time);
-    this.end_timestamp = values_in_interval.alignTimestamp(end_time);
+    if (run_all) {
+      timestamp = start_time;
+      end_timestamp = end_time;
+      previous_calendar = next_calendar = null;
+    } else if (specification.useCalendar()) {
+      previous_calendar = DateTime.previousInterval(start_time, interval, unit, 
+          specification.getTimezone());
+      if (unit == WEEK_UNIT) {
+        previous_calendar.add(DAY_UNIT, -(interval * WEEK_LENGTH));
+      } else {
+        previous_calendar.add(unit, -interval);
+      }
+      next_calendar = DateTime.previousInterval(start_time, interval, unit, 
+          specification.getTimezone());
+      
+      final Calendar end_calendar = DateTime.previousInterval(
+          end_time, interval, unit, specification.getTimezone());
+      if (end_calendar.getTimeInMillis() == next_calendar.getTimeInMillis()) {
+        // advance once
+        if (unit == WEEK_UNIT) {
+          end_calendar.add(DAY_UNIT, interval * WEEK_LENGTH);
+        } else {
+          end_calendar.add(unit, interval);
+        }
+      }
+      timestamp = next_calendar.getTimeInMillis();
+      end_timestamp = end_calendar.getTimeInMillis();
+    } else {
+      // Use the values-in-interval object to align the timestamps at which we
+      // expect data to arrive for the first and last intervals.
+      timestamp = values_in_interval.alignTimestamp(start_time);
+      end_timestamp = values_in_interval.alignTimestamp(end_time);
+      previous_calendar = next_calendar = null;
+    }
   }
 
   /**
@@ -72,6 +129,9 @@ public boolean hasNext() {
     // No matter the state of the values-in-interval object, if our current
     // timestamp hasn't reached the end of the requested overall interval, then
     // we still have iterating to do.
+    if (run_all) {
+      return values_in_interval.hasNextValue();
+    }
     return timestamp < end_timestamp;
   }
 
@@ -91,27 +151,30 @@ public DataPoint next() {
       values_in_interval.initializeIfNotDone();
 
       // Skip any leading data outside the query bounds.
-      long actual = values_in_interval.getIntervalTimestamp();
-      while (values_in_interval.hasNextValue() && actual < timestamp) {
+      long actual = values_in_interval.hasNextValue() ? 
+          values_in_interval.getIntervalTimestamp() : Long.MAX_VALUE;
+      
+      while (!run_all && values_in_interval.hasNextValue() 
+          && actual < timestamp) {
         // The actual timestamp precedes our expected, so there's data in the
         // values-in-interval object that we wish to ignore.
-        downsampler.runDouble(values_in_interval);
+        specification.getFunction().runDouble(values_in_interval);
         values_in_interval.moveToNextInterval();
         actual = values_in_interval.getIntervalTimestamp();
       }
 
       // Check whether the timestamp of the calculation interval matches what
       // we expect.
-      if (actual == timestamp) {
+      if (run_all || actual == timestamp) {
         // The calculated interval timestamp matches what we expect, so we can
         // do normal processing.
-        value = downsampler.runDouble(values_in_interval);
+        value = specification.getFunction().runDouble(values_in_interval);
         values_in_interval.moveToNextInterval();
       } else {
         // Our expected timestamp precedes the actual, so the interval is
         // missing. We will use a special value, based on the fill policy, to
         // represent this case.
-        switch (fill_policy) {
+        switch (specification.getFillPolicy()) {
         case NOT_A_NUMBER:
         case NULL:
           value = Double.NaN;
@@ -127,7 +190,20 @@ public DataPoint next() {
       }
 
       // Advance the expected timestamp to the next interval.
-      timestamp += values_in_interval.interval_ms;
+      if (!run_all) {
+        if (specification.useCalendar()) {
+          if (unit == WEEK_UNIT) {
+            previous_calendar.add(DAY_UNIT, interval * WEEK_LENGTH);
+            next_calendar.add(DAY_UNIT, interval * WEEK_LENGTH);
+          } else {
+            previous_calendar.add(unit, interval);
+            next_calendar.add(unit, interval);
+          }
+          timestamp = next_calendar.getTimeInMillis();
+        } else {
+          timestamp += specification.getInterval();
+        }
+      }
 
       // This object also represents the data.
       return this;
@@ -140,7 +216,12 @@ public DataPoint next() {
 
   @Override
   public long timestamp() {
-    return timestamp - values_in_interval.interval_ms;
+    if (run_all) {
+      return query_start;
+    } else if (specification.useCalendar()) {
+      return previous_calendar.getTimeInMillis();
+    }
+    return timestamp - specification.getInterval();
   }
 }
 
diff --git a/src/core/IncomingDataPoints.java b/src/core/IncomingDataPoints.java
index b253b6f536..6f6245b780 100644
--- a/src/core/IncomingDataPoints.java
+++ b/src/core/IncomingDataPoints.java
@@ -49,8 +49,8 @@ final class IncomingDataPoints implements WritableDataPoints {
   private final TSDB tsdb;
 
   /**
-   * The row key. 3 bytes for the metric name, 4 bytes for the base timestamp, 6
-   * bytes per tag (3 for the name, 3 for the value).
+   * The row key. Optional salt + 3 bytes for the metric name, 4 bytes for 
+   * the base timestamp, 6 bytes per tag (3 for the name, 3 for the value).
    */
   private byte[] row;
 
@@ -73,6 +73,12 @@ final class IncomingDataPoints implements WritableDataPoints {
 
   /** Are we doing a batch import? */
   private boolean batch_import;
+  
+  /** The metric for this time series */
+  private String metric;
+  
+  /** Copy of the tags given us by the caller */
+  private Map<String, String> tags;
 
   /**
    * Constructor.
@@ -163,7 +169,7 @@ static Deferred<byte[]> rowKeyTemplateAsync(final TSDB tsdb,
     // Lookup or create the metric ID.
     final Deferred<byte[]> metric_id;
     if (tsdb.config.auto_metric()) {
-      metric_id = tsdb.metrics.getOrCreateIdAsync(metric);
+      metric_id = tsdb.metrics.getOrCreateIdAsync(metric, metric, tags);
     } else {
       metric_id = tsdb.metrics.getIdAsync(metric);
     }
@@ -193,8 +199,8 @@ public Deferred<byte[]> call(final ArrayList<byte[]> tags) {
     }
 
     // Kick off the resolution of all tags.
-    return Tags.resolveOrCreateAllAsync(tsdb, tags).addCallbackDeferring(
-        new CopyTagsInRowKeyCB());
+    return Tags.resolveOrCreateAllAsync(tsdb, metric, tags)
+        .addCallbackDeferring(new CopyTagsInRowKeyCB());
   }
 
   public void setSeries(final String metric, final Map<String, String> tags) {
@@ -207,6 +213,8 @@ public void setSeries(final String metric, final Map<String, String> tags) {
     } catch (Exception e) {
       throw new RuntimeException("Should never happen", e);
     }
+    this.metric = metric;
+    this.tags = tags;
     size = 0;
   }
 
@@ -281,57 +289,80 @@ private Deferred<Object> addPointInternal(final long timestamp,
           + " when trying to add value=" + Arrays.toString(value) + " to "
           + this);
     }
-    last_ts = (ms_timestamp ? timestamp : timestamp * 1000);
+    
+    /** Callback executed for chaining filter calls to see if the value
+     * should be written or not. */
+    final class WriteCB implements Callback<Deferred<Object>, Boolean> {
+      @Override
+      public Deferred<Object> call(final Boolean allowed) throws Exception {
+        if (!allowed) {
+          return Deferred.fromResult(null);
+        }
+        
 
-    long base_time = baseTime();
-    long incoming_base_time;
-    if (ms_timestamp) {
-      // drop the ms timestamp to seconds to calculate the base timestamp
-      incoming_base_time = ((timestamp / 1000) - ((timestamp / 1000) % Const.MAX_TIMESPAN));
-    } else {
-      incoming_base_time = (timestamp - (timestamp % Const.MAX_TIMESPAN));
-    }
+        last_ts = (ms_timestamp ? timestamp : timestamp * 1000);
 
-    if (incoming_base_time - base_time >= Const.MAX_TIMESPAN) {
-      // Need to start a new row as we've exceeded Const.MAX_TIMESPAN.
-      base_time = updateBaseTime((ms_timestamp ? timestamp / 1000 : timestamp));
-    }
+        long base_time = baseTime();
+        long incoming_base_time;
+        if (ms_timestamp) {
+          // drop the ms timestamp to seconds to calculate the base timestamp
+          incoming_base_time = ((timestamp / 1000) - ((timestamp / 1000) % Const.MAX_TIMESPAN));
+        } else {
+          incoming_base_time = (timestamp - (timestamp % Const.MAX_TIMESPAN));
+        }
 
-    // Java is so stupid with its auto-promotion of int to float.
-    final byte[] qualifier = Internal.buildQualifier(timestamp, flags);
-
-    // TODO(tsuna): The following timing is rather useless. First of all,
-    // the histogram never resets, so it tends to converge to a certain
-    // distribution and never changes. What we really want is a moving
-    // histogram so we can see how the latency distribution varies over time.
-    // The other problem is that the Histogram class isn't thread-safe and
-    // here we access it from a callback that runs in an unknown thread, so
-    // we might miss some increments. So let's comment this out until we
-    // have a proper thread-safe moving histogram.
-    // final long start_put = System.nanoTime();
-    // final Callback<Object, Object> cb = new Callback<Object, Object>() {
-    // public Object call(final Object arg) {
-    // putlatency.add((int) ((System.nanoTime() - start_put) / 1000000));
-    // return arg;
-    // }
-    // public String toString() {
-    // return "time put request";
-    // }
-    // };
-
-    // TODO(tsuna): Add an errback to handle some error cases here.
-    if (tsdb.getConfig().enable_appends()) {
-      final AppendDataPoints kv = new AppendDataPoints(qualifier, value);
-      final AppendRequest point = new AppendRequest(tsdb.table, row, TSDB.FAMILY, 
-          AppendDataPoints.APPEND_COLUMN_QUALIFIER, kv.getBytes());
-      point.setDurable(!batch_import);
-      return tsdb.client.append(point);/* .addBoth(cb) */
-    } else {
-      final PutRequest point = new PutRequest(tsdb.table, row, TSDB.FAMILY, 
-          qualifier, value);
-      point.setDurable(!batch_import);
-      return tsdb.client.put(point)/* .addBoth(cb) */;
+        if (incoming_base_time - base_time >= Const.MAX_TIMESPAN) {
+          // Need to start a new row as we've exceeded Const.MAX_TIMESPAN.
+          base_time = updateBaseTime((ms_timestamp ? timestamp / 1000 : timestamp));
+        }
+
+        // Java is so stupid with its auto-promotion of int to float.
+        final byte[] qualifier = Internal.buildQualifier(timestamp, flags);
+
+        // TODO(tsuna): The following timing is rather useless. First of all,
+        // the histogram never resets, so it tends to converge to a certain
+        // distribution and never changes. What we really want is a moving
+        // histogram so we can see how the latency distribution varies over time.
+        // The other problem is that the Histogram class isn't thread-safe and
+        // here we access it from a callback that runs in an unknown thread, so
+        // we might miss some increments. So let's comment this out until we
+        // have a proper thread-safe moving histogram.
+        // final long start_put = System.nanoTime();
+        // final Callback<Object, Object> cb = new Callback<Object, Object>() {
+        // public Object call(final Object arg) {
+        // putlatency.add((int) ((System.nanoTime() - start_put) / 1000000));
+        // return arg;
+        // }
+        // public String toString() {
+        // return "time put request";
+        // }
+        // };
+
+        // TODO(tsuna): Add an errback to handle some error cases here.
+        if (tsdb.getConfig().enable_appends()) {
+          final AppendDataPoints kv = new AppendDataPoints(qualifier, value);
+          final AppendRequest point = new AppendRequest(tsdb.table, row, TSDB.FAMILY, 
+              AppendDataPoints.APPEND_COLUMN_QUALIFIER, kv.getBytes());
+          point.setDurable(!batch_import);
+          return tsdb.client.append(point);/* .addBoth(cb) */
+        } else {
+          final PutRequest point = new PutRequest(tsdb.table, row, TSDB.FAMILY, 
+              qualifier, value);
+          point.setDurable(!batch_import);
+          return tsdb.client.put(point)/* .addBoth(cb) */;
+        }
+      }
+      @Override
+      public String toString() {
+        return "IncomingDataPoints.addPointInternal Write Callback";
+      }
+    }
+    
+    if (tsdb.getTSfilter() != null && tsdb.getTSfilter().filterDataPoints()) {
+      return tsdb.getTSfilter().allowDataPoint(metric, timestamp, value, tags, flags)
+          .addCallbackDeferring(new WriteCB());
     }
+    return Deferred.fromResult(true).addCallbackDeferring(new WriteCB());
   }
 
   private void grow() {
@@ -422,6 +453,12 @@ public Deferred<String> metricNameAsync() {
     return tsdb.metrics.getNameAsync(id);
   }
 
+  @Override
+  public byte[] metricUID() {
+    return Arrays.copyOfRange(row, Const.SALT_WIDTH(), 
+        Const.SALT_WIDTH() + TSDB.metrics_width());
+  }
+  
   public Map<String, String> getTags() {
     try {
       return getTagsAsync().joinUninterruptibly();
@@ -450,6 +487,11 @@ public Deferred<List<String>> getAggregatedTagsAsync() {
     return Deferred.fromResult(empty);
   }
 
+  @Override
+  public List<byte[]> getAggregatedTagUids() {
+    return Collections.emptyList();
+  }
+  
   public List<String> getTSUIDs() {
     return Collections.emptyList();
   }
diff --git a/src/core/Internal.java b/src/core/Internal.java
index 733dc04859..5a40e073bf 100644
--- a/src/core/Internal.java
+++ b/src/core/Internal.java
@@ -123,6 +123,17 @@ public static long baseTime(final long timestamp) {
     }
   }
   
+  /**
+   * Sets the time in a raw data table row key
+   * @param row The row to modify
+   * @param base_time The base time to store
+   * @since 2.3
+   */
+  public static void setBaseTime(final byte[] row, int base_time) {
+    Bytes.setInt(row, base_time, Const.SALT_WIDTH() + 
+        TSDB.metrics_width());
+  }
+  
   /** @see Tags#getTags */
   public static Map<String, String> getTags(final TSDB tsdb, final byte[] row) {
     return Tags.getTags(tsdb, row);
diff --git a/src/core/MutableDataPoint.java b/src/core/MutableDataPoint.java
index 2f51a4e3f9..3620a2da98 100644
--- a/src/core/MutableDataPoint.java
+++ b/src/core/MutableDataPoint.java
@@ -92,6 +92,16 @@ public static MutableDataPoint ofLongValue(final long timestamp,
     return dp;
   }
 
+  /**
+   * Copy constructor
+   *
+   * @param value     A datapoint value.
+   */
+  public static MutableDataPoint fromPoint(final DataPoint value) {
+    if (value.isInteger()) return ofLongValue(value.timestamp(), value.longValue());
+    else return ofDoubleValue(value.timestamp(), value.doubleValue());
+  }
+
   @Override
   public long timestamp() {
     return timestamp;
diff --git a/src/core/Query.java b/src/core/Query.java
index 34553c591e..f4ea1bce4f 100644
--- a/src/core/Query.java
+++ b/src/core/Query.java
@@ -66,7 +66,7 @@ public interface Query {
    * @return A strictly positive integer.
    */
   long getEndTime();
-
+  
   /**
    * Sets whether or not the data queried will be deleted.
    * @param delete True if data should be deleted, false otherwise.
diff --git a/src/core/RowSeq.java b/src/core/RowSeq.java
index 42194aab3b..dcf8d608eb 100644
--- a/src/core/RowSeq.java
+++ b/src/core/RowSeq.java
@@ -285,6 +285,12 @@ public Deferred<String> metricNameAsync() {
     return RowKey.metricNameAsync(tsdb, key);
   }
   
+  @Override
+  public byte[] metricUID() {
+    return Arrays.copyOfRange(key, Const.SALT_WIDTH(), 
+        Const.SALT_WIDTH() + TSDB.metrics_width());
+  }
+  
   public Map<String, String> getTags() {
     try {
       return getTagsAsync().joinUninterruptibly();
@@ -314,6 +320,11 @@ public Deferred<List<String>> getAggregatedTagsAsync() {
     return Deferred.fromResult(empty);
   }
   
+  @Override
+  public List<byte[]> getAggregatedTagUids() {
+    return Collections.emptyList();
+  }
+  
   public List<String> getTSUIDs() {
     return Collections.emptyList();
   }
diff --git a/src/core/Span.java b/src/core/Span.java
index c49ee773cb..15338956ae 100644
--- a/src/core/Span.java
+++ b/src/core/Span.java
@@ -86,6 +86,12 @@ public Deferred<String> metricNameAsync() {
     return rows.get(0).metricNameAsync();
   }
 
+  @Override
+  public byte[] metricUID() {
+    checkNotEmpty();
+    return rows.get(0).metricUID();
+  }
+  
   /**
    * @return the list of tag pairs for the rows in this span
    * @throws IllegalStateException if the span was empty
@@ -121,6 +127,11 @@ public Deferred<List<String>> getAggregatedTagsAsync() {
     final List<String> empty = Collections.emptyList();
     return Deferred.fromResult(empty);
   }
+  
+  @Override
+  public List<byte[]> getAggregatedTagUids() {
+    return Collections.emptyList();
+  }
 
   /** @return the number of data points in this span, O(n)
    * Unfortunately we must walk the entire array for every row as there may be a 
@@ -474,6 +485,31 @@ Downsampler downsampler(final long start_time,
         interval_ms, downsampler, fill_policy);
     }
   }
+  
+  /**
+   * @param start_time The time in milliseconds at which the data begins.
+   * @param end_time The time in milliseconds at which the data ends.
+   * @param downsampler The downsampling specification to use
+   * @param query_start Start of the actual query
+   * @param query_end End of the actual query
+   * @return A new downsampler.
+   * @since 2.3
+   */
+  Downsampler downsampler(final long start_time,
+      final long end_time,
+      final DownsamplingSpecification downsampler,
+      final long query_start,
+      final long query_end) {
+    if (downsampler == null) {
+      return null;
+    }
+    if (FillPolicy.NONE == downsampler.getFillPolicy()) {
+      return new Downsampler(spanIterator(), downsampler, 
+          query_start, query_end);  
+    }
+    return new FillingDownsampler(spanIterator(), start_time, end_time, 
+        downsampler, query_start, query_end);
+  }
 
   public int getQueryIndex() {
     throw new UnsupportedOperationException("Not mapped to a query");
diff --git a/src/core/SpanGroup.java b/src/core/SpanGroup.java
index 026cb0fedc..7e50bb8ef6 100644
--- a/src/core/SpanGroup.java
+++ b/src/core/SpanGroup.java
@@ -13,6 +13,7 @@
 package net.opentsdb.core;
 
 import java.util.ArrayList;
+import java.util.Collections;
 import java.util.HashMap;
 import java.util.HashSet;
 import java.util.Iterator;
@@ -90,21 +91,18 @@ final class SpanGroup implements DataPoints {
   /** Aggregator to use to aggregate data points from different Spans. */
   private final Aggregator aggregator;
 
-  /**
-   * Downsampling function to use, if any (can be {@code null}).
-   * If this is non-null, {@code sample_interval} must be strictly positive.
-   */
-  private final Aggregator downsampler;
-
-  /** Minimum time interval (in seconds) wanted between each data point. */
-  private final long sample_interval;
+  /** Downsampling specification to use, if any (can be {@code null}). */
+  private DownsamplingSpecification downsampler;
+  
+  /** Start timestamp of the query for filtering */  
+  private final long query_start;
+  
+  /** End timestamp of the query for filtering */
+  private final long query_end;  
 
   /** Index of the query in the TSQuery class */
   private final int query_index;
   
-  /** Downsampling fill policy. */
-  private final FillPolicy fill_policy;
-  
   /** The TSDB to which we belong, used for resolution */
   private final TSDB tsdb;
   
@@ -191,6 +189,43 @@ final class SpanGroup implements DataPoints {
             final Aggregator aggregator,
             final long interval, final Aggregator downsampler, final int query_index,
             final FillPolicy fill_policy) {
+     this(tsdb, start_time, end_time, spans, rate, rate_options, aggregator,
+         downsampler != null ? 
+             new DownsamplingSpecification(interval, downsampler, fill_policy) : 
+           null,
+         0, 0, query_index);
+  }
+  
+  /**
+   * Ctor.
+   * @param tsdb The TSDB we belong to.
+   * @param start_time Any data point strictly before this timestamp will be
+   * ignored.
+   * @param end_time Any data point strictly after this timestamp will be
+   * ignored.
+   * @param spans A sequence of initial {@link Spans} to add to this group.
+   * Ignored if {@code null}. Additional spans can be added with {@link #add}.
+   * @param rate If {@code true}, the rate of the series will be used instead
+   * of the actual values.
+   * @param rate_options Specifies the optional additional rate calculation options.
+   * @param aggregator The aggregation function to use.
+   * @param downsampler The specification to use for downsampling, may be null.
+   * @param query_start Start of the actual query
+   * @param query_end End of the actual query
+   * @param query_index index of the original query
+   * @since 2.3
+   */
+  SpanGroup(final TSDB tsdb,
+            final long start_time, 
+            final long end_time,
+            final Iterable<Span> spans,
+            final boolean rate, 
+            final RateOptions rate_options,
+            final Aggregator aggregator,
+            final DownsamplingSpecification downsampler, 
+            final long query_start,
+            final long query_end,
+            final int query_index) {
      annotations = new ArrayList<Annotation>();
      this.start_time = (start_time & Const.SECOND_MASK) == 0 ? 
          start_time * 1000 : start_time;
@@ -205,9 +240,9 @@ final class SpanGroup implements DataPoints {
      this.rate_options = rate_options;
      this.aggregator = aggregator;
      this.downsampler = downsampler;
-     this.sample_interval = interval;
+     this.query_start = query_start;
+     this.query_end = query_end;
      this.query_index = query_index;
-     this.fill_policy = fill_policy;
      this.tsdb = tsdb;
   }
   
@@ -327,6 +362,11 @@ public Deferred<String> metricNameAsync() {
       spans.get(0).metricNameAsync();
   }
 
+  @Override
+  public byte[] metricUID() {
+    return spans.isEmpty() ? new byte[] {} : spans.get(0).metricUID();
+  }
+  
   public Map<String, String> getTags() {
     try {
       return getTagsAsync().joinUninterruptibly();
@@ -388,6 +428,22 @@ public Deferred<List<String>> getAggregatedTagsAsync() {
     
     return resolveAggTags(aggregated_tag_uids);
   }
+  
+  @Override
+  public List<byte[]> getAggregatedTagUids() {
+    if (aggregated_tag_uids != null) {
+      return new ArrayList<byte[]>(aggregated_tag_uids);
+    }
+    
+    if (spans.isEmpty()) {
+      return Collections.emptyList();
+    }
+    
+    if (aggregated_tag_uids == null) {
+      computeTags();
+    }
+    return new ArrayList<byte[]>(aggregated_tag_uids);
+  }
 
   public List<String> getTSUIDs() {
     List<String> tsuids = new ArrayList<String>(spans.size());
@@ -430,8 +486,8 @@ public int aggregatedSize() {
   public SeekableView iterator() {
     return AggregationIterator.create(spans, start_time, end_time, aggregator,
                                   aggregator.interpolationMethod(),
-                                  downsampler, sample_interval,
-                                  rate, rate_options, fill_policy);
+                                  downsampler, query_start, query_end,
+                                  rate, rate_options);
   }
 
   /**
@@ -487,7 +543,8 @@ private String toStringSharedAttributes() {
       + ", rate=" + rate
       + ", aggregator=" + aggregator
       + ", downsampler=" + downsampler
-      + ", sample_interval=" + sample_interval
+      + ", query_start=" + query_start
+      + ", query_end" + query_end
       + ')';
   }
 
diff --git a/src/core/TSDB.java b/src/core/TSDB.java
index 6eab7220c6..57e591ef07 100644
--- a/src/core/TSDB.java
+++ b/src/core/TSDB.java
@@ -20,6 +20,7 @@
 import java.util.List;
 import java.util.Map;
 import java.util.Set;
+import java.util.concurrent.atomic.AtomicLong;
 
 import com.stumbleupon.async.Callback;
 import com.stumbleupon.async.Deferred;
@@ -44,19 +45,24 @@
 import net.opentsdb.tree.TreeBuilder;
 import net.opentsdb.tsd.RTPublisher;
 import net.opentsdb.tsd.StorageExceptionHandler;
+import net.opentsdb.uid.NoSuchUniqueId;
 import net.opentsdb.uid.NoSuchUniqueName;
 import net.opentsdb.uid.UniqueId;
+import net.opentsdb.uid.UniqueIdFilterPlugin;
 import net.opentsdb.uid.UniqueId.UniqueIdType;
 import net.opentsdb.utils.Config;
 import net.opentsdb.utils.DateTime;
 import net.opentsdb.utils.PluginLoader;
 import net.opentsdb.utils.Threads;
 import net.opentsdb.meta.Annotation;
+import net.opentsdb.meta.MetaDataCache;
 import net.opentsdb.meta.TSMeta;
 import net.opentsdb.meta.UIDMeta;
+import net.opentsdb.query.expression.ExpressionFactory;
 import net.opentsdb.query.filter.TagVFilter;
 import net.opentsdb.search.SearchPlugin;
 import net.opentsdb.search.SearchQuery;
+import net.opentsdb.tools.StartupPlugin;
 import net.opentsdb.stats.Histogram;
 import net.opentsdb.stats.QueryStats;
 import net.opentsdb.stats.StatsCollector;
@@ -116,13 +122,32 @@ public final class TSDB {
 
   /** Search indexer to use if configure */
   private SearchPlugin search = null;
-  
+
+  /** Optional Startup Plugin to use if configured */
+  private StartupPlugin startup = null;
+
   /** Optional real time pulblisher plugin to use if configured */
   private RTPublisher rt_publisher = null;
   
+  /** Optional plugin for handling meta data caching and updating */
+  private MetaDataCache meta_cache = null;
+  
   /** Plugin for dealing with data points that can't be stored */
   private StorageExceptionHandler storage_exception_handler = null;
+
+  /** A filter plugin for allowing or blocking time series */
+  private WriteableDataPointFilterPlugin ts_filter;
   
+  /** A filter plugin for allowing or blocking UIDs */
+  private UniqueIdFilterPlugin uid_filter;
+  
+  /** Writes rejected by the filter */ 
+  private final AtomicLong rejected_dps = new AtomicLong();
+  private final AtomicLong rejected_aggregate_dps = new AtomicLong();
+  
+  /** Datapoints Added */
+  private static final AtomicLong datapoints_added = new AtomicLong();
+
   /**
    * Constructor
    * @param client An initialized HBase client object
@@ -180,17 +205,13 @@ public TSDB(final HBaseClient client, final Config config) {
     meta_table = config.getString("tsd.storage.hbase.meta_table").getBytes(CHARSET);
 
     if (config.getBoolean("tsd.core.uid.random_metrics")) {
-      metrics = new UniqueId(this.client, uidtable, METRICS_QUAL, METRICS_WIDTH, 
-          true);
+      metrics = new UniqueId(this, uidtable, METRICS_QUAL, METRICS_WIDTH, true);
     } else {
-      metrics = new UniqueId(this.client, uidtable, METRICS_QUAL, METRICS_WIDTH);
+      metrics = new UniqueId(this, uidtable, METRICS_QUAL, METRICS_WIDTH, false);
     }
-    tag_names = new UniqueId(this.client, uidtable, TAG_NAME_QUAL, TAG_NAME_WIDTH);
-    tag_values = new UniqueId(this.client, uidtable, TAG_VALUE_QUAL, TAG_VALUE_WIDTH);
+    tag_names = new UniqueId(this, uidtable, TAG_NAME_QUAL, TAG_NAME_WIDTH, false);
+    tag_values = new UniqueId(this, uidtable, TAG_VALUE_QUAL, TAG_VALUE_WIDTH, false);
     compactionq = new CompactionQueue(this);
-    metrics.setTSDB(this);
-    tag_names.setTSDB(this);
-    tag_values.setTSDB(this);
     
     if (config.hasProperty("tsd.core.timezone")) {
       DateTime.setDefaultTimezone(config.getString("tsd.core.timezone"));
@@ -208,6 +229,17 @@ public TSDB(final HBaseClient client, final Config config) {
       uid_cache_map.put(TAG_VALUE_QUAL.getBytes(CHARSET), tag_values);
       UniqueId.preloadUidCache(this, uid_cache_map);
     }
+    
+    if (config.getString("tsd.core.tag.allow_specialchars") != null) {
+      Tags.setAllowSpecialChars(config.getString("tsd.core.tag.allow_specialchars"));
+    }
+    
+    // load up the functions that require the TSDB object
+    ExpressionFactory.addTSDBFunctions(this);
+    
+    // set any extra tags from the config for stats
+    StatsCollector.setGlobalTags(config);
+    
     LOG.debug(config.dumpConfiguration());
   }
   
@@ -224,7 +256,23 @@ public TSDB(final Config config) {
   public static byte[] FAMILY() {
     return FAMILY;
   }
-  
+
+  /**
+   * Called by initializePlugins, also used to load startup plugins.
+   * @since 2.3
+   */
+  public static void loadPluginPath(final String plugin_path) {
+    if (plugin_path != null && !plugin_path.isEmpty()) {
+      try {
+        PluginLoader.loadJARs(plugin_path);
+      } catch (Exception e) {
+        LOG.error("Error loading plugins from plugin path: " + plugin_path, e);
+        throw new RuntimeException("Error loading plugins from plugin path: " +
+                plugin_path, e);
+      }
+    }
+  }
+
   /**
    * Should be called immediately after construction to initialize plugins and
    * objects that rely on such. It also moves most of the potential exception
@@ -237,16 +285,8 @@ public static byte[] FAMILY() {
    */
   public void initializePlugins(final boolean init_rpcs) {
     final String plugin_path = config.getString("tsd.core.plugin_path");
-    if (plugin_path != null && !plugin_path.isEmpty()) {
-      try {
-        PluginLoader.loadJARs(plugin_path);
-      } catch (Exception e) {
-        LOG.error("Error loading plugins from plugin path: " + plugin_path, e);
-        throw new RuntimeException("Error loading plugins from plugin path: " + 
-            plugin_path, e);
-      }
-    }
-    
+    loadPluginPath(plugin_path);
+
     try {
       TagVFilter.initializeFilterMap(this);
       // @#$@%$%#$ing typed exceptions
@@ -308,6 +348,26 @@ public void initializePlugins(final boolean init_rpcs) {
       rt_publisher = null;
     }
     
+    // load the meta cache plugin if enabled
+    if (config.getBoolean("tsd.core.meta.cache.enable")) {
+      meta_cache = PluginLoader.loadSpecificPlugin(
+          config.getString("tsd.core.meta.cache.plugin"), MetaDataCache.class);
+      if (meta_cache == null) {
+        throw new IllegalArgumentException(
+            "Unable to locate meta cache plugin: " + 
+            config.getString("tsd.core.meta.cache.plugin"));
+      }
+      try {
+        meta_cache.initialize(this);
+      } catch (Exception e) {
+        throw new RuntimeException(
+            "Failed to initialize meta cache plugin", e);
+      }
+      LOG.info("Successfully initialized meta cache plugin [" + 
+          meta_cache.getClass().getCanonicalName() + "] version: " 
+          + meta_cache.version());
+    }
+    
     // load the storage exception plugin if enabled
     if (config.getBoolean("tsd.core.storage_exception_handler.enable")) {
       storage_exception_handler = PluginLoader.loadSpecificPlugin(
@@ -328,6 +388,48 @@ public void initializePlugins(final boolean init_rpcs) {
           storage_exception_handler.getClass().getCanonicalName() + "] version: " 
           + storage_exception_handler.version());
     }
+    
+    // Writeable Data Point Filter
+    if (config.getBoolean("tsd.timeseriesfilter.enable")) {
+      ts_filter = PluginLoader.loadSpecificPlugin(
+          config.getString("tsd.timeseriesfilter.plugin"), 
+          WriteableDataPointFilterPlugin.class);
+      if (ts_filter == null) {
+        throw new IllegalArgumentException(
+            "Unable to locate time series filter plugin plugin: " + 
+            config.getString("tsd.timeseriesfilter.plugin"));
+      }
+      try {
+        ts_filter.initialize(this);
+      } catch (Exception e) {
+        throw new RuntimeException(
+            "Failed to initialize time series filter plugin", e);
+      }
+      LOG.info("Successfully initialized time series filter plugin [" + 
+          ts_filter.getClass().getCanonicalName() + "] version: " 
+          + ts_filter.version());
+    }
+    
+    // UID Filter
+    if (config.getBoolean("tsd.uidfilter.enable")) {
+      uid_filter = PluginLoader.loadSpecificPlugin(
+          config.getString("tsd.uidfilter.plugin"), 
+          UniqueIdFilterPlugin.class);
+      if (uid_filter == null) {
+        throw new IllegalArgumentException(
+            "Unable to locate UID filter plugin plugin: " + 
+            config.getString("tsd.uidfilter.plugin"));
+      }
+      try {
+        uid_filter.initialize(this);
+      } catch (Exception e) {
+        throw new RuntimeException(
+            "Failed to initialize UID filter plugin", e);
+      }
+      LOG.info("Successfully initialized UID filter plugin [" + 
+          uid_filter.getClass().getCanonicalName() + "] version: " 
+          + uid_filter.version());
+    }
   }
   
   /** 
@@ -338,8 +440,28 @@ public void initializePlugins(final boolean init_rpcs) {
   public final HBaseClient getClient() {
     return this.client;
   }
+
+  /**
+   * Sets the startup plugin so that it can be shutdown properly. 
+   * Note that this method will not initialize or call any other methods 
+   * belonging to the plugin's implementation.
+   * @param plugin The startup plugin that was used. 
+   * @since 2.3
+   */
+  public final void setStartupPlugin(final StartupPlugin plugin) { 
+    startup = plugin; 
+  }
   
-  /** 
+  /**
+   * Getter that returns the startup plugin object.
+   * @return The StartupPlugin object or null if the plugin was not set.
+   * @since 2.3
+   */
+  public final StartupPlugin getStartupPlugin() { 
+    return startup; 
+  }
+
+  /**
    * Getter that returns the configuration object
    * @return The configuration object
    * @since 2.0 
@@ -357,6 +479,22 @@ public final StorageExceptionHandler getStorageExceptionHandler() {
     return storage_exception_handler;
   }
 
+  /**
+   * @return the TS filter object, may be null
+   * @since 2.3
+   */
+  public WriteableDataPointFilterPlugin getTSfilter() {
+    return ts_filter;
+  }
+  
+  /** 
+   * @return The UID filter object, may be null. 
+   * @since 2.3 
+   */
+  public UniqueIdFilterPlugin getUidFilter() {
+    return uid_filter;
+  }
+  
   /**
    * Attempts to find the name for a unique identifier given a type
    * @param type The type of UID
@@ -517,6 +655,10 @@ public void collectStats(final StatsCollector collector) {
     } catch (Exception e) {
       throw new RuntimeException("Shouldn't be here", e);
     }
+    
+    collector.record("uid.filter.rejected", rejected_dps.get(), "kind=raw");
+    collector.record("uid.filter.rejected", rejected_aggregate_dps.get(), 
+        "kind=aggregate");
 
     {
       final Runtime runtime = Runtime.getRuntime();
@@ -531,6 +673,13 @@ public void collectStats(final StatsCollector collector) {
       collector.clearExtraTag("class");
     }
 
+    collector.addExtraTag("class", "TSDB");
+    try {
+      collector.record("datapoints.added", datapoints_added, "type=all");
+    } finally {
+      collector.clearExtraTag("class");
+    }
+
     collector.addExtraTag("class", "TsdbQuery");
     try {
       collector.record("hbase.latency", TsdbQuery.scanlatency, "method=scan");
@@ -566,6 +715,14 @@ public void collectStats(final StatsCollector collector) {
 
     compactionq.collectStats(collector);
     // Collect Stats from Plugins
+    if (startup != null) {
+      try {
+        collector.addExtraTag("plugin", "startup");
+        startup.collectStats(collector);
+      } finally {
+        collector.clearExtraTag("plugin");
+      }
+    }
     if (rt_publisher != null) {
       try {
         collector.addExtraTag("plugin", "publish");
@@ -590,6 +747,22 @@ public void collectStats(final StatsCollector collector) {
         collector.clearExtraTag("plugin");
       }
     }
+    if (ts_filter != null) {
+      try {
+        collector.addExtraTag("plugin", "timeseriesFilter");
+        ts_filter.collectStats(collector);
+      } finally {
+        collector.clearExtraTag("plugin");
+      }
+    }
+    if (uid_filter != null) {
+      try {
+        collector.addExtraTag("plugin", "uidFilter");
+        uid_filter.collectStats(collector);
+      } finally {
+        collector.clearExtraTag("plugin");
+      }
+    }
   }
 
   /** Returns a latency histogram for Put RPCs used to store data points. */
@@ -614,6 +787,8 @@ private static void collectUidStats(final UniqueId uid,
     collector.record("uid.cache-size", uid.cacheSize(), "kind=" + uid.kind());
     collector.record("uid.random-collisions", uid.randomIdCollisions(), 
         "kind=" + uid.kind());
+    collector.record("uid.rejected-assignments", uid.rejectedAssignments(), 
+        "kind=" + uid.kind());
   }
 
   /** @return the width, in bytes, of metric UIDs */
@@ -693,6 +868,7 @@ public Deferred<Object> addPoint(final String metric,
     } else {
       v = Bytes.fromLong(value);
     }
+
     final short flags = (short) (v.length - 1);  // Just the length.
     return addPointInternal(metric, timestamp, v, tags, flags);
   }
@@ -796,50 +972,81 @@ private Deferred<Object> addPointInternal(final String metric,
       base_time = (timestamp - (timestamp % Const.MAX_TIMESPAN));
     }
     
-    Bytes.setInt(row, (int) base_time, metrics.width() + Const.SALT_WIDTH());
-    RowKey.prefixKeyWithSalt(row);
-    
-    Deferred<Object> result = null;
-    if (config.enable_appends()) {
-      final AppendDataPoints kv = new AppendDataPoints(qualifier, value);
-      final AppendRequest point = new AppendRequest(table, row, FAMILY, 
-          AppendDataPoints.APPEND_COLUMN_QUALIFIER, kv.getBytes());
-      result = client.append(point);
-    } else {
-      scheduleForCompaction(row, (int) base_time);
-      final PutRequest point = new PutRequest(table, row, FAMILY, qualifier, value);
-      result = client.put(point);
-    }
-    
-    // TODO(tsuna): Add a callback to time the latency of HBase and store the
-    // timing in a moving Histogram (once we have a class for this).
-    
-    if (!config.enable_realtime_ts() && !config.enable_tsuid_incrementing() && 
-        !config.enable_tsuid_tracking() && rt_publisher == null) {
-      return result;
-    }
-    
-    final byte[] tsuid = UniqueId.getTSUIDFromKey(row, METRICS_WIDTH, 
-        Const.TIMESTAMP_BYTES);
-    
-    if (config.enable_tsuid_tracking()) {
-      if (config.enable_realtime_ts()) {
-        if (config.enable_tsuid_incrementing()) {
-          TSMeta.incrementAndGetCounter(TSDB.this, tsuid);
+    /** Callback executed for chaining filter calls to see if the value
+     * should be written or not. */
+    final class WriteCB implements Callback<Deferred<Object>, Boolean> {
+      @Override
+      public Deferred<Object> call(final Boolean allowed) throws Exception {
+        if (!allowed) {
+          rejected_dps.incrementAndGet();
+          return Deferred.fromResult(null);
+        }
+        
+        Bytes.setInt(row, (int) base_time, metrics.width() + Const.SALT_WIDTH());
+        RowKey.prefixKeyWithSalt(row);
+
+        Deferred<Object> result = null;
+        if (config.enable_appends()) {
+          final AppendDataPoints kv = new AppendDataPoints(qualifier, value);
+          final AppendRequest point = new AppendRequest(table, row, FAMILY, 
+              AppendDataPoints.APPEND_COLUMN_QUALIFIER, kv.getBytes());
+          result = client.append(point);
         } else {
-          TSMeta.storeIfNecessary(TSDB.this, tsuid);
+          scheduleForCompaction(row, (int) base_time);
+          final PutRequest point = new PutRequest(table, row, FAMILY, qualifier, value);
+          result = client.put(point);
         }
-      } else {
-        final PutRequest tracking = new PutRequest(meta_table, tsuid, 
-            TSMeta.FAMILY(), TSMeta.COUNTER_QUALIFIER(), Bytes.fromLong(1));
-        client.put(tracking);
+
+        // Count all added datapoints, not just those that came in through PUT rpc
+        // Will there be others? Well, something could call addPoint programatically right?
+        datapoints_added.incrementAndGet();
+
+        // TODO(tsuna): Add a callback to time the latency of HBase and store the
+        // timing in a moving Histogram (once we have a class for this).
+        
+        if (!config.enable_realtime_ts() && !config.enable_tsuid_incrementing() && 
+            !config.enable_tsuid_tracking() && rt_publisher == null) {
+          return result;
+        }
+        
+        final byte[] tsuid = UniqueId.getTSUIDFromKey(row, METRICS_WIDTH, 
+            Const.TIMESTAMP_BYTES);
+        
+        // if the meta cache plugin is instantiated then tracking goes through it
+        if (meta_cache != null) {
+          meta_cache.increment(tsuid);
+        } else {
+          if (config.enable_tsuid_tracking()) {
+            if (config.enable_realtime_ts()) {
+              if (config.enable_tsuid_incrementing()) {
+                TSMeta.incrementAndGetCounter(TSDB.this, tsuid);
+              } else {
+                TSMeta.storeIfNecessary(TSDB.this, tsuid);
+              }
+            } else {
+              final PutRequest tracking = new PutRequest(meta_table, tsuid, 
+                  TSMeta.FAMILY(), TSMeta.COUNTER_QUALIFIER(), Bytes.fromLong(1));
+              client.put(tracking);
+            }
+          }
+        }
+
+        if (rt_publisher != null) {
+          rt_publisher.sinkDataPoint(metric, timestamp, value, tags, tsuid, flags);
+        }
+        return result;
+      }
+      @Override
+      public String toString() {
+        return "addPointInternal Write Callback";
       }
     }
     
-    if (rt_publisher != null) {
-      rt_publisher.sinkDataPoint(metric, timestamp, value, tags, tsuid, flags);
+    if (ts_filter != null && ts_filter.filterDataPoints()) {
+      return ts_filter.allowDataPoint(metric, timestamp, value, tags, flags)
+          .addCallbackDeferring(new WriteCB());
     }
-    return result;
+    return Deferred.fromResult(true).addCallbackDeferring(new WriteCB());
   }
 
   /**
@@ -962,6 +1169,11 @@ public Object call(ArrayList<Object> compactions) throws Exception {
       LOG.info("Flushing compaction queue");
       deferreds.add(compactionq.flush().addCallback(new CompactCB()));
     }
+    if (startup != null) {
+      LOG.info("Shutting down startup plugin: " +
+              startup.getClass().getCanonicalName());
+      deferreds.add(startup.shutdown());
+    }
     if (search != null) {
       LOG.info("Shutting down search plugin: " + 
           search.getClass().getCanonicalName());
@@ -972,11 +1184,26 @@ public Object call(ArrayList<Object> compactions) throws Exception {
           rt_publisher.getClass().getCanonicalName());
       deferreds.add(rt_publisher.shutdown());
     }
+    if (meta_cache != null) {
+      LOG.info("Shutting down meta cache plugin: " + 
+          meta_cache.getClass().getCanonicalName());
+      deferreds.add(meta_cache.shutdown());
+    }
     if (storage_exception_handler != null) {
       LOG.info("Shutting down storage exception handler plugin: " + 
           storage_exception_handler.getClass().getCanonicalName());
       deferreds.add(storage_exception_handler.shutdown());
     }
+    if (ts_filter != null) {
+      LOG.info("Shutting down time series filter plugin: " + 
+          ts_filter.getClass().getCanonicalName());
+      deferreds.add(ts_filter.shutdown());
+    }
+    if (uid_filter != null) {
+      LOG.info("Shutting down UID filter plugin: " + 
+          uid_filter.getClass().getCanonicalName());
+      deferreds.add(uid_filter.shutdown());
+    }
     
     // wait for plugins to shutdown before we close the client
     return deferreds.size() > 0
@@ -1120,6 +1347,52 @@ public Deferred<Object> deleteUidAsync(final String type, final String name) {
     }
   }
   
+  /**
+   * Attempts to rename a UID from existing name to the given name
+   * Used by the UniqueIdRpc call to rename name of existing metrics, tagks or
+   * tagvs. The name must pass validation. If the UID doesn't exist, the method
+   * will throw an error. Chained IllegalArgumentException is directly exposed
+   * to caller. If the rename was successful, this method returns.
+   * @param type The type of uid to rename, one of metric, tagk and tagv
+   * @param oldname The existing name of the uid object
+   * @param newname The new name to be used on the uid object
+   * @throws IllegalArgumentException if error happened
+   * @since 2.2
+   */
+  public void renameUid(final String type, final String oldname,
+      final String newname) {
+    Tags.validateString(type, oldname);
+    Tags.validateString(type, newname);
+    if (type.toLowerCase().equals("metric")) {
+      try {
+        this.metrics.getId(oldname);
+        this.metrics.rename(oldname, newname);
+      } catch (NoSuchUniqueName nsue) {
+        throw new IllegalArgumentException("Name(\"" + oldname +
+            "\") does not exist");
+      }
+    } else if (type.toLowerCase().equals("tagk")) {
+      try {
+        this.tag_names.getId(oldname);
+        this.tag_names.rename(oldname, newname);
+      } catch (NoSuchUniqueName nsue) {
+        throw new IllegalArgumentException("Name(\"" + oldname +
+            "\") does not exist");
+      }
+    } else if (type.toLowerCase().equals("tagv")) {
+      try {
+        this.tag_values.getId(oldname);
+        this.tag_values.rename(oldname, newname);
+      } catch (NoSuchUniqueName nsue) {
+        throw new IllegalArgumentException("Name(\"" + oldname +
+            "\") does not exist");
+      }
+    } else {
+      LOG.warn("Unknown type name: " + type);
+      throw new IllegalArgumentException("Unknown type name");
+    }
+  }
+
   /** @return the name of the UID table as a byte array for client requests */
   public byte[] uidTable() {
     return this.uidtable;
diff --git a/src/core/TSQuery.java b/src/core/TSQuery.java
index c4c3ba918b..071b401812 100644
--- a/src/core/TSQuery.java
+++ b/src/core/TSQuery.java
@@ -16,6 +16,7 @@
 import java.util.HashMap;
 import java.util.List;
 import java.util.Map;
+import java.util.TimeZone;
 
 import com.fasterxml.jackson.annotation.JsonIgnore;
 import com.fasterxml.jackson.annotation.JsonIgnoreProperties;
@@ -95,6 +96,9 @@ public final class TSQuery {
   /** Whether or not to delete the queried data */
   private boolean delete = false;
   
+  /** A flag denoting whether or not to align intervals based on the calendar */
+  private boolean use_calendar;
+  
   /** The query status for tracking over all performance of this query */
   private QueryStats query_stats;
   
@@ -110,7 +114,7 @@ public int hashCode() {
     // NOTE: Do not add any non-user submitted variables to the hash. We don't
     // want the hash to change after validation.
     // We also don't care about stats or summary
-    return Objects.hashCode(start, end, timezone, options, padding, 
+    return Objects.hashCode(start, end, timezone, use_calendar, options, padding, 
         no_annotations, with_global_annotations, show_tsuids, queries, 
         ms_resolution);
   }
@@ -134,6 +138,7 @@ public boolean equals(final Object obj) {
     return Objects.equal(start, query.start)
         && Objects.equal(end, query.end)
         && Objects.equal(timezone, query.timezone)
+        && Objects.equal(use_calendar,query.use_calendar)
         && Objects.equal(options, query.options)
         && Objects.equal(padding, query.padding)
         && Objects.equal(no_annotations, query.no_annotations)
@@ -176,8 +181,25 @@ public void validateAndSetQuery() {
     }
     
     // validate queries
+    int i = 0;
     for (TSSubQuery sub : queries) {
       sub.validateAndSetQuery();
+      final DownsamplingSpecification ds = sub.downsamplingSpecification();
+      if (ds != null && timezone != null && !timezone.isEmpty() && 
+          ds != DownsamplingSpecification.NO_DOWNSAMPLER) {
+        final TimeZone tz = DateTime.timezones.get(timezone);
+        if (tz == null) {
+          throw new IllegalArgumentException(
+              "The timezone specification could not be found");
+        }
+        ds.setTimezone(tz);
+      }
+      if (ds != null && use_calendar && 
+          ds != DownsamplingSpecification.NO_DOWNSAMPLER) {
+        ds.setUseCalendar(true);
+      }
+      
+      sub.setIndex(i++);
     }
   }
   
@@ -360,6 +382,13 @@ public boolean getDelete() {
     return this.delete;
   }
   
+  /** @return the flag denoting whether intervals should be aligned based on 
+   * the calendar
+   * @since 2.3 */
+  public boolean getUseCalendar() {
+    return use_calendar;
+  }
+  
   /** @return the query stats object. Ignored during JSON serialization */
   @JsonIgnore
   public QueryStats getQueryStats() {
@@ -445,6 +474,12 @@ public void setDelete(boolean delete) {
     this.delete = delete;
   }
   
+  /** @param use_calendar a flag denoting whether or not to align intervals 
+   * based on the calendar @since 2.3 */
+  public void setUseCalendar(boolean use_calendar) {
+    this.use_calendar = use_calendar;
+  }
+  
   /** @param query_stats the query stats object to associate with this query */
   public void setQueryStats(final QueryStats query_stats) {
     this.query_stats = query_stats;
diff --git a/src/core/TSSubQuery.java b/src/core/TSSubQuery.java
index 8e9833f2f7..578a32b89f 100644
--- a/src/core/TSSubQuery.java
+++ b/src/core/TSSubQuery.java
@@ -20,6 +20,7 @@
 import java.util.NoSuchElementException;
 
 import net.opentsdb.query.filter.TagVFilter;
+import net.opentsdb.utils.ByteSet;
 
 import com.fasterxml.jackson.annotation.JsonIgnoreProperties;
 import com.google.common.base.Objects;
@@ -72,6 +73,12 @@ public final class TSSubQuery {
    * tags map. In the future we'll have special JSON objects for them. */
   private List<TagVFilter> filters;
   
+  /** Whether or not to match series with ONLY the given tags */
+  private boolean explicit_tags;
+  
+  /** Index of the sub query */
+  private int index;
+  
   /**
    * Default constructor necessary for POJO de/serialization
    */
@@ -85,7 +92,7 @@ public int hashCode() {
     // NOTE: Do not add any non-user submitted variables to the hash. We don't
     // want the hash to change after validation.
     return Objects.hashCode(aggregator, metric, tsuids, downsample, rate, 
-        rate_options, filters);
+        rate_options, filters, explicit_tags);
   }
   
   @Override
@@ -109,7 +116,8 @@ public boolean equals(final Object obj) {
         && Objects.equal(downsample, query.downsample)
         && Objects.equal(rate, query.rate)
         && Objects.equal(rate_options, query.rate_options)
-        && Objects.equal(filters, query.filters);
+        && Objects.equal(filters, query.filters) 
+        && Objects.equal(explicit_tags, query.explicit_tags);
   }
   
   public String toString() {
@@ -147,8 +155,12 @@ public String toString() {
       .append(", rate=")
       .append(rate)
       .append(", rate_options=")
-      .append(rate_options);
-    buf.append(")");
+      .append(rate_options)
+      .append(", explicit_tags=")
+      .append("explicit_tags")
+      .append(", index=")
+      .append(index)
+      .append(")");
     return buf.toString();
   }
   
@@ -199,16 +211,24 @@ public Aggregator aggregator() {
     return this.agg;
   }
   
-  /** @return the parsed downsampler aggregation function */
+  /** @return the parsed downsampler aggregation function
+   * @deprecated use {@link #downsamplingSpecification()} instead */
   public Aggregator downsampler() {
     return downsample_specifier.getFunction();
   }
   
-  /** @return the parsed downsample interval in seconds */
+  /** @return the parsed downsample interval in seconds
+   * @deprecated use {@link #downsamplingSpecification()} instead */
   public long downsampleInterval() {
     return downsample_specifier.getInterval();
   }
   
+  /** @return The downsampling specification for more options 
+   * @since 2.3 */
+  public DownsamplingSpecification downsamplingSpecification() {
+    return downsample_specifier;
+  }
+  
   /**
    * @return the downsampling fill policy
    * @since 2.2
@@ -276,6 +296,35 @@ public List<TagVFilter> getFilters() {
     return new ArrayList<TagVFilter>(filters);
   }
   
+  /** @return the unique set of tagks from the filters. May be null if no filters
+   * were set. Must make sure to resolve the string tag to UIDs in the filter first.
+   * @since 2.3
+   */
+  public ByteSet getFilterTagKs() {
+    if (filters == null || filters.isEmpty()) {
+      return null;
+    }
+    final ByteSet tagks = new ByteSet();
+    for (final TagVFilter filter : filters) {
+      if (filter != null && filter.getTagkBytes() != null) {
+        tagks.add(filter.getTagkBytes());
+      }
+    }
+    return tagks;
+  }
+  
+  /** @return whether or not to match series with ONLY the given tags 
+   * @since 2.3 */
+  public boolean getExplicitTags() {
+    return explicit_tags;
+  }
+  
+  /** @return the index of the sub query
+   * @since 2.3 */
+  public int getIndex() {
+    return index;
+  }
+  
   /** @param aggregator the name of an aggregation function */
   public void setAggregator(String aggregator) {
     this.aggregator = aggregator;
@@ -324,4 +373,16 @@ public void setFilters(List<TagVFilter> filters) {
     this.filters = filters;
   }
   
+  /** @param whether or not to match series with ONLY the given tags 
+   * @since 2.3 */
+  public void setExplicitTags(final boolean explicit_tags) {
+    this.explicit_tags = explicit_tags;
+  }
+  
+  /** @param index the index of the sub query
+   * @since 2.3 */
+  public void setIndex(final int index) {
+    this.index = index;
+  }
+  
 }
diff --git a/src/core/Tags.java b/src/core/Tags.java
index 83ec687824..ff1a4b2125 100644
--- a/src/core/Tags.java
+++ b/src/core/Tags.java
@@ -37,6 +37,7 @@
 public final class Tags {
 
   private static final Logger LOG = LoggerFactory.getLogger(Tags.class);
+  private static String allowSpecialChars = "";
 
   private Tags() {
     // Can't create instances of this utility class.
@@ -462,6 +463,49 @@ public Map<String, String> call(final ArrayList<String> names)
     return Deferred.groupInOrder(deferreds).addCallback(new NameCB());
   }
 
+  /**
+   * Returns the names mapped to tag key/value UIDs
+   * @param tsdb The TSDB instance to use for Unique ID lookups.
+   * @param tags The map of tag key to tag value pairs
+   * @return A map of tag names (keys), tag values (values). If the tags list
+   * was null or empty, the result will be an empty map
+   * @throws NoSuchUniqueId if the row key contained an invalid ID.
+   * @since 2.3
+   */
+  public static Deferred<Map<String, String>> getTagsAsync(final TSDB tsdb, 
+      final ByteMap<byte[]> tags) {
+    if (tags == null || tags.isEmpty()) {
+      return Deferred.fromResult(Collections.<String, String>emptyMap());
+    }
+    
+    final ArrayList<Deferred<String>> deferreds = 
+        new ArrayList<Deferred<String>>();
+    
+    for (final Map.Entry<byte[], byte[]> pair : tags) {
+      deferreds.add(tsdb.tag_names.getNameAsync(pair.getKey()));
+      deferreds.add(tsdb.tag_values.getNameAsync(pair.getValue()));
+    }
+    
+    class NameCB implements Callback<Map<String, String>, ArrayList<String>> {
+      public Map<String, String> call(final ArrayList<String> names) 
+        throws Exception {
+        final HashMap<String, String> result = new HashMap<String, String>();
+        String tagk = "";
+        for (String name : names) {
+          if (tagk.isEmpty()) {
+            tagk = name;
+          } else {
+            result.put(tagk, name);
+            tagk = "";
+          }
+        }
+        return result;
+      }
+    }
+    
+    return Deferred.groupInOrder(deferreds).addCallback(new NameCB());
+  }
+  
   /**
    * Returns the tag key and value pairs as a byte map given a row key
    * @param row The row key to parse the UIDs from
@@ -504,7 +548,7 @@ public static void validateString(final String what, final String s) {
       final char c = s.charAt(i);
       if (!(('a' <= c && c <= 'z') || ('A' <= c && c <= 'Z') 
           || ('0' <= c && c <= '9') || c == '-' || c == '_' || c == '.' 
-          || c == '/' || Character.isLetter(c))) {
+          || c == '/' || Character.isLetter(c) || isAllowSpecialChars(c))) {
         throw new IllegalArgumentException("Invalid " + what
             + " (\"" + s + "\"): illegal character: " + c);
       }
@@ -544,9 +588,9 @@ public static ArrayList<byte[]> resolveAll(final TSDB tsdb,
    */
   public static Deferred<ArrayList<byte[]>> resolveAllAsync(final TSDB tsdb,
       final Map<String, String> tags) {
-    return resolveAllInternalAsync(tsdb, tags, false);
-  }   
-
+    return resolveAllInternalAsync(tsdb, null, tags, false);
+  }
+  
   /**
   * Resolves (and creates, if necessary) all the tags (name=value) into the a
   * sorted byte arrays.
@@ -583,7 +627,6 @@ static ArrayList<byte[]> resolveAllInternal(final TSDB tsdb,
     return tag_ids;
   }
 
-
   /**
    * Resolves (and creates, if necessary) all the tags (name=value) into the a
    * sorted byte arrays.
@@ -595,11 +638,28 @@ static ArrayList<byte[]> resolveAllInternal(final TSDB tsdb,
    */
   static Deferred<ArrayList<byte[]>>
     resolveOrCreateAllAsync(final TSDB tsdb, final Map<String, String> tags) {
-    return resolveAllInternalAsync(tsdb, tags, true);
+    return resolveAllInternalAsync(tsdb, null, tags, true);
+  }
+  
+  /**
+   * Resolves (and creates, if necessary) all the tags (name=value) into the a
+   * sorted byte arrays.
+   * @param tsdb The TSDB to use for UniqueId lookups.
+   * @param metric The metric associated with this tag set for filtering.
+   * @param tags The tags to resolve.  If a new tag name or tag value is
+   * seen, it will be assigned an ID.
+   * @return an array of sorted tags (tag id, tag name).
+   * @since 2.3
+   */
+  static Deferred<ArrayList<byte[]>>
+    resolveOrCreateAllAsync(final TSDB tsdb, final String metric, 
+        final Map<String, String> tags) {
+    return resolveAllInternalAsync(tsdb, metric, tags, true);
   }
   
   private static Deferred<ArrayList<byte[]>>
     resolveAllInternalAsync(final TSDB tsdb,
+                            final String metric,
                             final Map<String, String> tags,
                             final boolean create) {
     final ArrayList<Deferred<byte[]>> tag_ids =
@@ -608,10 +668,10 @@ static ArrayList<byte[]> resolveAllInternal(final TSDB tsdb,
     // For each tag, start resolving the tag name and the tag value.
     for (final Map.Entry<String, String> entry : tags.entrySet()) {
       final Deferred<byte[]> name_id = create
-        ? tsdb.tag_names.getOrCreateIdAsync(entry.getKey())
+        ? tsdb.tag_names.getOrCreateIdAsync(entry.getKey(), metric, tags)
         : tsdb.tag_names.getIdAsync(entry.getKey());
       final Deferred<byte[]> value_id = create
-        ? tsdb.tag_values.getOrCreateIdAsync(entry.getValue())
+        ? tsdb.tag_values.getOrCreateIdAsync(entry.getValue(), metric, tags)
         : tsdb.tag_values.getIdAsync(entry.getValue());
 
       // Then once the tag name is resolved, get the resolved tag value.
@@ -749,4 +809,20 @@ public static boolean looksLikeInteger(final String value) {
     return true;
   }
 
+  /**
+   * Set the special characters due to allowing for a key or a value of the tag.
+   * @param characters character sequences as a string
+   */
+  public static void setAllowSpecialChars(String characters) {
+    allowSpecialChars = characters == null ? "" : characters;
+  }
+
+  /**
+   * Returns true if the character can be used a tag name or a tag value.
+   * @param character
+   * @return
+   */
+  static boolean isAllowSpecialChars(char character) {
+    return allowSpecialChars.indexOf(character) != -1;
+  }
 }
diff --git a/src/core/TsdbQuery.java b/src/core/TsdbQuery.java
index 6348e0ba59..3489442d57 100644
--- a/src/core/TsdbQuery.java
+++ b/src/core/TsdbQuery.java
@@ -95,6 +95,9 @@ final class TsdbQuery implements Query {
   /** Row key regex to pass to HBase if we have tags or TSUIDs */
   private String regex;
   
+  /** Whether or not to enable the fuzzy row filter for Hbase */
+  private boolean enable_fuzzy_filter;
+  
   /**
    * Tags by which we must group the results.
    * Each element is a tag ID.
@@ -116,17 +119,8 @@ final class TsdbQuery implements Query {
   /** Aggregator function to use. */
   private Aggregator aggregator;
 
-  /**
-   * Downsampling function to use, if any (can be {@code null}).
-   * If this is non-null, {@code sample_interval_ms} must be strictly positive.
-   */
-  private Aggregator downsampler;
-
-  /** Minimum time interval (in milliseconds) wanted between each data point. */
-  private long sample_interval_ms;
-  
-  /** Downsampling fill policy. */
-  private FillPolicy fill_policy;
+  /** Downsampling specification to use, if any (can be {@code null}). */
+  private DownsamplingSpecification downsampler;
 
   /** Optional list of TSUIDs to fetch and aggregate instead of a metric */
   private List<String> tsuids;
@@ -140,12 +134,14 @@ final class TsdbQuery implements Query {
   /** An object for storing stats in regarding the query. May be null */
   private QueryStats query_stats;
   
+  /** Whether or not to match series with ONLY the given tags */
+  private boolean explicit_tags;
+  
   /** Constructor. */
   public TsdbQuery(final TSDB tsdb) {
     this.tsdb = tsdb;
-    
-    // By default, we should interpolate.
-    fill_policy = DownsamplingSpecification.DEFAULT_FILL_POLICY;
+    enable_fuzzy_filter = tsdb.getConfig()
+        .getBoolean("tsd.query.enable_fuzzy_filter");
   }
 
   /**
@@ -307,6 +303,15 @@ public void setTimeSeries(final List<String> tsuids,
     this.rate_options = rate_options;
   }
   
+  /**
+   * @param explicit_tags Whether or not to match only on the given tags
+   * @since 2.3
+   */
+  public void setExplicitTags(final boolean explicit_tags) {
+    this.explicit_tags = explicit_tags;
+  }
+  
+  @Override
   public Deferred<Object> configureFromQuery(final TSQuery query, 
       final int index) {
     if (query.getQueries() == null || query.getQueries().isEmpty()) {
@@ -330,10 +335,9 @@ public Deferred<Object> configureFromQuery(final TSQuery query,
     if (rate_options == null) {
       rate_options = new RateOptions();
     }
-    downsampler = sub_query.downsampler();
-    sample_interval_ms = sub_query.downsampleInterval();
-    fill_policy = sub_query.fillPolicy();
+    downsampler = sub_query.downsamplingSpecification();
     filters = sub_query.getFilters();
+    explicit_tags = sub_query.getExplicitTags();
     
     // if we have tsuids set, that takes precedence
     if (sub_query.getTsuids() != null && !sub_query.getTsuids().isEmpty()) {
@@ -392,14 +396,8 @@ public Deferred<Object> call(final byte[] uid) throws Exception {
   @Override
   public void downsample(final long interval, final Aggregator downsampler,
       final FillPolicy fill_policy) {
-    if (downsampler == null) {
-      throw new NullPointerException("downsampler");
-    } else if (interval <= 0) {
-      throw new IllegalArgumentException("interval not > 0: " + interval);
-    }
-    this.downsampler = downsampler;
-    this.sample_interval_ms = interval;
-    this.fill_policy = fill_policy;
+    this.downsampler = new DownsamplingSpecification(
+        interval, downsampler,fill_policy);
   }
 
   /**
@@ -411,6 +409,10 @@ public void downsample(final long interval, final Aggregator downsampler,
    */
   @Override
   public void downsample(final long interval, final Aggregator downsampler) {
+    if (downsampler == Aggregators.NONE) {
+      throw new IllegalArgumentException("cannot use the NONE "
+          + "aggregator for downsampling");
+    }
     downsample(interval, downsampler, FillPolicy.NONE);
   }
 
@@ -555,8 +557,11 @@ private Deferred<TreeMap<byte[], Span>> findSpans() throws HBaseException {
           delete, query_stats, query_index).scan();
     }
     
-    scan_start_time = DateTime.nanoTime();    
+    scan_start_time = DateTime.nanoTime();
     final Scanner scanner = getScanner();
+    if (query_stats != null) {
+      query_stats.addScannerId(query_index, 0, scanner.toString());
+    }
     final Deferred<TreeMap<byte[], Span>> results =
       new Deferred<TreeMap<byte[], Span>>();
     
@@ -901,6 +906,30 @@ public DataPoints[] call(final TreeMap<byte[], Span> spans) throws Exception {
         }
         return NO_RESULT;
       }
+      
+      // The raw aggregator skips group bys and ignores downsampling
+      if (aggregator == Aggregators.NONE) {
+        final SpanGroup[] groups = new SpanGroup[spans.size()];
+        int i = 0;
+        for (final Span span : spans.values()) {
+          final SpanGroup group = new SpanGroup(
+              tsdb, 
+              getScanStartTimeSeconds(),
+              getScanEndTimeSeconds(),
+              null, 
+              rate, 
+              rate_options,
+              aggregator,
+              downsampler,
+              getStartTime(), 
+              getEndTime(),
+              query_index);
+          group.add(span);
+          groups[i++] = group;
+        }
+        return groups;
+      }
+      
       if (group_bys == null) {
         // We haven't been asked to find groups, so let's put all the spans
         // together in the same group.
@@ -910,8 +939,10 @@ public DataPoints[] call(final TreeMap<byte[], Span> spans) throws Exception {
                                               spans.values(),
                                               rate, rate_options,
                                               aggregator,
-                                              sample_interval_ms, downsampler,
-                                              query_index, fill_policy);
+                                              downsampler,
+                                              getStartTime(), 
+                                              getEndTime(),
+                                              query_index);
         if (query_stats != null) {
           query_stats.addStat(query_index, QueryStat.GROUP_BY_TIME, 0);
         }
@@ -958,8 +989,10 @@ public DataPoints[] call(final TreeMap<byte[], Span> spans) throws Exception {
           thegroup = new SpanGroup(tsdb, getScanStartTimeSeconds(),
                                    getScanEndTimeSeconds(),
                                    null, rate, rate_options, aggregator,
-                                   sample_interval_ms, downsampler, query_index, 
-                                   fill_policy);
+                                   downsampler,
+                                   getStartTime(), 
+                                   getEndTime(),
+                                   query_index);
           // Copy the array because we're going to keep `group' and overwrite
           // its contents. So we want the collection to have an immutable copy.
           final byte[] group_copy = new byte[group.length];
@@ -1040,9 +1073,10 @@ private long getScanStartTimeSeconds() {
     // First, we align the start timestamp to its representative value for the
     // interval in which it appears, if downsampling.
     long interval_aligned_ts = start;
-    if (0L != sample_interval_ms) {
+    if (downsampler != null && downsampler.getInterval() > 0) {
       // Downsampling enabled.
-      final long interval_offset = (1000L * start) % sample_interval_ms;
+      // TODO - calendar interval
+      final long interval_offset = (1000L * start) % downsampler.getInterval();
       interval_aligned_ts -= interval_offset / 1000L;
     }
 
@@ -1071,7 +1105,7 @@ private long getScanEndTimeSeconds() {
     }
 
     // The calculation depends on whether we're downsampling.
-    if (0L != sample_interval_ms) {
+    if (downsampler != null && downsampler.getInterval() > 0) {
       // Downsampling enabled.
       //
       // First, we align the end timestamp to its representative value for the
@@ -1084,9 +1118,9 @@ private long getScanEndTimeSeconds() {
       // skip forward an entire extra interval.
       //
       // This can be accomplished by simply not testing for zero offset.
-      final long interval_offset = (1000L * end) % sample_interval_ms;
+      final long interval_offset = (1000L * end) % downsampler.getInterval();
       final long interval_aligned_ts = end +
-        (sample_interval_ms - interval_offset) / 1000L;
+        (downsampler.getInterval() - interval_offset) / 1000L;
 
       // Then, if we're now aligned on a timespan boundary, then we need no
       // further adjustment: we are guaranteed to have always moved the end time
@@ -1117,13 +1151,11 @@ private long getScanEndTimeSeconds() {
    * @param scanner The scanner on which to add the filter.
    */
   private void createAndSetFilter(final Scanner scanner) {
-    if (regex == null) {
-      regex = QueryUtil.getRowKeyUIDRegex(group_bys, row_key_literals);
-    }
-    scanner.setKeyRegexp(regex, CHARSET);
-    if (LOG.isDebugEnabled()) {
-      LOG.debug("Scanner regex: " + QueryUtil.byteRegexToString(regex));
-    }
+    QueryUtil.setDataTableScanFilter(scanner, group_bys, row_key_literals, 
+        explicit_tags, enable_fuzzy_filter, 
+        (end_time == UNSET
+        ? -1  // Will scan until the end (0xFFF...).
+        : (int) getScanEndTimeSeconds()));
   }
   
   /**
@@ -1254,7 +1286,7 @@ static long getScanEndTimeSeconds(final TsdbQuery query) {
 
     /** @return the downsampling interval for unit tests. */
     static long getDownsampleIntervalMs(final TsdbQuery query) {
-      return query.sample_interval_ms;
+      return query.downsampler.getInterval();
     }
   
     static byte[] getMetric(final TsdbQuery query) {
diff --git a/src/core/WriteableDataPointFilterPlugin.java b/src/core/WriteableDataPointFilterPlugin.java
new file mode 100644
index 0000000000..8a01159667
--- /dev/null
+++ b/src/core/WriteableDataPointFilterPlugin.java
@@ -0,0 +1,99 @@
+// This file is part of OpenTSDB.
+// Copyright (C) 2016  The OpenTSDB Authors.
+//
+// This program is free software: you can redistribute it and/or modify it
+// under the terms of the GNU Lesser General Public License as published by
+// the Free Software Foundation, either version 2.1 of the License, or (at your
+// option) any later version.  This program is distributed in the hope that it
+// will be useful, but WITHOUT ANY WARRANTY; without even the implied warranty
+// of MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser
+// General Public License for more details.  You should have received a copy
+// of the GNU Lesser General Public License along with this program.  If not,
+// see <http://www.gnu.org/licenses/>.
+package net.opentsdb.core;
+
+import java.util.Map;
+
+import com.stumbleupon.async.Deferred;
+
+import net.opentsdb.stats.StatsCollector;
+
+/**
+ * A filter that can determine whether or not time series should be allowed 
+ * assignment based on their metric and tags. This is useful for such 
+ * situations as:
+ * <ul><li>Enforcing naming standards</li>
+ * <li>Blacklisting certain names or properties</li>
+ * <li>Preventing cardinality explosions</li></ul>
+ * <b>Note:</b> Implementations must have a parameterless constructor. The 
+ * {@link #initialize(TSDB)} method will be called immediately after the plugin is
+ * instantiated and before any other methods are called.
+ * @since 2.3
+ */
+public abstract class WriteableDataPointFilterPlugin {
+  
+  /**
+   * Called by TSDB to initialize the plugin
+   * Implementations are responsible for setting up any IO they need as well
+   * as starting any required background threads.
+   * <b>Note:</b> Implementations should throw exceptions if they can't start
+   * up properly. The TSD will then shutdown so the operator can fix the 
+   * problem. Please use IllegalArgumentException for configuration issues.
+   * @param tsdb The parent TSDB object
+   * @throws IllegalArgumentException if required configuration parameters are 
+   * missing
+   * @throws Exception if something else goes wrong
+   */
+  public abstract void initialize(final TSDB tsdb);
+
+  /**
+   * Called to gracefully shutdown the plugin. Implementations should close 
+   * any IO they have open
+   * @return A deferred object that indicates the completion of the request.
+   * The {@link Object} has not special meaning and can be {@code null}
+   * (think of it as {@code Deferred<Void>}).
+   */
+  public abstract Deferred<Object> shutdown();
+  
+  /**
+   * Should return the version of this plugin in the format:
+   * MAJOR.MINOR.MAINT, e.g. "2.3.1". The MAJOR version should match the major
+   * version of OpenTSDB the plugin is meant to work with.
+   * @return A version string used to log the loaded version
+   */
+  public abstract String version();
+  
+  /**
+   * Called by the TSD when a request for statistics collection has come in. The
+   * implementation may provide one or more statistics. If no statistics are
+   * available for the implementation, simply stub the method.
+   * @param collector The collector used for emitting statistics
+   */
+  public abstract void collectStats(final StatsCollector collector);
+  
+  /**
+   * Determine whether or not the data point should be stored.
+   * If the data should not be stored, the implementation can return false or an 
+   * exception in the deferred object. Otherwise it should return true and the
+   * data point will be written to storage.
+   * @param metric The metric name for the data point
+   * @param timestamp The timestamp of the data
+   * @param value The value encoded as either an integer or floating point value
+   * @param tags The tags associated with the data point
+   * @param flags Encoding flags for the value
+   * @return True if the data should be written, false if it should be rejected.
+   */
+  public abstract Deferred<Boolean> allowDataPoint(
+      final String metric,
+      final long timestamp,
+      final byte[] value,
+      final Map<String, String> tags,
+      final short flags);
+  
+  /**
+   * Whether or not the filter should process data points.
+   * @return False if {@link #allowDataPoint(String, long, byte[], Map, short)}
+   * should NOT be called, true if it should.
+   */
+  public abstract boolean filterDataPoints();
+}
diff --git a/src/examples/AddDataExample.java b/src/examples/AddDataExample.java
new file mode 100644
index 0000000000..7c16c69ac3
--- /dev/null
+++ b/src/examples/AddDataExample.java
@@ -0,0 +1,141 @@
+// This file is part of OpenTSDB.
+// Copyright (C) 2015  The OpenTSDB Authors.
+//
+// This program is free software: you can redistribute it and/or modify it
+// under the terms of the GNU Lesser General Public License as published by
+// the Free Software Foundation, either version 2.1 of the License, or (at your
+// option) any later version.  This program is distributed in the hope that it
+// will be useful, but WITHOUT ANY WARRANTY; without even the implied warranty
+// of MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser
+// General Public License for more details.  You should have received a copy
+// of the GNU Lesser General Public License along with this program.  If not,
+// see <http://www.gnu.org/licenses/>.
+
+package net.opentsdb.examples;
+
+import java.util.ArrayList;
+import java.util.HashMap;
+import java.util.Map;
+
+import com.stumbleupon.async.Callback;
+import com.stumbleupon.async.Deferred;
+
+import net.opentsdb.core.TSDB;
+import net.opentsdb.uid.NoSuchUniqueName;
+import net.opentsdb.uid.UniqueId.UniqueIdType;
+import net.opentsdb.utils.Config;
+
+/**
+ * Examples for how to add points to the tsdb.
+ * 
+ */
+public class AddDataExample {
+  private static String pathToConfigFile;
+  
+  public static void processArgs(final String[] args) {
+    // Set these as arguments so you don't have to keep path information in
+    // source files
+    if (args != null && args.length > 0) {
+      pathToConfigFile = args[0];
+    }
+  }
+
+  public static void main(final String[] args) throws Exception {
+    processArgs(args);
+    
+    // Create a config object with a path to the file for parsing. Or manually
+    // override settings.
+    // e.g. config.overrideConfig("tsd.storage.hbase.zk_quorum", "localhost");
+    final Config config;
+    if (pathToConfigFile != null && !pathToConfigFile.isEmpty()) {
+      config = new Config(pathToConfigFile);
+    } else {
+      // Search for a default config from /etc/opentsdb/opentsdb.conf, etc.
+      config = new Config(true);
+    }
+    final TSDB tsdb = new TSDB(config);
+
+    // Declare new metric
+    String metricName = "my.tsdb.test.metric";
+    // First check to see it doesn't already exist
+    byte[] byteMetricUID; // we don't actually need this for the first
+                          // .addPoint() call below.
+    // TODO: Ideally we could just call a not-yet-implemented tsdb.uIdExists()
+    // function. 
+    // Note, however, that this is optional. If auto metric is enabled
+    // (tsd.core.auto_create_metrics), the UID will be assigned in call to 
+    // addPoint().
+    try {
+      byteMetricUID = tsdb.getUID(UniqueIdType.METRIC, metricName);
+    } catch (IllegalArgumentException iae) {
+      System.out.println("Metric name not valid.");
+      iae.printStackTrace();
+      System.exit(1);
+    } catch (NoSuchUniqueName nsune) {
+      // If not, great. Create it.
+      byteMetricUID = tsdb.assignUid("metric", metricName);
+    }
+
+    // Make a single datum
+    long timestamp = System.currentTimeMillis() / 1000;
+    long value = 314159;
+    // Make key-val
+    Map<String, String> tags = new HashMap<String, String>(1);
+    tags.put("script", "example1");
+    
+    // Start timer
+    long startTime1 = System.currentTimeMillis();
+    
+    // Write a number of data points at 30 second intervals. Each write will 
+    // return a deferred (similar to a Java Future or JS Promise) that will 
+    // be called on completion with either a "null" value on success or an
+    // exception.
+    int n = 100;
+    ArrayList<Deferred<Object>> deferreds = new ArrayList<Deferred<Object>>(n);
+    for (int i = 0; i < n; i++) {
+      Deferred<Object> deferred = tsdb.addPoint(metricName, timestamp, value + i, tags);
+      deferreds.add(deferred);
+      timestamp += 30;
+    }
+    
+    // Add the callbacks to the deferred object. (They might have already
+    // returned, btw)
+    // This will cause the calling thread to wait until the add has completed.
+    System.out.println("Waiting for deferred result to return...");
+    Deferred.groupInOrder(deferreds)
+        .addErrback(new AddDataExample().new errBack())
+        .addCallback(new AddDataExample().new succBack())
+    // Block the thread until the deferred returns it's result. 
+        .join();
+    // Alternatively you can add another callback here or use a join with a 
+    // timeout argument.
+    
+    // End timer.
+    long elapsedTime1 = System.currentTimeMillis() - startTime1;
+    System.out.println("\nAdding " + n + " points took: " + elapsedTime1
+        + " milliseconds.\n");
+
+    // Gracefully shutdown connection to TSDB. This is CRITICAL as it will 
+    // flush any pending operations to HBase.
+    tsdb.shutdown().join();    
+  }
+
+  // This is an optional errorback to handle when there is a failure.
+  class errBack implements Callback<String, Exception> {
+    public String call(final Exception e) throws Exception {
+      String message = ">>>>>>>>>>>Failure!>>>>>>>>>>>";
+      System.err.println(message + " " + e.getMessage());
+      e.printStackTrace();
+      return message;
+    }
+  };
+
+  // This is an optional success callback to handle when there is a success.
+  class succBack implements Callback<Object, ArrayList<Object>> {
+    public Object call(final ArrayList<Object> results) {
+      System.out.println("Successfully wrote " + results.size() + " data points");
+      return null;
+    }
+  };
+
+}
diff --git a/src/examples/QueryExample.java b/src/examples/QueryExample.java
new file mode 100644
index 0000000000..d03b23ea7c
--- /dev/null
+++ b/src/examples/QueryExample.java
@@ -0,0 +1,198 @@
+// This file is part of OpenTSDB.
+// Copyright (C) 2015  The OpenTSDB Authors.
+//
+// This program is free software: you can redistribute it and/or modify it
+// under the terms of the GNU Lesser General Public License as published by
+// the Free Software Foundation, either version 2.1 of the License, or (at your
+// option) any later version.  This program is distributed in the hope that it
+// will be useful, but WITHOUT ANY WARRANTY; without even the implied warranty
+// of MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser
+// General Public License for more details.  You should have received a copy
+// of the GNU Lesser General Public License along with this program.  If not,
+// see <http://www.gnu.org/licenses/>.
+package net.opentsdb.examples;
+
+import java.io.IOException;
+import java.util.ArrayList;
+import java.util.List;
+import java.util.Map;
+
+import com.stumbleupon.async.Callback;
+import com.stumbleupon.async.Deferred;
+
+import net.opentsdb.core.DataPoint;
+import net.opentsdb.core.DataPoints;
+import net.opentsdb.core.Query;
+import net.opentsdb.core.SeekableView;
+import net.opentsdb.core.TSDB;
+import net.opentsdb.core.TSQuery;
+import net.opentsdb.core.TSSubQuery;
+import net.opentsdb.query.filter.TagVFilter;
+import net.opentsdb.utils.Config;
+import net.opentsdb.utils.DateTime;
+
+/**
+ * One example on how to query.
+ * Taken from 
+ * <a href="https://groups.google.com/forum/#!searchin/opentsdb/java$20api/opentsdb/6MKs-FkSLoA/gifHF327CIAJ">
+ * this thread</a>
+ * The metric and key query arguments assume that you've input data from the Quick Start tutorial
+ * <a href="http://opentsdb.net/docs/build/html/user_guide/quickstart.html">here.</a>
+ */
+public class QueryExample {
+
+  public static void main(final String[] args) throws IOException {
+    
+    // Set these as arguments so you don't have to keep path information in
+    // source files 
+    String pathToConfigFile = (args != null && args.length > 0 ? args[0] : null);
+    
+    // Create a config object with a path to the file for parsing. Or manually
+    // override settings.
+    // e.g. config.overrideConfig("tsd.storage.hbase.zk_quorum", "localhost");
+    final Config config;
+    if (pathToConfigFile != null && !pathToConfigFile.isEmpty()) {
+      config = new Config(pathToConfigFile);
+    } else {
+      // Search for a default config from /etc/opentsdb/opentsdb.conf, etc.
+      config = new Config(true);
+    }
+    final TSDB tsdb = new TSDB(config);
+    
+    // main query
+    final TSQuery query = new TSQuery();
+    
+    // use any string format from
+    // http://opentsdb.net/docs/build/html/user_guide/query/dates.html
+    query.setStart("1h-ago");
+    // Optional: set other global query params
+
+    // at least one sub query required. This is where you specify the metric and
+    // tags
+    final TSSubQuery subQuery = new TSSubQuery();
+    subQuery.setMetric("my.tsdb.test.metric");
+
+    // filters are optional but useful.
+    final List<TagVFilter> filters = new ArrayList<TagVFilter>(1);
+    filters.add(new TagVFilter.Builder()
+        .setType("literal_or")
+        .setFilter("example1")
+        .setTagk("script")
+        .setGroupBy(true)
+        .build());
+    subQuery.setFilters(filters);
+    
+    // you do have to set an aggregator. Just provide the name as a string
+    subQuery.setAggregator("sum");
+
+    // IMPORTANT: don't forget to add the subQuery
+    final ArrayList<TSSubQuery> subQueries = new ArrayList<TSSubQuery>(1);
+    subQueries.add(subQuery);
+    query.setQueries(subQueries);
+    query.setMsResolution(true); // otherwise we aggregate on the second. 
+
+    // make sure the query is valid. This will throw exceptions if something
+    // is missing
+    query.validateAndSetQuery();
+
+    // compile the queries into TsdbQuery objects behind the scenes
+    Query[] tsdbqueries = query.buildQueries(tsdb);
+
+    // create some arrays for storing the results and the async calls
+    final int nqueries = tsdbqueries.length;
+    final ArrayList<DataPoints[]> results = new ArrayList<DataPoints[]>(
+        nqueries);
+    final ArrayList<Deferred<DataPoints[]>> deferreds = 
+        new ArrayList<Deferred<DataPoints[]>>(nqueries);
+
+    // this executes each of the sub queries asynchronously and puts the
+    // deferred in an array so we can wait for them to complete.
+    for (int i = 0; i < nqueries; i++) {
+      deferreds.add(tsdbqueries[i].runAsync());
+    }
+
+    // Start timer
+    long startTime = DateTime.nanoTime();
+    
+    // This is a required callback class to store the results after each
+    // query has finished
+    class QueriesCB implements Callback<Object, ArrayList<DataPoints[]>> {
+      public Object call(final ArrayList<DataPoints[]> queryResults)
+          throws Exception {
+        results.addAll(queryResults);
+        return null;
+      }
+    }
+    
+    // Make sure to handle any errors that might crop up
+    class QueriesEB implements Callback<Object, Exception> {
+      @Override
+      public Object call(final Exception e) throws Exception {
+        System.err.println("Queries failed");
+        e.printStackTrace();
+        return null;
+      }
+    }
+
+    // this will cause the calling thread to wait until ALL of the queries
+    // have completed.
+    try {
+      Deferred.groupInOrder(deferreds)
+          .addCallback(new QueriesCB())
+          .addErrback(new QueriesEB())
+          .join();
+    } catch (Exception e) {
+      e.printStackTrace();
+    }
+
+    // End timer.
+    double elapsedTime = DateTime.msFromNanoDiff(DateTime.nanoTime(), startTime);
+    System.out.println("Query returned in: " + elapsedTime + " milliseconds.");
+    
+    // now all of the results are in so we just iterate over each set of
+    // results and do any processing necessary.
+    for (final DataPoints[] dataSets : results) {
+      for (final DataPoints data : dataSets) {
+        System.out.print(data.metricName());
+        Map<String, String> resolvedTags = data.getTags();
+        for (final Map.Entry<String, String> pair : resolvedTags.entrySet()) {
+          System.out.print(" " + pair.getKey() + "=" + pair.getValue());
+        }
+        System.out.print("\n");
+
+        final SeekableView it = data.iterator();
+        /*
+         * An important point about SeekableView:
+         * Because no data is copied during iteration and no new object gets
+         * created, the DataPoint returned must not be stored and gets
+         * invalidated as soon as next is called on the iterator (actually it
+         * doesn't get invalidated but rather its contents changes). If you want
+         * to store individual data points, you need to copy the timestamp and
+         * value out of each DataPoint into your own data structures.
+         * 
+         * In the vast majority of cases, the iterator will be used to go once
+         * through all the data points, which is why it's not a problem if the
+         * iterator acts just as a transient "view". Iterating will be very
+         * cheap since no memory allocation is required (except to instantiate
+         * the actual iterator at the beginning).
+         */
+        while (it.hasNext()) {
+          final DataPoint dp = it.next();
+          System.out.println("  " + dp.timestamp() + " "
+              + (dp.isInteger() ? dp.longValue() : dp.doubleValue()));
+        }
+        System.out.println("");
+      }
+    }
+    
+    // Gracefully shutdown connection to TSDB
+    try {
+      tsdb.shutdown().join();
+    } catch (InterruptedException e) {
+      e.printStackTrace();
+    } catch (Exception e) {
+      e.printStackTrace();
+    }
+  }
+
+}
\ No newline at end of file
diff --git a/src/meta/MetaDataCache.java b/src/meta/MetaDataCache.java
new file mode 100644
index 0000000000..96504b1ce7
--- /dev/null
+++ b/src/meta/MetaDataCache.java
@@ -0,0 +1,73 @@
+// This file is part of OpenTSDB.
+// Copyright (C) 2016  The OpenTSDB Authors.
+//
+// This program is free software: you can redistribute it and/or modify it
+// under the terms of the GNU Lesser General Public License as published by
+// the Free Software Foundation, either version 2.1 of the License, or (at your
+// option) any later version.  This program is distributed in the hope that it
+// will be useful, but WITHOUT ANY WARRANTY; without even the implied warranty
+// of MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser
+// General Public License for more details.  You should have received a copy
+// of the GNU Lesser General Public License along with this program.  If not,
+// see <http://www.gnu.org/licenses/>.
+package net.opentsdb.meta;
+
+import com.stumbleupon.async.Deferred;
+
+import net.opentsdb.core.TSDB;
+import net.opentsdb.stats.StatsCollector;
+
+/**
+ * This is a first stab at a meta data cache. Initially it only handles
+ * incrementing TSUID counters in a local database. The class will then 
+ * periodically sync the local counter cache with HBase and generate TSMeta
+ * objects if necessary. This keeps us from having to maintain thousands or
+ * millions of callback objects in memory while we wait for individual atomic
+ * increments per data point. 
+ * @since 2.3
+ */
+public abstract class MetaDataCache {
+  
+  /**
+   * Called by TSDB to initialize the plugin
+   * Implementations are responsible for setting up any IO they need as well
+   * as starting any required background threads.
+   * <b>Note:</b> Implementations should throw exceptions if they can't start
+   * up properly. The TSD will then shutdown so the operator can fix the 
+   * problem. Please use IllegalArgumentException for configuration issues.
+   * @param tsdb The parent TSDB object
+   * @throws IllegalArgumentException if required configuration parameters are 
+   * missing
+   * @throws Exception if something else goes wrong
+   */
+  public abstract void initialize(final TSDB tsdb);
+
+  /**
+   * Called when the TSD is shutting down to gracefully flush any buffers or
+   * close open connections.
+   */
+  public abstract Deferred<Object> shutdown();
+
+  /**
+   * Should return the version of this plugin in the format:
+   * MAJOR.MINOR.MAINT, e.g. 2.0.1. The MAJOR version should match the major
+   * version of OpenTSDB the plugin is meant to work with.
+   * @return A version string used to log the loaded version
+   */
+  public abstract String version();
+  
+  /**
+   * Called by the TSD when a request for statistics collection has come in. The
+   * implementation may provide one or more statistics. If no statistics are
+   * available for the implementation, simply stub the method.
+   * @param collector The collector used for emitting statistics
+   */
+  public abstract void collectStats(final StatsCollector collector);
+
+  /**
+   * Increments the given TSUID in the cache by 1
+   * @param tsuid The tsuid to increment 
+   */
+  public abstract void increment(final byte[] tsuid);
+
+}
diff --git a/src/opentsdb.conf b/src/opentsdb.conf
index a06420e9f2..8ba7028a52 100644
--- a/src/opentsdb.conf
+++ b/src/opentsdb.conf
@@ -7,7 +7,7 @@ tsd.network.port =
 # tsd.network.bind = 0.0.0.0
 
 # Disable Nagel's algorithm, default is True
-#tsd.network.tcpnodelay = true
+#tsd.network.tcp_no_delay = true
 
 # Determines whether or not to send keepalive packets to peers, default
 # is True
@@ -15,7 +15,7 @@ tsd.network.port =
 
 # Determines if the same socket should be used for new connections, default
 # is True
-#tsd.network.reuseaddress = true
+#tsd.network.reuse_address = true
 
 # Number of worker threads dedicated to Netty, defaults to # of CPUs * 2
 #tsd.network.worker_threads = 8
@@ -37,6 +37,14 @@ tsd.http.cachedir =
 # is False
 #tsd.core.auto_create_metrics = false
 
+# Whether or not to enable the built-in UI Rpc Plugins, default
+# is True
+#tsd.core.enable_ui = true
+
+# Whether or not to enable the built-in API Rpc Plugins, default
+# is True
+#tsd.core.enable_api = true
+
 # --------- STORAGE ----------
 # Whether or not to enable data compaction in HBase, default is True
 #tsd.storage.enable_compaction = true
@@ -45,6 +53,9 @@ tsd.http.cachedir =
 # default is 1,000
 # tsd.storage.flush_interval = 1000
 
+# Max number of rows to be returned per Scanner round trip
+# tsd.storage.hbase.scanner.maxNumRows = 128
+
 # Name of the HBase table where data points are stored, default is "tsdb"
 #tsd.storage.hbase.data_table = tsdb
 
diff --git a/src/parser.jj b/src/parser.jj
new file mode 100644
index 0000000000..29b00c9e40
--- /dev/null
+++ b/src/parser.jj
@@ -0,0 +1,74 @@
+/** Options required by Maven */
+options {
+  STATIC = false;
+  LOOKAHEAD = 5;
+}
+
+PARSER_BEGIN(SyntaxChecker)
+package net.opentsdb.query.expression.parser;
+
+import net.opentsdb.query.expression.ExpressionTree;
+import net.opentsdb.core.TSQuery;
+
+import java.util.List;
+import com.google.common.base.Joiner;
+import com.google.common.collect.Lists;
+
+/**
+* A simple class for validating the expressions
+* @since 2.3
+*/
+public class SyntaxChecker {
+
+  private TSQuery data_query;
+  private List<String> metricQueries;
+
+  public void setTSQuery(TSQuery data_query) {
+    this.data_query = data_query;
+  }
+
+  public void setMetricQueries(List<String> metricQueries) {
+    this.metricQueries = metricQueries;
+  }
+
+  public static void main(String[] args) {
+    try {
+      new SyntaxChecker(new java.io.StringReader(args[0])).EXPRESSION();
+      System.out.println("Syntax is okay");
+    } catch (Throwable e) {
+      // Catching Throwable is ugly but JavaCC throws Error objects!
+      System.out.println("Syntax check failed: " + e.getMessage());
+    }
+  }
+}
+
+PARSER_END(SyntaxChecker)
+
+SKIP:  { " " | "\t" | "\n" | "\r"                    }
+TOKEN: { <NAME: ("*" | (["a" - "z"] | ["A" - "Z"]| ["0"-"9"] | "-" | "_" | "#" | "/" | "$" | "@" | "|" | "." | "'" | "]" | "[")+ )> }
+TOKEN: { <PARAM: ("&&")> }
+
+ExpressionTree EXPRESSION():  {Token name; int paramIndex=0;}  {
+        name=<NAME> { ExpressionTree tree=new ExpressionTree(name.image,data_query); }
+        "(" PARAMETER(tree, paramIndex++) ("," PARAMETER(tree, paramIndex++))* ")"
+        {return tree;}
+}
+
+void PARAMETER(ExpressionTree tree, int paramIndex):  {String metric; Token param; ExpressionTree subTree;}  {
+        subTree=EXPRESSION() {tree.addSubExpression(subTree, paramIndex);} |
+        metric=METRIC() {metricQueries.add(metric); tree.addSubMetricQuery(metric, metricQueries.size()-1, paramIndex);} |
+        param=<NAME> {tree.addFunctionParameter(param.image);}
+}
+
+// metric is agg:[interval-agg:][rate:]metric[{tag=value,...}]
+String METRIC()    :  {Token agg,itvl,rate,metric,tagk,tagv; StringBuilder builder = new StringBuilder();
+                     Joiner JOINER = Joiner.on(",").skipNulls();
+                     List<String> tagPairs = Lists.newArrayList();
+                     } {
+                        agg =  <NAME> ":" { builder.append(agg.image).append(":"); }
+                        (itvl=<NAME> ":" { builder.append(itvl.image).append(":"); })?
+                        (rate=<NAME> ":" { builder.append(rate.image).append(":"); })?
+                        metric=<NAME> { builder.append(metric.image); }
+                        ("{" tagk=<NAME> "=" tagv=<NAME> {tagPairs.add(tagk+"="+tagv);}
+                             ("," tagk=<NAME> "=" tagv=<NAME> {tagPairs.add(tagk+"="+tagv);})* "}")?
+                             {if (tagPairs.size() > 0) builder.append("{").append(JOINER.join(tagPairs)).append("}"); return builder.toString();} }
\ No newline at end of file
diff --git a/src/query/QueryUtil.java b/src/query/QueryUtil.java
index ab168536ea..c7b9782b2a 100644
--- a/src/query/QueryUtil.java
+++ b/src/query/QueryUtil.java
@@ -20,12 +20,19 @@
 import java.util.Map.Entry;
 
 import net.opentsdb.core.Const;
+import net.opentsdb.core.Internal;
 import net.opentsdb.core.RowKey;
 import net.opentsdb.core.TSDB;
 import net.opentsdb.uid.UniqueId;
 
 import org.hbase.async.Bytes;
+import org.hbase.async.FilterList;
+import org.hbase.async.FuzzyRowFilter;
+import org.hbase.async.KeyRegexpFilter;
 import org.hbase.async.Bytes.ByteMap;
+import org.slf4j.Logger;
+import org.slf4j.LoggerFactory;
+import org.hbase.async.ScanFilter;
 import org.hbase.async.Scanner;
 
 /**
@@ -34,6 +41,7 @@
  * @since 2.2
  */
 public class QueryUtil {
+  private static final Logger LOG = LoggerFactory.getLogger(QueryUtil.class);
   
   /**
    * Crafts a regular expression for scanning over data table rows and filtering
@@ -48,9 +56,35 @@ public class QueryUtil {
    */
   public static String getRowKeyUIDRegex(final List<byte[]> group_bys, 
       final ByteMap<byte[][]> row_key_literals) {
+    return getRowKeyUIDRegex(group_bys, row_key_literals, false, null, null);
+  }
+  
+  /**
+   * Crafts a regular expression for scanning over data table rows and filtering
+   * time series that the user doesn't want. Also fills in an optional fuzzy
+   * mask and key as it builds the regex if configured to do so.
+   * @param group_bys An optional list of tag keys that we want to group on. May
+   * be null.
+   * @param row_key_literals An optional list of key value pairs to filter on.
+   * May be null.
+   * @param explicit_tags Whether or not explicit tags are enabled so that the
+   * regex only picks out series with the specified tags
+   * @param fuzzy_key An optional fuzzy filter row key
+   * @param fuzzy_mask An optional fuzzy filter mask
+   * @return A regular expression string to pass to the storage layer.
+   * @since 2.3
+   */
+  public static String getRowKeyUIDRegex(
+      final List<byte[]> group_bys, 
+      final ByteMap<byte[][]> row_key_literals, 
+      final boolean explicit_tags,
+      final byte[] fuzzy_key, 
+      final byte[] fuzzy_mask) {
     if (group_bys != null) {
       Collections.sort(group_bys, Bytes.MEMCMP);
     }
+    final int prefix_width = Const.SALT_WIDTH() + TSDB.metrics_width() + 
+        Const.TIMESTAMP_BYTES;
     final short name_width = TSDB.tagk_width();
     final short value_width = TSDB.tagv_width();
     final short tagsize = (short) (name_width + value_width);
@@ -73,7 +107,14 @@ public static String getRowKeyUIDRegex(final List<byte[]> group_bys,
 
     final Iterator<Entry<byte[], byte[][]>> it = row_key_literals == null ? 
         new ByteMap<byte[][]>().iterator() : row_key_literals.iterator();
-
+    int fuzzy_offset = Const.SALT_WIDTH() + TSDB.metrics_width();
+    if (fuzzy_mask != null) {
+      // make sure to skip the timestamp when scanning
+      while (fuzzy_offset < prefix_width) {
+        fuzzy_mask[fuzzy_offset++] = 1;
+      }
+    }
+    
     while(it.hasNext()) {
       Entry<byte[], byte[][]> entry = it.hasNext() ? it.next() : null;
       // TODO - This look ahead may be expensive. We need to get some data around
@@ -83,7 +124,19 @@ public static String getRowKeyUIDRegex(final List<byte[]> group_bys,
           entry.getValue() != null && entry.getValue().length == 0;
       
       // Skip any number of tags.
-      buf.append("(?:.{").append(tagsize).append("})*");
+      if (!explicit_tags) {
+        buf.append("(?:.{").append(tagsize).append("})*");
+      } else if (fuzzy_mask != null) {
+        // TODO - see if we can figure out how to improve the fuzzy filter by
+        // setting explicit tag values whenever we can. In testing there was
+        // a conflict between the row key regex and fuzzy filter that prevented
+        // results from returning properly.
+        System.arraycopy(entry.getKey(), 0, fuzzy_key, fuzzy_offset, name_width);
+        fuzzy_offset += name_width;
+        for (int i = 0; i < value_width; i++) {
+          fuzzy_mask[fuzzy_offset++] = 1;
+        }
+      }
       if (not_key) {
         // start the lookahead as we have a key we explicitly do not want in the
         // results
@@ -115,10 +168,95 @@ public static String getRowKeyUIDRegex(final List<byte[]> group_bys,
       }
     }
     // Skip any number of tags before the end.
-    buf.append("(?:.{").append(tagsize).append("})*$");
+    if (!explicit_tags) {
+      buf.append("(?:.{").append(tagsize).append("})*");
+    }
+    buf.append("$");
     return buf.toString();
   }
   
+  /**
+   * Sets a filter or filter list on the scanner based on whether or not the
+   * query had tags it needed to match.
+   * @param scanner The scanner to modify.
+   * @param group_bys An optional list of tag keys that we want to group on. May
+   * be null.
+   * @param row_key_literals An optional list of key value pairs to filter on.
+   * May be null.
+   * @param explicit_tag sWhether or not explicit tags are enabled so that the
+   * regex only picks out series with the specified tags
+   * @param enable_fuzzy_filter Whether or not a fuzzy filter should be used
+   * in combination with the explicit tags param. If explicit tags is disabled
+   * then this param is ignored. 
+   * @param end_time The end of the query time so the fuzzy filter knows when
+   * to stop scanning.
+   */
+  public static void setDataTableScanFilter(
+      final Scanner scanner, 
+      final List<byte[]> group_bys, 
+      final ByteMap<byte[][]> row_key_literals,
+      final boolean explicit_tags,
+      final boolean enable_fuzzy_filter,
+      final int end_time) {
+    
+    // no-op
+    if ((group_bys == null || group_bys.isEmpty()) 
+        && (row_key_literals == null || row_key_literals.isEmpty())) {
+      return;
+    }
+    
+    final int prefix_width = Const.SALT_WIDTH() + TSDB.metrics_width() + 
+        Const.TIMESTAMP_BYTES;
+    final short name_width = TSDB.tagk_width();
+    final short value_width = TSDB.tagv_width();
+    final byte[] fuzzy_key;
+    final byte[] fuzzy_mask;
+    if (explicit_tags && enable_fuzzy_filter) {
+      fuzzy_key = new byte[prefix_width + (row_key_literals.size() * 
+          (name_width + value_width))];
+      fuzzy_mask = new byte[prefix_width + (row_key_literals.size() *
+          (name_width + value_width))];
+      System.arraycopy(scanner.getCurrentKey(), 0, fuzzy_key, 0, 
+          scanner.getCurrentKey().length);
+    } else {
+      fuzzy_key = fuzzy_mask = null;
+    }
+    
+    final String regex = getRowKeyUIDRegex(group_bys, row_key_literals, 
+        explicit_tags, fuzzy_key, fuzzy_mask);
+    final KeyRegexpFilter regex_filter = new KeyRegexpFilter(
+        regex.toString(), Const.ASCII_CHARSET);
+    if (LOG.isDebugEnabled()) {
+      LOG.debug("Regex for scanner: " + scanner + ": " + 
+          byteRegexToString(regex));
+    }
+    
+    if (!(explicit_tags && enable_fuzzy_filter)) {
+      scanner.setFilter(regex_filter);
+      return;
+    }
+    
+    scanner.setStartKey(fuzzy_key);
+    final byte[] stop_key = Arrays.copyOf(fuzzy_key, fuzzy_key.length);
+    Internal.setBaseTime(stop_key, end_time);
+    int idx = Const.SALT_WIDTH() + TSDB.metrics_width() + 
+        Const.TIMESTAMP_BYTES + TSDB.tagk_width();
+    // max out the tag values
+    while (idx < stop_key.length) {
+      for (int i = 0; i < TSDB.tagv_width(); i++) {
+        stop_key[idx++] = (byte) 0xFF;
+      }
+      idx += TSDB.tagk_width();
+    }
+    scanner.setStopKey(stop_key);
+    final List<ScanFilter> filters = new ArrayList<ScanFilter>(2);
+    filters.add(
+        new FuzzyRowFilter(
+            new FuzzyRowFilter.FuzzyFilterPair(fuzzy_key, fuzzy_mask)));
+    filters.add(regex_filter);
+    scanner.setFilter(new FilterList(filters));
+  }
+  
   /**
    * Creates a regular expression with a list of or'd TUIDs to compare
    * against the rows in storage.
@@ -202,6 +340,7 @@ public static Scanner getMetricScanner(final TSDB tsdb, final int salt_bucket,
     System.arraycopy(metric, 0, end_row, Const.SALT_WIDTH(), metric_width);
     
     final Scanner scanner = tsdb.getClient().newScanner(table);
+    scanner.setMaxNumRows(tsdb.getConfig().scanner_maxNumRows());
     scanner.setStartKey(start_row);
     scanner.setStopKey(end_row);
     scanner.setFamily(family);
diff --git a/src/query/expression/Absolute.java b/src/query/expression/Absolute.java
new file mode 100644
index 0000000000..2b3cfb13f1
--- /dev/null
+++ b/src/query/expression/Absolute.java
@@ -0,0 +1,89 @@
+// This file is part of OpenTSDB.
+// Copyright (C) 2015  The OpenTSDB Authors.
+//
+// This program is free software: you can redistribute it and/or modify it
+// under the terms of the GNU Lesser General Public License as published by
+// the Free Software Foundation, either version 2.1 of the License, or (at your
+// option) any later version.  This program is distributed in the hope that it
+// will be useful, but WITHOUT ANY WARRANTY; without even the implied warranty
+// of MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser
+// General Public License for more details.  You should have received a copy
+// of the GNU Lesser General Public License along with this program.  If not,
+// see <http://www.gnu.org/licenses/>.
+package net.opentsdb.query.expression;
+
+import java.util.ArrayList;
+import java.util.List;
+
+import net.opentsdb.core.DataPoint;
+import net.opentsdb.core.DataPoints;
+import net.opentsdb.core.MutableDataPoint;
+import net.opentsdb.core.SeekableView;
+import net.opentsdb.core.TSQuery;
+
+/**
+ * Modifies each data point in the series with the absolute value, tossing away
+ * the signed component.
+ * @since 2.3
+ */
+public class Absolute implements Expression {
+
+  @Override
+  public DataPoints[] evaluate(final TSQuery data_query, 
+      final List<DataPoints[]> query_results, final List<String> params) {
+    if (data_query == null) {
+      throw new IllegalArgumentException("Missing time series query");
+    }
+    if (query_results == null || query_results.isEmpty()) {
+      return new DataPoints[]{};
+    }
+    
+    int num_results = 0;
+    for (DataPoints[] results: query_results) {
+      num_results += results.length;
+    }
+    
+    final DataPoints[] results = new DataPoints[num_results];
+    int ix = 0;
+    // one or more sub queries (m=...&m=...&m=...)
+    for (final DataPoints[] sub_query_result : query_results) {
+      // group bys (m=sum:foo{host=*})
+      for (final DataPoints dps : sub_query_result) {
+        results[ix++] = abs(dps);
+      }
+    }
+    return results;
+  }
+
+  /**
+   * Iterate over each data point and store the absolute value
+   * @param points The data points to modify
+   * @return The resulting data points
+   */
+  private DataPoints abs(final DataPoints points) {
+    // TODO(cl) - Using an array as the size function may not return the exact
+    // results and we should figure a way to avoid copying data anyway.
+    final List<DataPoint> dps = new ArrayList<DataPoint>();
+
+    final SeekableView view = points.iterator();
+    while (view.hasNext()) {
+      DataPoint pt = view.next();
+      if (pt.isInteger()) {
+        dps.add(MutableDataPoint.ofLongValue(
+            pt.timestamp(), Math.abs(pt.longValue())));
+      } else {
+        dps.add(MutableDataPoint.ofDoubleValue(
+            pt.timestamp(), Math.abs(pt.doubleValue())));
+      }
+    }
+    final DataPoint[] results = new DataPoint[dps.size()];
+    dps.toArray(results);
+    return new PostAggregatedDataPoints(points, results);
+  }
+
+  @Override
+  public String writeStringField(List<String> queryParams, String innerExpression) {
+    return "absolute(" + innerExpression + ")";
+  }
+
+}
diff --git a/src/query/expression/Alias.java b/src/query/expression/Alias.java
new file mode 100644
index 0000000000..737d1c46ba
--- /dev/null
+++ b/src/query/expression/Alias.java
@@ -0,0 +1,100 @@
+// This file is part of OpenTSDB.
+// Copyright (C) 2015  The OpenTSDB Authors.
+//
+// This program is free software: you can redistribute it and/or modify it
+// under the terms of the GNU Lesser General Public License as published by
+// the Free Software Foundation, either version 2.1 of the License, or (at your
+// option) any later version.  This program is distributed in the hope that it
+// will be useful, but WITHOUT ANY WARRANTY; without even the implied warranty
+// of MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser
+// General Public License for more details.  You should have received a copy
+// of the GNU Lesser General Public License along with this program.  If not,
+// see <http://www.gnu.org/licenses/>.
+package net.opentsdb.query.expression;
+
+import java.util.ArrayList;
+import java.util.List;
+
+import com.google.common.base.Joiner;
+
+import net.opentsdb.core.DataPoint;
+import net.opentsdb.core.DataPoints;
+import net.opentsdb.core.MutableDataPoint;
+import net.opentsdb.core.SeekableView;
+import net.opentsdb.core.TSQuery;
+
+/**
+ * Returns an alias if provided or the original metric name if not. The alias 
+ * may optionally contain a template for tag replacement so that tags are 
+ * advanced to the metric name for systems that require it. (e.g. flatten
+ * a name for Graphite).
+ * @since 2.3
+ */
+public class Alias implements Expression {
+
+  static Joiner COMMA_JOINER = Joiner.on(',').skipNulls();
+
+  @Override
+  public DataPoints[] evaluate(final TSQuery data_query, 
+      final List<DataPoints[]> query_results, final List<String> params) {
+    if (data_query == null) {
+      throw new IllegalArgumentException("Missing time series query");
+    }
+    if (query_results == null || query_results.isEmpty()) {
+      return new DataPoints[]{};
+    }
+    if (params == null || params.isEmpty()) {
+      throw new IllegalArgumentException("Missing the alias");
+    }
+    final String alias_template = COMMA_JOINER.join(params);
+    
+    int num_results = 0;
+    for (DataPoints[] results: query_results) {
+      num_results += results.length;
+    }
+    
+    final DataPoints[] results = new DataPoints[num_results];
+    int ix = 0;
+    // one or more sub queries (m=...&m=...&m=...)
+    for (final DataPoints[] sub_query_result : query_results) {
+      // group bys (m=sum:foo{host=*})
+      for (final DataPoints dps : sub_query_result) {
+        // TODO(cl) - Using an array as the size function may not return the exact
+        // results and we should figure a way to avoid copying data anyway.
+        final List<DataPoint> new_dps_list = new ArrayList<DataPoint>();
+        final SeekableView view = dps.iterator();
+        while (view.hasNext()) {
+          DataPoint pt = view.next();
+          if (pt.isInteger()) {
+            new_dps_list.add(MutableDataPoint.ofLongValue(
+                pt.timestamp(), Math.abs(pt.longValue())));
+          } else {
+            new_dps_list.add(MutableDataPoint.ofDoubleValue(
+                pt.timestamp(), Math.abs(pt.doubleValue())));
+          }
+        }
+        
+        final DataPoint[] new_dps = new DataPoint[dps.size()];
+        new_dps_list.toArray(new_dps);
+        final PostAggregatedDataPoints padps = new PostAggregatedDataPoints(
+            dps, new_dps);
+        
+        padps.setAlias(alias_template);
+        results[ix++] = padps;
+      }
+    }
+    return results;
+  }
+
+  @Override
+  public String writeStringField(final List<String> query_params, 
+      final String innerExpression) {
+    final StringBuilder buf = new StringBuilder();
+    buf.append("alias(")
+      .append(innerExpression)
+      .append(query_params == null || query_params.isEmpty() 
+        ? "" : "," + COMMA_JOINER.join(query_params))
+      .append(")");
+    return buf.toString();
+  }
+}
\ No newline at end of file
diff --git a/src/query/expression/DiffSeries.java b/src/query/expression/DiffSeries.java
new file mode 100644
index 0000000000..be8634b628
--- /dev/null
+++ b/src/query/expression/DiffSeries.java
@@ -0,0 +1,85 @@
+// This file is part of OpenTSDB.
+// Copyright (C) 2015  The OpenTSDB Authors.
+//
+// This program is free software: you can redistribute it and/or modify it
+// under the terms of the GNU Lesser General Public License as published by
+// the Free Software Foundation, either version 2.1 of the License, or (at your
+// option) any later version.  This program is distributed in the hope that it
+// will be useful, but WITHOUT ANY WARRANTY; without even the implied warranty
+// of MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser
+// General Public License for more details.  You should have received a copy
+// of the GNU Lesser General Public License along with this program.  If not,
+// see <http://www.gnu.org/licenses/>.
+package net.opentsdb.query.expression;
+
+import java.util.List;
+
+import net.opentsdb.core.DataPoints;
+import net.opentsdb.core.TSDB;
+import net.opentsdb.core.TSQuery;
+import net.opentsdb.query.expression.VariableIterator.SetOperator;
+
+/**
+ * Performs a UNION set join on up to 26 metric query results and returns the 
+ * difference.
+ */
+public class DiffSeries implements Expression {
+  /** The TSDB used for UID to name lookups */
+  final TSDB tsdb;
+  
+  /**
+   * Default ctor.
+   * @param tsdb The TSDB used for UID to name lookups
+   */
+  public DiffSeries(final TSDB tsdb) {
+    this.tsdb = tsdb;
+  }
+  
+  @Override
+  public DataPoints[] evaluate(final TSQuery data_query, 
+      final List<DataPoints[]> query_results, final List<String> params) {
+    if (data_query == null) {
+      throw new IllegalArgumentException("Missing time series query");
+    }
+    if (query_results == null || query_results.isEmpty()) {
+      return new DataPoints[]{};
+    }
+    
+    if (query_results.size() < 2 || query_results.size() > 26) {
+      throw new IllegalArgumentException("Must have 2 to 26 series, got " + 
+          query_results.size() + " instead");
+    }
+    
+    final StringBuilder buf = new StringBuilder();
+    char v = 'a';
+    for (int i = 0; i < query_results.size(); i++) {
+      buf.append(v++);
+      if (i < query_results.size() - 1) {
+        buf.append(" - ");
+      }
+    }
+    
+    final ExpressionIterator expression = new ExpressionIterator("diffSeries", 
+        buf.toString(), SetOperator.UNION, false, false);
+    v = 'a';
+    for (final DataPoints[] dps : query_results) {
+      final TimeSyncedIterator it = new TimeSyncedIterator(
+          Character.toString(v++), null, dps);
+      expression.addResults(it.getId(), it);
+    }
+    expression.compile();
+    
+    final DataPoints[] results = new DataPoints[expression.values().length];
+    for (int i = 0; i < expression.values().length; i++) {
+      results[i] = new EDPtoDPS(tsdb, i, expression);
+    }
+    return results;
+  }
+
+  @Override
+  public String writeStringField(final List<String> query_params, 
+      final String inner_expression) {
+    return "diffSeries(" + inner_expression + ")";
+  }
+
+}
diff --git a/src/query/expression/DivideSeries.java b/src/query/expression/DivideSeries.java
new file mode 100644
index 0000000000..cda975cd3f
--- /dev/null
+++ b/src/query/expression/DivideSeries.java
@@ -0,0 +1,86 @@
+// This file is part of OpenTSDB.
+// Copyright (C) 2015  The OpenTSDB Authors.
+//
+// This program is free software: you can redistribute it and/or modify it
+// under the terms of the GNU Lesser General Public License as published by
+// the Free Software Foundation, either version 2.1 of the License, or (at your
+// option) any later version.  This program is distributed in the hope that it
+// will be useful, but WITHOUT ANY WARRANTY; without even the implied warranty
+// of MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser
+// General Public License for more details.  You should have received a copy
+// of the GNU Lesser General Public License along with this program.  If not,
+// see <http://www.gnu.org/licenses/>.
+package net.opentsdb.query.expression;
+
+import java.util.List;
+
+import net.opentsdb.core.DataPoints;
+import net.opentsdb.core.TSDB;
+import net.opentsdb.core.TSQuery;
+import net.opentsdb.query.expression.VariableIterator.SetOperator;
+
+/**
+ * Performs a UNION set join on up to 26 metric query results and returns the 
+ * quotient.
+ */
+public class DivideSeries implements Expression {
+  /** The TSDB used for UID to name lookups */
+  final TSDB tsdb;
+  
+  /**
+   * Default ctor.
+   * @param tsdb The TSDB used for UID to name lookups
+   */
+  public DivideSeries(final TSDB tsdb) {
+    this.tsdb = tsdb;
+  }
+  
+  @Override
+  public DataPoints[] evaluate(final TSQuery data_query, 
+      final List<DataPoints[]> query_results, final List<String> params) {
+    if (data_query == null) {
+      throw new IllegalArgumentException("Missing time series query");
+    }
+    if (query_results == null || query_results.isEmpty()) {
+      return new DataPoints[]{};
+    }
+    
+    if (query_results.size() < 2 || query_results.size() > 26) {
+      throw new IllegalArgumentException("Must have 2 to 26 series, got " + 
+          query_results.size() + " instead");
+    }
+        
+    final StringBuilder buf = new StringBuilder();
+    char v = 'a';
+    for (int i = 0; i < query_results.size(); i++) {
+      buf.append(v++);
+      if (i < query_results.size() - 1) {
+        buf.append(" / ");
+      }
+    }
+    
+    final ExpressionIterator expression = new ExpressionIterator("divideSeries", 
+        buf.toString(), SetOperator.UNION, false, false);
+    v = 'a';
+    
+    for (final DataPoints[] dps : query_results) {
+      final TimeSyncedIterator it = new TimeSyncedIterator(
+          Character.toString(v++), null, dps);
+      expression.addResults(it.getId(), it);
+    }
+    expression.compile();
+    
+    final DataPoints[] results = new DataPoints[expression.values().length];
+    for (int i = 0; i < expression.values().length; i++) {
+      results[i] = new EDPtoDPS(tsdb, i, expression);
+    }
+    return results;
+  }
+
+  @Override
+  public String writeStringField(final List<String> query_params, 
+      final String inner_expression) {
+    return "divideSeries(" + inner_expression + ")";
+  }
+
+}
diff --git a/src/query/expression/EDPtoDPS.java b/src/query/expression/EDPtoDPS.java
new file mode 100644
index 0000000000..4c17ff70e6
--- /dev/null
+++ b/src/query/expression/EDPtoDPS.java
@@ -0,0 +1,246 @@
+// This file is part of OpenTSDB.
+// Copyright (C) 2015  The OpenTSDB Authors.
+//
+// This program is free software: you can redistribute it and/or modify it
+// under the terms of the GNU Lesser General Public License as published by
+// the Free Software Foundation, either version 2.1 of the License, or (at your
+// option) any later version.  This program is distributed in the hope that it
+// will be useful, but WITHOUT ANY WARRANTY; without even the implied warranty
+// of MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser
+// General Public License for more details.  You should have received a copy
+// of the GNU Lesser General Public License along with this program.  If not,
+// see <http://www.gnu.org/licenses/>.
+package net.opentsdb.query.expression;
+
+import java.util.ArrayList;
+import java.util.Collections;
+import java.util.List;
+import java.util.Map;
+
+import org.hbase.async.Bytes.ByteMap;
+
+import com.stumbleupon.async.Callback;
+import com.stumbleupon.async.Deferred;
+
+import net.opentsdb.core.DataPoint;
+import net.opentsdb.core.DataPoints;
+import net.opentsdb.core.MutableDataPoint;
+import net.opentsdb.core.SeekableView;
+import net.opentsdb.core.TSDB;
+import net.opentsdb.core.Tags;
+import net.opentsdb.meta.Annotation;
+import net.opentsdb.uid.UniqueId.UniqueIdType;
+import net.opentsdb.utils.ByteSet;
+
+/**
+ * An ugly temporary class for converting from an expression datapoint to a 
+ * standard data point for serialization in the default query format.
+ */
+public class EDPtoDPS implements DataPoints {
+  /** The TSDB used for UID to name lookups */
+  private final TSDB tsdb;
+  
+  /** The index of this data point in the iterator */
+  private final int index;
+  
+  /** The iterator that contains the results for this data point */
+  private final ExpressionIterator iterator;
+  
+  /** The list of data points from the iterator from which we read */
+  private final ExpressionDataPoint[] edps;
+  
+  /**
+   * Default ctor
+   * @param tsdb The TSDB used for UID to name lookups
+   * @param index The index of this data point in the iterator
+   * @param iterator The iterator that contains the results for this data point
+   */
+  public EDPtoDPS(final TSDB tsdb, final int index, 
+      final ExpressionIterator iterator) {
+    this.tsdb = tsdb;
+    this.index = index;
+    this.iterator = iterator;
+    edps = iterator.values();
+  }
+  
+  @Override
+  public String metricName() {
+    try {
+      return metricNameAsync().joinUninterruptibly();
+    } catch (RuntimeException e) {
+      throw e;
+    } catch (Exception e) {
+      throw new RuntimeException("Should never be here", e);
+    }
+  }
+
+  @Override
+  public Deferred<String> metricNameAsync() {
+    if (edps[index].metricUIDs() == null) {
+      throw new IllegalStateException("Iterator UID was null for index " + 
+          index + " and iterator " + iterator);
+    }
+    final byte[] uid = edps[index].metricUIDs().iterator().next();
+    return tsdb.getUidName(UniqueIdType.METRIC, uid);
+  }
+
+  @Override
+  public byte[] metricUID() {
+    if (edps[index].metricUIDs() == null) {
+      throw new IllegalStateException("Iterator UID was null for index " + 
+          index + " and iterator " + iterator);
+    }
+    return edps[index].metricUIDs().iterator().next();
+  }
+
+  @Override
+  public Map<String, String> getTags() {
+    try {
+      return getTagsAsync().joinUninterruptibly();
+    } catch (RuntimeException e) {
+      throw e;
+    } catch (Exception e) {
+      throw new RuntimeException("Should never be here", e);
+    }
+  }
+
+  @Override
+  public Deferred<Map<String, String>> getTagsAsync() {
+    return Tags.getTagsAsync(tsdb, edps[index].tags());
+  }
+
+  @Override
+  public ByteMap<byte[]> getTagUids() {
+    return edps[index].tags();
+  }
+
+  @Override
+  public List<String> getAggregatedTags() {
+    try {
+      return getAggregatedTagsAsync().joinUninterruptibly();
+    } catch (RuntimeException e) {
+      throw e;
+    } catch (Exception e) {
+      throw new RuntimeException("Should never be here", e);
+    }
+  }
+
+  @Override
+  public Deferred<List<String>> getAggregatedTagsAsync() {
+    final ByteSet tagks = edps[index].aggregatedTags();
+    final List<String> aggregated_tags = new ArrayList<String>(tagks.size());
+    
+    final List<Deferred<String>> names = 
+        new ArrayList<Deferred<String>>(tagks.size());
+    for (final byte[] tagk : tagks) {
+      names.add(tsdb.getUidName(UniqueIdType.TAGK, tagk));
+    }
+    
+    /** Adds the names to the aggregated_tags list */
+    final class ResolveCB implements Callback<List<String>, ArrayList<String>> {
+      @Override
+      public List<String> call(final ArrayList<String> names) throws Exception {
+        for (final String name : names) {
+          aggregated_tags.add(name);
+        }
+        return aggregated_tags;
+      }
+    }
+    
+    return Deferred.group(names).addCallback(new ResolveCB());
+  }
+
+  @Override
+  public List<byte[]> getAggregatedTagUids() {
+    final List<byte[]> agg_tags = new ArrayList<byte[]>(
+        edps[index].aggregatedTags());
+    return agg_tags;
+  }
+
+  @Override
+  public List<String> getTSUIDs() {
+    // TODO Fix it up
+    return Collections.emptyList();
+  }
+
+  @Override
+  public List<Annotation> getAnnotations() {
+    // TODO Fix it up
+    return Collections.emptyList();
+  }
+
+  @Override
+  public int size() {
+    // TODO Estimate
+    return -1;
+  }
+
+  @Override
+  public int aggregatedSize() {
+    // TODO Estimate
+    return -1;
+  }
+
+  @Override
+  public SeekableView iterator() {
+    return new Iterator();
+  }
+
+  @Override
+  public long timestamp(int i) {
+    throw new UnsupportedOperationException();
+  }
+
+  @Override
+  public boolean isInteger(int i) {
+    throw new UnsupportedOperationException();
+  }
+
+  @Override
+  public long longValue(int i) {
+    throw new UnsupportedOperationException();
+  }
+
+  @Override
+  public double doubleValue(int i) {
+    throw new UnsupportedOperationException();
+  }
+
+  @Override
+  public int getQueryIndex() {
+    // TODO Fix it up
+    return 0;
+  }
+  
+  /**
+   * Simple class that fills the local data point while iterating through the 
+   * expression data points at the proper index.
+   */
+  private class Iterator implements SeekableView {
+    /** A data pont to mutate as we iterate */
+    final MutableDataPoint dp = new MutableDataPoint();
+    
+    @Override
+    public boolean hasNext() {
+      return iterator.hasNext(index);
+    }
+
+    @Override
+    public DataPoint next() {
+      iterator.next(index);
+      dp.reset(edps[index].timestamp(), edps[index].toDouble());
+      return dp;
+    }
+
+    @Override
+    public void remove() {
+      throw new UnsupportedOperationException();
+    }
+
+    @Override
+    public void seek(long timestamp) {
+      throw new UnsupportedOperationException();
+    }
+    
+  }
+}
diff --git a/src/query/expression/Expression.java b/src/query/expression/Expression.java
new file mode 100644
index 0000000000..d7d15acc1d
--- /dev/null
+++ b/src/query/expression/Expression.java
@@ -0,0 +1,46 @@
+// This file is part of OpenTSDB.
+// Copyright (C) 2015  The OpenTSDB Authors.
+//
+// This program is free software: you can redistribute it and/or modify it
+// under the terms of the GNU Lesser General Public License as published by
+// the Free Software Foundation, either version 2.1 of the License, or (at your
+// option) any later version.  This program is distributed in the hope that it
+// will be useful, but WITHOUT ANY WARRANTY; without even the implied warranty
+// of MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser
+// General Public License for more details.  You should have received a copy
+// of the GNU Lesser General Public License along with this program.  If not,
+// see <http://www.gnu.org/licenses/>.
+package net.opentsdb.query.expression;
+
+import java.util.List;
+
+import net.opentsdb.core.DataPoints;
+import net.opentsdb.core.TSQuery;
+
+/**
+ * The interface for various expressions/functions used when querying OpenTSDB.
+ * @since 2.3
+ */
+public interface Expression {
+
+  /**
+   * Computes a set of results given the results of a {@link TSQuery} that may
+   * include multiple metrics and/or group by result sets.
+   * @param data_query The original query from the user
+   * @param results The results of the query
+   * @param params Parameters parsed from the expression endpoint related to
+   * the implementing function
+   * @return An array of data points resulting from the implementation
+   */
+  public DataPoints[] evaluate(TSQuery data_query, 
+      List<DataPoints[]> results, List<String> params);
+
+  /**
+   * TODO - document me!
+   * @param params
+   * @param inner_expression
+   * @return
+   */
+  public String writeStringField(List<String> params, String inner_expression);
+  
+}
diff --git a/src/query/expression/ExpressionDataPoint.java b/src/query/expression/ExpressionDataPoint.java
new file mode 100644
index 0000000000..620a3d7f31
--- /dev/null
+++ b/src/query/expression/ExpressionDataPoint.java
@@ -0,0 +1,253 @@
+// This file is part of OpenTSDB.
+// Copyright (C) 2015  The OpenTSDB Authors.
+//
+// This program is free software: you can redistribute it and/or modify it
+// under the terms of the GNU Lesser General Public License as published by
+// the Free Software Foundation, either version 2.1 of the License, or (at your
+// option) any later version.  This program is distributed in the hope that it
+// will be useful, but WITHOUT ANY WARRANTY; without even the implied warranty
+// of MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser
+// General Public License for more details.  You should have received a copy
+// of the GNU Lesser General Public License along with this program.  If not,
+// see <http://www.gnu.org/licenses/>.
+package net.opentsdb.query.expression;
+
+import java.util.HashSet;
+import java.util.Set;
+
+import org.hbase.async.Bytes.ByteMap;
+
+import net.opentsdb.core.DataPoint;
+import net.opentsdb.core.DataPoints;
+import net.opentsdb.core.MutableDataPoint;
+import net.opentsdb.utils.ByteSet;
+
+/**
+ * Contains the information for a series that has been processed through an 
+ * expression iterator. Each time a metric data point series set is added we 
+ * add the metric and compute the tag sets. 
+ * <p>
+ * As the iterator progresses, it will call into the {@link #reset} methods.
+ * @since 2.3
+ */
+public class ExpressionDataPoint implements DataPoint {
+
+  /** A list of metric UIDs wrapped up into this expression result */
+  private final ByteSet metric_uids;
+  
+  /** The list of tag key/value pairs common to all series in this expression */
+  private final ByteMap<byte[]> tags;
+  
+  /** The list of aggregated tag keys common to all series in this expression */
+  private final ByteSet aggregated_tags;
+  
+  /** The list of TSUIDs from all series in this expression */
+  private final Set<String> tsuids;
+  
+  /** The size of the aggregated results.
+   * TODO - this is simply the size of the first series added. We need a way
+   * to compute this properly.
+   */
+  private long size;
+  
+  /** The total number of raw data points in all series */
+  private long raw_size;
+  
+  /** The data point overwritten each time through the iterator */
+  private final MutableDataPoint dp;
+  
+  /** An index in the original {@link TimeSyncedIterator} iterator array */
+  private int index;
+  
+  /**
+   * Default ctor that simply sets up new objects for all internal fields.
+   * TODO - lazily initialize the field to avoid unused objects
+   */
+  public ExpressionDataPoint() {
+    metric_uids = new ByteSet();
+    tags = new ByteMap<byte[]>();
+    aggregated_tags = new ByteSet();
+    tsuids = new HashSet<String>();
+    dp = new MutableDataPoint();
+  }
+  
+  /**
+   * Ctor that sets up the meta data maps and initializes an empty dp
+   * @param dps The data point to pull meta from
+   */
+  @SuppressWarnings("unchecked")
+  public ExpressionDataPoint(final DataPoints dps) {
+    metric_uids = new ByteSet();
+    metric_uids.add(dps.metricUID());
+    tags = dps.getTagUids() != null ? 
+        (ByteMap<byte[]>) dps.getTagUids().clone() : new ByteMap<byte[]>();
+    aggregated_tags = new ByteSet();
+    if (dps.getAggregatedTagUids() != null) {
+      for (final byte[] tagk : dps.getAggregatedTagUids()) {
+        aggregated_tags.add(tagk);
+      }
+    }
+    tsuids = new HashSet<String>(dps.getTSUIDs());
+    // TODO - restore when these are faster
+    //size = dps.size();
+    //raw_size = dps.aggregatedSize();
+    dp = new MutableDataPoint();
+    dp.reset(Long.MAX_VALUE, Double.NaN);
+  }
+  
+  /**
+   * Ctor that clones the meta data of the existing dps and sets up an empty value
+   * @param dps The data point to pull meta from
+   */
+  @SuppressWarnings("unchecked")
+  public ExpressionDataPoint(final ExpressionDataPoint dps) {
+    metric_uids = new ByteSet();
+    metric_uids.addAll(dps.metric_uids);
+    tags = (ByteMap<byte[]>) dps.tags.clone();
+    aggregated_tags = new ByteSet();
+    aggregated_tags.addAll(dps.aggregated_tags);
+    tsuids = new HashSet<String>(dps.tsuids);
+    size = dps.size;
+    raw_size = dps.raw_size;
+    dp = new MutableDataPoint();
+    dp.reset(Long.MAX_VALUE, Double.NaN);
+  }
+  
+  /**
+   * Add another metric series to this collection, computing the tag and
+   * agg intersections and incrementing the size.
+   * @param dps The series to add
+   */
+  public void add(final DataPoints dps) {
+    metric_uids.add(dps.metricUID());
+    
+    // TODO - tags intersection
+    
+    for (final byte[] tagk : dps.getAggregatedTagUids()) {
+      aggregated_tags.add(tagk);
+    }
+    
+    tsuids.addAll(dps.getTSUIDs());
+    // TODO - this ain't right. We need to number of dps emitted from HERE. For
+    // now we'll just take the first dps size. If it's downsampled then this
+    // will be accurate.
+    //size += dps.size();
+    // TODO - restore when this is faster
+    //raw_size += dps.aggregatedSize();
+  }
+  
+  /**
+   * Add another metric series to this collection, computing the tag and
+   * agg intersections and incrementing the size.
+   * @param dps The series to add
+   */
+  public void add(final ExpressionDataPoint dps) {
+    metric_uids.addAll(dps.metric_uids);
+    
+    // TODO - tags intersection
+    
+    aggregated_tags.addAll(dps.aggregated_tags);
+    
+    tsuids.addAll(dps.tsuids);
+    // TODO - this ain't right. We need to number of dps emitted from HERE. For
+    // now we'll just take the first dps size. If it's downsampled then this
+    // will be accurate.
+    //size += dps.size();
+    raw_size += dps.raw_size;
+  }
+  
+  /** @return the metric UIDs */
+  public ByteSet metricUIDs() {
+    return metric_uids;
+  }
+  
+  /** @return the list of common tag pairs in the series */
+  public ByteMap<byte[]> tags() {
+    return tags;
+  }
+  
+  /** @return the list of aggregated tags */
+  public ByteSet aggregatedTags() {
+    return aggregated_tags;
+  }
+  
+  /** @return the list of TSUIDs aggregated into this series */
+  public Set<String> tsuids() {
+    return tsuids;
+  }
+  
+  /** @return the aggregated number of data points in this series */
+  public long size() {
+    return size;
+  }
+  
+  /** @return the number of raw data points in this series */
+  public long rawSize() {
+    return raw_size;
+  }
+  
+  /**
+   * Stores a Double data point
+   * @param timestamp The timestamp
+   * @param value The value
+   */
+  public void reset(final long timestamp, final double value) {
+    dp.reset(timestamp, value);
+  }
+  
+  /**
+   * Stores a data point pulled from the given data point interface
+   * @param dp the data point to read from
+   */
+  public void reset(final DataPoint dp) {
+    this.dp.reset(dp);
+  }
+
+  @Override
+  public String toString() {
+    final StringBuffer buf = new StringBuffer();
+    buf.append("ExpressionDataPoint(metricUIDs=")
+       .append(metric_uids)
+       .append(", tsuids=")
+       .append(tsuids)
+       .append(")");
+    return buf.toString();
+  }
+  
+  // DataPoint implementations
+  
+  @Override
+  public long timestamp() {
+    return dp.timestamp();
+  }
+
+  @Override
+  public boolean isInteger() {
+    return dp.isInteger();
+  }
+
+  @Override
+  public long longValue() {
+    return dp.longValue();
+  }
+
+  @Override
+  public double doubleValue() {
+    return dp.doubleValue();
+  }
+
+  @Override
+  public double toDouble() {
+    return dp.toDouble();
+  }
+  
+  /** @param index The index in the {@link TimeSyncedIterator} array */
+  public void setIndex(final int index) {
+    this.index = index;
+  }
+  
+  /** @return the index in the {@link TimeSyncedIterator} array */
+  public int getIndex() {
+    return index;
+  }
+}
diff --git a/src/query/expression/ExpressionFactory.java b/src/query/expression/ExpressionFactory.java
new file mode 100644
index 0000000000..e0fbdd44e8
--- /dev/null
+++ b/src/query/expression/ExpressionFactory.java
@@ -0,0 +1,95 @@
+// This file is part of OpenTSDB.
+// Copyright (C) 2015  The OpenTSDB Authors.
+//
+// This program is free software: you can redistribute it and/or modify it
+// under the terms of the GNU Lesser General Public License as published by
+// the Free Software Foundation, either version 2.1 of the License, or (at your
+// option) any later version.  This program is distributed in the hope that it
+// will be useful, but WITHOUT ANY WARRANTY; without even the implied warranty
+// of MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser
+// General Public License for more details.  You should have received a copy
+// of the GNU Lesser General Public License along with this program.  If not,
+// see <http://www.gnu.org/licenses/>.
+package net.opentsdb.query.expression;
+
+import java.util.HashMap;
+import java.util.Map;
+
+import net.opentsdb.core.TSDB;
+
+/**
+ * A static class that stores and instantiates a static map of the available
+ * functions.
+ * TODO - Enable plugable expression and load from the class path.
+ * Since 2.3
+ */
+public final class ExpressionFactory {
+  
+  private static Map<String, Expression> available_functions = 
+      new HashMap<String, Expression>();
+  
+  static {
+    available_functions.put("alias", new Alias());
+    available_functions.put("scale", new Scale());
+    available_functions.put("absolute", new Absolute());
+    available_functions.put("movingAverage", new MovingAverage());
+    available_functions.put("highestCurrent", new HighestCurrent());
+    available_functions.put("highestMax", new HighestMax());
+    available_functions.put("shift", new TimeShift());
+    available_functions.put("timeShift", new TimeShift());
+  }
+  
+  /** Don't instantiate me! */
+  private ExpressionFactory() { }
+  
+  /**
+   * Adds more functions to the map that depend on an instantiated TSDB object.
+   * Only call this once please.
+   * @param tsdb The TSDB object to initialize with
+   */
+  public static void addTSDBFunctions(final TSDB tsdb) {
+    available_functions.put("divideSeries", new DivideSeries(tsdb));
+    available_functions.put("divide", new DivideSeries(tsdb));
+    available_functions.put("sumSeries", new SumSeries(tsdb));
+    available_functions.put("sum", new SumSeries(tsdb));
+    available_functions.put("diffSeries", new DiffSeries(tsdb));
+    available_functions.put("difference", new DiffSeries(tsdb));
+    available_functions.put("multiplySeries", new MultiplySeries(tsdb));
+    available_functions.put("multiply", new MultiplySeries(tsdb));
+  }
+  
+  /**
+   * Add an expression to the map.
+   * WARNING: The map is not thread safe so don't use this to dynamically
+   * modify the map while the TSD is running.
+   * @param name The name of the expression
+   * @param expr The expression object to store.
+   * @throws IllegalArgumentException if the name is null or empty or the
+   * function is null.
+   */
+  static void addFunction(final String name, final Expression expr) {
+    if (name == null || name.isEmpty()) {
+      throw new IllegalArgumentException("Missing function name");
+    }
+    if (expr == null) {
+      throw new IllegalArgumentException("Function cannot be null");
+    }
+    available_functions.put(name, expr);
+  }
+  
+  /**
+   * Returns the expression function given the name
+   * @param function The name of the expression to use  
+   * @return The expression when located
+   * @throws UnsupportedOperationException if the requested function hasn't
+   * been stored in the map.
+   */
+  public static Expression getByName(final String function) {
+    final Expression expression = available_functions.get(function);
+    if (expression == null) {
+      throw new UnsupportedOperationException("Function " + function 
+          + " has not been implemented");
+    }
+    return expression;
+  }
+}
diff --git a/src/query/expression/ExpressionIterator.java b/src/query/expression/ExpressionIterator.java
new file mode 100644
index 0000000000..d090382bfb
--- /dev/null
+++ b/src/query/expression/ExpressionIterator.java
@@ -0,0 +1,472 @@
+// This file is part of OpenTSDB.
+// Copyright (C) 2015  The OpenTSDB Authors.
+//
+// This program is free software: you can redistribute it and/or modify it
+// under the terms of the GNU Lesser General Public License as published by
+// the Free Software Foundation, either version 2.1 of the License, or (at your
+// option) any later version.  This program is distributed in the hope that it
+// will be useful, but WITHOUT ANY WARRANTY; without even the implied warranty
+// of MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser
+// General Public License for more details.  You should have received a copy
+// of the GNU Lesser General Public License along with this program.  If not,
+// see <http://www.gnu.org/licenses/>.
+package net.opentsdb.query.expression;
+
+import java.util.HashMap;
+import java.util.HashSet;
+import java.util.Iterator;
+import java.util.List;
+import java.util.Map;
+import java.util.Map.Entry;
+import java.util.Set;
+
+import net.opentsdb.core.FillPolicy;
+import net.opentsdb.query.expression.VariableIterator.SetOperator;
+import net.opentsdb.utils.ByteSet;
+
+import org.apache.commons.jexl2.JexlContext;
+import org.apache.commons.jexl2.JexlEngine;
+import org.apache.commons.jexl2.MapContext;
+import org.apache.commons.jexl2.Script;
+import org.slf4j.Logger;
+import org.slf4j.LoggerFactory;
+
+import com.google.common.collect.ImmutableSet;
+
+/**
+ * A iterator that applies an expression to the results of multiple sub queries.
+ * To use this class:
+ * - Instantiate with a valid expression
+ * - Call {@link #getVariableNames()} and iterate over a set of TSSubQueries and
+ *   their results. For each query that matches a variable name, call
+ *   {@link #addResults(String, ITimeSyncedIterator)} with the result set.
+ * - Call {@link #compile()} to setup the meta data, fills and compute the
+ *   intersection of the series.
+ * - Call {@link #values()} and store the reference. Results for each
+ *   series will be written here as you iterate.
+ * - Call {@link #hasNext()} and {@link #next()} to iterate over results.
+ * - At each iteration, fetch the timestamp and value from the data points array.
+ * <p>
+ * Iteration is performed across all series supplied to the iterator, synchronizing
+ * on the timestamps and substituting fill values where appropriate.
+ * <p>
+ * WARNING: You MUST supply a result set and associated sub query to match each
+ * of the variable names in the expression. If you fail to do so, when you call
+ * {@link #compile()} you'll get an exception.
+ * <p>
+ * NOTE: Right now this class only supports intersection on the series so that
+ * each metric result must contain series with the same tags based on the flags
+ * provided in the ctor.
+ * NOTE: If a result set doesn't include a fill policy, we default to ZERO for
+ * "missing" data points.
+ */
+public class ExpressionIterator implements ITimeSyncedIterator {
+  private static final Logger LOG = LoggerFactory.getLogger(ExpressionIterator.class);
+  
+  /** Docs don't say whether this is thread safe or not. SOME methods are marked
+   * as not thread safe, so I assume it's ok to instantiate one of these guys
+   * and keep creating scripts from it.
+   */
+  public final static JexlEngine JEXL_ENGINE = new JexlEngine();
+  
+  /** Whether or not to intersect on the query tagks instead of the result set
+   * tagks */
+  private final boolean intersect_on_query_tagks;
+  
+  /** Whether or not to include the aggregated tags in the result set */
+  private final boolean include_agg_tags;
+  
+  /** List of iterators and their IDs */
+  private final Map<String, ITimeSyncedIterator> results;
+  
+  /** The compiled expression */
+  private final Script expression;
+  
+  /** The context where we'll dump results for processing through the expression */
+  private final JexlContext context = new MapContext();
+  
+  /** A list of unique variable names pulled from the expression */
+  private final Set<String> names;
+  
+  /** The intersection iterator we'll use for processing */
+  // TODO - write an interface to allow other set operators, e.g. union, disjoint
+  private VariableIterator iterator;
+
+  /** A map of results from the intersection iterator to pass to the expression */
+  private Map<String, ExpressionDataPoint[]> iteration_results;
+  
+  /** The results of processing the expressions */
+  private ExpressionDataPoint[] dps;
+  
+  /** The ID of this iterator */
+  private final String id;
+  
+  /** The index of this iterator in expressions */
+  private int index;
+  
+  /** A fill policy for this expression if data is missing */
+  private NumericFillPolicy fill_policy;
+  
+  /** The set operator to use for joining sets */
+  private SetOperator set_operator;
+  
+  // NOTE - if the query is set to NONE for the aggregation and the query has
+  // no tagk filters then we shouldn't set the II's intersect_on_query_tagks
+  /**
+   * Default Ctor that compiles the expression for use with this iterator.
+   * @param id The id of this iterator.
+   * @param expression The expression to compile and use
+   * @param set_operator The type of set operator to use
+   * @param intersect_on_query_tagks Whether or not to include only the query 
+   * specified tags during intersection
+   * @param include_agg_tags Whether or not to include aggregated tags during
+   * intersection
+   * @throws IllegalArgumentException if the expression is null or empty or doesn't
+   * contain any variables. 
+   * @throws JexlException if the expression isn't valid
+   */
+  public ExpressionIterator(final String id, final String expression, 
+      final SetOperator set_operator,
+      final boolean intersect_on_query_tagks, final boolean include_agg_tags) {
+    if (expression == null || expression.isEmpty()) {
+      throw new IllegalArgumentException("The expression cannot be  null");
+    }
+    if (set_operator == null) {
+      throw new IllegalArgumentException("The set operator cannot be null");
+    }
+    this.id = id;
+    this.intersect_on_query_tagks = intersect_on_query_tagks;
+    this.include_agg_tags = include_agg_tags;
+    results = new HashMap<String, ITimeSyncedIterator>();
+    this.expression = JEXL_ENGINE.createScript(expression);
+    names = new HashSet<String>();
+    extractVariableNames();
+    if (names.size() < 1) {
+      throw new IllegalArgumentException(
+          "The expression didn't appear to have any variables");
+    }
+    this.set_operator = set_operator;
+    fill_policy = new NumericFillPolicy(FillPolicy.NOT_A_NUMBER);
+  }
+  
+  /**
+   * Copy constructor that setups up a dupe of this iterator with fresh sub
+   * iterator objects for use in a nested expression.
+   * @param iterator The expression to copy from.
+   */
+  private ExpressionIterator(final ExpressionIterator iterator) {
+    id = iterator.id;
+    // need to recompile, don't know if we'll run into threading issues
+    expression = JEXL_ENGINE.createScript(iterator.expression.toString());
+    intersect_on_query_tagks = iterator.intersect_on_query_tagks;
+    include_agg_tags = iterator.include_agg_tags;
+    set_operator = iterator.set_operator;
+    
+    results = new HashMap<String, ITimeSyncedIterator>();
+    for (Entry<String, ITimeSyncedIterator> entry : iterator.results.entrySet()) {
+      results.put(entry.getKey(), entry.getValue().getCopy());
+    }
+    
+    names = new HashSet<String>();
+    extractVariableNames();
+    if (names.size() < 1) {
+      throw new IllegalArgumentException(
+          "The expression didn't appear to have any variables");
+    }
+  }
+  
+  @Override
+  public String toString() {
+    final StringBuffer buf = new StringBuffer();
+    buf.append("ExpressionIterator(id=")
+       .append(id)
+       .append(", expression=\"")
+       .append(expression.toString())
+       .append(", setOperator=")
+       .append(set_operator)
+       .append(", fillPolicy=")
+       .append(fill_policy)
+       .append(", intersectOnQueryTagks=")
+       .append(intersect_on_query_tagks)
+       .append(", includeAggTags=")
+       .append(include_agg_tags)
+       .append(", index=")
+       .append(index)
+       .append("\", VariableIterator=")
+       .append(iterator)
+       .append(", dps=")
+       .append(dps)
+       .append(", results=")
+       .append(results)
+       .append(")");
+    return buf.toString();
+  }
+  
+  /**
+   * Adds a sub query result object to the iterator.
+   * TODO - accept a proper object, not a map
+   * @param id The ID of source iterator.
+   * @param iterator The source iterator. 
+   * @throws IllegalArgumentException if the object is missing required data
+   */
+  public void addResults(final String id, final ITimeSyncedIterator iterator) {
+    if (id == null) {
+      throw new IllegalArgumentException("Missing ID");
+    }
+    if (iterator == null) {
+      throw new IllegalArgumentException("Iterator cannot be null");
+    }
+    results.put(id, iterator);
+  }
+  
+  /**
+   * Builds the iterator by computing the intersection of all series in all sets
+   * and sets up the output.
+   * @throws IllegalArgumentException if there aren't any results, or we don't 
+   * have a result for each variable, or something else is wrong.
+   * @throws IllegalDataException if no series were left after computing the
+   * intersection.
+   */
+  public void compile() {
+    if (LOG.isDebugEnabled()) {
+      LOG.debug("Compiling " + this);
+    }
+    if (results.size() < 1) {
+      throw new IllegalArgumentException("No results for any variables in "
+          + "the expression: " + this);
+    }
+    if (results.size() < names.size()) {
+      throw new IllegalArgumentException("Not enough query results [" 
+          + results.size() + " total results found] for the expression variables [" 
+          + names.size() + " expected] " + this);
+    }
+    
+    // don't care if we have extra results, but we had darned well better make
+    // sure we have a result set for each variable    
+    for (final String variable : names) {
+      // validation
+      final ITimeSyncedIterator it = results.get(variable.toLowerCase());
+      if (it == null) {
+        throw new IllegalArgumentException("Missing results for variable " + variable);
+      }
+
+      if (it instanceof ExpressionIterator) {
+        ((ExpressionIterator)it).compile();
+      }
+      if (LOG.isDebugEnabled()) {
+        LOG.debug("Matched variable " + variable + " to " + it);
+      }
+    }
+    
+    // TODO implement other set functions
+    switch (set_operator) {
+    case INTERSECTION:
+      iterator = new IntersectionIterator(id, results, intersect_on_query_tagks, 
+          include_agg_tags);
+      break;
+    case UNION:
+      iterator = new UnionIterator(id, results, intersect_on_query_tagks, 
+          include_agg_tags);
+    }
+    iteration_results = iterator.getResults();
+    
+    dps = new ExpressionDataPoint[iterator.getSeriesSize()];
+    for (int i = 0; i < iterator.getSeriesSize(); i++) {
+      final Iterator<Entry<String, ExpressionDataPoint[]>> it = 
+          iteration_results.entrySet().iterator();
+      Entry<String, ExpressionDataPoint[]> entry = it.next();
+      
+      if (entry.getValue() == null || entry.getValue()[i] == null) {
+        dps[i] = new ExpressionDataPoint();
+      } else {
+        dps[i] = new ExpressionDataPoint(entry.getValue()[i]);
+      }
+      while (it.hasNext()) {
+        entry = it.next();
+        if (entry.getValue() != null && entry.getValue()[i] != null) {
+          dps[i].add(entry.getValue()[i]);
+        }
+      }
+    }
+    
+    if (LOG.isDebugEnabled()) {
+      LOG.debug("Finished compiling " + this);
+    }
+  }
+
+  /**
+   * Checks to see if we have another value in any of the series.
+   * Make sure to call {@link #compile()} first.
+   * @return True if there is more data to process, false if not
+   */
+  @Override
+  public boolean hasNext() {
+    return iterator.hasNext();
+  }
+  
+  /**
+   * Fetches the next set of data and computes a value for the expression.
+   * Make sure to call {@link #compile()} first.
+   * And make sure to call {@link #hasNext()} before calling this.
+   * @return A link to the data points for this result set
+   * @throws IllegalDataException if there wasn't any data left in any of the
+   * series.
+   * @throws JexlException if something went pear shaped processing the expression
+   */
+  public ExpressionDataPoint[] next(final long timestamp) {
+    
+    // fetch the timestamp ONCE to save some cycles.
+    // final long timestamp = iterator.nextTimestamp();
+    iterator.next();
+    
+    // set aside a couple of addresses for the variables
+    double val;
+    double result;
+    for (int i = 0; i < iterator.getSeriesSize(); i++) {
+      // this here is why life sucks. there MUST be a better way to bind variables
+      for (final String variable : names) {
+        if (iteration_results.get(variable)[i] == null) {
+          context.set(variable, results.get(variable).getFillPolicy().getValue());
+        } else {
+          val = iteration_results.get(variable)[i].toDouble();
+          if (Double.isNaN(val)) {
+            context.set(variable, results.get(variable).getFillPolicy().getValue());
+          } else {
+            context.set(variable, val);
+          }
+        }
+      }
+      final Object output = expression.execute(context);
+      if (output instanceof Double) {
+        result = (Double) expression.execute(context);
+      } else if (output instanceof Boolean) {
+        result = (((Boolean) expression.execute(context)) ? 1 : 0);
+      } else {
+        throw new IllegalStateException("Expression returned a result of type: " 
+            + output.getClass().getName() + " for " + this);
+      }
+      dps[i].reset(timestamp, result);
+    }
+    return dps;
+  }
+  
+  /** @return a list of expression results. You can keep this list and check the 
+   * results on each call to {@link #next()} */
+  @Override
+  public ExpressionDataPoint[] values() {
+    return dps;
+  }
+  
+  /**
+   * Pulls the variable names from the expression and stores them in {@link #names}
+   */
+  private void extractVariableNames() {
+    if (expression == null) {
+      throw new IllegalArgumentException("The expression was null");
+    }
+
+    for (final List<String> exp_list : JEXL_ENGINE.getVariables(expression)) {
+      for (final String variable : exp_list) {
+        names.add(variable);
+      }
+    }
+  }
+
+  /** @return an immutable set of the variable IDs used in the expression. Case
+   * sensitive. */
+  public Set<String> getVariableNames() {
+    return ImmutableSet.copyOf(names);
+  }
+  
+  public void setSetOperator(final SetOperator set_operator) {
+    this.set_operator = set_operator;
+  }
+  
+  @Override
+  public long nextTimestamp() {
+    return iterator.nextTimestamp();
+  }
+
+  @Override
+  public int size() {
+    return dps.length;
+  }
+
+  @Override
+  public void nullIterator(int index) {
+    if (index < 0 || index >= dps.length) {
+      throw new IllegalArgumentException("Index out of bounds");
+    }
+    // TODO - do it
+  }
+
+  @Override
+  public int getIndex() {
+    return index;
+  }
+
+  @Override
+  public void setIndex(int index) {
+    this.index = index;
+  }
+
+  @Override
+  public String getId() {
+    return id;
+  }
+
+  @Override
+  public ByteSet getQueryTagKs() {
+    return null;
+  }
+
+  @Override
+  public void setFillPolicy(NumericFillPolicy policy) {
+    fill_policy = policy;
+  }
+
+  @Override
+  public NumericFillPolicy getFillPolicy() {
+    return fill_policy;
+  }
+
+  @Override
+  public ITimeSyncedIterator getCopy() {
+    final ExpressionIterator ei = new ExpressionIterator(this);
+    return ei;
+  }
+
+  @Override
+  public boolean hasNext(final int i) {
+    return iterator.hasNext(i);
+  }
+  
+  @Override
+  public void next(final int i) {
+    iterator.next(i);
+    
+    // set aside a couple of addresses for the variables
+    double val;
+    double result;
+    // this here is why life sucks. there MUST be a better way to bind variables
+    long ts = Long.MAX_VALUE;
+    for (final String variable : names) {
+      if (iteration_results.get(variable)[i] == null) {
+        context.set(variable, results.get(variable).getFillPolicy().getValue());
+      } else {
+        if (iteration_results.get(variable)[i].timestamp() < ts) {
+          ts = iteration_results.get(variable)[i].timestamp();
+        }
+        val = iteration_results.get(variable)[i].toDouble();
+        if (Double.isNaN(val)) {
+          context.set(variable, results.get(variable).getFillPolicy().getValue());
+        } else {
+          context.set(variable, val);
+        }
+      }
+    }
+    result = (Double)expression.execute(context);
+    dps[i].reset(ts, result);
+  }
+  
+}
diff --git a/src/query/expression/ExpressionReader.java b/src/query/expression/ExpressionReader.java
new file mode 100644
index 0000000000..01cf7e0105
--- /dev/null
+++ b/src/query/expression/ExpressionReader.java
@@ -0,0 +1,156 @@
+// This file is part of OpenTSDB.
+// Copyright (C) 2015  The OpenTSDB Authors.
+//
+// This program is free software: you can redistribute it and/or modify it
+// under the terms of the GNU Lesser General Public License as published by
+// the Free Software Foundation, either version 2.1 of the License, or (at your
+// option) any later version.  This program is distributed in the hope that it
+// will be useful, but WITHOUT ANY WARRANTY; without even the implied warranty
+// of MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser
+// General Public License for more details.  You should have received a copy
+// of the GNU Lesser General Public License along with this program.  If not,
+// see <http://www.gnu.org/licenses/>.
+package net.opentsdb.query.expression;
+
+import java.util.NoSuchElementException;
+
+/**
+ * Parses a Graphite style expression.
+ * Please use {@link #isEOF()} before any method call. Otherwise the methods
+ * will throw a NoSuchElementException. 
+ * @since 2.3
+ */
+public class ExpressionReader {
+  /** The character array to parse */
+  protected final char[] chars;
+
+  /** The current index in the character array */
+  private int mark = 0;
+
+  /**
+   * Default ctor 
+   * @param chars The characters to parse
+   */
+  public ExpressionReader(final char[] chars) {
+    if (chars == null) {
+      throw new IllegalArgumentException("Character set cannot be null");
+    }
+    this.chars = chars;
+  }
+
+  /** @return the current index */
+  public int getMark() {
+    return mark;
+  }
+
+  /** @return the current character without advancing the index */
+  public char peek() {
+    if (isEOF()) {
+      throw new NoSuchElementException("Index " + mark + " is out of bounds " 
+          + chars.length);
+    }
+    return chars[mark];
+  }
+
+  /** @return the current character and advances the index */
+  public char next() {
+    if (isEOF()) {
+      throw new NoSuchElementException("Index " + mark + " is out of bounds " 
+          + chars.length);
+    }
+    return chars[mark++];
+  }
+
+  /** @param the number of characters to skip */
+  public void skip(final int num) {
+    if (num < 0) {
+      throw new UnsupportedOperationException("Skipping backwards is not allowed");
+    }
+    mark += num;
+  }
+
+  /**
+   * Checks to see if the next character matches the parameter
+   * @param c The character to check for
+   * @return True if they match, false if not
+   */
+  public boolean isNextChar(final char c) {
+    return peek() == c;
+  }
+
+  /** @return true if the given sequence appears next in the array. */
+  public boolean isNextSeq(final CharSequence seq) {
+    if (seq == null) {
+      throw new IllegalArgumentException("Comparative sequence cannot be null");
+    }
+    for (int i = 0; i < seq.length(); i++) {
+      if (mark + i >= chars.length) {
+        return false;
+      }
+      if (chars[mark + i] != seq.charAt(i)) {
+        return false;
+      }
+    }
+
+    return true;
+  }
+
+  /** @return the name of the function */
+  public String readFuncName() {
+    // in case we get something like "  function(foo)" consume a bit
+    skipWhitespaces();
+    StringBuilder builder = new StringBuilder();
+    while (peek() != '(' && !Character.isWhitespace(peek())) {
+      builder.append(next());
+    }
+    skipWhitespaces(); // increment over whitespace after
+    return builder.toString();
+  }
+
+  /** @return Whether or not the index is at the end of the character array */
+  public boolean isEOF() {
+    return mark >= chars.length;
+  }
+
+  /** Increments the mark over white spaces */
+  public void skipWhitespaces() {
+    for (int i = mark; i < chars.length; i++) {
+      if (Character.isWhitespace(chars[i])) {
+        mark++;
+      } else {
+        break;
+      }
+    }
+  }
+
+  /** @return the next parameter from the expression
+   * TODO - may need some work */
+  public String readNextParameter() {    
+    final StringBuilder builder = new StringBuilder();
+    int num_nested = 0;
+    while (!isEOF() && !Character.isWhitespace(peek())) {
+      final char ch = peek();
+      if (ch == '(') {
+        num_nested++;
+      } else if (ch == ')')  {
+        num_nested--;
+      }
+      
+      if (num_nested < 0) {
+        break;
+      }
+      if (num_nested <= 0 && isNextSeq(",,")) {
+        break;
+      }
+      builder.append(next());
+    }
+    return builder.toString();
+  }
+
+  @Override
+  public String toString() {
+    // make a copy
+    return new String(chars);
+  }
+
+}
diff --git a/src/query/expression/ExpressionTree.java b/src/query/expression/ExpressionTree.java
new file mode 100644
index 0000000000..28bc5feaf2
--- /dev/null
+++ b/src/query/expression/ExpressionTree.java
@@ -0,0 +1,257 @@
+// This file is part of OpenTSDB.
+// Copyright (C) 2015  The OpenTSDB Authors.
+//
+// This program is free software: you can redistribute it and/or modify it
+// under the terms of the GNU Lesser General Public License as published by
+// the Free Software Foundation, either version 2.1 of the License, or (at your
+// option) any later version.  This program is distributed in the hope that it
+// will be useful, but WITHOUT ANY WARRANTY; without even the implied warranty
+// of MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser
+// General Public License for more details.  You should have received a copy
+// of the GNU Lesser General Public License along with this program.  If not,
+// see <http://www.gnu.org/licenses/>.
+package net.opentsdb.query.expression;
+
+import com.google.common.annotations.VisibleForTesting;
+import com.google.common.base.Joiner;
+import com.google.common.collect.Lists;
+import com.google.common.collect.Maps;
+
+import net.opentsdb.core.DataPoints;
+import net.opentsdb.core.IllegalDataException;
+import net.opentsdb.core.TSQuery;
+
+import java.util.Collection;
+import java.util.Collections;
+import java.util.List;
+import java.util.Map;
+
+/**
+ * A node in a tree of nested expressions. The tree may link to other nodes as
+ * sub expressions. Evaluating the tree evaluates all sub expressions.
+ * <p>
+ * Before calling {@link evaluate} you MUST call a one or a combination of
+ * {@link addSubExpression}, {@link addSubMetricQuery} and optionally 
+ * {@link addFunctionParameter}
+ * <p>
+ * TODO(cl) - Cleanup needed. Tracking the indices can likely be done better 
+ * and it would be good to have a ctor that sets the sub or metric query. 
+ * @since 2.3
+ */
+public class ExpressionTree {
+  /** Used for the toString() helpers */
+  private static final Joiner DOUBLE_COMMA_JOINER = Joiner.on(",").skipNulls();
+  
+  /** An enumerator of the different query types */
+  enum Parameter {
+    SUB_EXPRESSION,
+    METRIC_QUERY
+  }
+  
+  /** The root expression for the tree */
+  private final Expression expression;
+  /** The original time series query */
+  private final TSQuery data_query;
+  /** An optional list of sub expressions */
+  private List<ExpressionTree> sub_expressions;
+  /** A list of parameters for the root expression */
+  private List<String> func_params;
+  /** A mapping of result indices to sub metric queries */
+  private Map<Integer, String> sub_metric_queries;
+  /** A mapping of query types to their result index */
+  private Map<Integer, Parameter> parameter_index = Maps.newHashMap();
+
+  /**
+   * Creates a tree with a root and no children
+   * @param expression_name The name of the expression to lookup in the factory
+   * @param data_query The original query
+   * @throws UnsupportedOperationException if the expression is not implemented
+   */
+  public ExpressionTree(final String expression_name, final TSQuery data_query) {
+    this(ExpressionFactory.getByName(expression_name), data_query);
+  }
+  
+  /**
+   * Creates a tree with a root and no children
+   * @param expression The expression to use
+   * @param data_query The original query
+   */
+  public ExpressionTree(final Expression expression, final TSQuery data_query) {
+    this.expression = expression;
+    this.data_query = data_query;
+  }
+
+  public void addSubExpression(final ExpressionTree child, final int param_index) {
+    if (child == null) {
+      throw new IllegalArgumentException("Cannot add a null child tree");
+    }
+    if (child == this) {
+      throw new IllegalDataException("Recursive sub expression detected: " 
+          + this);
+    }
+    if (param_index < 0) {
+      throw new IllegalArgumentException("Parameter index must be 0 or greater");
+    }
+    if (sub_expressions == null) {
+      sub_expressions = Lists.newArrayList();
+    }
+    sub_expressions.add(child);
+    parameter_index.put(param_index, Parameter.SUB_EXPRESSION);
+  }
+
+  /**
+   * Sets the metric query key and index, setting the Parameter type to 
+   * METRIC_QUERY
+   * @param metric_query The metric query id
+   * @param sub_query_index The index of the metric query
+   * @param param_index The index of the parameter (??) 
+   */
+  public void addSubMetricQuery(final String metric_query, 
+                                final int sub_query_index,
+                                final int param_index) {
+    if (metric_query == null || metric_query.isEmpty()) {
+      throw new IllegalArgumentException("Metric query cannot be null or empty");
+    }
+    if (sub_query_index < 0) {
+      throw new IllegalArgumentException("Sub query index must be 0 or greater");
+    }
+    if (param_index < 0) {
+      throw new IllegalArgumentException("Parameter index must be 0 or greater");
+    }
+    if (sub_metric_queries == null) {
+      sub_metric_queries = Maps.newHashMap();
+    }
+    sub_metric_queries.put(sub_query_index, metric_query);
+    parameter_index.put(param_index, Parameter.METRIC_QUERY);
+  }
+  
+  /**
+   * Adds parameters for the root expression only.
+   * @param param The parameter to add, cannot be null or empty
+   * @throws IllegalArgumentException if the parameter is null or empty
+   */
+  public void addFunctionParameter(final String param) {
+    if (param == null || param.isEmpty()) {
+      throw new IllegalArgumentException("Parameter cannot be null or empty");
+    }
+    if (func_params == null) {
+      func_params = Lists.newArrayList();
+    }
+    func_params.add(param);
+  }
+
+  /**
+   * Processes the expression tree, including sub expressions, and returns the 
+   * results.
+   * TODO(cl) - More tests around indices, etc. This can likely be cleaned up.
+   * @param query_results The result set to pass to the expressions
+   * @return The result set or an exception will bubble up if something wasn't
+   * configured properly.
+   */
+  public DataPoints[] evaluate(final List<DataPoints[]> query_results) {
+    // TODO - size the array
+    final List<DataPoints[]> materialized = Lists.newArrayList();
+    List<Integer> metric_query_keys = null;
+    if (sub_metric_queries != null && sub_metric_queries.size() > 0) {
+      metric_query_keys = Lists.newArrayList(sub_metric_queries.keySet());
+      Collections.sort(metric_query_keys);
+    }
+
+    int metric_pointer = 0;
+    int sub_expression_pointer = 0;
+    for (int i = 0; i < parameter_index.size(); i++) {
+      final Parameter param = parameter_index.get(i);
+
+      if (param == Parameter.METRIC_QUERY) {
+        if (metric_query_keys == null) {
+          throw new RuntimeException("Attempt to read metric " +
+                  "results when none exist");
+        }
+
+        final int ix = metric_query_keys.get(metric_pointer++);
+        materialized.add(query_results.get(ix));
+      } else if (param == Parameter.SUB_EXPRESSION) {
+        final ExpressionTree st = sub_expressions.get(sub_expression_pointer++);
+        materialized.add(st.evaluate(query_results));
+      } else {
+        throw new IllegalDataException("Unknown parameter type: " + param 
+            + " in tree: " + this);
+      }
+    }
+    
+    return expression.evaluate(data_query, materialized, func_params);
+  }
+  
+  @Override
+  public String toString() {
+    return writeStringField();
+  }
+
+  /**
+   * Helper to create the original expression (or at least a nested expression
+   * without the parameters included)
+   * @return A string representing the full expression.
+   */
+  public String writeStringField() {
+    final List<String> strs = Lists.newArrayList();
+    if (sub_expressions != null) {
+      for (ExpressionTree sub : sub_expressions) {
+        strs.add(sub.toString());
+      }
+    }
+
+    if (sub_metric_queries != null) {
+      final String sub_metrics = clean(sub_metric_queries.values());
+      if (sub_metrics != null && sub_metrics.length() > 0) {
+        strs.add(sub_metrics);
+      }
+    }
+
+    final String inner_expression = DOUBLE_COMMA_JOINER.join(strs);
+    return expression.writeStringField(func_params, inner_expression);
+  }
+
+  /**
+   * Helper to clean out some characters
+   * @param values The collection of strings to cleanup
+   * @return An empty string if values was empty or a cleaned up string
+   */
+  private String clean(final Collection<String> values) {
+    if (values == null || values.size() == 0) {
+      return "";
+    }
+
+    final List<String> strs = Lists.newArrayList();
+    for (String v : values) {
+      final String tmp = v.replaceAll("\\{.*\\}", "");
+      final int ix = tmp.lastIndexOf(':');
+      if (ix < 0) {
+        strs.add(tmp);
+      } else {
+        strs.add(tmp.substring(ix+1));
+      }
+    }
+
+    return DOUBLE_COMMA_JOINER.join(strs);
+  }
+
+  @VisibleForTesting
+  List<ExpressionTree> subExpressions() {
+    return sub_expressions;
+  }
+  
+  @VisibleForTesting
+  List<String> funcParams() {
+    return func_params;
+  }
+  
+  @VisibleForTesting
+  Map<Integer, String> subMetricQueries() {
+    return sub_metric_queries;
+  }
+  
+  @VisibleForTesting
+  Map<Integer, Parameter> parameterIndex() {
+    return parameter_index;
+  }
+}
\ No newline at end of file
diff --git a/src/query/expression/Expressions.java b/src/query/expression/Expressions.java
new file mode 100644
index 0000000000..1d7e2de954
--- /dev/null
+++ b/src/query/expression/Expressions.java
@@ -0,0 +1,166 @@
+// This file is part of OpenTSDB.
+// Copyright (C) 2015  The OpenTSDB Authors.
+//
+// This program is free software: you can redistribute it and/or modify it
+// under the terms of the GNU Lesser General Public License as published by
+// the Free Software Foundation, either version 2.1 of the License, or (at your
+// option) any later version.  This program is distributed in the hope that it
+// will be useful, but WITHOUT ANY WARRANTY; without even the implied warranty
+// of MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser
+// General Public License for more details.  You should have received a copy
+// of the GNU Lesser General Public License along with this program.  If not,
+// see <http://www.gnu.org/licenses/>.
+package net.opentsdb.query.expression;
+
+import java.io.StringReader;
+import java.util.ArrayList;
+import java.util.List;
+
+import net.opentsdb.core.TSQuery;
+import net.opentsdb.query.expression.parser.ParseException;
+import net.opentsdb.query.expression.parser.SyntaxChecker;
+
+/**
+ * Static class with helpers to parse and deal with expressions
+ * @since 2.3
+ */
+public class Expressions {
+
+  /** No instantiation for you! */
+  private Expressions() { }
+  
+  /**
+   * Parses an expression into a tree
+   * @param expression The expression to parse (as a string)
+   * @param metric_queries A list to store the parsed metrics in
+   * @param data_query The time series query
+   * @return The parsed tree ready for evaluation
+   * @throws IllegalArgumentException if the expression was null, empty or 
+   * invalid.
+   * @throws UnsupportedOperationException if the requested function couldn't
+   * be found.
+   */
+  public static ExpressionTree parse(final String expression,
+                                     final List<String> metric_queries,
+                                     final TSQuery data_query) {
+    if (expression == null || expression.isEmpty()) {
+      throw new IllegalArgumentException("Expression may not be null or empty");
+    }
+    if (expression.indexOf('(') == -1 || expression.indexOf(')') == -1) {
+      throw new IllegalArgumentException("Invalid Expression: " + expression);
+    }
+
+    final ExpressionReader reader = new ExpressionReader(expression.toCharArray());
+    // consume any whitespace ahead of the expression
+    reader.skipWhitespaces();
+
+    final String function_name = reader.readFuncName();
+    final Expression root_expression = ExpressionFactory.getByName(function_name);
+
+    final ExpressionTree root = new ExpressionTree(root_expression, data_query);
+    reader.skipWhitespaces();
+    
+    if (reader.peek() == '(') {
+      reader.next();
+      parse(reader, metric_queries, root, data_query);
+    }
+
+    return root;
+  }
+
+  /**
+   * Parses a list of string expressions into the proper trees, adding the
+   * metrics to the {@link metric_queries} list.
+   * @param expressions A list of zero or more expressions (if empty, you get an
+   * empty tree list back)
+   * @param ts_query The original query with timestamps
+   * @param metric_queries The list to fill with metrics to fetch
+   */
+  public static List<ExpressionTree> parseExpressions(
+                                            final List<String> expressions, 
+                                            final TSQuery ts_query, 
+                                            final List<String> metric_queries) {
+    final List<ExpressionTree> trees = 
+        new ArrayList<ExpressionTree>(expressions.size());
+    for (final String expr: expressions) {
+      final SyntaxChecker checker = new SyntaxChecker(new StringReader(expr));
+      checker.setMetricQueries(metric_queries);
+      checker.setTSQuery(ts_query);
+      try {
+        trees.add(checker.EXPRESSION());
+      } catch (ParseException e) {
+        throw new IllegalArgumentException("Failed to parse " + expr, e);
+      }
+    }
+    return trees;
+  }
+  
+  /**
+   * Helper to parse out the function(s) and parameters
+   * @param reader The reader used for iterating over the expression
+   * @param metric_queries A list to store the parsed metrics in
+   * @param root The root tree
+   * @param data_query The time series query
+   */
+  private static void parse(final ExpressionReader reader, 
+                            final List<String> metric_queries,
+                            final ExpressionTree root,
+                            final TSQuery data_query) {
+
+    int parameter_index = 0;
+    reader.skipWhitespaces();
+    if (reader.peek() != ')') {
+      final String param = reader.readNextParameter();
+      parseParam(param, metric_queries, root, data_query, parameter_index++);
+    }
+
+    while (!reader.isEOF()) {
+      reader.skipWhitespaces();
+      if (reader.peek() == ')') {
+        return;
+      } else if (reader.isNextSeq(",,")) {
+        reader.skip(2); //swallow the ",," delimiter
+        reader.skipWhitespaces();
+        final String param = reader.readNextParameter();
+        parseParam(param, metric_queries, root, data_query, parameter_index++);
+      } else {
+        throw new IllegalArgumentException("Invalid delimiter in parameter " +
+                "list at pos=" + reader.getMark() + ", expr="
+                + reader.toString());
+      }
+    }
+  }
+
+  /**
+   * Helper that parses out the parameter from the expression
+   * @param param The parameter to parse
+   * @param metric_queries A list to store the parsed metrics in
+   * @param root The root tree
+   * @param data_query The time series query
+   * @param index Index of the parameter
+   */
+  private static void parseParam(final String param, 
+                                 final List<String> metric_queries,
+                                 final ExpressionTree root, 
+                                 final TSQuery data_query, 
+                                 final int index) {
+    if (param == null || param.length() == 0) {
+      throw new IllegalArgumentException("Parameter cannot be null or empty");
+    }
+
+    if (param.indexOf('(') > 0 && param.indexOf(')') > 0) {
+      // sub expression
+      final ExpressionTree sub_tree = parse(param, metric_queries, data_query);
+      root.addSubExpression(sub_tree, index);
+    } else if (param.indexOf(':') >= 0) {
+      // metric query
+      metric_queries.add(param);
+      root.addSubMetricQuery(param, metric_queries.size() - 1, index);
+    } else {
+      // expression parameter
+      root.addFunctionParameter(param);
+    }
+  }
+
+}
+
diff --git a/src/query/expression/HighestCurrent.java b/src/query/expression/HighestCurrent.java
new file mode 100644
index 0000000000..11d9f04f82
--- /dev/null
+++ b/src/query/expression/HighestCurrent.java
@@ -0,0 +1,279 @@
+// This file is part of OpenTSDB.
+// Copyright (C) 2015  The OpenTSDB Authors.
+//
+// This program is free software: you can redistribute it and/or modify it
+// under the terms of the GNU Lesser General Public License as published by
+// the Free Software Foundation, either version 2.1 of the License, or (at your
+// option) any later version.  This program is distributed in the hope that it
+// will be useful, but WITHOUT ANY WARRANTY; without even the implied warranty
+// of MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser
+// General Public License for more details.  You should have received a copy
+// of the GNU Lesser General Public License along with this program.  If not,
+// see <http://www.gnu.org/licenses/>.
+package net.opentsdb.query.expression;
+
+import java.util.ArrayList;
+import java.util.Arrays;
+import java.util.List;
+
+import net.opentsdb.core.AggregationIterator;
+import net.opentsdb.core.Aggregator;
+import net.opentsdb.core.Aggregators;
+import net.opentsdb.core.DataPoint;
+import net.opentsdb.core.DataPoints;
+import net.opentsdb.core.MutableDataPoint;
+import net.opentsdb.core.SeekableView;
+import net.opentsdb.core.TSQuery;
+import net.opentsdb.core.Aggregators.Interpolation;
+import net.opentsdb.query.expression.HighestMax.TopNSortingEntry;
+
+/**
+ * Implements top-n functionality by iterating over each of the time series,
+ * sorting and returning the top "n" time series with the highest current (or
+ * latest) value.
+ * @since 2.3
+ */
+public class HighestCurrent implements Expression {
+
+  @Override
+  public DataPoints[] evaluate(final TSQuery data_query, 
+      final List<DataPoints[]> query_results, final List<String> params) {
+    if (data_query == null) {
+      throw new IllegalArgumentException("Missing time series query");
+    }
+    if (query_results == null || query_results.isEmpty()) {
+      return new DataPoints[]{};
+    }
+    // TODO(cl) - allow for empty top-n maybe? Just sort the results by max?
+    if (params == null || params.isEmpty()) {
+      throw new IllegalArgumentException("Need aggregation window for moving average");
+    }
+
+    String param = params.get(0);
+    if (param == null || param.length() == 0) {
+      throw new IllegalArgumentException("Missing top n value "
+          + "(number of series to return)");
+    }
+
+    int topn = 0;
+    if (param.matches("^[0-9]+$")) {
+      try {
+        topn = Integer.parseInt(param);
+      } catch (NumberFormatException nfe) {
+        throw new IllegalArgumentException(
+            "Invalid parameter, must be an integer", nfe);
+      }
+    } else {
+      throw new IllegalArgumentException("Unparseable top n value: " + param);
+    }
+    if (topn < 1) {
+      throw new IllegalArgumentException("Top n value must be greater "
+          + "than zero: " + topn);
+    }
+
+    int num_results = 0;
+    for (DataPoints[] results: query_results) {
+      num_results += results.length;
+    }
+
+    final PostAggregatedDataPoints[] post_agg_results = 
+        new PostAggregatedDataPoints[num_results];
+    int ix = 0;
+    // one or more sub queries (m=...&m=...&m=...)
+    for (final DataPoints[] sub_query_result : query_results) {
+      // group bys (m=sum:foo{host=*})
+      for (final DataPoints dps : sub_query_result) {
+        // TODO(cl) - Avoid iterating and copying if we can help it. We should
+        // be able to pass the original DataPoints object to the seekable view
+        // and then iterate through it.
+        final List<DataPoint> mutable_points = new ArrayList<DataPoint>();
+        for (final DataPoint point : dps) {
+          mutable_points.add(point.isInteger() ?
+              MutableDataPoint.ofLongValue(point.timestamp(), point.longValue())
+            : MutableDataPoint.ofDoubleValue(point.timestamp(), point.doubleValue()));
+        }
+        post_agg_results[ix++] = new PostAggregatedDataPoints(dps,
+                mutable_points.toArray(new DataPoint[mutable_points.size()]));
+      }
+    }
+    
+    final SeekableView[] views = new SeekableView[num_results];
+    for (int i = 0; i < num_results; i++) {
+      views[i] = post_agg_results[i].iterator();
+    }
+
+    final MaxLatestAggregator aggregator = new
+            MaxLatestAggregator(Aggregators.Interpolation.LERP,
+            "maxLatest", num_results, data_query.startTime(), data_query.endTime());
+
+    final SeekableView view = (new AggregationIterator(views,
+            data_query.startTime(), data_query.endTime(),
+            aggregator, Aggregators.Interpolation.LERP, false));
+
+    // slurp all the points even though we aren't using them at this stage
+    while (view.hasNext()) {
+      final DataPoint mdp = view.next();
+      @SuppressWarnings("unused")
+      final Object o = mdp.isInteger() ? mdp.longValue() : mdp.doubleValue();
+    }
+
+    final long[] max_longs = aggregator.getLongMaxes();
+    final double[] max_doubles = aggregator.getDoubleMaxes();
+    final TopNSortingEntry[] max_by_ts = 
+        new TopNSortingEntry[num_results];
+    if (aggregator.hasDoubles() && aggregator.hasLongs()) {
+      for (int i = 0; i < num_results; i++) {
+        max_by_ts[i] = new TopNSortingEntry(
+            Math.max((double)max_longs[i], max_doubles[i]), i);
+      }
+    } else if (aggregator.hasLongs() && !aggregator.hasDoubles()) {
+      for (int i = 0; i < num_results; i++) {
+        max_by_ts[i] = new TopNSortingEntry((double) max_longs[i], i);
+      }
+    } else if (aggregator.hasDoubles() && !aggregator.hasLongs()) {
+      for (int i = 0; i < num_results; i++) {
+        max_by_ts[i] = new TopNSortingEntry(max_doubles[i], i);
+      }
+    }
+
+    Arrays.sort(max_by_ts);
+
+    final int result_count = Math.min(topn, num_results);
+    final DataPoints[] results = new DataPoints[result_count];
+    for (int i = 0; i < result_count; i++) {
+      results[i] = post_agg_results[max_by_ts[i].pos];
+    }
+
+    return results;
+  }
+  
+  @Override
+  public String writeStringField(final List<String> query_params, 
+      final String inner_expression) {
+    return "highestCurrent(" + inner_expression + ")";
+  }
+  
+  /**
+   * Aggregator that stores only the latest value for each series so that they
+   * can be sorted on it
+   */
+  public static class MaxLatestAggregator extends Aggregator {
+    /** The total number of series in the result set, including sub queries and
+     * group bys */
+    private final int total_series;
+    /** An array of maximum integers by time series */
+    private final long[] max_longs;
+    /** An array of maximum doubles by time series */
+    private final double[] max_doubles;
+    /** Whether or not any of the series contain integers */
+    private boolean has_longs = false;
+    /** Whether or not any of the series contain doubles */
+    private boolean has_doubles = false;
+    /** Query start time in milliseconds for filtering */
+    private long start;
+    /** Query end time in milliseconds for filtering */
+    private long end;
+    /** The most recent timestamp in the different series */
+    private long latest_ts = -1;
+
+    /**
+     * An aggregator that keeps track of the maximum latest value for each series
+     * @param method The interpolation method (not used)
+     * @param name The name of the aggregator 
+     * @param total_series The total number of series in the result set, 
+     * including sub queries and group bys
+     * @param start Query start time in milliseconds for filtering
+     * @param end Query end time in milliseconds for filtering
+     */
+    public MaxLatestAggregator(final Interpolation method, final String name, 
+        final int total_series, final long start, final long end) {
+      super(method, name);
+      this.total_series = total_series;
+      this.start = start;
+      this.end = end;
+      this.max_longs = new long[total_series];
+      this.max_doubles = new double[total_series];
+
+      for (int i = 0; i < total_series; i++) {
+        max_doubles[i] = Double.MIN_VALUE;
+        max_longs[i] = Long.MIN_VALUE;
+      }
+    }
+
+    @Override
+    public long runLong(Longs values) {
+      // TODO(cl) - Can we get anything other than a DataPoint?
+      if (values instanceof DataPoint) {
+        long ts = ((DataPoint) values).timestamp();
+        //data point falls outside required range
+        if (ts < start || ts > end) {
+          return 0;
+        }
+      }
+
+      final long[] longs = new long[total_series];
+      int ix = 0;
+      longs[ix++] = values.nextLongValue();
+      while (values.hasNextValue()) {
+        longs[ix++] = values.nextLongValue();
+      }
+
+      if (values instanceof DataPoint) {
+        final long ts = ((DataPoint) values).timestamp();
+        if (ts > latest_ts) {
+          System.arraycopy(longs, 0, max_longs, 0, total_series);
+        }
+      }
+
+      has_longs = true;
+      return 0;
+    }
+
+    @Override
+    public double runDouble(Doubles values) {
+      // TODO(cl) - Can we get anything other than a DataPoint?
+      if (values instanceof DataPoint) {
+        long ts = ((DataPoint) values).timestamp();
+        //data point falls outside required range
+        if (ts < start || ts > end) {
+          return 0;
+        }
+      }
+
+      // TODO(cl) - Properly handle NaNs here
+      final double[] doubles = new double[total_series];
+      int ix = 0;
+      doubles[ix++] = values.nextDoubleValue();
+      while (values.hasNextValue()) {
+        doubles[ix++] = values.nextDoubleValue();
+      }
+
+      if (values instanceof DataPoint) {
+        final long ts = ((DataPoint) values).timestamp();
+        if (ts > latest_ts) {
+          System.arraycopy(doubles, 0, max_doubles, 0, total_series);
+        }
+      }
+
+      has_doubles = true;
+      return 0;
+    }
+
+    public long[] getLongMaxes() {
+      return max_longs;
+    }
+
+    public double[] getDoubleMaxes() {
+      return max_doubles;
+    }
+
+    public boolean hasLongs() {
+      return has_longs;
+    }
+
+    public boolean hasDoubles() {
+      return has_doubles;
+    }
+    
+  }
+}
diff --git a/src/query/expression/HighestMax.java b/src/query/expression/HighestMax.java
new file mode 100644
index 0000000000..0b942d5c1b
--- /dev/null
+++ b/src/query/expression/HighestMax.java
@@ -0,0 +1,293 @@
+// This file is part of OpenTSDB.
+// Copyright (C) 2010-2012  The OpenTSDB Authors.
+//
+// This program is free software: you can redistribute it and/or modify it
+// under the terms of the GNU Lesser General Public License as published by
+// the Free Software Foundation, either version 2.1 of the License, or (at your
+// option) any later version.  This program is distributed in the hope that it
+// will be useful, but WITHOUT ANY WARRANTY; without even the implied warranty
+// of MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser
+// General Public License for more details.  You should have received a copy
+// of the GNU Lesser General Public License along with this program.  If not,
+// see <http://www.gnu.org/licenses/>.
+package net.opentsdb.query.expression;
+
+import java.util.ArrayList;
+import java.util.Arrays;
+import java.util.Comparator;
+import java.util.List;
+
+import net.opentsdb.core.AggregationIterator;
+import net.opentsdb.core.Aggregator;
+import net.opentsdb.core.Aggregators;
+import net.opentsdb.core.DataPoint;
+import net.opentsdb.core.DataPoints;
+import net.opentsdb.core.MutableDataPoint;
+import net.opentsdb.core.SeekableView;
+import net.opentsdb.core.TSQuery;
+import net.opentsdb.core.Aggregators.Interpolation;
+
+/**
+ * Implements top-n functionality by iterating over each of the time series,
+ * finding the max value for each time series within the query time range,
+ * and up to "n" time series with the highest values, sorted in descending
+ * order.
+ * @since 2.3
+ */
+public class HighestMax implements Expression {
+
+  @Override
+  public DataPoints[] evaluate(final TSQuery data_query, 
+      final List<DataPoints[]> query_results, final List<String> params) {
+    if (data_query == null) {
+      throw new IllegalArgumentException("Missing time series query");
+    }
+    if (query_results == null || query_results.isEmpty()) {
+      return new DataPoints[]{};
+    }
+    // TODO(cl) - allow for empty top-n maybe? Just sort the results by max?
+    if (params == null || params.isEmpty()) {
+      throw new IllegalArgumentException("Need aggregation window for moving average");
+    }
+
+    String param = params.get(0);
+    if (param == null || param.length() == 0) {
+      throw new IllegalArgumentException("Missing top n value "
+          + "(number of series to return)");
+    }
+
+    int topn = 0;
+    if (param.matches("^[0-9]+$")) {
+      try {
+        topn = Integer.parseInt(param);
+      } catch (NumberFormatException nfe) {
+        throw new IllegalArgumentException(
+            "Invalid parameter, must be an integer", nfe);
+      }
+    } else {
+      throw new IllegalArgumentException("Unparseable top n value: " + param);
+    }
+    if (topn < 1) {
+      throw new IllegalArgumentException("Top n value must be greater "
+          + "than zero: " + topn);
+    }
+
+    int num_results = 0;
+    for (DataPoints[] results: query_results) {
+      num_results += results.length;
+    }
+
+    final PostAggregatedDataPoints[] post_agg_results = 
+        new PostAggregatedDataPoints[num_results];
+    int ix = 0;
+    // one or more sub queries (m=...&m=...&m=...)
+    for (final DataPoints[] sub_query_result : query_results) {
+      // group bys (m=sum:foo{host=*})
+      for (final DataPoints dps : sub_query_result) {
+        // TODO(cl) - Avoid iterating and copying if we can help it. We should
+        // be able to pass the original DataPoints object to the seekable view
+        // and then iterate through it.
+        final List<DataPoint> mutable_points = new ArrayList<DataPoint>();
+        for (final DataPoint point : dps) {
+          mutable_points.add(point.isInteger() ?
+              MutableDataPoint.ofLongValue(point.timestamp(), point.longValue())
+            : MutableDataPoint.ofDoubleValue(point.timestamp(), point.doubleValue()));
+        }
+        post_agg_results[ix++] = new PostAggregatedDataPoints(dps,
+                mutable_points.toArray(new DataPoint[mutable_points.size()]));
+      }
+    }
+    
+    final SeekableView[] views = new SeekableView[num_results];
+    for (int i = 0; i < num_results; i++) {
+      views[i] = post_agg_results[i].iterator();
+    }
+
+    final MaxCacheAggregator aggregator = new MaxCacheAggregator(
+            Aggregators.Interpolation.LERP, "maxCache", num_results, 
+            data_query.startTime(), data_query.endTime());
+
+    final SeekableView view = (new AggregationIterator(views,
+            data_query.startTime(), data_query.endTime(),
+            aggregator, Aggregators.Interpolation.LERP, false));
+
+    // slurp all the points even though we aren't using them at this stage
+    while (view.hasNext()) {
+      final DataPoint mdp = view.next();
+      @SuppressWarnings("unused")
+      final Object o = mdp.isInteger() ? mdp.longValue() : mdp.doubleValue();
+    }
+
+    final long[] max_longs = aggregator.getLongMaxes();
+    final double[] max_doubles = aggregator.getDoubleMaxes();
+    final TopNSortingEntry[] max_by_ts = new TopNSortingEntry[num_results];
+    if (aggregator.hasDoubles() && aggregator.hasLongs()) {
+      for (int i = 0; i < num_results; i++) {
+        max_by_ts[i] = new TopNSortingEntry(
+            Math.max((double)max_longs[i], max_doubles[i]), i);
+      }
+    } else if (aggregator.hasLongs() && !aggregator.hasDoubles()) {
+      for (int i = 0; i < num_results; i++) {
+        max_by_ts[i] = new TopNSortingEntry((double) max_longs[i], i);
+      }
+    } else if (aggregator.hasDoubles() && !aggregator.hasLongs()) {
+      for (int i = 0; i < num_results; i++) {
+        max_by_ts[i] = new TopNSortingEntry(max_doubles[i], i);
+      }
+    }
+    
+    Arrays.sort(max_by_ts);
+    
+    final int result_count = Math.min(topn, num_results);
+    final DataPoints[] results = new DataPoints[result_count];
+    for (int i = 0; i < result_count; i++) {
+      results[i] = post_agg_results[max_by_ts[i].pos];
+    }
+
+    return results;
+  }
+
+  /**
+   * Helper class for sorting the series. It will sort from highest to lowest.
+   */
+  static class TopNSortingEntry implements Comparable<TopNSortingEntry> {
+    final double val;
+    final int pos;
+    
+    public TopNSortingEntry(final double val, final int pos) {
+      this.val = val;
+      this.pos = pos;
+    }
+    
+    @Override
+    public String toString() {
+      return "{" + val + "," + pos + "}";
+    }
+    
+    @Override
+    public int compareTo(final TopNSortingEntry o) {
+      return -1 * Double.compare(val, o.val);
+    }
+  }
+
+  @Override
+  public String writeStringField(final List<String> query_params, 
+      final String inner_expression) {
+    return "highestMax(" + inner_expression + ")";
+  }
+  
+  /**
+   * Aggregator that stores the overall maximum value for the entire series
+   */
+  public static class MaxCacheAggregator extends Aggregator {
+    /** The total number of series in the result set, including sub queries and
+     * group bys */
+    private final int total_series;
+    /** An array of maximum integers by time series */
+    private final long[] max_longs;
+    /** An array of maximum doubles by time series */
+    private final double[] max_doubles;
+    /** Whether or not any of the series contain integers */
+    private boolean has_longs = false;
+    /** Whether or not any of the series contain doubles */
+    private boolean has_doubles = false;
+    /** Query start time in milliseconds for filtering */
+    private long start;
+    /** Query end time in milliseconds for filtering */
+    private long end;
+
+    /**
+     * An aggregator that keeps track of the maximum values for each time series
+     * in the result set.
+     * @param method The interpolation method (not used)
+     * @param name The name of the aggregator 
+     * @param total_series The total number of series in the result set, 
+     * including sub queries and group bys
+     * @param start Query start time in milliseconds for filtering
+     * @param end Query end time in milliseconds for filtering
+     */
+    public MaxCacheAggregator(final Interpolation method, final String name, 
+        final int total_series, final long start, final long end) {
+      super(method, name);
+      this.total_series = total_series;
+      this.start = start;
+      this.end = end;
+      this.max_longs = new long[total_series];
+      this.max_doubles = new double[total_series];
+
+      for (int i = 0; i < total_series; i++) {
+        max_doubles[i] = Double.MIN_VALUE;
+        max_longs[i] = Long.MIN_VALUE;
+      }
+    }
+
+    @Override
+    public long runLong(final Longs values) {
+      // TODO(cl) - Can we get anything other than a DataPoint?
+      if (values instanceof DataPoint) {
+        long ts = ((DataPoint) values).timestamp();
+        //data point falls outside required range
+        if (ts < start || ts > end) {
+          return 0;
+        }
+      }
+
+      final long[] longs = new long[total_series];
+      int ix = 0;
+      longs[ix++] = values.nextLongValue();
+      while (values.hasNextValue()) {
+        longs[ix++] = values.nextLongValue();
+      }
+
+      for (int i = 0; i < total_series;i++) {
+        max_longs[i] = Math.max(max_longs[i], longs[i]);
+      }
+
+      has_longs = true;
+      return 0;
+    }
+
+    @Override
+    public double runDouble(Doubles values) {
+      // TODO(cl) - Can we get anything other than a DataPoint?
+      if (values instanceof DataPoint) {
+        long ts = ((DataPoint) values).timestamp();
+        //data point falls outside required range
+        if (ts < start || ts > end) {
+          return 0;
+        }
+      }
+
+      final double[] doubles = new double[total_series];
+      int ix = 0;
+      doubles[ix++] = values.nextDoubleValue();
+      while (values.hasNextValue()) {
+        doubles[ix++] = values.nextDoubleValue();
+      }
+      for (int i = 0; i < total_series;i++) {
+        // TODO(cl) - Properly handle NaNs here
+        max_doubles[i] = Math.max(max_doubles[i], doubles[i]);
+      }
+
+      has_doubles = true;
+      return 0;
+    }
+
+    public long[] getLongMaxes() {
+      return max_longs;
+    }
+
+    public double[] getDoubleMaxes() {
+      return max_doubles;
+    }
+
+    public boolean hasLongs() {
+      return has_longs;
+    }
+
+    public boolean hasDoubles() {
+      return has_doubles;
+    }
+    
+  }
+}
diff --git a/src/query/expression/ITimeSyncedIterator.java b/src/query/expression/ITimeSyncedIterator.java
new file mode 100644
index 0000000000..b72a0df401
--- /dev/null
+++ b/src/query/expression/ITimeSyncedIterator.java
@@ -0,0 +1,89 @@
+// This file is part of OpenTSDB.
+// Copyright (C) 2015  The OpenTSDB Authors.
+//
+// This program is free software: you can redistribute it and/or modify it
+// under the terms of the GNU Lesser General Public License as published by
+// the Free Software Foundation, either version 2.1 of the License, or (at your
+// option) any later version.  This program is distributed in the hope that it
+// will be useful, but WITHOUT ANY WARRANTY; without even the implied warranty
+// of MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser
+// General Public License for more details.  You should have received a copy
+// of the GNU Lesser General Public License along with this program.  If not,
+// see <http://www.gnu.org/licenses/>.
+package net.opentsdb.query.expression;
+
+import net.opentsdb.utils.ByteSet;
+
+/**
+ * An interface for expressions or queries that operate across time series
+ * and require point-by-point timestamp synchronization. 
+ * @since 2.3
+ */
+public interface ITimeSyncedIterator {
+
+  /** @return true if any of the series in the set has another value */
+  public boolean hasNext();
+  
+  /**
+   * @param timestamp The timestamp to fastforward to
+   * @return The data point array for the given timestamp. Implementations
+   * may throw an exception if the timestamp is invliad or they may return an
+   * empty array.
+   */
+  public ExpressionDataPoint[] next(final long timestamp);
+  
+  /** 
+   * Determines whether the individual series in the {@link values} array has 
+   * another value. This may be used for non-synchronous iteration.
+   * @param index The index of the series in the values array to check for
+   * @return True if the series has another value, false if not
+   */
+  public boolean hasNext(final int index);
+  
+  /**
+   * Fetches the next value for an individual series in the {@link values} array.
+   * @param index The index of the series in the values array to advance
+   */
+  public void next(final int index);  
+  
+  /**
+   * @return the next timestamp available in this set.
+   */
+  public long nextTimestamp();
+  
+  /** @return the number of series in this set */
+  public int size();
+  
+  /** @return an array of the emitters populated during iteration */
+  public ExpressionDataPoint[] values();
+
+  /** @param index the index to null. Nulls the given object so we don't use it
+   * in timestamps.
+   */
+  public void nullIterator(final int index);
+  
+  /** @return the index in the ExpressionIterator */
+  public int getIndex();
+  
+  /** @param the index in the ExpressionIterator */
+  public void setIndex(final int index);
+  
+  /** @return the ID of this set given by the user */
+  public String getId();
+
+  /** @return a set of unique tag key UIDs from the filter list. If no filters
+   * were defined then the set may be empty.  */
+  public ByteSet getQueryTagKs();
+
+  /** @param A fill policy for the iterator. Iterators should implement a default */
+  public void setFillPolicy(final NumericFillPolicy policy);
+  
+  /** @return the fill policy for the iterator */
+  public NumericFillPolicy getFillPolicy();
+  
+  /** @return a copy of the iterator. This should return references to 
+   * underlying data objects but not necessarily copy all of the underlying 
+   * data (to avoid memory explosions). This is useful for creating other
+   * iterators that operate over the same data. */
+  public ITimeSyncedIterator getCopy();
+}
diff --git a/src/query/expression/IntersectionIterator.java b/src/query/expression/IntersectionIterator.java
new file mode 100644
index 0000000000..40d01068a0
--- /dev/null
+++ b/src/query/expression/IntersectionIterator.java
@@ -0,0 +1,521 @@
+// This file is part of OpenTSDB.
+// Copyright (C) 2015  The OpenTSDB Authors.
+//
+// This program is free software: you can redistribute it and/or modify it
+// under the terms of the GNU Lesser General Public License as published by
+// the Free Software Foundation, either version 2.1 of the License, or (at your
+// option) any later version.  This program is distributed in the hope that it
+// will be useful, but WITHOUT ANY WARRANTY; without even the implied warranty
+// of MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser
+// General Public License for more details.  You should have received a copy
+// of the GNU Lesser General Public License along with this program.  If not,
+// see <http://www.gnu.org/licenses/>.
+package net.opentsdb.query.expression;
+
+import java.util.HashMap;
+import java.util.Iterator;
+import java.util.Map;
+import java.util.Map.Entry;
+
+import net.opentsdb.core.IllegalDataException;
+import net.opentsdb.core.TSDB;
+import net.opentsdb.utils.ByteSet;
+
+import org.hbase.async.Bytes;
+import org.hbase.async.Bytes.ByteMap;
+import org.hbase.async.HBaseClient;
+import org.slf4j.Logger;
+import org.slf4j.LoggerFactory;
+
+import sun.reflect.generics.reflectiveObjects.NotImplementedException;
+
+/**
+ * This class handles taking a set of queries and their results and iterates 
+ * over each series in each set with time alignment after computing the 
+ * intersection of all sets.
+ * <p>
+ * The iterator performs the following:
+ * - calculates the intersection of all queries based on the tags or query tags
+ *   and optionally the aggregated tags.
+ * - any series that are not members of ever set are kicked out (and logged).
+ * - series are aligned across queries so that expressions can operate over them.
+ * - series are also time aligned and maintain alignment during iteration.
+ * <p>
+ * The {@link #current_values} map will map the expression "variables" to the
+ * proper iterator for each serie's array. E.g.
+ *   <"A", [1, 2, 3, 4]>
+ *   <"B", [1, 2, 3, 4]>
+ * <p>
+ * So to use it's you simply fetch the result map, call {@link #hasNext()} and
+ * {@link #next()} to iterate and in a for loop, iterate {@link #getSeriesSize()}
+ * times to get all of the current values.
+ * For efficiency, call {@link #getResults()} once before iterating, then on 
+ * each call to {@link #next()} you can just iterate over the same result map 
+ * again as the values will be updated.
+ * @since 2.3
+ */
+public class IntersectionIterator implements ITimeSyncedIterator, VariableIterator {
+  private static final Logger LOG = LoggerFactory.getLogger(IntersectionIterator.class);
+  
+  /** The queries compiled and fetched from storage */
+  private final Map<String, ITimeSyncedIterator> queries;
+  
+  /** A list of the current values for each series post intersection */
+  private final Map<String, ExpressionDataPoint[]> current_values;
+
+  /** A map of the sub query index to their names for intersection computation */
+  private final String[] index_to_names;
+  
+  /** Whether or not to intersect on the query tagks instead of the result set
+   * tagks */
+  private final boolean intersect_on_query_tagks;
+  
+  /** Whether or not to include the aggregated tags in the result set */
+  private final boolean include_agg_tags;
+  
+  /** The start/current timestamp for the iterator in ms */
+  private long timestamp;
+  
+  /** Post intersection number of time series */
+  private int series_size;
+  
+  /** The ID of this iterator */
+  private final String id;
+  
+  /** The index of this iterator in a list of iterators */
+  private int index;
+  
+  /**
+   * Ctor to create the expression lock-step iterator from a set of query results.
+   * If the results map is empty, then the ctor will complete but the results map
+   * will be empty and calls to {@link #hasNext()} will always return false.
+   * @param results The query results to store
+   * @param intersect_on_query_tagks Whether or not to include only the query 
+   * specified tags during intersection
+   * @param include_agg_tags Whether or not to include aggregated tags during
+   * intersection
+   * @throws IllegalDataException if, after computing the intersection, no results
+   * would be left.
+   */
+  public IntersectionIterator(final String id, final Map<String, ITimeSyncedIterator> results, 
+      final boolean intersect_on_query_tagks, final boolean include_agg_tags) {
+    this.id = id;
+    this.intersect_on_query_tagks = intersect_on_query_tagks;
+    this.include_agg_tags = include_agg_tags;
+    timestamp = Long.MAX_VALUE;
+    queries = new HashMap<String, ITimeSyncedIterator>(results.size());
+    current_values = new HashMap<String, ExpressionDataPoint[]>(results.size());
+    index_to_names = new String[results.size()];
+    
+    int max_series = 0;
+    int i = 0;
+    for (final Map.Entry<String, ITimeSyncedIterator> entry : results.entrySet()) {
+      if (LOG.isDebugEnabled()) {
+        LOG.debug("Adding iterator " + entry.getValue());
+      }
+      queries.put(entry.getKey(), entry.getValue());
+      entry.getValue().setIndex(i);
+      index_to_names[i] = entry.getKey();
+      if (entry.getValue().values().length > max_series) {
+        max_series = entry.getValue().values().length;
+      }
+      ++i;
+    }
+    
+    if (max_series < 1) {
+      // we don't want to throw an exception here, just set it up so that the
+      // call to {@link #hasNext()} will be false.
+      LOG.debug("No series in the result sets");
+      return;
+    }
+    
+    computeIntersection();
+    
+    // calculate the starting timestamp from the various iterators
+    for (final ITimeSyncedIterator it : queries.values()) {
+      final long ts = it.nextTimestamp();
+      if (ts < timestamp) {
+        timestamp = ts;
+      }
+    }
+  }
+
+  /**
+   * A sort of copy constructor that populates the iterator from an existing 
+   * iterator, copying all child iterators.
+   * @param iterator The iterator to copy from.
+   */
+  private IntersectionIterator(final IntersectionIterator iterator) {
+    id = iterator.id;
+    intersect_on_query_tagks = iterator.intersect_on_query_tagks;
+    include_agg_tags = iterator.include_agg_tags;
+    timestamp = Long.MAX_VALUE;
+    queries = new HashMap<String, ITimeSyncedIterator>(iterator.queries.size());
+    current_values = new HashMap<String, ExpressionDataPoint[]>(queries.size());
+    index_to_names = new String[queries.size()];
+    
+    int max_series = 0;
+    int i = 0;
+    for (final Entry<String, ITimeSyncedIterator> entry : iterator.queries.entrySet()) {
+      queries.put(entry.getKey(), entry.getValue().getCopy());
+      entry.getValue().setIndex(i);
+      index_to_names[i] = entry.getKey();
+      if (entry.getValue().values().length > max_series) {
+        max_series = entry.getValue().values().length;
+      }
+      ++i;
+    }
+    
+    if (max_series < 1) {
+      // we don't want to throw an exception here, just set it up so that the
+      // call to {@link #hasNext()} will be false.
+      LOG.debug("No series in the result sets");
+      return;
+    }
+    
+    computeIntersection();
+    
+    // calculate the starting timestamp from the various iterators
+    for (final ITimeSyncedIterator it : queries.values()) {
+      final long ts = it.nextTimestamp();
+      if (ts < timestamp) {
+        timestamp = ts;
+      }
+    }
+  }
+  
+  @Override
+  public String toString() {
+    final StringBuilder buf = new StringBuilder();
+    buf.append("IntersectionIterator(id=")
+       .append(id)
+       .append(", useQueryTags=")
+       .append(intersect_on_query_tagks)
+       .append(", includeAggTags=")
+       .append(include_agg_tags)
+       .append(", index=")
+       .append(index)
+       .append(", queries=")
+       .append(queries);
+    return buf.toString();
+  }
+  
+  @Override
+  public boolean hasNext() {
+    for (final ITimeSyncedIterator sub : queries.values()) {
+      if (sub.hasNext()) {
+        return true;
+      }
+    }
+    return false;
+  }
+  
+  /** fetch the next set of time aligned results for all series */
+  @Override
+  public void next() {
+    if (!hasNext()) {
+      throw new IllegalDataException("No more data");
+    }
+    for (final ITimeSyncedIterator sub : queries.values()) {
+      sub.next(timestamp);
+    }
+    timestamp = nextTimestamp();
+  }
+  
+  /** @return a map of values that will change on each iteration */
+  @Override 
+  public Map<String, ExpressionDataPoint[]> getResults() {
+    return current_values;
+  }
+
+  /** @return the number of series in each map of the result set */
+  @Override
+  public int getSeriesSize() {
+    return series_size;
+  }
+  
+  /** @return the next timestamp calculated from all series in the set */
+  public long nextTimestamp() {
+    long ts = Long.MAX_VALUE;
+    for (final ITimeSyncedIterator sub : queries.values()) {
+      if (sub != null) {
+        final long t = sub.nextTimestamp();
+        if (t < ts) {
+          ts = t;
+        }
+      }
+    }
+    return ts;
+  }
+  
+  /**
+   * A super ugly messy way to compute the intersection of the various sets of 
+   * time series returned from the sub queries. 
+   * <p>
+   * The process is:
+   * - Iterate over each query set
+   * - For the first set, flatten each series' tag and (optionally) aggregated tag
+   *   set into a single byte array for use as an ID.
+   * - Populate a map with the IDs and references to the series iterator for the
+   *   first query set.
+   * - For each additional set, flatten the tags and if the tag set ID isn't in
+   *   the intersection map, kick it out.
+   * - For each key in the intersection map, if it doesn't appear in the current
+   *   query set, kick it out.
+   * - Once all sets are finished, align the resulting series iterators in the 
+   *   {@link #current_values} map which is then prepped for expression processing.
+   * @throws IllegalDataException if more than one series was supplied and 
+   * the resulting intersection failed to produce any series
+   */
+  private void computeIntersection() {
+    final ByteMap<ExpressionDataPoint[]> ordered_intersection = 
+        new ByteMap<ExpressionDataPoint[]>(); 
+    final Iterator<ITimeSyncedIterator> it = queries.values().iterator();
+    
+    // assume we have at least on query in our set
+    ITimeSyncedIterator sub = it.next();
+    Map<String, ByteMap<Integer>> flattened_tags = 
+        new HashMap<String, ByteMap<Integer>>(queries.size()); 
+    ByteMap<Integer> tags = new ByteMap<Integer>();
+    flattened_tags.put(sub.getId(), tags);
+    ExpressionDataPoint[] dps = sub.values();
+    
+    for (int i = 0; i < sub.size(); i++) {
+      final byte[] tagks = flattenTags(intersect_on_query_tagks, include_agg_tags,
+          dps[i].tags(), dps[i].aggregatedTags(), sub);
+      tags.put(tagks, i);
+
+      final ExpressionDataPoint[] idps = new ExpressionDataPoint[queries.size()];
+      idps[sub.getIndex()] = dps[i];
+      ordered_intersection.put(tagks, idps);
+    }
+    
+    if (!it.hasNext()) {
+      setCurrentAndMeta(ordered_intersection);
+      return;
+    }
+    
+    while (it.hasNext()) {
+      sub = it.next();
+      tags = new ByteMap<Integer>();
+      flattened_tags.put(sub.getId(), tags);
+      dps = sub.values();
+      
+      // loop through the series in the sub iterator, compute the flattened tag
+      // ids, then kick out any that are NOT in the existing intersection map.
+      for (int i = 0; i < sub.size(); i++) {
+        final byte[] tagks = flattenTags(intersect_on_query_tagks, include_agg_tags, 
+            dps[i].tags(), dps[i].aggregatedTags(), sub);
+        tags.put(tagks, i);
+
+        final ExpressionDataPoint[] idps = ordered_intersection.get(tagks);
+        if (idps == null) {
+          if (LOG.isDebugEnabled()) {
+            LOG.debug("Kicking out " + Bytes.pretty(tagks) + " from " + sub.getId());
+          }
+          sub.nullIterator(i);
+          continue;
+        }
+        idps[sub.getIndex()] = dps[i];
+      }
+      
+      // gotta go backwards now to complete the intersection by kicking
+      // any series that appear in other sets but not HERE
+      final Iterator<Entry<byte[], ExpressionDataPoint[]>> reverse_it = 
+          ordered_intersection.iterator();
+      while (reverse_it.hasNext()) {
+        Entry<byte[], ExpressionDataPoint[]> e = reverse_it.next();
+        if (!tags.containsKey(e.getKey())) {
+          if (LOG.isDebugEnabled()) {
+            LOG.debug("Kicking out " + Bytes.pretty(e.getKey()) + 
+                " from the main list since the query for " + sub.getId() + 
+                " didn't have it");
+          }
+          
+          // null the iterators for the other sets
+          for (final Map.Entry<String, ByteMap<Integer>> entry : 
+              flattened_tags.entrySet()) {
+            if (entry.getKey().equals(sub.getId())) {
+              continue;
+            }
+            final Integer index = entry.getValue().get(e.getKey());
+            if (index != null) {
+              queries.get(entry.getKey()).nullIterator(index);
+            }
+          }
+          
+          reverse_it.remove();
+        }
+      }
+    }
+    
+    // now set our properly condensed and ordered values
+    if (ordered_intersection.size() < 1) {
+      // TODO - is it best to toss an exception here or return an empty result?
+      throw new IllegalDataException("No intersections found: " + this);
+    }
+    
+    setCurrentAndMeta(ordered_intersection);
+  }
+  
+  /**
+   * Takes the resulting intersection and builds the {@link #current_values}
+   * and {@link #meta} maps.
+   * @param ordered_intersection The intersection to build from.
+   */
+  private void setCurrentAndMeta(final ByteMap<ExpressionDataPoint[]> 
+      ordered_intersection) {
+    for (final String id : queries.keySet()) {
+      current_values.put(id, new ExpressionDataPoint[ordered_intersection.size()]);
+    }
+    
+    int i = 0;
+    for (final ExpressionDataPoint[] idps : ordered_intersection.values()) {
+      for (int x = 0; x < idps.length; x++) {
+        final ExpressionDataPoint[] current_dps = 
+            current_values.get(index_to_names[x]);
+        current_dps[i] = idps[x];
+      }
+      ++i;
+    }
+    series_size = ordered_intersection.size();
+  }
+  
+  /**
+   * Flattens the appropriate tags into a single byte array
+   * @param use_query_tags Whether or not to include tags returned with the
+   * results or just use those group by'd in the query
+   * @param include_agg_tags Whether or not to include the aggregated tags in
+   * the identifier
+   * @param tags The map of tags from the result set
+   * @param agg_tags The list of aggregated tags
+   * @param sub The sub query iterator
+   * @return A byte array with the flattened tag keys and values. Note that
+   * if the tags set is empty, this may return an empty array (but not a null
+   * array)
+   */
+  static byte[] flattenTags(final boolean use_query_tags, 
+      final boolean include_agg_tags, final ByteMap<byte[]> tags, 
+      final ByteSet agg_tags, final ITimeSyncedIterator sub) {
+    if (tags.isEmpty()) {
+      return HBaseClient.EMPTY_ARRAY;
+    }
+    final ByteSet query_tagks;
+    // NOTE: We MAY need the agg tags but I'm not sure yet
+    final int tag_size;
+    if (use_query_tags) {
+      int i = 0;
+      if (sub.getQueryTagKs() != null && !sub.getQueryTagKs().isEmpty()) {
+        query_tagks = sub.getQueryTagKs();
+        for (final Map.Entry<byte[], byte[]> pair : tags.entrySet()) {
+          if (query_tagks.contains(pair.getKey())) {
+            i++;
+          }
+        }
+      } else {
+        query_tagks = new ByteSet();
+      }
+      tag_size = i;
+    } else {
+      query_tagks = new ByteSet();
+      tag_size = tags.size();
+    }
+    
+    int len = (tag_size * (TSDB.tagk_width() + TSDB.tagv_width())) +
+      (include_agg_tags ? (agg_tags.size() * TSDB.tagk_width()) : 0);
+    final byte[] tagks = new byte[len];
+    int i = 0;
+    for (final Map.Entry<byte[], byte[]> pair : tags.entrySet()) {
+      if (use_query_tags && !query_tagks.contains(pair.getKey())) {
+        continue;
+      }
+      System.arraycopy(pair.getKey(), 0, tagks, i, TSDB.tagk_width());
+      i += TSDB.tagk_width();
+      System.arraycopy(pair.getValue(), 0, tagks, i, TSDB.tagv_width());
+      i += TSDB.tagv_width();
+    }
+    if (include_agg_tags) {
+      for (final byte[] tagk : agg_tags) {
+        System.arraycopy(tagk, 0, tagks, i, TSDB.tagk_width());
+        i += TSDB.tagk_width();
+      }
+    }
+    return tagks;
+  }
+
+  @Override
+  public ExpressionDataPoint[] next(long timestamp) {
+    throw new NotImplementedException();
+  }
+
+  @Override
+  public int size() {
+    throw new NotImplementedException();
+  }
+
+  @Override
+  public ExpressionDataPoint[] values() {
+    throw new NotImplementedException();
+  }
+
+  @Override
+  public void nullIterator(int index) {
+    throw new NotImplementedException();
+  }
+
+  @Override
+  public int getIndex() {
+    return index;
+  }
+
+  @Override
+  public void setIndex(int index) {
+    this.index = index;
+  }
+
+  @Override
+  public String getId() {
+    return id;
+  }
+
+  @Override
+  public ByteSet getQueryTagKs() {
+    throw new NotImplementedException();
+  }
+
+  @Override
+  public void setFillPolicy(NumericFillPolicy policy) {
+    throw new NotImplementedException();
+  }
+
+  @Override
+  public NumericFillPolicy getFillPolicy() {
+    throw new NotImplementedException();
+  }
+
+  @Override
+  public ITimeSyncedIterator getCopy() {
+    return new IntersectionIterator(this);
+  }
+
+  @Override
+  public boolean hasNext(int index) {
+    for (final ITimeSyncedIterator sub : queries.values()) {
+      if (sub.hasNext(index)) {
+        return true;
+      }
+    }
+    return false;
+  }
+
+  @Override
+  public void next(int index) {
+    if (!hasNext()) {
+      throw new IllegalDataException("No more data");
+    }
+    for (final ITimeSyncedIterator sub : queries.values()) {
+      sub.next(index);
+    }
+  }
+
+}
diff --git a/src/query/expression/MovingAverage.java b/src/query/expression/MovingAverage.java
new file mode 100644
index 0000000000..5a86b90c7c
--- /dev/null
+++ b/src/query/expression/MovingAverage.java
@@ -0,0 +1,345 @@
+// This file is part of OpenTSDB.
+// Copyright (C) 2015  The OpenTSDB Authors.
+//
+// This program is free software: you can redistribute it and/or modify it
+// under the terms of the GNU Lesser General Public License as published by
+// the Free Software Foundation, either version 2.1 of the License, or (at your
+// option) any later version.  This program is distributed in the hope that it
+// will be useful, but WITHOUT ANY WARRANTY; without even the implied warranty
+// of MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser
+// General Public License for more details.  You should have received a copy
+// of the GNU Lesser General Public License along with this program.  If not,
+// see <http://www.gnu.org/licenses/>.
+package net.opentsdb.query.expression;
+
+import java.util.ArrayList;
+import java.util.Iterator;
+import java.util.LinkedList;
+import java.util.List;
+import java.util.concurrent.TimeUnit;
+
+import net.opentsdb.core.AggregationIterator;
+import net.opentsdb.core.Aggregator;
+import net.opentsdb.core.Aggregators;
+import net.opentsdb.core.DataPoint;
+import net.opentsdb.core.DataPoints;
+import net.opentsdb.core.IllegalDataException;
+import net.opentsdb.core.MutableDataPoint;
+import net.opentsdb.core.SeekableView;
+import net.opentsdb.core.TSQuery;
+import net.opentsdb.core.Aggregators.Interpolation;
+
+/**
+ * Implements a moving average function windowed on either the number of 
+ * data points or a unit of time.
+ * @since 2.3
+ */
+public class MovingAverage implements Expression {
+  
+  @Override
+  public DataPoints[] evaluate(final TSQuery data_query, 
+      final List<DataPoints[]> query_results, final List<String> params) {
+    if (data_query == null) {
+      throw new IllegalArgumentException("Missing time series query");
+    }
+    if (query_results == null || query_results.isEmpty()) {
+      return new DataPoints[]{};
+    }
+    if (params == null || params.isEmpty()) {
+      throw new IllegalArgumentException("Missing moving average window size");
+    }
+
+    String param = params.get(0);
+    if (param == null || param.isEmpty()) {
+      throw new IllegalArgumentException("Missing moving average window size");
+    }
+    param = param.trim();
+    
+    long condition = -1;
+    boolean is_time_unit = false;
+    if (param.matches("^[0-9]+$")) {
+      try {
+        condition = Integer.parseInt(param);
+      } catch (NumberFormatException nfe) {
+        throw new IllegalArgumentException(
+            "Invalid parameter, must be an integer", nfe);
+      }
+    } else if (param.startsWith("'") && param.endsWith("'")) {
+      condition = parseParam(param);
+      is_time_unit = true;
+    } else {
+      throw new IllegalArgumentException("Unparseable window size: " + param);
+    }
+    if (condition <= 0) {
+      throw new IllegalArgumentException("Moving average window must be an "
+          + "integer greater than zero");
+    }
+
+    int num_results = 0;
+    for (final DataPoints[] results : query_results) {
+      num_results += results.length;
+    }
+    
+    final PostAggregatedDataPoints[] post_agg_results = 
+        new PostAggregatedDataPoints[num_results];
+    int ix = 0;
+    // one or more queries (m=...&m=...&m=...)
+    for (final DataPoints[] sub_query_result : query_results) {
+      // group bys (m=sum:foo{host=*})
+      for (final DataPoints dps: sub_query_result) {
+        // TODO(cl) - Avoid iterating and copying if we can help it. We should
+        // be able to pass the original DataPoints object to the seekable view
+        // and then iterate through it.
+        final List<DataPoint> mutable_points = new ArrayList<DataPoint>();
+        for (final DataPoint point: dps) {
+          // avoid flip-flopping between integers and floats, always use double
+          // for average.
+          mutable_points.add(
+              MutableDataPoint.ofDoubleValue(point.timestamp(), point.toDouble()));
+        }
+        
+        post_agg_results[ix++] = new PostAggregatedDataPoints(dps,
+                mutable_points.toArray(new DataPoint[mutable_points.size()]));
+      }
+    }
+    
+    final DataPoints[] results = new DataPoints[num_results];
+    for (int i = 0; i < num_results; i++) {
+      final Aggregator moving_average = new MovingAverageAggregator(
+          Aggregators.Interpolation.LERP, "movingAverage", 
+          condition, is_time_unit);
+      final SeekableView[] metrics_groups = new SeekableView[] { 
+          post_agg_results[i].iterator() };
+      final SeekableView view = new AggregationIterator(metrics_groups,
+              data_query.startTime(), data_query.endTime(),
+              moving_average, 
+              Aggregators.Interpolation.LERP, false);
+      final List<DataPoint> points = new ArrayList<DataPoint>();
+      while (view.hasNext()) {
+        final DataPoint mdp = view.next();
+        points.add(MutableDataPoint.ofDoubleValue(mdp.timestamp(), mdp.toDouble()));
+      }
+      results[i] = new PostAggregatedDataPoints(post_agg_results[i],
+        points.toArray(new DataPoint[points.size()]));
+    }
+    return results;
+  }
+  
+  /**
+   * Parses the parameter string to fetch the window size
+   * <p>
+   * Package private for UTs
+   * @param param The string to parse
+   * @return The window size (number of points or a unit of time in ms)
+   */
+  long parseParam(final String param) {
+    if (param == null || param.isEmpty()) {
+      throw new IllegalArgumentException(
+          "Window parameter may not be null or empty");
+    }
+    final char[] chars = param.toCharArray();
+    int idx = 0;
+    for (int c = 1; c < chars.length; c++) {
+      if (Character.isDigit(chars[c])) {
+        idx++;
+      } else {
+        break;
+      }
+    }
+    if (idx < 1) {
+      throw new IllegalArgumentException("Invalid moving window parameter: " 
+          + param);
+    }
+
+    try {
+      final int time = Integer.parseInt(param.substring(1, idx + 1));
+      final String unit = param.substring(idx + 1, param.length() - 1);
+  
+      // TODO(CL) - add a Graphite unit parser to DateTime for this kind of conversion
+      if ("day".equals(unit) || "d".equals(unit)) {
+        return TimeUnit.MILLISECONDS.convert(time, TimeUnit.DAYS);
+      } else if ("hr".equals(unit) || "hour".equals(unit) || "h".equals(unit)) {
+        return TimeUnit.MILLISECONDS.convert(time, TimeUnit.HOURS);
+      } else if ("min".equals(unit) || "m".equals(unit)) {
+        return TimeUnit.MILLISECONDS.convert(time, TimeUnit.MINUTES); 
+      } else if ("sec".equals(unit) || "s".equals(unit)) {
+        return TimeUnit.MILLISECONDS.convert(time, TimeUnit.SECONDS);
+      } else {
+        throw new IllegalArgumentException("Unknown time unit=" + unit 
+            + " in window=" + param);
+      }
+    } catch (NumberFormatException nfe) {
+      throw new IllegalArgumentException("Unable to parse moving window "
+          + "parameter: " + param, nfe);
+    }
+  }
+
+  @Override
+  public String writeStringField(final List<String> query_params, 
+      final String inner_expression) {
+    return "movingAverage(" + inner_expression + ")";
+  }
+
+  /**
+   * An aggregator that expects a single data point for each iteration. The
+   * values are prepended to a linked list. Next it iterates over the list until
+   * it either runs out of values (and returns a 0 with the proper timestamp) or
+   * returns the average of all values in the given window (time or number based).
+   * <p>
+   * Package private for unit testing
+   */
+  static final class MovingAverageAggregator extends Aggregator {
+    /** The individual values in the window */
+    private final LinkedList<DataPoint> accumulation;
+    /** The condition to satisfy, either a time unit or # of data points */
+    private final long condition;
+    /** Whether or not the condition is a time unit or the # of data points */
+    private final boolean is_time_unit;
+    /** Sentinel used to kick out the first timed window value */
+    private boolean window_started;
+    
+    /**
+     * Ctor for this implementation
+     * @param method The interpolation method to use (ignored)
+     * @param name The name of this aggregator
+     * @param condition The windowing condition
+     * @param is_time_unit Whether or not the condition is a time unit or 
+     * the # of data points
+     */
+    public MovingAverageAggregator(final Interpolation method, final String name, 
+        final long condition, final boolean is_time_unit) {
+      super(method, name);
+      this.condition = condition;
+      this.is_time_unit = is_time_unit;
+      accumulation = new LinkedList<DataPoint>();
+    }
+
+    @Override
+    public long runLong(final Longs values) {
+      final long value = values.nextLongValue();
+      if (values.hasNextValue()) {
+        throw new IllegalDataException(
+            "There should only be one value in " + values);
+      }
+      final long ts = ((DataPoint) values).timestamp();
+      accumulation.addFirst(MutableDataPoint.ofLongValue(ts, value));
+
+      // for timed windows we need to skip the first data point in the series
+      // as we have no idea what the previous value's timestamp was.
+      if (is_time_unit && !window_started) {
+        window_started = true;
+        return 0;
+      }
+      
+      long sum = 0; 
+      int count = 0;
+      final Iterator<DataPoint> iter = accumulation.iterator();
+      boolean condition_met = false;
+      long time_window_cumulation = 0; // how many ms are in our window
+      long last_ts = -1; // the timestamp of the previous dp
+
+      // now sum up the preceding points
+      while(iter.hasNext()) {
+        final DataPoint dp = iter.next();
+        if (is_time_unit) {
+          if (last_ts < 0) {
+            last_ts = dp.timestamp();
+          } else {
+            time_window_cumulation += last_ts - dp.timestamp();
+            last_ts = dp.timestamp();
+            if (time_window_cumulation >= condition) {
+              condition_met = true;
+              break;
+            }
+          }
+        }
+        // cast to long if we dumped a double in there
+        sum += dp.isInteger() ? dp.longValue() : dp.doubleValue();
+        count++;
+        if (!is_time_unit && count >= condition) {
+          condition_met = true;
+          break;
+        }
+      }
+      while (iter.hasNext()) {
+        // should drop the last entry in the linked list to avoid accumulating
+        // everything in memory
+        iter.next();
+        iter.remove();
+      }
+
+      if (!condition_met || count == 0) {
+        return 0;
+      }
+      return sum / count;
+    }
+
+    @Override
+    public double runDouble(Doubles values) {
+      final double value = values.nextDoubleValue();
+      if (values.hasNextValue()) {
+        throw new IllegalDataException(
+            "There should only be one value in " + values);
+      }
+      final long ts = ((DataPoint) values).timestamp();
+      accumulation.addFirst(MutableDataPoint.ofDoubleValue(ts, value));
+      
+      // for timed windows we need to skip the first data point in the series
+      // as we have no idea what the previous value's timestamp was.
+      if (is_time_unit && !window_started) {
+        window_started = true;
+        return 0;
+      }
+      
+      double sum = 0;
+      int count = 0;
+      final Iterator<DataPoint> iter = accumulation.iterator();
+      boolean condition_met = false;
+      long time_window_cumulation = 0; // how many ms are in our window
+      long last_ts = -1; // the timestamp of the previous dp
+      
+      // now sum up the preceding points
+      while(iter.hasNext()) {
+        final DataPoint dp = iter.next();
+        
+        if (is_time_unit) {
+          if (last_ts < 0) {
+            last_ts = dp.timestamp();
+          } else {
+            time_window_cumulation += last_ts - dp.timestamp();
+            last_ts = dp.timestamp();
+            if (time_window_cumulation >= condition) {
+              condition_met = true;
+              break;
+            }
+          }
+        }
+        
+        // cast to double if we dumped a long in there
+        final double v = dp.isInteger() ? dp.longValue() : dp.doubleValue();
+        if (!Double.isNaN(v)) {
+          // skip NaNs to avoid NaNing everything in the window.
+          sum += v;
+          count++;
+        }
+        
+        if (!is_time_unit && count >= condition) {
+          condition_met = true;
+          break;
+        }
+      }
+      
+      while (iter.hasNext()) {
+        // should drop the last entry in the linked list to avoid accumulating
+        // everything in memory
+        iter.next();
+        iter.remove();
+      }
+
+      if (!condition_met || count == 0) {
+        return 0;
+      }
+      return sum/count;
+    }
+  }
+}
diff --git a/src/query/expression/MultiplySeries.java b/src/query/expression/MultiplySeries.java
new file mode 100644
index 0000000000..34cbb251d8
--- /dev/null
+++ b/src/query/expression/MultiplySeries.java
@@ -0,0 +1,86 @@
+// This file is part of OpenTSDB.
+// Copyright (C) 2015  The OpenTSDB Authors.
+//
+// This program is free software: you can redistribute it and/or modify it
+// under the terms of the GNU Lesser General Public License as published by
+// the Free Software Foundation, either version 2.1 of the License, or (at your
+// option) any later version.  This program is distributed in the hope that it
+// will be useful, but WITHOUT ANY WARRANTY; without even the implied warranty
+// of MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser
+// General Public License for more details.  You should have received a copy
+// of the GNU Lesser General Public License along with this program.  If not,
+// see <http://www.gnu.org/licenses/>.
+package net.opentsdb.query.expression;
+
+import java.util.List;
+
+import net.opentsdb.core.DataPoints;
+import net.opentsdb.core.TSDB;
+import net.opentsdb.core.TSQuery;
+import net.opentsdb.query.expression.VariableIterator.SetOperator;
+
+/**
+ * Performs a UNION set join on up to 26 metric query results and returns the 
+ * product.
+ */
+public class MultiplySeries implements Expression {
+  /** The TSDB used for UID to name lookups */
+  final TSDB tsdb;
+  
+  /**
+   * Default ctor.
+   * @param tsdb The TSDB used for UID to name lookups
+   */
+  public MultiplySeries(final TSDB tsdb) {
+    this.tsdb = tsdb;
+  }
+  
+  @Override
+  public DataPoints[] evaluate(final TSQuery data_query, 
+      final List<DataPoints[]> query_results, final List<String> params) {
+    if (data_query == null) {
+      throw new IllegalArgumentException("Missing time series query");
+    }
+    if (query_results == null || query_results.isEmpty()) {
+      return new DataPoints[]{};
+    }
+    
+    if (query_results.size() < 2 || query_results.size() > 26) {
+      throw new IllegalArgumentException("Must have 2 to 26 series, got " + 
+          query_results.size() + " instead");
+    }
+    
+    final StringBuilder buf = new StringBuilder();
+    char v = 'a';
+    for (int i = 0; i < query_results.size(); i++) {
+      buf.append(v++);
+      if (i < query_results.size() - 1) {
+        buf.append(" * ");
+      }
+    }
+    
+    final ExpressionIterator expression = new ExpressionIterator("multiplySeries", 
+        buf.toString(), SetOperator.UNION, false, false);
+    v = 'a';
+    
+    for (final DataPoints[] dps : query_results) {
+      final TimeSyncedIterator it = new TimeSyncedIterator(
+          Character.toString(v++), null, dps);
+      expression.addResults(it.getId(), it);
+    }
+    expression.compile();
+    
+    final DataPoints[] results = new DataPoints[expression.values().length];
+    for (int i = 0; i < expression.values().length; i++) {
+      results[i] = new EDPtoDPS(tsdb, i, expression);
+    }
+    return results;
+  }
+
+  @Override
+  public String writeStringField(final List<String> query_params, 
+      final String inner_expression) {
+    return "multiplySeries(" + inner_expression + ")";
+  }
+
+}
diff --git a/src/query/expression/NumericFillPolicy.java b/src/query/expression/NumericFillPolicy.java
new file mode 100644
index 0000000000..cf0f4673d7
--- /dev/null
+++ b/src/query/expression/NumericFillPolicy.java
@@ -0,0 +1,176 @@
+// This file is part of OpenTSDB.
+// Copyright (C) 2015  The OpenTSDB Authors.
+//
+// This program is free software: you can redistribute it and/or modify it
+// under the terms of the GNU Lesser General Public License as published by
+// the Free Software Foundation, either version 2.1 of the License, or (at your
+// option) any later version.  This program is distributed in the hope that it
+// will be useful, but WITHOUT ANY WARRANTY; without even the implied warranty
+// of MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser
+// General Public License for more details.  You should have received a copy
+// of the GNU Lesser General Public License along with this program.  If not,
+// see <http://www.gnu.org/licenses/>.
+package net.opentsdb.query.expression;
+
+import com.fasterxml.jackson.annotation.JsonIgnoreProperties;
+import com.fasterxml.jackson.annotation.JsonProperty;
+import com.fasterxml.jackson.databind.annotation.JsonDeserialize;
+import com.fasterxml.jackson.databind.annotation.JsonPOJOBuilder;
+import com.google.common.base.Objects;
+
+import net.opentsdb.core.FillPolicy;
+
+/**
+ * POJO for serdes of fill policies. It allows the user to pick either policies
+ * with default values or a scalar that can be supplied with any number.
+ * @since 2.3
+ */
+@JsonDeserialize(builder = NumericFillPolicy.Builder.class)
+public class NumericFillPolicy {
+
+  /** The fill policy to use. This is required */
+  private FillPolicy policy;
+  
+  /** The value to store with the fill policy */
+  private double value;
+
+  /**
+   * CTor to set the policy. Also calls {@link #validate()}
+   * @param policy The policy to set.
+   */
+  public NumericFillPolicy(final FillPolicy policy) {
+    this.policy = policy;
+    validate();
+  }
+  
+  /**
+   * CTor to set the policy and value. Also calls {@link #validate()}
+   * @param policy The name of the fill policy
+   * @param value The value to use when filling
+   * @throws IllegalArgumentException if the policy and value don't gel together
+   */
+  public NumericFillPolicy(final FillPolicy policy, final double value) {
+    this.policy = policy;
+    this.value = value;
+    validate();
+  }
+  
+  @Override
+  public String toString() {
+    return "policy=" + policy + ", value=" + value;
+  }
+  
+  /** @returns a NumericFillPolicy builder */
+  public static Builder Builder() {
+    return new Builder();
+  }
+  
+  /**
+   * A builder class for deserialization via Jackson
+   */
+  @JsonIgnoreProperties(ignoreUnknown = true)
+  @JsonPOJOBuilder(buildMethodName = "build", withPrefix = "")
+  public static final class Builder {
+    @JsonProperty
+    private FillPolicy policy;
+    @JsonProperty
+    private double value;
+    
+    public Builder setPolicy(FillPolicy policy) {
+      this.policy = policy;
+      return this;
+    }
+    
+    public Builder setValue(double value) {
+      this.value = value;
+      return this;
+    }
+    
+    public NumericFillPolicy build() {
+      return new NumericFillPolicy(policy, value);
+    }
+  }
+  
+  @Override
+  public int hashCode() {
+    return Objects.hashCode(policy, value);
+  }
+  
+  @Override
+  public boolean equals(Object obj) {
+    if (obj == null) {
+      return false;
+    }
+    if (obj == this) {
+      return true;
+    }
+    if (!(obj instanceof NumericFillPolicy)) {
+      return false;
+    }
+    final NumericFillPolicy nfp = (NumericFillPolicy)obj;
+    return Objects.equal(policy, nfp.policy) &&
+           Objects.equal(value, nfp.value);
+  }
+  
+  /** @return the fill policy */
+  public FillPolicy getPolicy() {
+    return policy;
+  }
+
+  /** @param policy the fill policy to use */
+  public void setPolicy(final FillPolicy policy) {
+    this.policy = policy;
+  }
+
+  /** @return the value to use when filling */
+  public double getValue() {
+    return value;
+  }
+
+  /** @param value the value to use when filling */
+  public void setValue(final double value) {
+    this.value = value;
+  }
+  
+  /**
+   * Makes sure the policy name and value are a suitable combination. If one
+   * or the other is missing then we set the other with the proper value.
+   * @throws IllegalArgumentException if the combination is bad
+   */
+  public void validate() {
+    if (policy == null) {
+      if (value == 0) {
+        policy = FillPolicy.ZERO;
+      } else if (Double.isNaN(value)) {
+        policy = FillPolicy.NOT_A_NUMBER;
+      } else {
+        policy = FillPolicy.SCALAR;
+      }
+    } else {
+      switch (policy) {
+      case NONE:
+      case NOT_A_NUMBER:
+        if (value != 0 && !Double.isNaN(value)) {
+          throw new IllegalArgumentException(
+              "The value for NONE and NAN must be NaN");
+        }
+        value = Double.NaN;
+        break;
+      case ZERO:
+        if (value != 0) {
+          throw new IllegalArgumentException("The value for ZERO must be 0");
+        }
+        value = 0;
+        break;
+      case NULL:
+        if (value != 0 && !Double.isNaN(value)) {
+          throw new IllegalArgumentException("The value for NULL must be 0");
+        }
+        value = Double.NaN;
+        break;
+      case SCALAR: // it CAN be zero
+        break;
+      }
+    }
+  }
+}
diff --git a/src/query/expression/PostAggregatedDataPoints.java b/src/query/expression/PostAggregatedDataPoints.java
new file mode 100644
index 0000000000..2af4bf47ff
--- /dev/null
+++ b/src/query/expression/PostAggregatedDataPoints.java
@@ -0,0 +1,252 @@
+// This file is part of OpenTSDB.
+// Copyright (C) 2015  The OpenTSDB Authors.
+//
+// This program is free software: you can redistribute it and/or modify it
+// under the terms of the GNU Lesser General Public License as published by
+// the Free Software Foundation, either version 2.1 of the License, or (at your
+// option) any later version.  This program is distributed in the hope that it
+// will be useful, but WITHOUT ANY WARRANTY; without even the implied warranty
+// of MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser
+// General Public License for more details.  You should have received a copy
+// of the GNU Lesser General Public License along with this program.  If not,
+// see <http://www.gnu.org/licenses/>.
+package net.opentsdb.query.expression;
+
+import java.util.Collections;
+import java.util.List;
+import java.util.Map;
+import java.util.Map.Entry;
+import java.util.NoSuchElementException;
+
+import org.hbase.async.Bytes.ByteMap;
+
+import net.opentsdb.core.DataPoint;
+import net.opentsdb.core.DataPoints;
+import net.opentsdb.core.SeekableView;
+import net.opentsdb.meta.Annotation;
+
+import com.stumbleupon.async.Callback;
+import com.stumbleupon.async.Deferred;
+
+/**
+ * A class to store an array of data points processed through expressions along
+ * with the original meta data of the result set (metric, tags, etc).
+ * @since 2.3
+ */
+public class PostAggregatedDataPoints implements DataPoints {
+
+  /** The original results from storage, used for fetching meta data */
+  private final DataPoints base_data_points;
+  
+  /** The results of the expression calculation */
+  private final DataPoint[] points;
+
+  /** An optional alias for the results */
+  private String alias = null;
+
+  /**
+   * Default ctor
+   * @param base_data_points The original results from storage for fetching meta
+   * @param points The results of the expression calculation
+   */
+  public PostAggregatedDataPoints(final DataPoints base_data_points, 
+      final DataPoint[] points) {
+    if (base_data_points == null) {
+      throw new IllegalArgumentException("base_data_points cannot be null");
+    }
+    if (points == null) {
+      throw new IllegalArgumentException("points cannot be null");
+    }
+    this.base_data_points = base_data_points;
+    this.points = points;
+  }
+
+  @Override
+  public String metricName() {
+    try {
+      return metricNameAsync().join();
+    } catch (Exception e) {
+      throw new RuntimeException("Unexpected exception waiting for "
+          + "name resolution", e);
+    }
+  }
+
+  @Override
+  public Deferred<String> metricNameAsync() {
+    if (alias != null) {
+      if (alias.contains("@") && getTagUids().size() > 0) {
+        // need to resolve the tag UIDs for the templating feature
+        
+        class TemplateFill implements Callback<Deferred<String>, 
+            Map<String, String>> {
+          @Override
+          public Deferred<String> call(final Map<String, String> tags)
+              throws Exception {
+            for (final Entry<String, String> pair : tags.entrySet()) {
+              alias = alias.replace("@" + pair.getKey(), pair.getValue());
+            }
+            return Deferred.fromResult(alias);
+          }
+        }
+        return base_data_points.getTagsAsync()
+            .addCallbackDeferring(new TemplateFill());
+      }
+      return Deferred.fromResult(alias);
+    }
+    return base_data_points.metricNameAsync();
+  }
+  
+  @Override
+  public byte[] metricUID() {
+    if (alias != null) {
+      return new byte[] { };
+    }
+    return base_data_points.metricUID();
+  }
+
+  @Override
+  public Map<String, String> getTags() {
+    if (alias != null) {
+      return Collections.<String, String>emptyMap();
+    } else {
+      return base_data_points.getTags();
+    }
+  }
+
+  @Override
+  public Deferred<Map<String, String>> getTagsAsync() {
+    if (alias != null) {
+      return Deferred.fromResult(Collections.<String, String>emptyMap());
+    }
+    return base_data_points.getTagsAsync();
+  }
+
+  @Override
+  public List<String> getAggregatedTags() {
+    if (alias != null) {
+      return Collections.<String>emptyList();
+    }
+    return base_data_points.getAggregatedTags();
+  }
+
+  @Override
+  public Deferred<List<String>> getAggregatedTagsAsync() {
+    if (alias != null) {
+      return Deferred.fromResult(Collections.<String>emptyList());
+    }
+    return base_data_points.getAggregatedTagsAsync();
+  }
+
+  @Override
+  public List<byte[]> getAggregatedTagUids() {
+    if (alias != null) {
+      return Collections.<byte[]>emptyList();
+    }
+    return base_data_points.getAggregatedTagUids();
+  }
+  
+  @Override
+  public List<String> getTSUIDs() {
+    return base_data_points.getTSUIDs();
+  }
+
+  @Override
+  public List<Annotation> getAnnotations() {
+    return base_data_points.getAnnotations();
+  }
+  
+  @Override
+  public ByteMap<byte[]> getTagUids() {
+    return base_data_points.getTagUids();
+  }
+
+  @Override
+  public int getQueryIndex() {
+    return base_data_points.getQueryIndex();
+  }
+
+  @Override
+  public int size() {
+    return points.length;
+  }
+
+  @Override
+  public int aggregatedSize() {
+    return points.length;
+  }
+
+  @Override
+  public SeekableView iterator() {
+    return new SeekableViewImpl(points);
+  }
+
+  @Override
+  public long timestamp(int i) {
+    return points[i].timestamp();
+  }
+
+  @Override
+  public boolean isInteger(int i) {
+    return points[i].isInteger();
+  }
+
+  @Override
+  public long longValue(int i) {
+    return points[i].longValue();
+  }
+
+  @Override
+  public double doubleValue(int i) {
+    return points[i].doubleValue();
+  }
+  
+  /**
+   * An iterator working over the data points resulting from the expression
+   * calculation.
+   */
+  static class SeekableViewImpl implements SeekableView {
+
+    private int pos = 0;
+    private final DataPoint[] dps;
+    
+    SeekableViewImpl(final DataPoint[] dps) {
+      this.dps = dps;
+    }
+
+    @Override
+    public boolean hasNext() {
+      return pos < dps.length;
+    }
+
+    @Override
+    public DataPoint next() {
+      if (hasNext()) {
+        return dps[pos++];
+      } else {
+        throw new NoSuchElementException("no more elements");
+      }
+    }
+
+    @Override
+    public void remove() {
+      throw new UnsupportedOperationException();
+    }
+
+    @Override
+    public void seek(long timestamp) {
+      for (int i = pos; i < dps.length; i++) {
+        if (dps[i].timestamp() >= timestamp) {
+          break;
+        } else {
+          pos++;
+        }
+      }
+    }
+  }
+
+  /** @param alias The alias to set for the time series. Used in place of
+   * the metric and nulls out all tags. */
+  public void setAlias(String alias) {
+    this.alias = alias;
+  }
+}
diff --git a/src/query/expression/Scale.java b/src/query/expression/Scale.java
new file mode 100644
index 0000000000..2a7bf3649f
--- /dev/null
+++ b/src/query/expression/Scale.java
@@ -0,0 +1,110 @@
+// This file is part of OpenTSDB.
+// Copyright (C) 2015  The OpenTSDB Authors.
+//
+// This program is free software: you can redistribute it and/or modify it
+// under the terms of the GNU Lesser General Public License as published by
+// the Free Software Foundation, either version 2.1 of the License, or (at your
+// option) any later version.  This program is distributed in the hope that it
+// will be useful, but WITHOUT ANY WARRANTY; without even the implied warranty
+// of MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser
+// General Public License for more details.  You should have received a copy
+// of the GNU Lesser General Public License along with this program.  If not,
+// see <http://www.gnu.org/licenses/>.
+package net.opentsdb.query.expression;
+
+import java.util.ArrayList;
+import java.util.List;
+
+import net.opentsdb.core.DataPoint;
+import net.opentsdb.core.DataPoints;
+import net.opentsdb.core.MutableDataPoint;
+import net.opentsdb.core.SeekableView;
+import net.opentsdb.core.TSQuery;
+
+/**
+ * Multiplies each data point in the series by the given factor.
+ * @since 2.3
+ */
+public class Scale implements Expression {
+  
+  @Override
+  public DataPoints[] evaluate(final TSQuery data_query, 
+      final List<DataPoints[]> query_results, final List<String> params) {
+    if (data_query == null) {
+      throw new IllegalArgumentException("Missing time series query");
+    }
+    if (query_results == null || query_results.isEmpty()) {
+      return new DataPoints[]{};
+    }
+    if (params == null || params.isEmpty()) {
+      throw new IllegalArgumentException("Missing scaling factor");
+    }
+
+    double scale_factor = 0; // zero is fine, if useless *shrug*
+    final String factor = params.get(0);
+    if (factor != null && factor.matches("^[-0-9\\.]+$")) {
+      try {
+        scale_factor = Double.parseDouble(factor);
+      } catch (NumberFormatException nfe) {
+        throw new IllegalArgumentException(
+            "Invalid parameter, must be an integer or floating point", nfe);
+      }
+    } else {
+      throw new IllegalArgumentException("Unparseable scale factor value: " 
+          + scale_factor);
+    }
+    
+    int num_results = 0;
+    for (DataPoints[] results: query_results) {
+      num_results += results.length;
+    }
+    
+    final DataPoints[] results = new DataPoints[num_results];
+    int ix = 0;
+    // one or more sub queries (m=...&m=...&m=...)
+    for (final DataPoints[] sub_query_result : query_results) {
+      // group bys (m=sum:foo{host=*})
+      for (final DataPoints dps : sub_query_result) {
+        results[ix++] = scale(dps, scale_factor);
+      }
+    }
+    return results;
+  }
+  
+  /**
+   * Multiplies each data point in the series by the scale factor, maintaining
+   * integers if both the data point and scale are integers.
+   * @param points The data points to factor
+   * @param scale_factor The factor to multiply by
+   * @return The resulting data points
+   */
+  private DataPoints scale(final DataPoints points, final double scale_factor) {
+    // TODO(cl) - Using an array as the size function may not return the exact
+    // results and we should figure a way to avoid copying data anyway.
+    final List<DataPoint> dps = new ArrayList<DataPoint>();
+    final boolean scale_is_int = (scale_factor == Math.floor(scale_factor)) && 
+        !Double.isInfinite(scale_factor);
+    final SeekableView view = points.iterator();
+    while (view.hasNext()) {
+      DataPoint pt = view.next();
+      if (pt.isInteger() && scale_is_int) {
+        dps.add(MutableDataPoint.ofLongValue(pt.timestamp(), 
+            (long)scale_factor * pt.longValue()));
+      } else {
+        // NaNs are fine here, they'll just be re-computed as NaN
+        dps.add(MutableDataPoint.ofDoubleValue(pt.timestamp(), 
+            scale_factor * pt.toDouble()));
+      }
+    }
+    final DataPoint[] results = new DataPoint[dps.size()];
+    dps.toArray(results);
+    return new PostAggregatedDataPoints(points, results);
+  }
+
+  @Override
+  public String writeStringField(final List<String> query_params, 
+      final String inner_expression) {
+    return "scale(" + inner_expression + ")";
+  }
+
+}
diff --git a/src/query/expression/SumSeries.java b/src/query/expression/SumSeries.java
new file mode 100644
index 0000000000..3241901bcc
--- /dev/null
+++ b/src/query/expression/SumSeries.java
@@ -0,0 +1,85 @@
+// This file is part of OpenTSDB.
+// Copyright (C) 2015  The OpenTSDB Authors.
+//
+// This program is free software: you can redistribute it and/or modify it
+// under the terms of the GNU Lesser General Public License as published by
+// the Free Software Foundation, either version 2.1 of the License, or (at your
+// option) any later version.  This program is distributed in the hope that it
+// will be useful, but WITHOUT ANY WARRANTY; without even the implied warranty
+// of MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser
+// General Public License for more details.  You should have received a copy
+// of the GNU Lesser General Public License along with this program.  If not,
+// see <http://www.gnu.org/licenses/>.
+package net.opentsdb.query.expression;
+
+import java.util.List;
+
+import net.opentsdb.core.DataPoints;
+import net.opentsdb.core.TSDB;
+import net.opentsdb.core.TSQuery;
+import net.opentsdb.query.expression.VariableIterator.SetOperator;
+
+/**
+ * Performs a UNION set join on x metric query results and returns the results.
+ */
+public class SumSeries implements Expression {
+  /** The TSDB used for UID to name lookups */
+  final TSDB tsdb;
+  
+  /**
+   * Default ctor.
+   * @param tsdb The TSDB used for UID to name lookups
+   */
+  public SumSeries(final TSDB tsdb) {
+    this.tsdb = tsdb;
+  }
+  
+  @Override
+  public DataPoints[] evaluate(final TSQuery data_query, 
+      final List<DataPoints[]> query_results, final List<String> params) {
+    if (data_query == null) {
+      throw new IllegalArgumentException("Missing time series query");
+    }
+    if (query_results == null || query_results.isEmpty()) {
+      return new DataPoints[]{};
+    }
+    
+    if (query_results.size() < 2 || query_results.size() > 26) {
+      throw new IllegalArgumentException("Must have 2 to 26 series, got " + 
+          query_results.size() + " instead");
+    }
+    
+    final StringBuilder buf = new StringBuilder();
+    char v = 'a';
+    for (int i = 0; i < query_results.size(); i++) {
+      buf.append(v++);
+      if (i < query_results.size() - 1) {
+        buf.append(" + ");
+      }
+    }
+    System.out.println("Expression: [" + buf.toString() + "]");
+    final ExpressionIterator expression = new ExpressionIterator("sumSeries", 
+        buf.toString(), SetOperator.UNION, false, false);
+    v = 'a';
+    
+    for (final DataPoints[] dps : query_results) {
+      final TimeSyncedIterator it = new TimeSyncedIterator(
+          Character.toString(v++), null, dps);
+      expression.addResults(it.getId(), it);
+    }
+    expression.compile();
+    
+    final DataPoints[] results = new DataPoints[expression.values().length];
+    for (int i = 0; i < expression.values().length; i++) {
+      results[i] = new EDPtoDPS(tsdb, i, expression);
+    }
+    return results;
+  }
+
+  @Override
+  public String writeStringField(final List<String> query_params, 
+      final String inner_expression) {
+    return "sumSeries(" + inner_expression + ")";
+  }
+
+}
diff --git a/src/query/expression/TimeShift.java b/src/query/expression/TimeShift.java
new file mode 100644
index 0000000000..876175d64a
--- /dev/null
+++ b/src/query/expression/TimeShift.java
@@ -0,0 +1,135 @@
+package net.opentsdb.query.expression;
+/**
+ * Copyright 2015 The opentsdb Authors
+ * <p/>
+ * Licensed under the Apache License, Version 2.0 (the "License");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ * <p/>
+ * http://www.apache.org/licenses/LICENSE-2.0
+ * <p/>
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+import net.opentsdb.core.*;
+
+import java.util.ArrayList;
+import java.util.List;
+import java.util.concurrent.TimeUnit;
+
+public class TimeShift implements Expression {
+  /**
+   * in place modify of TsdbResult array to increase timestamps by timeshift
+   * @param data_query
+   * @param results
+   * @param params
+   * @return
+   */
+  @Override
+  public DataPoints[] evaluate(TSQuery data_query, List<DataPoints[]> results, List<String> params) {
+    //not 100% sure what to do here -> do I need to think of the case where I have no data points
+    if(results == null || results.isEmpty()) {
+      return new DataPoints[]{};
+    }
+    if(params == null || results.isEmpty()) {
+      throw new IllegalArgumentException("Need amount of timeshift to perform timeshift");
+    }
+
+    String param = params.get(0);
+    if (param == null || param.length() == 0) {
+      throw new IllegalArgumentException("Invalid timeshift='" + param + "'");
+    }
+
+    param = param.trim();
+
+    long timeshift = -1;
+    if (param.startsWith("'") && param.endsWith("'")) {
+      timeshift = parseParam(param) / 1000;
+    } else {
+      throw new RuntimeException("Invalid timeshift parameter: eg '10min'");
+    }
+
+    if (timeshift <= 0) {
+      throw new RuntimeException("timeshift <= 0");
+    }
+
+    DataPoints[] inputPoints = results.get(0);
+    DataPoints[] outputPoints = new DataPoints[inputPoints.length];
+    for(int n = 0; n < inputPoints.length; n++) {
+      outputPoints[n] = shift(inputPoints[n], timeshift);
+    }
+    return outputPoints;
+  }
+
+  public static long parseParam(String param) {
+    char[] chars = param.toCharArray();
+    int tuIndex = 0;
+    for (int c = 1; c < chars.length; c++) {
+      if (Character.isDigit(chars[c])) {
+        tuIndex++;
+      } else {
+        break;
+      }
+    }
+
+    if (tuIndex == 0) {
+      throw new RuntimeException("Invalid Parameter: " + param);
+    }
+
+    int time = Integer.parseInt(param.substring(1, tuIndex + 1));
+    String unit = param.substring(tuIndex + 1, param.length() - 1);
+    if ("sec".equals(unit)) {
+      return TimeUnit.MILLISECONDS.convert(time, TimeUnit.SECONDS);
+    } else if ("min".equals(unit)) {
+      return TimeUnit.MILLISECONDS.convert(time, TimeUnit.MINUTES);
+    } else if ("hr".equals(unit)) {
+      return TimeUnit.MILLISECONDS.convert(time, TimeUnit.HOURS);
+    } else if ("day".equals(unit) || "days".equals(unit)) {
+      return TimeUnit.MILLISECONDS.convert(time, TimeUnit.DAYS);
+    } else if ("week".equals(unit) || "weeks".equals(unit)) {
+      //didn't have week so small cheat here
+      return TimeUnit.MILLISECONDS.convert(time*7, TimeUnit.DAYS);
+    }
+    else {
+      throw new RuntimeException("unknown time unit=" + unit);
+    }
+  }
+
+  /**
+   * Adjusts the timestamp of each datapoint by timeshift
+   * @param points The data points to factor
+   * @param timeshift The factor to multiply by
+   * @return The resulting data points
+   */
+  private DataPoints shift(final DataPoints points, final long timeshift) {
+    // TODO(cl) - Using an array as the size function may not return the exact
+    // results and we should figure a way to avoid copying data anyway.
+    final List<DataPoint> dps = new ArrayList<DataPoint>();
+    final boolean shift_is_int = (timeshift == Math.floor(timeshift)) &&
+            !Double.isInfinite(timeshift);
+    final SeekableView view = points.iterator();
+    while (view.hasNext()) {
+      DataPoint pt = view.next();
+      if (shift_is_int) {
+        dps.add(MutableDataPoint.ofLongValue(pt.timestamp() + timeshift,
+                pt.longValue()));
+      } else {
+        // NaNs are fine here, they'll just be re-computed as NaN
+        dps.add(MutableDataPoint.ofDoubleValue(pt.timestamp() + timeshift,
+                timeshift * pt.toDouble()));
+      }
+    }
+    final DataPoint[] results = new DataPoint[dps.size()];
+    dps.toArray(results);
+    return new PostAggregatedDataPoints(points, results);
+  }
+
+    @Override
+  public String writeStringField(List<String> params, String inner_expression) {
+      return "timeshift(" + inner_expression + ")";
+  }
+}
diff --git a/src/query/expression/TimeSyncedIterator.java b/src/query/expression/TimeSyncedIterator.java
new file mode 100644
index 0000000000..451e7b96c2
--- /dev/null
+++ b/src/query/expression/TimeSyncedIterator.java
@@ -0,0 +1,248 @@
+// This file is part of OpenTSDB.
+// Copyright (C) 2015  The OpenTSDB Authors.
+//
+// This program is free software: you can redistribute it and/or modify it
+// under the terms of the GNU Lesser General Public License as published by
+// the Free Software Foundation, either version 2.1 of the License, or (at your
+// option) any later version.  This program is distributed in the hope that it
+// will be useful, but WITHOUT ANY WARRANTY; without even the implied warranty
+// of MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser
+// General Public License for more details.  You should have received a copy
+// of the GNU Lesser General Public License along with this program.  If not,
+// see <http://www.gnu.org/licenses/>.
+package net.opentsdb.query.expression;
+
+import net.opentsdb.core.DataPoint;
+import net.opentsdb.core.DataPoints;
+import net.opentsdb.core.FillPolicy;
+import net.opentsdb.core.SeekableView;
+import net.opentsdb.utils.ByteSet;
+
+/**
+ * Holds the results of a sub query (a single metric) and iterates over each
+ * resultant series in lock-step for expression evaluation.
+ * @since 2.3
+ */
+public class TimeSyncedIterator implements ITimeSyncedIterator {
+  
+  /** The name of this sub query given by the user */
+  private final String id;
+  
+  /** The set of tag keys issued with the query */
+  private final ByteSet query_tagks;
+
+  /** The data point interfaces fetched from storage */
+  private final DataPoints[] dps;
+  
+  /** The current value used for iterating */
+  private final DataPoint[] current_values;
+  
+  /** References to the MutableDataObjects the ExpressionIterator will read */
+  private final ExpressionDataPoint[] emitter_values;
+  
+  /** A list of the iterators used for fetching the next value */
+  private final SeekableView[] iterators;
+
+  /** Set by the ExpressionIterator when it computes the intersection */ 
+  private int index;
+  
+  /** A policy to use for emitting values when a timestamp is missing data */
+  private NumericFillPolicy fill_policy;
+  
+  /**
+   * Instantiates an iterator based on the results of a TSSubQuery. 
+   * This will setup the emitters so it's safe to call {@link #values()}
+   * @param id The name of the query.
+   * @param query_tagks The set of tags used in filters on the query.
+   * @param dps The data points fetched from storage.
+   * @throws IllegalArgumentException if one of the parameters is null or the ID
+   * is empty
+   */
+  public TimeSyncedIterator(final String id, final ByteSet query_tagks, 
+      final DataPoints[] dps) {
+    if (id == null || id.isEmpty()) {
+      throw new IllegalArgumentException("Missing ID string");
+    }
+    if (dps == null) {
+      // it's ok for these to be empty, but they canna be null ya ken?
+      throw new IllegalArgumentException("Missing data points");
+    }
+    this.id = id;
+    this.query_tagks = query_tagks;
+    this.dps = dps;
+    // TODO - load from a default or something
+    fill_policy = new NumericFillPolicy(FillPolicy.ZERO);
+    current_values = new DataPoint[dps.length];
+    emitter_values = new ExpressionDataPoint[dps.length];
+    iterators = new SeekableView[dps.length];
+    setupEmitters();
+  }
+  
+  /**
+   * A copy constructor that loads from an existing iterator.
+   * @param iterator The iterator to load from
+   */
+  private TimeSyncedIterator(final TimeSyncedIterator iterator) {
+    id = iterator.id;
+    query_tagks = iterator.query_tagks; // sharing is ok here
+    dps = iterator.dps; // TODO ?? OK?
+    fill_policy = iterator.fill_policy;
+    current_values = new DataPoint[dps.length];
+    emitter_values = new ExpressionDataPoint[dps.length];
+    iterators = new SeekableView[dps.length];
+    setupEmitters();
+  }
+
+  @Override
+  public String toString() {
+    final StringBuilder buf = new StringBuilder();
+    buf.append("TimeSyncedIterator(id=")
+       .append(id)
+       .append(", index=")
+       .append(index)
+       .append(", dpsSize=")
+       .append(dps.length)
+       .append(")");
+    return buf.toString();
+  }
+  
+  @Override
+  public int size() {
+    return dps.length;
+  }
+  
+  @Override
+  public boolean hasNext() {
+    for (final DataPoint dp : current_values) {
+      if (dp != null) {
+        return true;
+      }
+    }
+    return false;
+  }
+  
+  @Override
+  public ExpressionDataPoint[] next(final long timestamp) {
+    for (int i = 0; i < current_values.length; i++) {
+      if (current_values[i] == null) {
+        emitter_values[i].reset(timestamp, fill_policy.getValue());
+        continue;
+      }
+      
+      if (current_values[i].timestamp() > timestamp) {
+        emitter_values[i].reset(timestamp, fill_policy.getValue());
+      } else {
+        emitter_values[i].reset(current_values[i]);
+        if (!iterators[i].hasNext()) {
+          current_values[i] = null;
+        } else {
+          current_values[i] = iterators[i].next();
+        }
+      }
+    }
+    return emitter_values;
+  }
+  
+  @Override
+  public long nextTimestamp() {
+    long ts = Long.MAX_VALUE;
+    for (final DataPoint dp : current_values) {
+      if (dp != null) {
+        long t = dp.timestamp();
+        if (t < ts) {
+          ts = t;
+        }
+      }
+    }
+    return ts;
+  }
+  
+  @Override
+  public void next(final int i) {
+    if (current_values[i] == null) {
+      throw new RuntimeException("No more elements");
+    }
+    emitter_values[i].reset(current_values[i]);
+    if (iterators[i].hasNext()) {
+      current_values[i] = iterators[i].next();
+    } else {
+      current_values[i] = null;
+    }
+  }
+  
+  @Override
+  public boolean hasNext(final int i) {
+    return current_values[i] != null;
+  }
+  
+  @Override
+  public int getIndex() {
+    return index;
+  }
+  
+  @Override
+  public void setIndex(final int index) {
+    this.index = index;
+  }
+
+  @Override
+  public String getId() {
+    return id;
+  }
+
+  /** @return the set of data points */
+  public DataPoints[] getDataPoints() {
+    return dps;
+  }
+  
+  @Override
+  public void nullIterator(final int index) {
+    if (index < 0 || index > current_values.length) {
+      throw new IllegalArgumentException("Index out of range: " + index);
+    }
+    current_values[index] = null;
+  }
+  
+  @Override
+  public ExpressionDataPoint[] values() {
+    return emitter_values;
+  }
+  
+  @Override
+  public ByteSet getQueryTagKs() {
+    return query_tagks;
+  }
+
+  @Override
+  public void setFillPolicy(final NumericFillPolicy policy) {
+    fill_policy = policy;
+  }
+
+  @Override
+  public NumericFillPolicy getFillPolicy() {
+    return fill_policy;
+  }
+
+  @Override
+  public ITimeSyncedIterator getCopy() {
+    return new TimeSyncedIterator(this);
+  }
+  
+  /**
+   * Iterates over the values and sets up the current and emitter values
+   */
+  private void setupEmitters() {
+    // set the iterators
+    for (int i = 0; i < dps.length; i++) {
+      iterators[i] = dps[i].iterator();
+      if (!iterators[i].hasNext()) {
+        current_values[i] = null;
+        emitter_values[i] = null;
+      } else {
+        current_values[i] = iterators[i].next();
+        emitter_values[i] = new ExpressionDataPoint(dps[i]);
+        emitter_values[i].setIndex(i);
+      }
+    }
+  }
+}
diff --git a/src/query/expression/UnionIterator.java b/src/query/expression/UnionIterator.java
new file mode 100644
index 0000000000..54cd70869a
--- /dev/null
+++ b/src/query/expression/UnionIterator.java
@@ -0,0 +1,455 @@
+// This file is part of OpenTSDB.
+// Copyright (C) 2015  The OpenTSDB Authors.
+//
+// This program is free software: you can redistribute it and/or modify it
+// under the terms of the GNU Lesser General Public License as published by
+// the Free Software Foundation, either version 2.1 of the License, or (at your
+// option) any later version.  This program is distributed in the hope that it
+// will be useful, but WITHOUT ANY WARRANTY; without even the implied warranty
+// of MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser
+// General Public License for more details.  You should have received a copy
+// of the GNU Lesser General Public License along with this program.  If not,
+// see <http://www.gnu.org/licenses/>.
+package net.opentsdb.query.expression;
+
+import java.util.HashMap;
+import java.util.Iterator;
+import java.util.Map;
+import java.util.Map.Entry;
+
+import net.opentsdb.core.FillPolicy;
+import net.opentsdb.core.IllegalDataException;
+import net.opentsdb.core.TSDB;
+import net.opentsdb.utils.ByteSet;
+
+import org.hbase.async.HBaseClient;
+import org.hbase.async.Bytes.ByteMap;
+import org.slf4j.Logger;
+import org.slf4j.LoggerFactory;
+
+import sun.reflect.generics.reflectiveObjects.NotImplementedException;
+
+/**
+ * An iterator that computes the union of all series in the result sets. This 
+ * means we match every series with it's corresponding series in the other sets.
+ * If one or more set lacks the matching series, then a {@code null} is stored
+ * and when the caller iterates over the results, the need to detect the null
+ * and substitute a fill value.
+ * @since 2.3
+ */
+public class UnionIterator implements ITimeSyncedIterator, VariableIterator {
+  private static final Logger LOG = LoggerFactory.getLogger(UnionIterator.class);
+  
+  /** The queries compiled and fetched from storage */
+  private final Map<String, ITimeSyncedIterator> queries;
+  
+  /** A list of the current values for each series post intersection */
+  private final Map<String, ExpressionDataPoint[]> current_values;
+
+  /** A map used for single series iteration where the array is the index */
+  private final Map<String, int[]> single_series_matrix;
+  
+  /** A map of the sub query index to their names for intersection computation */
+  private final String[] index_to_names;
+  
+  /** Whether or not to intersect on the query tagks instead of the result set
+   * tagks */
+  private final boolean union_on_query_tagks;
+  
+  /** Whether or not to include the aggregated tags in the result set */
+  private final boolean include_agg_tags;
+  
+  /** The start/current timestamp for the iterator in ms */
+  private long timestamp;
+  
+  /** Post intersection number of time series */
+  private int series_size;
+  
+  /** The ID of this iterator */
+  private final String id;
+  
+  /** The index of this iterator in a list of iterators */
+  private int index;
+  
+  /** The fill policy to use when a series is missing from one of the sets.
+   * Default is zero. */
+  private NumericFillPolicy fill_policy;
+  
+  /** A data point used for filling missing time series */
+  private ExpressionDataPoint fill_dp;
+  
+  /**
+   * Default ctor
+   * @param id The variable ID for this iterator
+   * @param results Upstream iterators
+   * @param union_on_query_tagks Whether or not to flatten and join on only
+   * the tags from the query or those returned in the results.
+   * @param include_agg_tags Whether or not to include the flattened aggregated
+   * tag keys in the join.
+   */
+  public UnionIterator(final String id, final Map<String, ITimeSyncedIterator> results,
+      final boolean union_on_query_tagks, final boolean include_agg_tags) {
+    this.id = id;
+    this.union_on_query_tagks = union_on_query_tagks;
+    this.include_agg_tags = include_agg_tags;
+    timestamp = Long.MAX_VALUE;
+    queries = new HashMap<String, ITimeSyncedIterator>(results.size());
+    current_values = new HashMap<String, ExpressionDataPoint[]>(results.size());
+    single_series_matrix = new HashMap<String, int[]>(results.size());
+    index_to_names = new String[results.size()];
+    fill_policy = new NumericFillPolicy(FillPolicy.ZERO);
+    fill_dp = new ExpressionDataPoint();
+    
+    int i = 0;
+    for (final Map.Entry<String, ITimeSyncedIterator> entry : results.entrySet()) {
+      if (LOG.isDebugEnabled()) {
+        LOG.debug("Adding iterator " + entry.getValue());
+      }
+      queries.put(entry.getKey(), entry.getValue());
+      entry.getValue().setIndex(i);
+      index_to_names[i] = entry.getKey();
+      ++i;
+    }
+
+    computeUnion();
+    
+    // calculate the starting timestamp from the various iterators
+    for (final ITimeSyncedIterator it : queries.values()) {
+      final long ts = it.nextTimestamp();
+      if (ts < timestamp) {
+        timestamp = ts;
+      }
+    }
+    
+    if (LOG.isDebugEnabled()) {
+      LOG.debug("Computed union: " + this);
+    }
+  }
+  
+  /**
+   * Private copy constructor that copies references and sets up new collections
+   * without copying results.
+   * @param iterator The iterator to copy from.
+   */
+  private UnionIterator(final UnionIterator iterator) {
+    id = iterator.id;
+    union_on_query_tagks = iterator.union_on_query_tagks;
+    include_agg_tags = iterator.include_agg_tags;
+    timestamp = Long.MAX_VALUE;
+    queries = new HashMap<String, ITimeSyncedIterator>(iterator.queries.size());
+    current_values = new HashMap<String, ExpressionDataPoint[]>(queries.size());
+    single_series_matrix = new HashMap<String, int[]>(queries.size());
+    index_to_names = new String[queries.size()];
+    fill_policy = iterator.fill_policy;
+    
+    int i = 0;
+    for (final Map.Entry<String, ITimeSyncedIterator> entry : iterator.queries.entrySet()) {
+      if (LOG.isDebugEnabled()) {
+        LOG.debug("Adding iterator " + entry.getValue());
+      }
+      queries.put(entry.getKey(), entry.getValue());
+      entry.getValue().setIndex(i);
+      index_to_names[i] = entry.getKey();
+      ++i;
+    }
+
+    computeUnion();
+    
+    // calculate the starting timestamp from the various iterators
+    for (final ITimeSyncedIterator it : queries.values()) {
+      final long ts = it.nextTimestamp();
+      if (ts < timestamp) {
+        timestamp = ts;
+      }
+    }
+  }
+  
+  /**
+   * Computes the union of all sets, matching on tags and optionally the 
+   * aggregated tags across each variable.
+   */
+  private void computeUnion() {
+    // key = flattened tags, array of queries.size()
+    final ByteMap<ExpressionDataPoint[]> ordered_union = 
+        new ByteMap<ExpressionDataPoint[]>(); 
+
+    final Iterator<ITimeSyncedIterator> it = queries.values().iterator();
+    while (it.hasNext()) {
+      final ITimeSyncedIterator sub = it.next();
+      final ExpressionDataPoint[] dps = sub.values();
+      final ByteMap<Integer> local_tags = new ByteMap<Integer>();
+      
+      for (int i = 0; i < sub.size(); i++) {
+        final byte[] key = flattenTags(union_on_query_tagks, include_agg_tags, 
+            dps[i], sub);
+        local_tags.put(key, i);
+        ExpressionDataPoint[] udps = ordered_union.get(key);
+        if (udps == null) {
+          udps = new ExpressionDataPoint[queries.size()];
+          ordered_union.put(key, udps);
+        }
+        udps[sub.getIndex()] = dps[i];
+      }
+    }
+    
+    if (ordered_union.size() < 1) {
+      // if no data, just stop here
+      return;
+    }
+    
+    setCurrentAndMeta(ordered_union);
+  }
+  
+  /**
+   * Takes the resulting union and builds the {@link #current_values}
+   * and {@link #meta} maps.
+   * @param ordered_union The union to build from.
+   */
+  private void setCurrentAndMeta(final ByteMap<ExpressionDataPoint[]> 
+      ordered_union) {
+    for (final String id : queries.keySet()) {
+      current_values.put(id, new ExpressionDataPoint[ordered_union.size()]);
+      // TODO - blech. Fill with a sentinel value to reflect "no data here!"
+      final int[] m = new int[ordered_union.size()];
+      for (int i = 0; i < m.length; i++) {
+        m[i] = -1;
+      }
+      single_series_matrix.put(id, m);
+    }
+    
+    int i = 0;
+    for (final Entry<byte[], ExpressionDataPoint[]> entry : ordered_union.entrySet()) {
+      final ExpressionDataPoint[] idps = entry.getValue();
+      for (int x = 0; x < idps.length; x++) {
+        final ExpressionDataPoint[] current_dps = 
+            current_values.get(index_to_names[x]);
+        current_dps[i] = idps[x];
+        final int[] m = single_series_matrix.get(index_to_names[x]);
+        if (idps[x] != null) {
+          m[i] = idps[x].getIndex();
+        }
+      }
+      ++i;
+    }
+    
+    // set fills on nulls
+    for (final ExpressionDataPoint[] idps : current_values.values()) {
+      for (i = 0; i < idps.length; i++) {
+        if (idps[i] == null) {
+          idps[i] = fill_dp;
+        }
+      }
+    }
+    series_size = ordered_union.size();
+  }
+  
+  /**
+   * Creates a key based on the concatenation of the tag pairs then the agg
+   * tag keys.
+   * @param use_query_tags Whether or not to include tags returned with the
+   * results or just use those group by'd in the query
+   * @param include_agg_tags Whether or not to include the aggregated tags in
+   * the identifier
+   * @param dp The current expression data point
+   * @param sub The sub query iterator
+   * @return A byte array with the flattened tag keys and values. Note that
+   * if the tags set is empty, this may return an empty array (but not a null
+   * array)
+   */
+  static byte[] flattenTags(final boolean use_query_tags, 
+      final boolean include_agg_tags, final ExpressionDataPoint dp, 
+      final ITimeSyncedIterator sub) {
+    if (dp.tags() == null || dp.tags().isEmpty()) {
+      return HBaseClient.EMPTY_ARRAY;
+    }
+    final int tagk_width = TSDB.tagk_width();
+    final int tagv_width = TSDB.tagv_width();
+    
+    final ByteSet query_tagks;
+    // NOTE: We MAY need the agg tags but I'm not sure yet
+    final int tag_size;
+    if (use_query_tags) {
+      int i = 0;
+      if (sub.getQueryTagKs() != null && !sub.getQueryTagKs().isEmpty()) {
+        query_tagks = sub.getQueryTagKs();
+        for (final Map.Entry<byte[], byte[]> pair : dp.tags().entrySet()) {
+          if (query_tagks.contains(pair.getKey())) {
+            i++;
+          }
+        }
+      } else {
+        query_tagks = new ByteSet();
+      }
+      tag_size = i;
+    } else {
+      query_tagks = new ByteSet();
+      tag_size = dp.tags().size();
+    }
+    
+    final int length = (tag_size * (tagk_width + tagv_width))
+        + (include_agg_tags ? (dp.aggregatedTags().size() * tagk_width) : 0);
+    final byte[] key = new byte[length];
+    int idx = 0;
+    for (final Entry<byte[], byte[]> pair : dp.tags().entrySet()) {
+      if (use_query_tags && !query_tagks.contains(pair.getKey())) {
+        continue;
+      }
+      System.arraycopy(pair.getKey(), 0, key, idx, tagk_width);
+      idx += tagk_width;
+      System.arraycopy(pair.getValue(), 0, key, idx, tagv_width);
+      idx += tagv_width;
+    }
+    if (include_agg_tags) {
+      for (final byte[] tagk : dp.aggregatedTags()) {
+        System.arraycopy(tagk, 0, key, idx, tagk_width);
+        idx += tagk_width;
+      }
+    }
+    return key;
+  }
+  
+  @Override
+  public String toString() {
+    final StringBuilder buf = new StringBuilder();
+    buf.append("UnionIterator(id=")
+       .append(id)
+       .append(", useQueryTags=")
+       .append(union_on_query_tagks)
+       .append(", includeAggTags=")
+       .append(include_agg_tags)
+       .append(", index=")
+       .append(index)
+       .append(", queries=")
+       .append(queries);
+    return buf.toString();
+  }
+
+  // Iterator implementations
+  
+  @Override
+  public boolean hasNext() {
+    for (final ITimeSyncedIterator sub : queries.values()) {
+      if (sub.hasNext()) {
+        return true;
+      }
+    }
+    return false;
+  }
+
+  @Override
+  public ExpressionDataPoint[] next(long timestamp) {
+    throw new NotImplementedException();
+  }
+
+  @Override
+  public long nextTimestamp() {
+    long ts = Long.MAX_VALUE;
+    for (final ITimeSyncedIterator sub : queries.values()) {
+      if (sub != null) {
+        final long t = sub.nextTimestamp();
+        if (t < ts) {
+          ts = t;
+        }
+      }
+    }
+    return ts;
+  }
+
+  @Override
+  public int size() {
+    throw new NotImplementedException();
+  }
+
+  @Override
+  public ExpressionDataPoint[] values() {
+    throw new NotImplementedException();
+  }
+
+  @Override
+  public void nullIterator(int index) {
+    throw new NotImplementedException();
+  }
+
+  @Override
+  public int getIndex() {
+    return index;
+  }
+
+  @Override
+  public void setIndex(int index) {
+    this.index = index;
+  }
+
+  @Override
+  public String getId() {
+    return id;
+  }
+
+  @Override
+  public ByteSet getQueryTagKs() {
+    throw new NotImplementedException();
+  }
+
+  @Override
+  public void setFillPolicy(NumericFillPolicy policy) {
+    this.fill_policy = policy;
+  }
+
+  @Override
+  public NumericFillPolicy getFillPolicy() {
+    return fill_policy;
+  }
+
+  @Override
+  public ITimeSyncedIterator getCopy() {
+    return new UnionIterator(this);
+  }
+
+  @Override
+  public void next() {
+    if (!hasNext()) {
+      throw new IllegalDataException("No more data");
+    }
+    for (final ITimeSyncedIterator sub : queries.values()) {
+      sub.next(timestamp);
+    }
+    // reset the fill data point
+    fill_dp.reset(timestamp, fill_policy.getValue());
+    timestamp = nextTimestamp();
+  }
+
+  @Override
+  public Map<String, ExpressionDataPoint[]> getResults() {
+    return current_values;
+  }
+
+  @Override
+  public int getSeriesSize() {
+    return series_size;
+  }
+
+  @Override
+  public boolean hasNext(int index) {
+    for (final Entry<String, int[]> entry : single_series_matrix.entrySet()) {
+      final int idx = entry.getValue()[index];
+      if (idx >= 0 && queries.get(entry.getKey()).hasNext(idx)) {
+        return true;
+      }
+    }
+    return false;
+  }
+
+  @Override
+  public void next(int index) {
+    if (!hasNext()) {
+      throw new IllegalDataException("No more data");
+    }
+    for (final Entry<String, int[]> entry : single_series_matrix.entrySet()) {
+      final int idx = entry.getValue()[index];
+      if (idx >= 0) {
+        queries.get(entry.getKey()).next(idx);
+      }
+    }
+  }
+  
+}
diff --git a/src/query/expression/VariableIterator.java b/src/query/expression/VariableIterator.java
new file mode 100644
index 0000000000..9bfba0b889
--- /dev/null
+++ b/src/query/expression/VariableIterator.java
@@ -0,0 +1,115 @@
+// This file is part of OpenTSDB.
+// Copyright (C) 2015  The OpenTSDB Authors.
+//
+// This program is free software: you can redistribute it and/or modify it
+// under the terms of the GNU Lesser General Public License as published by
+// the Free Software Foundation, either version 2.1 of the License, or (at your
+// option) any later version.  This program is distributed in the hope that it
+// will be useful, but WITHOUT ANY WARRANTY; without even the implied warranty
+// of MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser
+// General Public License for more details.  You should have received a copy
+// of the GNU Lesser General Public License along with this program.  If not,
+// see <http://www.gnu.org/licenses/>.
+package net.opentsdb.query.expression;
+
+import java.util.Map;
+
+import com.fasterxml.jackson.annotation.JsonCreator;
+import com.fasterxml.jackson.annotation.JsonValue;
+
+/**
+ * An interface that helps merge different time series sets (e.g. different
+ * metrics with a group by operator). The implementations handle joining the
+ * two sets according to the {@link SetOperator}.
+ * @since 2.3
+ */
+public interface VariableIterator {
+
+  /** An operator that determines how to sets of time series are merged via
+   * expression. */
+  public enum SetOperator {
+    /** A union, meaning results from all sets will appear, using FillPolicies
+     * for missing series */
+    UNION("union"),
+    
+    /** Computes the intersection, returning results only for series that appear
+     * in all sets */
+    INTERSECTION("intersection");
+    
+    /** The user-friendly name of this operator. */
+    private final String name;
+    
+    /** @param the readable name of the operator */
+    SetOperator(final String name) {
+      this.name = name;
+    }
+    
+    /** @return the readable name of the operator */
+    @JsonValue
+    public String getName() {
+      return name;
+    }
+    
+    /** 
+     * Converts a string to lower case then looks up the operator
+     * @param name The name to find an operator for
+     * @return The operator if found.
+     * @throws IllegalArgumentException if the operator wasn't found
+     */
+    @JsonCreator
+    public static SetOperator fromString(final String name) {
+      for (final SetOperator operator : SetOperator.values()) {
+        if (operator.name.equalsIgnoreCase(name)) {
+          return operator;
+        }
+      }
+      throw new IllegalArgumentException("Unrecognized set operator: " + name);
+    }
+  }
+  
+  /**
+   * Whether or not another set of results are available. Always call this
+   * before calling next.
+   * @return True if more results are available, false if not.
+   */
+  public boolean hasNext();
+  
+  /**
+   * Iterates the {@link getResults()} to the next set of results. If there
+   * aren't any results left, the implementation may throw an exception. Always
+   * call {@link hasNext()} first.
+   */
+  public void next();
+
+  /** 
+   * Determines whether the individual series in the {@link values} array has 
+   * another value. This may be used for non-synchronous iteration.
+   * @param index The index of the series in the values array to check for
+   * @return True if the series has another value, false if not
+   */
+  public boolean hasNext(final int index);
+  
+  /**
+   * Fetches the next value for an individual series in the {@link values} array.
+   * @param index The index of the series in the values array to advance
+   */
+  public void next(final int index);  
+  
+  /**
+   * Returns a map of variable names to result series. You can maintain the
+   * reference returned without having to call getResults() on every iteration.
+   * Calling {@link next()} will simply update the ExpressionDataPoint array.
+   * The implementation may return a null map if there weren't any results
+   * available. Always all {@link hasNext()} before getting the results.
+   * @return A map with results to read from.
+   */
+  public Map<String, ExpressionDataPoint[]> getResults();
+  
+  /** @return The number of time series after the join. This should match the
+   * number of entries in the results data point array, not the number of 
+   * variables in the results map. */
+  public int getSeriesSize();
+  
+  /** @return the next timestamp for all results without iterating */
+  public long nextTimestamp();
+}
diff --git a/src/query/pojo/Downsampler.java b/src/query/pojo/Downsampler.java
new file mode 100644
index 0000000000..dfda751ffe
--- /dev/null
+++ b/src/query/pojo/Downsampler.java
@@ -0,0 +1,146 @@
+// This file is part of OpenTSDB.
+// Copyright (C) 2015  The OpenTSDB Authors.
+//
+// This program is free software: you can redistribute it and/or modify it
+// under the terms of the GNU Lesser General Public License as published by
+// the Free Software Foundation, either version 2.1 of the License, or (at your
+// option) any later version.  This program is distributed in the hope that it
+// will be useful, but WITHOUT ANY WARRANTY; without even the implied warranty
+// of MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser
+// General Public License for more details.  You should have received a copy
+// of the GNU Lesser General Public License along with this program.  If not,
+// see <http://www.gnu.org/licenses/>.
+package net.opentsdb.query.pojo;
+
+import java.util.NoSuchElementException;
+
+import com.fasterxml.jackson.annotation.JsonIgnoreProperties;
+import com.fasterxml.jackson.annotation.JsonProperty;
+import com.fasterxml.jackson.databind.annotation.JsonDeserialize;
+import com.fasterxml.jackson.databind.annotation.JsonPOJOBuilder;
+import com.google.common.base.Objects;
+
+import net.opentsdb.core.Aggregators;
+import net.opentsdb.query.expression.NumericFillPolicy;
+import net.opentsdb.utils.DateTime;
+
+/**
+ * Pojo builder class used for serdes of the downsampler component of a query
+ * @since 2.3
+ */
+@JsonDeserialize(builder = Downsampler.Builder.class)
+public class Downsampler extends Validatable {
+  /** The relative interval with value and unit, e.g. 60s */
+  private String interval;
+  
+  /** The aggregator to use for downsampling */
+  private String aggregator;
+  
+  /** A fill policy for downsampling and working with missing values */
+  private NumericFillPolicy fill_policy;
+  
+  /**
+   * Default ctor
+   * @param builder The builder to pull values from
+   */
+  public Downsampler(Builder builder) {
+    interval = builder.interval;
+    aggregator = builder.aggregator;
+    fill_policy = builder.fillPolicy;
+  }
+  
+  /** @return A new builder for the downsampler */
+  public static Builder Builder() {
+    return new Builder();
+  }
+  
+  /** Validates the downsampler
+   * @throws IllegalArgumentException if one or more parameters were invalid
+   */
+  public void validate() {
+    if (interval == null || interval.isEmpty()) {
+      throw new IllegalArgumentException("Missing or empty interval");
+    }
+    DateTime.parseDuration(interval);
+    
+    if (aggregator == null || aggregator.isEmpty()) {
+      throw new IllegalArgumentException("Missing or empty aggregator");
+    }
+    try {
+      Aggregators.get(aggregator.toLowerCase());
+    } catch (final NoSuchElementException e) {
+      throw new IllegalArgumentException("Invalid aggregator");
+    }
+    
+    if (fill_policy != null) {
+      fill_policy.validate();
+    }
+  }
+  
+  /** @return the interval for the downsampler */
+  public String getInterval() {
+    return interval;
+  }
+  
+  /** @return the name of the aggregator to use */
+  public String getAggregator() {
+    return aggregator;
+  }
+  
+  /** @return the fill policy to use */
+  public NumericFillPolicy getFillPolicy() {
+    return fill_policy;
+  }
+  
+  @Override
+  public boolean equals(final Object o) {
+    if (this == o)
+      return true;
+    if (o == null || getClass() != o.getClass())
+      return false;
+
+    final Downsampler downsampler = (Downsampler) o;
+
+    return Objects.equal(interval, downsampler.interval)
+        && Objects.equal(aggregator, downsampler.aggregator)
+        && Objects.equal(fill_policy, downsampler.fill_policy);
+  }
+
+  @Override
+  public int hashCode() {
+    return Objects.hashCode(interval, aggregator, fill_policy);
+  }
+
+  /**
+   * A builder for the downsampler component of a query
+   */
+  @JsonIgnoreProperties(ignoreUnknown = true)
+  @JsonPOJOBuilder(buildMethodName = "build", withPrefix = "")
+  public static final class Builder {
+    @JsonProperty
+    private String interval;
+    @JsonProperty
+    private String aggregator;
+    @JsonProperty
+    private NumericFillPolicy fillPolicy;
+    
+    public Builder setInterval(String interval) {
+      this.interval = interval;
+      return this;
+    }
+    
+    public Builder setAggregator(String aggregator) {
+      this.aggregator = aggregator;
+      return this;
+    }
+    
+    public Builder setFillPolicy(NumericFillPolicy fill_policy) {
+      this.fillPolicy = fill_policy;
+      return this;
+    }
+    
+    public Downsampler build() {
+      return new Downsampler(this);
+    }
+  }
+}
diff --git a/src/query/pojo/Expression.java b/src/query/pojo/Expression.java
new file mode 100644
index 0000000000..0b313d9835
--- /dev/null
+++ b/src/query/pojo/Expression.java
@@ -0,0 +1,198 @@
+// This file is part of OpenTSDB.
+// Copyright (C) 2015  The OpenTSDB Authors.
+//
+// This program is free software: you can redistribute it and/or modify it
+// under the terms of the GNU Lesser General Public License as published by
+// the Free Software Foundation, either version 2.1 of the License, or (at your
+// option) any later version.  This program is distributed in the hope that it
+// will be useful, but WITHOUT ANY WARRANTY; without even the implied warranty
+// of MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser
+// General Public License for more details.  You should have received a copy
+// of the GNU Lesser General Public License along with this program.  If not,
+// see <http://www.gnu.org/licenses/>.
+package net.opentsdb.query.pojo;
+
+import net.opentsdb.query.expression.ExpressionIterator;
+import net.opentsdb.query.expression.NumericFillPolicy;
+import net.opentsdb.query.expression.VariableIterator.SetOperator;
+
+import java.util.HashSet;
+import java.util.List;
+import java.util.Set;
+
+import org.apache.commons.jexl2.Script;
+
+import com.fasterxml.jackson.annotation.JsonIgnore;
+import com.fasterxml.jackson.annotation.JsonIgnoreProperties;
+import com.fasterxml.jackson.annotation.JsonProperty;
+import com.fasterxml.jackson.databind.annotation.JsonDeserialize;
+import com.fasterxml.jackson.databind.annotation.JsonPOJOBuilder;
+import com.google.common.base.Objects;
+
+/**
+ * Pojo builder class used for serdes of the expression component of a query
+ * @since 2.3
+ */
+@JsonIgnoreProperties(ignoreUnknown = true)
+@JsonDeserialize(builder = Expression.Builder.class)
+public class Expression extends Validatable {
+  /** An id for this expression for use in output selection or nested expressions */
+  private String id;
+  
+  /** The raw expression as a string */
+  private String expr;
+  
+  /** The joiner operator */
+  private Join join;
+  
+  /** The fill policy to use for ? */
+  private NumericFillPolicy fill_policy;
+  
+  /** Set of unique variables used by this expression. */
+  private Set<String> variables;
+  
+  /** The parsed expression via JEXL. */
+  private Script parsed_expression;
+  
+  /**
+   * Default ctor 
+   * @param builder The builder to pull values from
+   */
+  protected Expression(Builder builder) {
+    id = builder.id;
+    expr = builder.expr;
+    join = builder.join;
+    fill_policy = builder.fillPolicy;
+  }
+  
+  /** @return the id for this expression for use in output selection or 
+   * nested expressions */
+  public String getId() {
+    return id;
+  }
+
+  /** @return the raw expression as a string */
+  public String getExpr() {
+    return expr;
+  }
+
+  /** @return he joiner operator */
+  public Join getJoin() {
+    return join;
+  }
+  
+  /** @return the fill policy to use for ? */
+  public NumericFillPolicy getFillPolicy() {
+    return fill_policy;
+  }
+  
+  /** @return A new builder for the expression */
+  public static Builder Builder() {
+    return new Builder();
+  }
+
+  /** Validates the expression
+   * @throws IllegalArgumentException if one or more parameters were invalid
+   */
+  public void validate() {
+    if (id == null || id.isEmpty()) {
+      throw new IllegalArgumentException("missing or empty id");
+    }
+    Query.validateId(id);
+    
+    if (expr == null || expr.isEmpty()) {
+      throw new IllegalArgumentException("missing or empty expr");
+    }
+    
+    // parse it just to make sure we're happy and extract the variable names. 
+    // Will throw JexlException
+    parsed_expression = ExpressionIterator.JEXL_ENGINE.createScript(expr);
+    variables = new HashSet<String>();
+    for (final List<String> exp_list : 
+      ExpressionIterator.JEXL_ENGINE.getVariables(parsed_expression)) {
+      for (final String variable : exp_list) {
+        variables.add(variable);
+      }
+    }
+    
+    // others are optional
+    if (join == null) {
+      join = Join.Builder().setOperator(SetOperator.UNION).build();
+    }
+  }
+
+  /** @return The parsed expression. May be null if {@link validate} has not 
+   * been called yet. */
+  @JsonIgnore
+  public Script getParsedExpression() {
+    return parsed_expression;
+  }
+  
+  /** @return A set of unique variables for the expression. May be null if 
+   * {@link validate} has not been called yet. */
+  @JsonIgnore
+  public Set<String> getVariables() {
+    return variables;
+  }
+  
+  @Override
+  public boolean equals(final Object o) {
+    if (this == o)
+      return true;
+    if (o == null || getClass() != o.getClass())
+      return false;
+
+    final Expression expression = (Expression) o;
+
+    return Objects.equal(id, expression.id)
+        && Objects.equal(expr, expression.expr)
+        && Objects.equal(join, expression.join)
+        && Objects.equal(fill_policy, expression.fill_policy);
+  }
+
+  @Override
+  public int hashCode() {
+    return Objects.hashCode(id, expr, join, fill_policy);
+  }
+
+  /**
+   * A builder for the downsampler component of a query
+   */
+  @JsonIgnoreProperties(ignoreUnknown = true)
+  @JsonPOJOBuilder(buildMethodName = "build", withPrefix = "")
+  public static final class Builder {
+    @JsonProperty
+    private String id;
+    @JsonProperty
+    private String expr;
+    @JsonProperty
+    private Join join;
+    @JsonProperty
+    private NumericFillPolicy fillPolicy;
+    
+    public Builder setId(String id) {
+      Query.validateId(id);
+      this.id = id;
+      return this;
+    }
+
+    public Builder setExpression(String expr) {
+      this.expr = expr;
+      return this;
+    }
+
+    public Builder setJoin(Join join) {
+      this.join = join;
+      return this;
+    }
+    
+    public Builder setFillPolicy(NumericFillPolicy fill_policy) {
+      this.fillPolicy = fill_policy;
+      return this;
+    }
+    
+    public Expression build() {
+      return new Expression(this);
+    }
+  }
+}
diff --git a/src/query/pojo/Filter.java b/src/query/pojo/Filter.java
new file mode 100644
index 0000000000..c1eeea2818
--- /dev/null
+++ b/src/query/pojo/Filter.java
@@ -0,0 +1,134 @@
+// This file is part of OpenTSDB.
+// Copyright (C) 2015  The OpenTSDB Authors.
+//
+// This program is free software: you can redistribute it and/or modify it
+// under the terms of the GNU Lesser General Public License as published by
+// the Free Software Foundation, either version 2.1 of the License, or (at your
+// option) any later version.  This program is distributed in the hope that it
+// will be useful, but WITHOUT ANY WARRANTY; without even the implied warranty
+// of MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser
+// General Public License for more details.  You should have received a copy
+// of the GNU Lesser General Public License along with this program.  If not,
+// see <http://www.gnu.org/licenses/>.
+package net.opentsdb.query.pojo;
+
+import com.fasterxml.jackson.annotation.JsonIgnoreProperties;
+import com.fasterxml.jackson.annotation.JsonProperty;
+import com.fasterxml.jackson.databind.annotation.JsonDeserialize;
+import com.fasterxml.jackson.databind.annotation.JsonPOJOBuilder;
+import com.google.common.base.Objects;
+
+import net.opentsdb.query.filter.TagVFilter;
+
+import java.util.List;
+
+/**
+ * Pojo builder class used for serdes of a filter component of a query
+ * @since 2.3
+ */
+@JsonDeserialize(builder = Filter.Builder.class)
+public class Filter extends Validatable {
+  /** The id of the filter set to use in a metric query */
+  private String id;
+  
+  /** The list of filters in the filter set */
+  private List<TagVFilter> tags;
+  
+  /** Whether or not to only fetch series with exactly the same tag keys as 
+   * in the filter list. */
+  private boolean explicit_tags;
+  
+  /**
+   * Default ctor
+   * @param builder The builder to pull values from
+   */
+  private Filter(Builder builder) {
+    this.id = builder.id;
+    this.tags = builder.tags;
+    this.explicit_tags = builder.explicitTags;
+  }
+
+  /** @return the id of the filter set to use in a metric query */
+  public String getId() {
+    return id;
+  }
+
+  /** @return the list of filters in the filter set */
+  public List<TagVFilter> getTags() {
+    return tags;
+  }
+
+  /** @return Whether or not to only fetch series with exactly the same tag keys as 
+   * in the filter list. */
+  public boolean getExplicitTags() {
+    return explicit_tags;
+  }
+  
+  /** @return A new builder for the filter */
+  public static Builder Builder() {
+    return new Builder();
+  }
+
+  /** Validates the filter set
+   * @throws IllegalArgumentException if one or more parameters were invalid
+   */
+  public void validate() {
+    if (id == null || id.isEmpty()) {
+      throw new IllegalArgumentException("Missing or empty id");
+    }
+    Query.validateId(id);
+  }
+  
+  @Override
+  public boolean equals(final Object o) {
+    if (this == o)
+      return true;
+    if (o == null || getClass() != o.getClass())
+      return false;
+
+    final Filter filter = (Filter) o;
+
+    return Objects.equal(id, filter.id)
+        && Objects.equal(tags, filter.tags)
+        && Objects.equal(explicit_tags, filter.explicit_tags);
+  }
+
+  @Override
+  public int hashCode() {
+    return Objects.hashCode(id, tags, explicit_tags);
+  }
+
+  /**
+   * A builder for the downsampler component of a query
+   */
+  @JsonIgnoreProperties(ignoreUnknown = true)
+  @JsonPOJOBuilder(buildMethodName = "build", withPrefix = "")
+  public static final class Builder {
+    @JsonProperty
+    private String id;
+    @JsonProperty
+    private List<TagVFilter> tags;
+    @JsonProperty
+    private boolean explicitTags;
+    
+    public Builder setId(String id) {
+      Query.validateId(id);
+      this.id = id;
+      return this;
+    }
+
+    public Builder setTags(List<TagVFilter> tags) {
+      this.tags = tags;
+      return this;
+    }
+
+    public Builder setExplicitTags(boolean explicit_tags) {
+      this.explicitTags = explicit_tags;
+      return this;
+    }
+    
+    public Filter build() {
+      return new Filter(this);
+    }
+  }
+}
diff --git a/src/query/pojo/Join.java b/src/query/pojo/Join.java
new file mode 100644
index 0000000000..ea5c228fa3
--- /dev/null
+++ b/src/query/pojo/Join.java
@@ -0,0 +1,132 @@
+// This file is part of OpenTSDB.
+// Copyright (C) 2015  The OpenTSDB Authors.
+//
+// This program is free software: you can redistribute it and/or modify it
+// under the terms of the GNU Lesser General Public License as published by
+// the Free Software Foundation, either version 2.1 of the License, or (at your
+// option) any later version.  This program is distributed in the hope that it
+// will be useful, but WITHOUT ANY WARRANTY; without even the implied warranty
+// of MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser
+// General Public License for more details.  You should have received a copy
+// of the GNU Lesser General Public License along with this program.  If not,
+// see <http://www.gnu.org/licenses/>.
+package net.opentsdb.query.pojo;
+
+import net.opentsdb.query.expression.VariableIterator.SetOperator;
+
+import com.fasterxml.jackson.annotation.JsonIgnoreProperties;
+import com.fasterxml.jackson.annotation.JsonProperty;
+import com.fasterxml.jackson.databind.annotation.JsonDeserialize;
+import com.fasterxml.jackson.databind.annotation.JsonPOJOBuilder;
+import com.google.common.base.Objects;
+
+/**
+ * Pojo builder class used for serdes of the join component of a query
+ * @since 2.3
+ */
+@JsonDeserialize(builder = Join.Builder.class)
+public class Join extends Validatable {
+  /** The set operator to use for joining sets */
+  private SetOperator operator;
+  
+  /** Whether or not to use the original query tags instead of the resulting 
+   * series tags when joining. */
+  private boolean use_query_tags = false;
+  
+  /** Whether or not to use the aggregated tags in the results when joining. */
+  private boolean include_agg_tags = true;
+  
+  /**
+   * Default ctor
+   * @param builder The builder to pull values from
+   */
+  public Join(final Builder builder) {
+    operator = builder.operator;
+    use_query_tags = builder.useQueryTags;
+    include_agg_tags = builder.includeAggTags;
+  }
+  
+  /** @return the set operator to use for joining sets */
+  public SetOperator getOperator() {
+    return operator;
+  }
+  
+  /** @return whether or not to use the original query tags instead of the 
+   * resulting series tags when joining. */
+  public boolean getUseQueryTags() {
+    return use_query_tags;
+  }
+  
+  /** @return Whether or not to use the aggregated tags in the results 
+   * when joining. */
+  public boolean getIncludeAggTags() {
+    return include_agg_tags;
+  }
+  
+  /** @return A new builder for the joiner */
+  public static Builder Builder() {
+    return new Builder();
+  }
+  
+  /** Validates the joiner
+   * @throws IllegalArgumentException if one or more parameters were invalid
+   */
+  @Override
+  public void validate() {
+    if (operator == null) {
+      throw new IllegalArgumentException("Missing join operator");
+    }
+  }
+  
+  @Override
+  public boolean equals(final Object o) {
+    if (this == o)
+      return true;
+    if (o == null || getClass() != o.getClass())
+      return false;
+
+    final Join join = (Join) o;
+
+    return Objects.equal(operator, join.operator)
+        && Objects.equal(use_query_tags, join.use_query_tags)
+    && Objects.equal(include_agg_tags, join.include_agg_tags);
+  }
+
+  @Override
+  public int hashCode() {
+    return Objects.hashCode(operator, use_query_tags, include_agg_tags);
+  }
+  
+  /**
+   * A builder for the downsampler component of a query
+   */
+  @JsonIgnoreProperties(ignoreUnknown = true)
+  @JsonPOJOBuilder(buildMethodName = "build", withPrefix = "")
+  public static final class Builder {
+    @JsonProperty
+    private SetOperator operator;
+    @JsonProperty
+    private boolean useQueryTags = false;
+    @JsonProperty
+    private boolean includeAggTags = true;
+    
+    public Builder setOperator(final SetOperator operator) {
+      this.operator = operator;
+      return this;
+    }
+    
+    public Builder setUseQueryTags(final boolean use_query_tags) {
+      this.useQueryTags = use_query_tags;
+      return this;
+    }
+    
+    public Builder setIncludeAggTags(final boolean include_agg_tags) {
+      this.includeAggTags = include_agg_tags;
+      return this;
+    }
+    
+    public Join build() {
+      return new Join(this);
+    }
+  }
+}
diff --git a/src/query/pojo/Metric.java b/src/query/pojo/Metric.java
new file mode 100644
index 0000000000..a5e85e0d5d
--- /dev/null
+++ b/src/query/pojo/Metric.java
@@ -0,0 +1,206 @@
+// This file is part of OpenTSDB.
+// Copyright (C) 2015  The OpenTSDB Authors.
+//
+// This program is free software: you can redistribute it and/or modify it
+// under the terms of the GNU Lesser General Public License as published by
+// the Free Software Foundation, either version 2.1 of the License, or (at your
+// option) any later version.  This program is distributed in the hope that it
+// will be useful, but WITHOUT ANY WARRANTY; without even the implied warranty
+// of MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser
+// General Public License for more details.  You should have received a copy
+// of the GNU Lesser General Public License along with this program.  If not,
+// see <http://www.gnu.org/licenses/>.
+package net.opentsdb.query.pojo;
+
+import java.util.NoSuchElementException;
+
+import com.fasterxml.jackson.annotation.JsonIgnoreProperties;
+import com.fasterxml.jackson.annotation.JsonProperty;
+import com.fasterxml.jackson.databind.annotation.JsonDeserialize;
+import com.fasterxml.jackson.databind.annotation.JsonPOJOBuilder;
+import com.google.common.base.Objects;
+
+import net.opentsdb.core.Aggregators;
+import net.opentsdb.query.expression.NumericFillPolicy;
+import net.opentsdb.utils.DateTime;
+
+/**
+ * Pojo builder class used for serdes of a metric component of a query
+ * @since 2.3
+ */
+@JsonDeserialize(builder = Metric.Builder.class)
+public class Metric extends Validatable {
+  /** The name of the metric */
+  private String metric;
+  
+  /** An ID for the metric */
+  private String id;
+  
+  /** The ID of a filter set */
+  private String filter;
+  
+  /** An optional time offset for time over time expressions */
+  private String time_offset;
+  
+  /** An optional aggregation override for the metric */
+  private String aggregator;
+  
+  /** A fill policy for dealing with missing values in the metric */
+  private NumericFillPolicy fill_policy;
+
+  /**
+   * Default ctor
+   * @param builder The builder to pull values from
+   */
+  public Metric(Builder builder) {
+    metric = builder.metric;
+    id = builder.id;
+    filter = builder.filter;
+    time_offset = builder.timeOffset;
+    aggregator = builder.aggregator;
+    fill_policy = builder.fillPolicy;
+  }
+
+  /** @return the name of the metric */
+  public String getMetric() {
+    return metric;
+  }
+
+  /** @return an ID for the metric */
+  public String getId() {
+    return id;
+  }
+
+  /** @return the ID of a filter set */
+  public String getFilter() {
+    return filter;
+  }
+
+  /** @return an optional time offset for time over time expressions */
+  public String getTimeOffset() {
+    return time_offset;
+  }
+
+  /** @return an optional aggregation override for the metric */
+  public String getAggregator() {
+    return aggregator;
+  }
+  
+  /** @return a fill policy for dealing with missing values in the metric */
+  public NumericFillPolicy getFillPolicy() {
+    return fill_policy;
+  }
+  
+  /** @return A new builder for the metric */
+  public static Builder Builder() {
+    return new Builder();
+  }
+
+  /** Validates the metric
+   * @throws IllegalArgumentException if one or more parameters were invalid
+   */
+  public void validate() {
+    if (metric == null || metric.isEmpty()) {
+      throw new IllegalArgumentException("missing or empty metric");
+    }
+
+    if (id == null || id.isEmpty()) {
+      throw new IllegalArgumentException("missing or empty id");
+    }
+    Query.validateId(id);
+
+    if (time_offset != null) {
+      DateTime.parseDateTimeString(time_offset, null);
+    }
+    
+    if (aggregator != null && !aggregator.isEmpty()) {
+      try {
+        Aggregators.get(aggregator.toLowerCase());
+      } catch (final NoSuchElementException e) {
+        throw new IllegalArgumentException("Invalid aggregator");
+      }
+    }
+
+    if (fill_policy != null) {
+      fill_policy.validate();
+    }
+  }
+
+  @Override
+  public boolean equals(final Object o) {
+    if (this == o)
+      return true;
+    if (o == null || getClass() != o.getClass())
+      return false;
+
+    final Metric that = (Metric) o;
+
+    return Objects.equal(that.filter, filter)
+        && Objects.equal(that.id, id)
+        && Objects.equal(that.metric, metric)
+        && Objects.equal(that.time_offset, time_offset)
+        && Objects.equal(that.aggregator, aggregator)
+        && Objects.equal(that.fill_policy, fill_policy);
+  }
+
+  @Override
+  public int hashCode() {
+    return Objects.hashCode(metric, id, filter, time_offset, aggregator, 
+        fill_policy);
+  }
+
+  /**
+   * A builder for a metric component of a query
+   */
+  @JsonIgnoreProperties(ignoreUnknown = true)
+  @JsonPOJOBuilder(buildMethodName = "build", withPrefix = "")
+  public static final class Builder {
+    @JsonProperty
+    private String metric;
+    @JsonProperty
+    private String id;
+    @JsonProperty
+    private String filter;
+    @JsonProperty
+    private String timeOffset;
+    @JsonProperty
+    private String aggregator;
+    @JsonProperty
+    private NumericFillPolicy fillPolicy;
+    
+    public Builder setMetric(String metric) {
+      this.metric = metric;
+      return this;
+    }
+
+    public Builder setId(String id) {
+      Query.validateId(id);
+      this.id = id;
+      return this;
+    }
+
+    public Builder setFilter(String filter) {
+      this.filter = filter;
+      return this;
+    }
+
+    public Builder setTimeOffset(String time_offset) {
+      this.timeOffset = time_offset;
+      return this;
+    }
+
+    public Builder setAggregator(String aggregator) {
+      this.aggregator = aggregator;
+      return this;
+    }
+
+    public Builder setFillPolicy(NumericFillPolicy fill_policy) {
+      this.fillPolicy = fill_policy;
+      return this;
+    }
+    
+    public Metric build() {
+      return new Metric(this);
+    }
+  }
+}
diff --git a/src/query/pojo/Output.java b/src/query/pojo/Output.java
new file mode 100644
index 0000000000..8b996cf9ab
--- /dev/null
+++ b/src/query/pojo/Output.java
@@ -0,0 +1,117 @@
+// This file is part of OpenTSDB.
+// Copyright (C) 2015  The OpenTSDB Authors.
+//
+// This program is free software: you can redistribute it and/or modify it
+// under the terms of the GNU Lesser General Public License as published by
+// the Free Software Foundation, either version 2.1 of the License, or (at your
+// option) any later version.  This program is distributed in the hope that it
+// will be useful, but WITHOUT ANY WARRANTY; without even the implied warranty
+// of MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser
+// General Public License for more details.  You should have received a copy
+// of the GNU Lesser General Public License along with this program.  If not,
+// see <http://www.gnu.org/licenses/>.
+package net.opentsdb.query.pojo;
+
+import com.fasterxml.jackson.annotation.JsonIgnoreProperties;
+import com.fasterxml.jackson.annotation.JsonProperty;
+import com.fasterxml.jackson.databind.annotation.JsonDeserialize;
+import com.fasterxml.jackson.databind.annotation.JsonPOJOBuilder;
+import com.google.common.base.Objects;
+
+/**
+ * Pojo builder class used for serdes of the output component of a query
+ * @since 2.3
+ */
+@JsonIgnoreProperties(ignoreUnknown = true)
+@JsonDeserialize(builder = Output.Builder.class)
+public class Output extends Validatable {
+  /** The ID of a metric or expression to emit */
+  private String id;
+  
+  /** An alias to use as the metric name for the output */
+  private String alias;
+
+  /**
+   * Default ctor
+   * @param builder The builder to pull values from
+   */
+  public Output(Builder builder) {
+    this.id = builder.id;
+    this.alias = builder.alias;
+  }
+  
+  /** @return the ID of a metric or expression to emit */
+  public String getId() {
+    return id;
+  }
+
+  /** @return an alias to use as the metric name for the output */
+  public String getAlias() {
+    return alias;
+  }
+
+  /** @return A new builder for the output */
+  public static Builder Builder() {
+    return new Builder();
+  }
+
+  /** Validates the output
+   * @throws IllegalArgumentException if one or more parameters were invalid
+   */
+  @Override public void validate() { 
+    if (id == null || id.isEmpty()) {
+      throw new IllegalArgumentException("missing or empty id");
+    }
+    Query.validateId(id);
+  }
+  
+  @Override
+  public String toString() {
+    return "var=" + id + ", alias=" + alias;
+  }
+  
+  @Override
+  public boolean equals(Object o) {
+    if (this == o)
+      return true;
+    if (o == null || getClass() != o.getClass())
+      return false;
+
+    Output output = (Output) o;
+
+    return Objects.equal(output.alias, alias)
+        && Objects.equal(output.id, id);
+  }
+
+  @Override
+  public int hashCode() {
+    return Objects.hashCode(id, alias);
+  }
+  
+  /**
+   * A builder for the downsampler component of a query
+   */
+  @JsonIgnoreProperties(ignoreUnknown = true)
+  @JsonPOJOBuilder(buildMethodName = "build", withPrefix = "")
+  public static final class Builder {
+    @JsonProperty
+    private String id;
+    @JsonProperty
+    private String alias;
+
+    public Builder setId(String id) {
+      Query.validateId(id);
+      this.id = id;
+      return this;
+    }
+
+    public Builder setAlias(String alias) {
+      this.alias = alias;
+      return this;
+    }
+
+    public Output build() {
+      return new Output(this);
+    }
+  }
+}
diff --git a/src/query/pojo/Query.java b/src/query/pojo/Query.java
new file mode 100644
index 0000000000..731c449950
--- /dev/null
+++ b/src/query/pojo/Query.java
@@ -0,0 +1,292 @@
+// This file is part of OpenTSDB.
+// Copyright (C) 2015  The OpenTSDB Authors.
+//
+// This program is free software: you can redistribute it and/or modify it
+// under the terms of the GNU Lesser General Public License as published by
+// the Free Software Foundation, either version 2.1 of the License, or (at your
+// option) any later version.  This program is distributed in the hope that it
+// will be useful, but WITHOUT ANY WARRANTY; without even the implied warranty
+// of MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser
+// General Public License for more details.  You should have received a copy
+// of the GNU Lesser General Public License along with this program.  If not,
+// see <http://www.gnu.org/licenses/>.
+package net.opentsdb.query.pojo;
+
+import com.fasterxml.jackson.annotation.JsonIgnoreProperties;
+import com.fasterxml.jackson.annotation.JsonProperty;
+import com.fasterxml.jackson.databind.annotation.JsonDeserialize;
+import com.fasterxml.jackson.databind.annotation.JsonPOJOBuilder;
+import com.google.common.base.Objects;
+
+import net.opentsdb.utils.JSON;
+
+import java.util.HashSet;
+import java.util.List;
+import java.util.Set;
+
+/**
+ * Pojo builder class used for serdes of the expression query
+ * @since 2.3
+ */
+@JsonIgnoreProperties(ignoreUnknown = true)
+@JsonDeserialize(builder = Query.Builder.class)
+public class Query extends Validatable {
+  /** An optional name for the query */
+  private String name;
+  
+  /** The timespan component of the query */
+  private Timespan time;
+  
+  /** A list of filters */
+  private List<Filter> filters;
+  
+  /** A list of metrics */
+  private List<Metric> metrics;
+  
+  /** A list of expressions */
+  private List<Expression> expressions;
+  
+  /** A list of outputs */
+  private List<Output> outputs;
+
+  /**
+   * Default ctor
+   * @param builder The builder to pull values from
+   */
+  public Query(Builder builder) {
+    this.name = builder.name;
+    this.time = builder.time;
+    this.filters = builder.filters;
+    this.metrics = builder.metrics;
+    this.expressions = builder.expressions;
+    this.outputs = builder.outputs;
+  }
+
+  /** @return an optional name for the query */
+  public String getName() {
+    return name;
+  }
+
+  /** @return the timespan component of the query */
+  public Timespan getTime() {
+    return time;
+  }
+
+  /** @return a list of filters */
+  public List<Filter> getFilters() {
+    return filters;
+  }
+
+  /** @return a list of metrics */
+  public List<Metric> getMetrics() {
+    return metrics;
+  }
+
+  /** @return a list of expressions */
+  public List<Expression> getExpressions() {
+    return expressions;
+  }
+
+  /** @return a list of outputs */
+  public List<Output> getOutputs() {
+    return outputs;
+  }
+
+  /** @return A new builder for the query */
+  public static Builder Builder() {
+    return new Builder();
+  }
+  
+  /** Validates the query
+   * @throws IllegalArgumentException if one or more parameters were invalid
+   */
+  public void validate() {
+    if (time == null) {
+      throw new IllegalArgumentException("missing time");
+    }
+
+    validatePOJO(time, "time");
+
+    if (metrics == null || metrics.isEmpty()) {
+      throw new IllegalArgumentException("missing or empty metrics");
+    }
+
+    final Set<String> variable_ids = new HashSet<String>();
+    for (Metric metric : metrics) {
+      if (variable_ids.contains(metric.getId())) {
+        throw new IllegalArgumentException("duplicated metric id: "
+            + metric.getId());
+      }
+      variable_ids.add(metric.getId());
+    }
+
+    final Set<String> filter_ids = new HashSet<String>();
+
+    for (Filter filter : filters) {
+      if (filter_ids.contains(filter.getId())) {
+        throw new IllegalArgumentException("duplicated filter id: "
+            + filter.getId());
+      }
+      filter_ids.add(filter.getId());
+    }
+    
+    for (Expression expression : expressions) {
+      if (variable_ids.contains(expression.getId())) {
+        throw new IllegalArgumentException("Duplicated variable or expression id: "
+            + expression.getId());
+      }
+      variable_ids.add(expression.getId());
+    }
+
+    validateCollection(metrics, "metric");
+
+    if (filters != null) {
+      validateCollection(filters, "filter");
+    }
+
+    if (expressions != null) {
+      validateCollection(expressions, "expression");
+    }
+
+    validateFilters();
+    
+    if (expressions != null) {
+      validateCollection(expressions, "expression");
+      for (final Expression exp : expressions) {
+        if (exp.getVariables() == null) {
+          throw new IllegalArgumentException("No variables found for an "
+              + "expression?! " + JSON.serializeToString(exp));
+        }
+        
+        for (final String var : exp.getVariables()) {
+          if (!variable_ids.contains(var)) {
+            throw new IllegalArgumentException("Expression [" + exp.getExpr() 
+              + "] was missing input " + var);
+          }
+        }
+      }
+    }
+  }
+
+  /** Validates the filters, making sure each metric has a filter
+   * @throws IllegalArgumentException if one or more parameters were invalid
+   */
+  private void validateFilters() {
+    Set<String> ids = new HashSet<String>();
+    for (Filter filter : filters) {
+      ids.add(filter.getId());
+    }
+
+    for(Metric metric : metrics) {
+      if (metric.getFilter() != null && 
+          !metric.getFilter().isEmpty() && 
+          !ids.contains(metric.getFilter())) {
+        throw new IllegalArgumentException(
+            String.format("unrecognized filter id %s in metric %s",
+                metric.getFilter(), metric.getId()));
+      }
+    }
+  }
+  
+  /**
+   * Makes sure the ID has only letters and characters
+   * @param id The ID to parse
+   * @throws IllegalArgumentException if the ID is invalid
+   */
+  public static void validateId(final String id) {
+    if (id == null || id.isEmpty()) {
+      throw new IllegalArgumentException("The ID cannot be null or empty");
+    }
+    for (int i = 0; i < id.length(); i++) {
+      final char c = id.charAt(i);
+      if (!(Character.isLetterOrDigit(c))) {
+        throw new IllegalArgumentException("Invalid id (\"" + id + 
+            "\"): illegal character: " + c);
+      }
+    }
+    if (id.length() == 1) {
+      if (Character.isDigit(id.charAt(0))) {
+        throw new IllegalArgumentException("The ID cannot be an integer");
+      }
+    }
+  }
+
+  @Override
+  public boolean equals(Object o) {
+    if (this == o)
+      return true;
+    if (o == null || getClass() != o.getClass())
+      return false;
+
+    Query query = (Query) o;
+
+    return Objects.equal(query.expressions, expressions)
+        && Objects.equal(query.filters, filters)
+        && Objects.equal(query.metrics, metrics)
+        && Objects.equal(query.name, name)
+        && Objects.equal(query.outputs, outputs)
+        && Objects.equal(query.time, time);
+  }
+
+  @Override
+  public int hashCode() {
+    return Objects.hashCode(name, time, filters, metrics, expressions, outputs);
+  }
+
+  /**
+   * A builder for the query component of a query
+   */
+  @JsonIgnoreProperties(ignoreUnknown = true)
+  @JsonPOJOBuilder(buildMethodName = "build", withPrefix = "")
+  public static final class Builder {
+    @JsonProperty
+    private String name;
+    @JsonProperty
+    private Timespan time;
+    @JsonProperty
+    private List<Filter> filters;
+    @JsonProperty
+    private List<Metric> metrics;
+    @JsonProperty
+    private List<Expression> expressions;
+    @JsonProperty
+    private List<Output> outputs;
+
+    public Builder() { }
+
+    public Builder setName(final String name) {
+      this.name = name;
+      return this;
+    }
+
+    public Builder setTime(final Timespan time) {
+      this.time = time;
+      return this;
+    }
+
+    public Builder setFilters(final List<Filter> filters) {
+      this.filters = filters;
+      return this;
+    }
+
+    public Builder setMetrics(final List<Metric> metrics) {
+      this.metrics = metrics;
+      return this;
+    }
+
+    public Builder setExpressions(final List<Expression> expressions) {
+      this.expressions = expressions;
+      return this;
+    }
+
+    public Builder setOutputs(final List<Output> outputs) {
+      this.outputs = outputs;
+      return this;
+    }
+
+    public Query build() {
+      return new Query(this);
+    }
+  }
+  
+}
diff --git a/src/query/pojo/Timespan.java b/src/query/pojo/Timespan.java
new file mode 100644
index 0000000000..96e56ba255
--- /dev/null
+++ b/src/query/pojo/Timespan.java
@@ -0,0 +1,208 @@
+// This file is part of OpenTSDB.
+// Copyright (C) 2015  The OpenTSDB Authors.
+//
+// This program is free software: you can redistribute it and/or modify it
+// under the terms of the GNU Lesser General Public License as published by
+// the Free Software Foundation, either version 2.1 of the License, or (at your
+// option) any later version.  This program is distributed in the hope that it
+// will be useful, but WITHOUT ANY WARRANTY; without even the implied warranty
+// of MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser
+// General Public License for more details.  You should have received a copy
+// of the GNU Lesser General Public License along with this program.  If not,
+// see <http://www.gnu.org/licenses/>.
+package net.opentsdb.query.pojo;
+
+import java.util.NoSuchElementException;
+
+import com.fasterxml.jackson.annotation.JsonIgnoreProperties;
+import com.fasterxml.jackson.annotation.JsonProperty;
+import com.fasterxml.jackson.databind.annotation.JsonDeserialize;
+import com.fasterxml.jackson.databind.annotation.JsonPOJOBuilder;
+import com.google.common.base.Objects;
+
+import net.opentsdb.core.Aggregators;
+import net.opentsdb.utils.DateTime;
+
+/**
+ * Pojo builder class used for serdes of the timespan component of a query
+ * @since 2.3
+ */
+@JsonIgnoreProperties(ignoreUnknown = true)
+@JsonDeserialize(builder = Timespan.Builder.class)
+public class Timespan extends Validatable {
+  /** User given start date/time, could be relative or absolute */
+  private String start;
+  
+  /** User given end date/time, could be relative, absolute or empty */
+  private String end;
+  
+  /** User's timezone used for converting absolute human readable dates */
+  private String timezone;
+
+  /** An optional downsampler for all queries */
+  private Downsampler downsampler;
+  
+  /** The global aggregator to use */
+  private String aggregator; 
+  
+  /** Whether or not to compute a rate */
+  private boolean rate;
+
+  /**
+   * Default ctor
+   * @param builder The builder to pull values from
+   */
+  public Timespan(Builder builder) {
+    start = builder.start;
+    end = builder.end;
+    timezone = builder.timezone;
+    downsampler = builder.downsampler;
+    aggregator = builder.aggregator;
+    rate = builder.rate;
+  }
+  
+  /** @return user given start date/time, could be relative or absolute */
+  public String getStart() {
+    return start;
+  }
+
+  /** @return user given end date/time, could be relative, absolute or empty */
+  public String getEnd() {
+    return end;
+  }
+
+  /** @return user's timezone used for converting absolute human readable dates */
+  public String getTimezone() {
+    return timezone;
+  }
+
+  /** @return an optional downsampler for all queries */
+  public Downsampler getDownsampler() {
+    return downsampler;
+  }
+  
+  /** @return the global aggregator to use */
+  public String getAggregator() {
+    return aggregator;
+  }
+  
+  /** @return whether or not to compute a rate */
+  public boolean isRate() {
+    return rate;
+  }
+  
+  @Override
+  public boolean equals(Object o) {
+    if (this == o)
+      return true;
+    if (o == null || getClass() != o.getClass())
+      return false;
+
+    Timespan timespan = (Timespan) o;
+
+    return Objects.equal(timespan.downsampler, downsampler)
+        && Objects.equal(timespan.end, end)
+        && Objects.equal(timespan.start, start)
+        && Objects.equal(timespan.timezone, timezone)
+        && Objects.equal(timespan.aggregator, aggregator)
+        && Objects.equal(timespan.rate, rate);
+  }
+
+  @Override
+  public int hashCode() {
+    return Objects.hashCode(start, end, timezone, downsampler, aggregator, rate);
+  }
+
+  /** @return A new builder for the downsampler */
+  public static Builder Builder() {
+    return new Builder();
+  }
+
+  /** Validates the timespan
+   * @throws IllegalArgumentException if one or more parameters were invalid
+   */
+  public void validate() {
+    if (start == null || start.isEmpty()) {
+      throw new IllegalArgumentException("missing or empty start");
+    }
+    DateTime.parseDateTimeString(start, timezone);
+    
+    if (end != null && !end.isEmpty()) {
+      DateTime.parseDateTimeString(end, timezone);
+    }
+    
+    if (downsampler != null) {
+      downsampler.validate();
+    }
+    
+    if (aggregator == null || aggregator.isEmpty()) {
+      throw new IllegalArgumentException("Missing or empty aggregator");
+    }
+    
+    try {
+      Aggregators.get(aggregator.toLowerCase());
+    } catch (final NoSuchElementException e) {
+      throw new IllegalArgumentException("Invalid aggregator");
+    }
+  }
+  
+  /**
+   * A builder for the downsampler component of a query
+   */
+  @JsonIgnoreProperties(ignoreUnknown = true)
+  @JsonPOJOBuilder(buildMethodName = "build", withPrefix = "")
+  public static final class Builder {
+    @JsonProperty
+    private String start;
+
+    @JsonProperty
+    private String end;
+
+    @JsonProperty
+    private String timezone;
+
+    @JsonProperty
+    private Downsampler downsampler;
+    
+    @JsonProperty
+    private String aggregator;
+    
+    @JsonProperty
+    private boolean rate;
+    
+    public Builder setStart(final String start) {
+      this.start = start;
+      return this;
+    }
+
+    public Builder setEnd(final String end) {
+      this.end = end;
+      return this;
+    }
+
+    public Builder setTimezone(final String timezone) {
+      this.timezone = timezone;
+      return this;
+    }
+
+    public Builder setDownsampler(final Downsampler downsample) {
+      this.downsampler = downsample;
+      return this;
+    }
+
+    public Builder setAggregator(final String aggregator) {
+      this.aggregator = aggregator;
+      return this;
+    }
+    
+    public Builder setRate(final boolean rate) {
+      this.rate = rate;
+      return this;
+    }
+    
+    public Timespan build() {
+      return new Timespan(this);
+    }
+  }
+  
+}
diff --git a/src/query/pojo/Validatable.java b/src/query/pojo/Validatable.java
new file mode 100644
index 0000000000..77b53af650
--- /dev/null
+++ b/src/query/pojo/Validatable.java
@@ -0,0 +1,59 @@
+// This file is part of OpenTSDB.
+// Copyright (C) 2015  The OpenTSDB Authors.
+//
+// This program is free software: you can redistribute it and/or modify it
+// under the terms of the GNU Lesser General Public License as published by
+// the Free Software Foundation, either version 2.1 of the License, or (at your
+// option) any later version.  This program is distributed in the hope that it
+// will be useful, but WITHOUT ANY WARRANTY; without even the implied warranty
+// of MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser
+// General Public License for more details.  You should have received a copy
+// of the GNU Lesser General Public License along with this program.  If not,
+// see <http://www.gnu.org/licenses/>.
+package net.opentsdb.query.pojo;
+
+import java.util.Collection;
+import java.util.Iterator;
+
+/**
+ * An interface for the pojos to implement to make sure all the bits of the 
+ * expression queries are there
+ * @since 2.3
+ */
+public abstract class Validatable {
+  abstract public void validate();
+
+  /**
+   * Iterate through a field that is a collection of POJOs and validate each of
+   * them. Inherit member POJO's error message.
+   * @param collection the validatable POJO collection
+   * @param name name of the field
+   */
+  <T extends Validatable> void validateCollection(final Collection<T> collection,
+                                                  final String name) {
+    Iterator<T> iterator = collection.iterator();
+    int i = 0;
+    while (iterator.hasNext()) {
+      try {
+        iterator.next().validate();
+      } catch (final IllegalArgumentException e) {
+        throw new IllegalArgumentException("Invalid " + name + 
+            " at index " + i, e);
+      }
+      i++;
+    }
+  }
+
+  /**
+   * Validate a single POJO validate
+   * @param pojo The POJO object to validate
+   * @param name name of the field
+   */
+  <T extends Validatable> void validatePOJO(final T pojo, final String name) {
+    try {
+      pojo.validate();
+    } catch (final IllegalArgumentException e) {
+      throw new IllegalArgumentException("Invalid " + name, e);
+    }
+  }
+}
diff --git a/src/stats/StatsCollector.java b/src/stats/StatsCollector.java
index 6d002e1568..6170533fff 100644
--- a/src/stats/StatsCollector.java
+++ b/src/stats/StatsCollector.java
@@ -15,10 +15,13 @@
 import org.slf4j.Logger;
 import org.slf4j.LoggerFactory;
 
+import net.opentsdb.utils.Config;
+
 import java.net.InetAddress;
 import java.net.UnknownHostException;
 import java.util.HashMap;
 import java.util.Map;
+import java.util.Map.Entry;
 
 /**
  * Receives various stats/metrics from the current process.
@@ -34,6 +37,9 @@ public abstract class StatsCollector {
   private static final Logger LOG =
     LoggerFactory.getLogger(StatsCollector.class);
 
+  /** Tags to add to every stat emitted by the collector */
+  private static Map<String, String> global_tags;
+  
   /** Prefix to add to every metric name, for example `tsd'. */
   protected final String prefix;
 
@@ -42,7 +48,7 @@ public abstract class StatsCollector {
 
   /** Buffer used to build lines emitted. */
   private final StringBuilder buf = new StringBuilder();
-
+  
   /**
    * Constructor.
    * @param prefix A prefix to add to every metric name, for example
@@ -50,8 +56,13 @@ public abstract class StatsCollector {
    */
   public StatsCollector(final String prefix) {
     this.prefix = prefix;
+    if (global_tags != null && !global_tags.isEmpty()) {
+      for (final Entry<String, String> entry : global_tags.entrySet()) {
+        addExtraTag(entry.getKey(), entry.getValue());
+      }
+    }
   }
-
+  
   /**
    * Method to override to actually emit a data point.
    * @param datapoint A data point in a format suitable for a text
@@ -240,4 +251,21 @@ public final void clearExtraTag(final String name) {
     extratags.remove(name);
   }
 
+  /**
+   * Parses the configuration to determine if any extra tags should be included
+   * with every stat emitted.
+   * @param config The config object to parse
+   * @throws IllegalArgumentException if the config is null. Other exceptions
+   * may be thrown if the config values are unparseable.
+   */
+  public static final void setGlobalTags(final Config config) {
+    if (config == null) {
+      throw new IllegalArgumentException("Configuration cannot be null.");
+    }
+    
+    if (config.getBoolean("tsd.core.stats_with_port")) {
+      global_tags = new HashMap<String, String>(1);
+      global_tags.put("port", config.getString("tsd.network.port"));
+    }
+  }
 }
diff --git a/src/tools/CliOptions.java b/src/tools/CliOptions.java
index aeccb1bb36..a87c45a19f 100644
--- a/src/tools/CliOptions.java
+++ b/src/tools/CliOptions.java
@@ -77,7 +77,7 @@ static String[] parse(final ArgP argp, String[] args) {
       args = argp.parse(args);
     } catch (IllegalArgumentException e) {
       System.err.println("Invalid usage.  " + e.getMessage());
-      return null;
+      System.exit(2);
     }
     honorVerboseFlag(argp);
     return args;
@@ -120,6 +120,10 @@ static void overloadConfig(final ArgP argp, final Config config) {
       // map the overrides
       if (entry.getKey().toLowerCase().equals("--auto-metric")) {
         config.overrideConfig("tsd.core.auto_create_metrics", "true");
+      } else if (entry.getKey().toLowerCase().equals("--disable-ui")) {
+        config.overrideConfig("tsd.core.enable_ui", "false");
+      } else if (entry.getKey().toLowerCase().equals("--disable-api")) {
+        config.overrideConfig("tsd.core.enable_api", "false");
       } else if (entry.getKey().toLowerCase().equals("--table")) {
         config.overrideConfig("tsd.storage.hbase.data_table", entry.getValue());
       } else if (entry.getKey().toLowerCase().equals("--uidtable")) {
@@ -140,13 +144,15 @@ static void overloadConfig(final ArgP argp, final Config config) {
         config.overrideConfig("tsd.core.flushinterval", entry.getValue());
       } else if (entry.getKey().toLowerCase().equals("--backlog")) {
         config.overrideConfig("tsd.network.backlog", entry.getValue());
+      } else if (entry.getKey().toLowerCase().equals("--read-only")) {
+        config.overrideConfig("tsd.mode", "ro");
       } else if (entry.getKey().toLowerCase().equals("--bind")) {
         config.overrideConfig("tsd.network.bind", entry.getValue());
       } else if (entry.getKey().toLowerCase().equals("--async-io")) {
         config.overrideConfig("tsd.network.async_io", entry.getValue());
       } else if (entry.getKey().toLowerCase().equals("--worker-threads")) {
         config.overrideConfig("tsd.network.worker_threads", entry.getValue());
-      }
+      } 	  
     }
   }
   
diff --git a/src/tools/DumpSeries.java b/src/tools/DumpSeries.java
index a7e9222fcc..ac710878fd 100644
--- a/src/tools/DumpSeries.java
+++ b/src/tools/DumpSeries.java
@@ -15,10 +15,12 @@
 import java.nio.charset.Charset;
 import java.util.ArrayList;
 import java.util.Arrays;
+import java.util.Collection;
 import java.util.Date;
 import java.util.List;
 import java.util.Map;
 
+import net.opentsdb.core.AppendDataPoints;
 import org.hbase.async.DeleteRequest;
 import org.hbase.async.HBaseClient;
 import org.hbase.async.KeyValue;
@@ -180,7 +182,7 @@ private static void formatKeyValue(final StringBuilder buf,
     final byte[] value = kv.value();
     final int q_len = qualifier.length;
 
-    if (q_len % 2 != 0) {
+    if (!AppendDataPoints.isAppendDataPoints(qualifier) && q_len % 2 != 0) {
       if (!importformat) {
         // custom data object, not a data point
         if (kv.qualifier()[0] == Annotation.PREFIX()) {
@@ -203,8 +205,16 @@ private static void formatKeyValue(final StringBuilder buf,
         appendImportCell(buf, cell, base_time, tags);
       }
     } else {
-      // compacted column
-      final ArrayList<Cell> cells = Internal.extractDataPoints(kv);
+      final Collection<Cell> cells;
+      if (q_len == 3) {
+        // append data points
+        final AppendDataPoints adps = new AppendDataPoints();
+        cells = adps.parseKeyValue(tsdb, kv);
+      } else {
+        // compacted column
+        cells = Internal.extractDataPoints(kv);
+      }
+
       if (!importformat) {
         buf.append(Arrays.toString(kv.qualifier()))
            .append('\t')
diff --git a/src/tools/StartupPlugin.java b/src/tools/StartupPlugin.java
new file mode 100644
index 0000000000..cbfa040522
--- /dev/null
+++ b/src/tools/StartupPlugin.java
@@ -0,0 +1,85 @@
+// This file is part of OpenTSDB.
+// Copyright (C) 2016  The OpenTSDB Authors.
+//
+// This program is free software: you can redistribute it and/or modify it
+// under the terms of the GNU Lesser General Public License as published by
+// the Free Software Foundation, either version 2.1 of the License, or (at your
+// option) any later version.  This program is distributed in the hope that it
+// will be useful, but WITHOUT ANY WARRANTY; without even the implied warranty
+// of MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser
+// General Public License for more details.  You should have received a copy
+// of the GNU Lesser General Public License along with this program.  If not,
+// see <http://www.gnu.org/licenses/>.
+package net.opentsdb.tools;
+
+import com.stumbleupon.async.Deferred;
+
+import net.opentsdb.utils.Config;
+import net.opentsdb.core.TSDB;
+import net.opentsdb.stats.StatsCollector;
+
+/**
+ * The StartupPlugin allows users to interact with the OpenTSDB configuration
+ * as soon as it is completely parsed, just before OpenTSDB begins to use it.
+ * <p>
+ * <b>Note:</b> Implementations must have a parameterless constructor. The
+ * {@link #initialize(TSDB)} method will be called immediately after the plugin is
+ * instantiated and before any other methods are called.
+ * @since 2.3
+ */
+public abstract class StartupPlugin {
+
+  /**
+   * Called by TSDB to initialize the plugin
+   * Implementations are responsible for setting up any IO they need as well
+   * as starting any required background threads.
+   * <b>Note:</b> Implementations should throw exceptions if they can't start
+   * up properly. The TSD will then shutdown so the operator can fix the
+   * problem. Please use IllegalArgumentException for configuration issues.
+   * @param tsdb The parent TSDB object
+   * @return A reference to the same configuration object passed in the parameters
+   * on success.
+   * @throws IllegalArgumentException if required configuration parameters are
+   * missing
+   */
+  public abstract Config initialize(Config config);
+
+  /**
+   * Called when the TSD is fully initialized and ready to handle traffic.
+   */
+  public abstract void setReady(final TSDB tsdb);
+
+  /**
+   * Called to gracefully shutdown the plugin. Implementations should close
+   * any IO they have open
+   * @return A deferred object that indicates the completion of the request.
+   * The {@link Object} has not special meaning and can be {@code null}
+   * (think of it as {@code Deferred<Void>}).
+   */
+  public abstract Deferred<Object> shutdown();
+
+  /**
+   * Should return the version of this plugin in the format:
+   * MAJOR.MINOR.MAINT, e.g. "2.0.1". The MAJOR version should match the major
+   * version of OpenTSDB the plugin is meant to work with.
+   * @return A version string used to log the loaded version
+   */
+  public abstract String version();
+
+  /**
+   * Should return the version of this plugin in the format:
+   * MAJOR.MINOR.MAINT, e.g. "2.0.1". The MAJOR version should match the major
+   * version of OpenTSDB the plugin is meant to work with.
+   * @return A version string used to log the loaded version
+   */
+  public abstract String getType();
+
+  /**
+   * Called by the TSD when a request for statistics collection has come in. The
+   * implementation may provide one or more statistics. If no statistics are
+   * available for the implementation, simply stub the method.
+   * @param collector The collector used for emitting statistics
+   */
+  public abstract void collectStats(final StatsCollector collector);
+
+}
\ No newline at end of file
diff --git a/src/tools/TSDMain.java b/src/tools/TSDMain.java
index da02826a5f..a5bda860a0 100644
--- a/src/tools/TSDMain.java
+++ b/src/tools/TSDMain.java
@@ -13,10 +13,14 @@
 package net.opentsdb.tools;
 
 import java.io.IOException;
+import java.lang.reflect.Constructor;
+
 import java.net.InetAddress;
 import java.net.InetSocketAddress;
 import java.util.concurrent.Executor;
 import java.util.concurrent.Executors;
+import java.util.HashMap;
+import java.util.Map;
 
 import org.jboss.netty.bootstrap.ServerBootstrap;
 import org.jboss.netty.channel.socket.ServerSocketChannelFactory;
@@ -34,6 +38,8 @@
 import net.opentsdb.tsd.RpcManager;
 import net.opentsdb.utils.Config;
 import net.opentsdb.utils.FileSystem;
+import net.opentsdb.utils.Pair;
+import net.opentsdb.utils.PluginLoader;
 import net.opentsdb.utils.Threads;
 
 /**
@@ -53,6 +59,11 @@ static void usage(final ArgP argp, final String errmsg, final int retval) {
     System.exit(retval);
   }
 
+  /** A map of configured filters for use in querying */
+  private static Map<String, Pair<Class<?>, Constructor<? extends StartupPlugin>>>
+          startupPlugin_filter_map = new HashMap<String,
+          Pair<Class<?>, Constructor<? extends StartupPlugin>>>();
+
   private static final short DEFAULT_FLUSH_INTERVAL = 1000;
   
   private static TSDB tsdb = null;
@@ -80,12 +91,21 @@ public static void main(String[] args) throws IOException {
                    "Number for async io workers (default: cpu * 2).");
     argp.addOption("--async-io", "true|false",
                    "Use async NIO (default true) or traditional blocking io");
+    argp.addOption("--read-only", "true|false",
+                   "Set tsd.mode to ro (default false)");
+    argp.addOption("--disable-ui", "true|false",
+                   "Set tsd.core.enable_ui to false (default true)");
+    argp.addOption("--disable-api", "true|false",
+                   "Set tsd.core.enable_api to false (default true)");
     argp.addOption("--backlog", "NUM",
                    "Size of connection attempt queue (default: 3072 or kernel"
                    + " somaxconn.");
+    argp.addOption("--max-connections", "NUM",
+                   "Maximum number of connections to accept");
     argp.addOption("--flush-interval", "MSEC",
                    "Maximum time for which a new data point can be buffered"
                    + " (default: " + DEFAULT_FLUSH_INTERVAL + ").");
+    argp.addOption("--statswport", "Force all stats to include the port");
     CliOptions.addAutoMetricFlag(argp);
     args = CliOptions.parse(argp, args);
     args = null; // free().
@@ -125,6 +145,12 @@ public static void main(String[] args) throws IOException {
     }
 
     final ServerSocketChannelFactory factory;
+    int connections_limit = 0;
+    try {
+      connections_limit = config.getInt("tsd.core.connections.limit");
+    } catch (NumberFormatException nfe) {
+      usage(argp, "Invalid connections limit", 1);
+    }
     if (config.getBoolean("tsd.network.async_io")) {
       int workers = Runtime.getRuntime().availableProcessors() * 2;
       if (config.hasProperty("tsd.network.worker_threads")) {
@@ -145,9 +171,21 @@ public static void main(String[] args) throws IOException {
           Executors.newCachedThreadPool(), Executors.newCachedThreadPool(), 
           new Threads.PrependThreadNamer());
     }
-    
+
+    StartupPlugin startup = null;
+    try {
+      startup = loadStartupPlugins(config);
+    } catch (IllegalArgumentException e) {
+      usage(argp, e.getMessage(), 3);
+    } catch (Exception e) {
+      throw new RuntimeException("Initialization failed", e);
+    }
+
     try {
       tsdb = new TSDB(config);
+      if (startup != null) {
+        tsdb.setStartupPlugin(startup);
+      }
       tsdb.initializePlugins(true);
       if (config.getBoolean("tsd.storage.hbase.prefetch_meta")) {
         tsdb.preFetchHBaseMeta();
@@ -163,7 +201,7 @@ public static void main(String[] args) throws IOException {
       // here to fail fast.
       final RpcManager manager = RpcManager.instance(tsdb);
 
-      server.setPipelineFactory(new PipelineFactory(tsdb, manager));
+      server.setPipelineFactory(new PipelineFactory(tsdb, manager, connections_limit));
       if (config.hasProperty("tsd.network.backlog")) {
         server.setOption("backlog", config.getInt("tsd.network.backlog")); 
       }
@@ -184,6 +222,9 @@ public static void main(String[] args) throws IOException {
       final InetSocketAddress addr = new InetSocketAddress(bindAddress,
           config.getInt("tsd.network.port"));
       server.bind(addr);
+      if (startup != null) {
+        startup.setReady(tsdb);
+      }
       log.info("Ready to serve on " + addr);
     } catch (Throwable e) {
       factory.releaseExternalResources();
@@ -198,6 +239,45 @@ public static void main(String[] args) throws IOException {
     // The server is now running in separate threads, we can exit main.
   }
 
+  private static StartupPlugin loadStartupPlugins(Config config) {
+    Logger log = LoggerFactory.getLogger(TSDMain.class);
+
+    // load the startup plugin if enabled
+    StartupPlugin startup = null;
+
+    if (config.getBoolean("tsd.startup.enable")) {
+      log.debug("Startup Plugin is Enabled");
+      final String plugin_path = config.getString("tsd.core.plugin_path");
+      final String plugin_class = config.getString("tsd.startup.plugin");
+
+      log.debug("Plugin Path: " + plugin_path);
+      try {
+        TSDB.loadPluginPath(plugin_path);
+      } catch (Exception e) {
+        log.error("Error loading plugins from plugin path: " + plugin_path, e);
+      }
+
+      log.debug("Attempt to Load: " + plugin_class);
+      startup = PluginLoader.loadSpecificPlugin(plugin_class, StartupPlugin.class);
+      if (startup == null) {
+        throw new IllegalArgumentException("Unable to locate startup plugin: " +
+                config.getString("tsd.startup.plugin"));
+      }
+      try {
+        startup.initialize(config);
+      } catch (Exception e) {
+        throw new RuntimeException("Failed to initialize startup plugin", e);
+      }
+      log.info("Successfully initialized startup plugin [" +
+              startup.getClass().getCanonicalName() + "] version: "
+              + startup.version());
+    } else {
+      startup = null;
+    }
+
+    return startup;
+  }
+
   private static void registerShutdownHook() {
     final class TSDBShutdown extends Thread {
       public TSDBShutdown() {
diff --git a/src/tools/TextImporter.java b/src/tools/TextImporter.java
index a8c72ef586..2f33f009be 100644
--- a/src/tools/TextImporter.java
+++ b/src/tools/TextImporter.java
@@ -259,6 +259,10 @@ public String toString() {
    * @throws IOException when shit happens.
    */
   private static BufferedReader open(final String path) throws IOException {
+    if (path.equals("-")) {
+      return new BufferedReader(new InputStreamReader(System.in));
+    }
+
     InputStream is = new FileInputStream(path);
     if (path.endsWith(".gz")) {
       is = new GZIPInputStream(is);
diff --git a/src/tsd/AbstractHttpQuery.java b/src/tsd/AbstractHttpQuery.java
index 967eaab09f..035404a5ad 100644
--- a/src/tsd/AbstractHttpQuery.java
+++ b/src/tsd/AbstractHttpQuery.java
@@ -467,21 +467,37 @@ protected Logger logger() {
     return LOG;
   }
 
+  protected final String logChannel() {
+    if (request.containsHeader("X-Forwarded-For")) {
+        String inetAddress;
+        String proxyChain = request.getHeader("X-Forwarded-For");
+        int firstComma = proxyChain.indexOf(',');
+        if (firstComma != -1) {
+          inetAddress = proxyChain.substring(0, proxyChain.indexOf(','));
+        } else {
+          inetAddress = proxyChain;
+        }
+        return "[id: 0x" + Integer.toHexString(chan.hashCode()) + ", /" + inetAddress + " => " + chan.getLocalAddress() + ']';
+    } else {
+        return chan.toString();
+    }
+  }
+
   protected final void logInfo(final String msg) {
     if (logger().isInfoEnabled()) {
-      logger().info(chan.toString() + ' ' + msg);
+      logger().info(logChannel() + ' ' + msg);
     }
   }
 
   protected final void logWarn(final String msg) {
     if (logger().isWarnEnabled()) {
-      logger().warn(chan.toString() + ' ' + msg);
+      logger().warn(logChannel() + ' ' + msg);
     }
   }
 
   protected final void logError(final String msg, final Exception e) {
     if (logger().isErrorEnabled()) {
-      logger().error(chan.toString() + ' ' + msg, e);
+      logger().error(logChannel() + ' ' + msg, e);
     }
   }
 
diff --git a/src/tsd/ConnectionManager.java b/src/tsd/ConnectionManager.java
index 35c3288bad..902c31315b 100644
--- a/src/tsd/ConnectionManager.java
+++ b/src/tsd/ConnectionManager.java
@@ -14,12 +14,14 @@
 
 import java.io.IOException;
 import java.nio.channels.ClosedChannelException;
+import java.util.concurrent.atomic.AtomicInteger;
 import java.util.concurrent.atomic.AtomicLong;
 
 import org.slf4j.Logger;
 import org.slf4j.LoggerFactory;
 import org.jboss.netty.channel.Channel;
 import org.jboss.netty.channel.ChannelEvent;
+import org.jboss.netty.channel.ChannelException;
 import org.jboss.netty.channel.ChannelHandlerContext;
 import org.jboss.netty.channel.ChannelStateEvent;
 import org.jboss.netty.channel.ExceptionEvent;
@@ -37,10 +39,20 @@ final class ConnectionManager extends SimpleChannelHandler {
   private static final Logger LOG = LoggerFactory.getLogger(ConnectionManager.class);
 
   private static final AtomicLong connections_established = new AtomicLong();
+  private static final AtomicLong connections_rejected = new AtomicLong();
   private static final AtomicLong exceptions_unknown = new AtomicLong();
   private static final AtomicLong exceptions_closed = new AtomicLong();
   private static final AtomicLong exceptions_reset = new AtomicLong();
   private static final AtomicLong exceptions_timeout = new AtomicLong();
+  
+  /** Max connections can be serviced by tsd, if over limit, tsd will refuse 
+   * new connections. */
+  private final int connections_limit;
+  
+  /** A counter used for determining how many channels are open. Something odd
+   * happens with the DefaultChannelGroup in that .size() doesn't return the
+   * actual number of open connections. TODO - find out why. */
+  private final AtomicInteger open_connections = new AtomicInteger();
 
   private static final DefaultChannelGroup channels =
     new DefaultChannelGroup("all-channels");
@@ -49,8 +61,21 @@ static void closeAllConnections() {
     channels.close().awaitUninterruptibly();
   }
 
-  /** Constructor. */
+  /**
+   * Default Ctor with no concurrent connection limit.
+   */
   public ConnectionManager() {
+    connections_limit = 0;
+  }
+  
+  /**
+   * CTor for setting a limit on concurrent connections.
+   * @param connections_limit The maximum number of concurrent connections allowed.
+   * @since 2.3
+   */
+  public ConnectionManager(final int connections_limit) {
+    LOG.info("TSD concurrent connection limit set to: " + connections_limit);
+    this.connections_limit = connections_limit;
   }
 
   /**
@@ -59,6 +84,8 @@ public ConnectionManager() {
    */
   public static void collectStats(final StatsCollector collector) {
     collector.record("connectionmgr.connections", channels.size(), "type=open");
+    collector.record("connectionmgr.connections", connections_rejected,
+        "type=rejected");
     collector.record("connectionmgr.connections", connections_established, 
         "type=total");
     collector.record("connectionmgr.exceptions", exceptions_closed, 
@@ -73,11 +100,25 @@ public static void collectStats(final StatsCollector collector) {
 
   @Override
   public void channelOpen(final ChannelHandlerContext ctx,
-                          final ChannelStateEvent e) {
+                          final ChannelStateEvent e) throws IOException {
+    if (connections_limit > 0) {
+      final int channel_size = open_connections.incrementAndGet();
+      if (channel_size > connections_limit) {
+        throw new ConnectionRefusedException("Channel size (" + channel_size + ") exceeds total "
+            + "connection limit (" + connections_limit + ")");
+        // exceptionCaught will close the connection and increment the counter.
+      }
+    }
     channels.add(e.getChannel());
     connections_established.incrementAndGet();
   }
 
+  @Override
+  public void channelClosed(final ChannelHandlerContext ctx,
+                          final ChannelStateEvent e) throws IOException {
+    open_connections.decrementAndGet();
+  }
+  
   @Override
   public void handleUpstream(final ChannelHandlerContext ctx,
                              final ChannelEvent e) throws Exception {
@@ -109,6 +150,13 @@ public void exceptionCaught(final ChannelHandlerContext ctx,
         // in Java.  Like, people have been bitching about errno for years,
         // and Java managed to do something *far* worse.  That's quite a feat.
         return;
+      } else if (cause instanceof ConnectionRefusedException) {
+        connections_rejected.incrementAndGet();
+        if (LOG.isDebugEnabled()) {
+          LOG.debug("Refusing connection from " + chan, e.getCause());
+        }
+        chan.close();
+        return;
       }
     }
     if (cause instanceof CodecEmbedderException) {
@@ -122,4 +170,17 @@ public void exceptionCaught(final ChannelHandlerContext ctx,
     e.getChannel().close();
   }
 
+  /** Simple exception for refusing a connection. */
+  private static class ConnectionRefusedException extends ChannelException {
+    
+    /**
+     * Default ctor with a message.
+     * @param message A descriptive message for the exception.
+     */
+    public ConnectionRefusedException(final String message) {
+      super(message);
+    }
+
+    private static final long serialVersionUID = 5348377149312597939L;    
+  }
 }
diff --git a/src/tsd/DropCachesRpc.java b/src/tsd/DropCachesRpc.java
new file mode 100644
index 0000000000..9cd59d15e9
--- /dev/null
+++ b/src/tsd/DropCachesRpc.java
@@ -0,0 +1,88 @@
+// This file is part of OpenTSDB.
+// Copyright (C) 2013  The OpenTSDB Authors.
+//
+// This program is free software: you can redistribute it and/or modify it
+// under the terms of the GNU Lesser General Public License as published by
+// the Free Software Foundation, either version 2.1 of the License, or (at your
+// option) any later version.  This program is distributed in the hope that it
+// will be useful, but WITHOUT ANY WARRANTY; without even the implied warranty
+// of MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser
+// General Public License for more details.  You should have received a copy
+// of the GNU Lesser General Public License along with this program.  If not,
+// see <http://www.gnu.org/licenses/>.
+package net.opentsdb.tsd;
+
+import java.io.IOException;
+import java.lang.reflect.Method;
+import java.net.URI;
+import java.util.ArrayList;
+import java.util.Collection;
+import java.util.HashMap;
+import java.util.List;
+import java.util.Map;
+import java.util.concurrent.atomic.AtomicReference;
+import java.util.regex.Pattern;
+
+import com.google.common.annotations.VisibleForTesting;
+import com.google.common.base.Preconditions;
+import com.google.common.base.Splitter;
+import com.google.common.base.Strings;
+import com.google.common.collect.ImmutableList;
+import com.google.common.collect.ImmutableMap;
+import com.google.common.collect.Lists;
+import com.google.common.util.concurrent.Atomics;
+import com.stumbleupon.async.Callback;
+import com.stumbleupon.async.Deferred;
+
+import org.jboss.netty.channel.Channel;
+import org.jboss.netty.handler.codec.http.HttpMethod;
+import org.jboss.netty.handler.codec.http.HttpResponseStatus;
+import org.slf4j.Logger;
+import org.slf4j.LoggerFactory;
+
+import net.opentsdb.tools.BuildData;
+import net.opentsdb.core.Aggregators;
+import net.opentsdb.core.TSDB;
+import net.opentsdb.query.filter.TagVFilter;
+import net.opentsdb.stats.StatsCollector;
+import net.opentsdb.utils.Config;
+import net.opentsdb.utils.JSON;
+import net.opentsdb.utils.PluginLoader;
+
+import java.io.IOException;
+
+/** The "dropcaches" command. */
+public final class DropCachesRpc implements TelnetRpc, HttpRpc {
+    private static final Logger LOG = LoggerFactory.getLogger(DropCachesRpc.class);
+
+    public Deferred<Object> execute(final TSDB tsdb, final Channel chan,
+                                    final String[] cmd) {
+        dropCaches(tsdb, chan);
+        chan.write("Caches dropped.\n");
+        return Deferred.fromResult(null);
+    }
+
+    public void execute(final TSDB tsdb, final HttpQuery query)
+            throws IOException {
+
+        // only accept GET/DELETE
+        RpcUtil.allowedMethods(query.method(), HttpMethod.GET.getName(), HttpMethod.DELETE.getName());
+
+        dropCaches(tsdb, query.channel());
+
+        if (query.apiVersion() > 0) {
+            final HashMap<String, String> response = new HashMap<String, String>();
+            response.put("status", "200");
+            response.put("message", "Caches dropped");
+            query.sendReply(query.serializer().formatDropCachesV1(response));
+        } else { // deprecated API
+            query.sendReply("Caches dropped.\n");
+        }
+    }
+
+    /** Drops in memory caches.  */
+    private void dropCaches(final TSDB tsdb, final Channel chan) {
+        LOG.warn(chan + " Dropping all in-memory caches.");
+        tsdb.dropCaches();
+    }
+}
\ No newline at end of file
diff --git a/src/tsd/HttpJsonSerializer.java b/src/tsd/HttpJsonSerializer.java
index e57acf208a..b29a834bab 100644
--- a/src/tsd/HttpJsonSerializer.java
+++ b/src/tsd/HttpJsonSerializer.java
@@ -193,6 +193,26 @@ public HashMap<String, List<String>> parseUidAssignV1() {
     }
   }
   
+  /**
+   * Parses metric, tagk or tagv, and name to rename UID
+   * @return as hash map of type and name
+   * @throws JSONException if parsing failed
+   * @throws BadRequestException if the content was missing or parsing failed
+   */
+  public HashMap<String, String> parseUidRenameV1() {
+    final String json = query.getContent();
+    if (json == null || json.isEmpty()) {
+      throw new BadRequestException(HttpResponseStatus.BAD_REQUEST,
+          "Missing message content",
+          "Supply valid JSON formatted data in the body of your request");
+    }
+    try {
+      return JSON.parseToObject(json, TR_HASH_MAP);
+    } catch (IllegalArgumentException iae) {
+      throw new BadRequestException("Unable to parse the given JSON", iae);
+    }
+  }
+
   /**
    * Parses a timeseries data query
    * @return A TSQuery with data ready to validate
@@ -534,6 +554,15 @@ public ChannelBuffer formatUidAssignV1(final
     return this.serializeJSON(response);
   }
   
+  /**
+   * Format a response from the Uid Rename RPC
+   * @param response A map of result and error of the rename
+   * @return A JSON structure
+   * @throws JSONException if serialization failed
+   */
+  public ChannelBuffer formatUidRenameV1(final Map<String, String> response) {
+    return this.serializeJSON(response);
+  }
   /**
    * Format the results from a timeseries data query
    * @param data_query The TSQuery object used to fetch the results
diff --git a/src/tsd/HttpQuery.java b/src/tsd/HttpQuery.java
index 7f704fcdad..49c30268d6 100644
--- a/src/tsd/HttpQuery.java
+++ b/src/tsd/HttpQuery.java
@@ -372,8 +372,6 @@ public void internalError(final Exception cause) {
       HttpQuery.escapeJson(pretty_exc, buf);
       buf.append("\"}");
       sendReply(HttpResponseStatus.INTERNAL_SERVER_ERROR, buf);
-    } else if (hasQueryStringParam("png")) {
-      sendAsPNG(HttpResponseStatus.INTERNAL_SERVER_ERROR, pretty_exc, 30);
     } else {
       sendReply(HttpResponseStatus.INTERNAL_SERVER_ERROR,
                 makePage("Internal Server Error", "Houston, we have a problem",
@@ -421,8 +419,6 @@ public void badRequest(final BadRequestException exception) {
       HttpQuery.escapeJson(exception.getMessage(), buf);
       buf.append("\"}");
       sendReply(HttpResponseStatus.BAD_REQUEST, buf);
-    } else if (hasQueryStringParam("png")) {
-      sendAsPNG(HttpResponseStatus.BAD_REQUEST, exception.getMessage(), 3600);
     } else {
       sendReply(HttpResponseStatus.BAD_REQUEST,
                 makePage("Bad Request", "Looks like it's your fault this time",
@@ -456,8 +452,6 @@ public void notFound() {
     if (hasQueryStringParam("json")) {
       sendReply(HttpResponseStatus.NOT_FOUND,
                 new StringBuilder("{\"err\":\"Page Not Found\"}"));
-    } else if (hasQueryStringParam("png")) {
-      sendAsPNG(HttpResponseStatus.NOT_FOUND, "Page Not Found", 3600);
     } else {
       sendReply(HttpResponseStatus.NOT_FOUND, PAGE_NOT_FOUND);
     }
@@ -604,49 +598,6 @@ public void sendReply(final HttpResponseStatus status,
     sendBuffer(status, buf);
   }
 
-  /**
-   * Sends the given message as a PNG image.
-   * <strong>This method will block</strong> while image is being generated.
-   * It's only recommended for cases where we want to report an error back to
-   * the user and the user's browser expects a PNG image.  Don't abuse it.
-   * @param status The status of the request (e.g. 200 OK or 404 Not Found).
-   * @param msg The message to send as an image.
-   * @param max_age The expiration time of this entity, in seconds.  This is
-   * not a timestamp, it's how old the resource is allowed to be in the client
-   * cache.  See RFC 2616 section 14.9 for more information.  Use 0 to disable
-   * caching.
-   */
-  public void sendAsPNG(final HttpResponseStatus status,
-                        final String msg,
-                        final int max_age) {
-    try {
-      final long now = System.currentTimeMillis() / 1000;
-      Plot plot = new Plot(now - 1, now);
-      HashMap<String, String> params = new HashMap<String, String>(1);
-      StringBuilder buf = new StringBuilder(1 + msg.length() + 18);
-
-      buf.append('"');
-      escapeJson(msg, buf);
-      buf.append("\" at graph 0.02,0.97");
-      params.put("label", buf.toString());
-      buf = null;
-      plot.setParams(params);
-      params = null;
-      final String basepath =
-        tsdb.getConfig().getDirectoryName("tsd.http.cachedir")
-        + Integer.toHexString(msg.hashCode());
-      GraphHandler.runGnuplot(this, basepath, plot);
-      plot = null;
-      sendFile(status, basepath + ".png", max_age);
-    } catch (Exception e) {
-      getQueryString().remove("png");  // Avoid recursion.
-      this.sendReply(HttpResponseStatus.INTERNAL_SERVER_ERROR,
-          serializer.formatErrorV1(new RuntimeException(
-              "Failed to generate a PNG with the"
-              + " following message: " + msg, e)));
-    }
-  }
-
   /**
    * Send a file (with zero-copy) to the client with a 200 OK status.
    * This method doesn't provide any security guarantee.  The caller is
diff --git a/src/tsd/HttpSerializer.java b/src/tsd/HttpSerializer.java
index 34adc3e01d..1022177224 100644
--- a/src/tsd/HttpSerializer.java
+++ b/src/tsd/HttpSerializer.java
@@ -198,6 +198,18 @@ public HashMap<String, List<String>> parseUidAssignV1() {
         " has not implemented parseUidAssignV1");
   }
   
+  /**
+   * Parses metrics, tagk or tagvs type and name to rename UID
+   * @return as hash map of type and name
+   * @throws BadRequestException if the plugin has not implemented this method
+   */
+  public HashMap<String, String> parseUidRenameV1() {
+    throw new BadRequestException(HttpResponseStatus.NOT_IMPLEMENTED,
+        "The requested API endpoint has not been implemented",
+        this.getClass().getCanonicalName() +
+        " has not implemented parseUidRenameV1");
+  }
+
   /**
    * Parses a SearchQuery request
    * @return The parsed search query
@@ -443,6 +455,19 @@ public ChannelBuffer formatUidAssignV1(final
         " has not implemented formatUidAssignV1");
   }
   
+  /**
+   * Format a response from the Uid Rename RPC
+   * @param response A map of result and reason for error of the rename
+   * @return A ChannelBuffer object to pass on to the caller
+   * @throws BadRequestException if the plugin has not implemented this method
+   */
+  public ChannelBuffer formatUidRenameV1(final Map<String, String> response) {
+    throw new BadRequestException(HttpResponseStatus.NOT_IMPLEMENTED,
+        "The requested API endpoint has not been implemented",
+        this.getClass().getCanonicalName() +
+        " has not implemented formatUidRenameV1");
+  }
+
   /**
    * Format the results from a timeseries data query
    * @param query The TSQuery object used to fetch the results
diff --git a/src/tsd/PipelineFactory.java b/src/tsd/PipelineFactory.java
index 85f66a7fbd..05414f4491 100644
--- a/src/tsd/PipelineFactory.java
+++ b/src/tsd/PipelineFactory.java
@@ -14,8 +14,6 @@
 
 import static org.jboss.netty.channel.Channels.pipeline;
 
-import java.util.concurrent.ThreadFactory;
-
 import org.jboss.netty.buffer.ChannelBuffer;
 import org.jboss.netty.channel.Channel;
 import org.jboss.netty.channel.ChannelHandler;
@@ -30,7 +28,6 @@
 import org.jboss.netty.handler.codec.http.HttpRequestDecoder;
 import org.jboss.netty.handler.codec.http.HttpResponseEncoder;
 import org.jboss.netty.handler.timeout.IdleStateHandler;
-import org.jboss.netty.util.HashedWheelTimer;
 import org.jboss.netty.util.Timer;
 
 import net.opentsdb.core.TSDB;
@@ -38,6 +35,9 @@
 /**
  * Creates a newly configured {@link ChannelPipeline} for a new channel.
  * This class is supposed to be a singleton.
+ * NOTE: On creation (as of 2.3) the property given in the config for 
+ * "tsd.core.connections.limit" will be used to limit the number of concurrent
+ * connections supported by the pipeline. The default is zero.
  */
 public final class PipelineFactory implements ChannelPipelineFactory {
 
@@ -47,7 +47,7 @@ public final class PipelineFactory implements ChannelPipelineFactory {
 
   // Those are sharable but maintain some state, so a single instance per
   // PipelineFactory is needed.
-  private final ConnectionManager connmgr = new ConnectionManager();
+  private final ConnectionManager connmgr;
   private final DetectHttpOrRpc HTTP_OR_RPC = new DetectHttpOrRpc();
   private final Timer timer;
   private final ChannelHandler timeoutHandler;
@@ -70,7 +70,8 @@ public final class PipelineFactory implements ChannelPipelineFactory {
    * serializers
    */
   public PipelineFactory(final TSDB tsdb) {
-    this(tsdb, RpcManager.instance(tsdb));
+    this(tsdb, RpcManager.instance(tsdb), 
+        tsdb.getConfig().getInt("tsd.core.connections.limit"));
   }
 
   /**
@@ -79,15 +80,32 @@ public PipelineFactory(final TSDB tsdb) {
    * @param tsdb The TSDB to use.
    * @param manager instance of a ready-to-use {@link RpcManager}.
    * @throws RuntimeException if there is an issue loading plugins
-   * @throws Exception if the HttpQuery handler is unable to load 
-   * serializers
+   * @throws Exception if the HttpQuery handler is unable to load serializers
    */
   public PipelineFactory(final TSDB tsdb, final RpcManager manager) {
+    this(tsdb, RpcManager.instance(tsdb), 
+        tsdb.getConfig().getInt("tsd.core.connections.limit"));
+  }
+  
+  /**
+   * Constructor that initializes the RPC router and loads HTTP formatter 
+   * plugins using an already-configured {@link RpcManager}.
+   * @param tsdb The TSDB to use.
+   * @param manager instance of a ready-to-use {@link RpcManager}.
+   * @param connections_limit The maximum number of concurrent connections 
+   * supported by the TSD.
+   * @throws RuntimeException if there is an issue loading plugins
+   * @throws Exception if the HttpQuery handler is unable to load serializers
+   * @since 2.3
+   */
+  public PipelineFactory(final TSDB tsdb, final RpcManager manager, 
+      final int connections_limit) {
     this.tsdb = tsdb;
-    this.socketTimeout = tsdb.getConfig().getInt("tsd.core.socket.timeout");
+    socketTimeout = tsdb.getConfig().getInt("tsd.core.socket.timeout");
     timer = tsdb.getTimer();
-    this.timeoutHandler = new IdleStateHandler(timer, 0, 0, this.socketTimeout);
-    this.rpchandler = new RpcHandler(tsdb, manager);
+    timeoutHandler = new IdleStateHandler(timer, 0, 0, socketTimeout);
+    rpchandler = new RpcHandler(tsdb, manager);
+    connmgr = new ConnectionManager(connections_limit);
     try {
       HttpQuery.initializeSerializerMaps(tsdb);
     } catch (RuntimeException e) {
@@ -153,4 +171,3 @@ protected Object decode(final ChannelHandlerContext ctx,
   }
   
 }
- 
\ No newline at end of file
diff --git a/src/tsd/QueryExecutor.java b/src/tsd/QueryExecutor.java
new file mode 100644
index 0000000000..b0598241e2
--- /dev/null
+++ b/src/tsd/QueryExecutor.java
@@ -0,0 +1,980 @@
+// This file is part of OpenTSDB.
+// Copyright (C) 2010-2016  The OpenTSDB Authors.
+//
+// This program is free software: you can redistribute it and/or modify it
+// under the terms of the GNU Lesser General Public License as published by
+// the Free Software Foundation, either version 2.1 of the License, or (at your
+// option) any later version.  This program is distributed in the hope that it
+// will be useful, but WITHOUT ANY WARRANTY; without even the implied warranty
+// of MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser
+// General Public License for more details.  You should have received a copy
+// of the GNU Lesser General Public License along with this program.  If not,
+// see <http://www.gnu.org/licenses/>.
+package net.opentsdb.tsd;
+
+import java.io.IOException;
+import java.io.OutputStream;
+import java.util.ArrayList;
+import java.util.Collections;
+import java.util.HashMap;
+import java.util.Iterator;
+import java.util.List;
+import java.util.Map;
+import java.util.Map.Entry;
+
+import org.hbase.async.HBaseException;
+import org.hbase.async.RpcTimedOutException;
+import org.jboss.netty.buffer.ChannelBuffer;
+import org.jboss.netty.buffer.ChannelBufferOutputStream;
+import org.jboss.netty.buffer.ChannelBuffers;
+import org.jboss.netty.handler.codec.http.HttpResponseStatus;
+import org.jgrapht.experimental.dag.DirectedAcyclicGraph;
+import org.jgrapht.experimental.dag.DirectedAcyclicGraph.CycleFoundException;
+import org.jgrapht.graph.DefaultEdge;
+import org.jgrapht.traverse.TopologicalOrderIterator;
+import org.slf4j.Logger;
+import org.slf4j.LoggerFactory;
+
+import com.fasterxml.jackson.core.JsonGenerator;
+import com.stumbleupon.async.Callback;
+import com.stumbleupon.async.Deferred;
+import com.stumbleupon.async.DeferredGroupException;
+
+import net.opentsdb.core.DataPoint;
+import net.opentsdb.core.DataPoints;
+import net.opentsdb.core.QueryException;
+import net.opentsdb.core.TSDB;
+import net.opentsdb.core.TSQuery;
+import net.opentsdb.core.TSSubQuery;
+import net.opentsdb.core.Tags;
+import net.opentsdb.query.expression.ExpressionDataPoint;
+import net.opentsdb.query.expression.ExpressionIterator;
+import net.opentsdb.query.expression.NumericFillPolicy;
+import net.opentsdb.query.expression.TimeSyncedIterator;
+import net.opentsdb.query.expression.VariableIterator.SetOperator;
+import net.opentsdb.query.filter.TagVFilter;
+import net.opentsdb.query.pojo.Expression;
+import net.opentsdb.query.pojo.Filter;
+import net.opentsdb.query.pojo.Metric;
+import net.opentsdb.query.pojo.Output;
+import net.opentsdb.query.pojo.Query;
+import net.opentsdb.query.pojo.Timespan;
+import net.opentsdb.stats.QueryStats;
+import net.opentsdb.uid.NoSuchUniqueName;
+import net.opentsdb.uid.UniqueId.UniqueIdType;
+import net.opentsdb.utils.DateTime;
+import net.opentsdb.utils.JSON;
+
+/**
+ * TEMP class for handling V2 queries with expression support. So far we ONLY
+ * support expressions and this will be pipelined better. For now it's functioning
+ * fairly well.
+ * 
+ * So far this sucker allows for expressions and nested expressions with the
+ * ability to determine the output. If no output fields are specified, all 
+ * expressions are dumped to the output. If one or more outputs are given then
+ * only those outputs will be emitted.
+ * 
+ * TODO 
+ * - handle/add output flags to determine whats emitted
+ * - allow for queries only, no expressions
+ * - possibly other set operations
+ * - time over time queries
+ * - skip querying for data that isn't going to be emitted
+ */
+public class QueryExecutor {
+  private static final Logger LOG = LoggerFactory.getLogger(QueryExecutor.class);
+  
+  /** The TSDB to which we belong (and will use for fetching data) */
+  private final TSDB tsdb; 
+  
+  /** The user's query */
+  private final Query query;
+  
+  /** TEMP A v1 TSQuery that we use for fetching the data from HBase */
+  private final TSQuery ts_query;
+  
+  /** A map of the sub queries to their Metric ids */
+  private final Map<String, TSSubQuery> sub_queries;
+  
+  /** A map of the sub query results to their Metric ids */
+  private final Map<String, DataPoints[]> sub_query_results;
+  
+  /** A map of expression iterators to their IDs */
+  private final Map<String, ExpressionIterator> expressions;
+
+  /** A map of Metric fill policies to the metric IDs */
+  private final Map<String, NumericFillPolicy> fills;
+
+  /** The HTTP query from the user */
+  private HttpQuery http_query;
+  
+  /**
+   * Default Ctor that constructs a TSQuery and TSSubQueries from the new 
+   * Query POJO class.
+   * @param tsdb The TSDB to which we belong
+   * @param query The raw query to parse and use for output
+   * @throws IllegalArgumentException if we were unable to parse the Query into
+   * a TSQuery.
+   */
+  public QueryExecutor(final TSDB tsdb, final Query query) {
+    this.tsdb = tsdb;
+    this.query = query;
+    
+    // if metrics is null, this is a bad query
+    sub_queries = new HashMap<String, TSSubQuery>(query.getMetrics().size());
+    sub_query_results = new HashMap<String, DataPoints[]>(
+        query.getMetrics().size());
+    
+    if (query.getExpressions() != null) {
+      expressions = new HashMap<String, ExpressionIterator>(
+          query.getExpressions().size());
+    } else {
+      expressions = null;
+    }
+    
+    final Timespan timespan = query.getTime();
+    
+    // compile the ts_query
+    ts_query = new TSQuery();
+    ts_query.setStart(timespan.getStart());
+    ts_query.setTimezone(timespan.getTimezone());
+    
+    if (timespan.getEnd() != null && !timespan.getEnd().isEmpty()) {
+      ts_query.setEnd(timespan.getEnd());
+    }
+    
+    fills = new HashMap<String, NumericFillPolicy>(query.getMetrics().size());
+    for (final Metric mq : query.getMetrics()) {
+      if (mq.getFillPolicy() != null) {
+        fills.put(mq.getId(), mq.getFillPolicy());
+      }
+      final TSSubQuery sub = new TSSubQuery();
+      sub_queries.put(mq.getId(), sub);
+      
+      sub.setMetric(mq.getMetric());
+
+      if (timespan.getDownsampler() != null) {
+        sub.setDownsample(timespan.getDownsampler().getInterval() + "-" + 
+            timespan.getDownsampler().getAggregator());
+      }
+
+      // filters
+      if (mq.getFilter() != null && !mq.getFilter().isEmpty()) {
+        List<TagVFilter> filters = null;
+        boolean explicit_tags = false;
+        if (query.getFilters() == null || query.getFilters().isEmpty()) {
+          throw new IllegalArgumentException("No filter defined: " + mq.getFilter());
+        }
+        for (final Filter filter : query.getFilters()) {
+          if (filter.getId().equals(mq.getFilter())) {
+            // TODO - it'd be more efficient if we could share the filters but
+            // for now, this is the only way to avoid concurrent modifications.
+            filters = new ArrayList<TagVFilter>(filter.getTags().size());
+            for (final TagVFilter f : filter.getTags()) {
+              filters.add(f.getCopy());
+            }
+            explicit_tags = filter.getExplicitTags();
+            break;
+          }
+        }
+        if (filters != null) {
+          sub.setFilters(filters);
+          sub.setExplicitTags(explicit_tags);
+        }
+      }
+      
+      sub.setRate(timespan.isRate());
+      sub.setAggregator(
+          mq.getAggregator() != null ? mq.getAggregator() : timespan.getAggregator());
+    }
+    
+    final ArrayList<TSSubQuery> subs = 
+        new ArrayList<TSSubQuery>(sub_queries.values()); 
+    ts_query.setQueries(subs);
+    
+    // setup expressions
+    for (final Expression expression : query.getExpressions()) {
+      // TODO - flags
+      
+      // TODO - get a default from the configs
+      final SetOperator operator = expression.getJoin() != null ? 
+          expression.getJoin().getOperator() : SetOperator.UNION;
+      final boolean qts = expression.getJoin() == null ? false : expression.getJoin().getUseQueryTags();
+      final boolean ats = expression.getJoin() == null ? true : expression.getJoin().getIncludeAggTags();
+      final ExpressionIterator iterator = 
+          new ExpressionIterator(expression.getId(), expression.getExpr(), 
+          operator, qts, ats);
+      if (expression.getFillPolicy() != null) {
+        iterator.setFillPolicy(expression.getFillPolicy());
+      }
+      expressions.put(expression.getId(), iterator);
+      
+    }
+
+    ts_query.validateAndSetQuery();
+  }
+
+  /**
+   * Execute the RPC and serialize the response
+   * @param query The HTTP query to parse and and return results to
+   */
+  public void execute(final HttpQuery query) {
+    http_query = query;
+    final QueryStats query_stats = 
+        new QueryStats(query.getRemoteAddress(), ts_query, query.getHeaders());
+    ts_query.setQueryStats(query_stats);
+    
+    /**
+     * Sends the serialized results to the caller. This should be the very
+     * last callback executed.
+     */
+    class CompleteCB implements Callback<Object, ChannelBuffer> {
+      @Override
+      public Object call(final ChannelBuffer cb) throws Exception {
+        query.sendReply(cb);
+        return null;
+      }
+    }
+    
+    /**
+     * After all of the queries have run and we have data (or not) then we
+     * need to compile the iterators.
+     * This class could probably be improved:
+     * First we iterate over the results AND for each result, iterate over
+     * the expressions, giving a time synced iterator to each expression that 
+     * needs the result set.
+     * THEN we iterate over the expressions again and build a DAG to determine
+     * if any of the expressions require the output of an expression. If so
+     * then we add the expressions to the proper parent and compile them in
+     * order.
+     * After all of that we're ready to start serializing and iterating
+     * over the results.
+     */
+    class QueriesCB implements Callback<Object, ArrayList<DataPoints[]>> {
+      public Object call(final ArrayList<DataPoints[]> query_results) 
+        throws Exception {
+        
+        for (int i = 0; i < query_results.size(); i++) {
+          final TSSubQuery sub = ts_query.getQueries().get(i);
+          
+          Iterator<Entry<String, TSSubQuery>> it = sub_queries.entrySet().iterator();
+          while (it.hasNext()) {
+            final Entry<String, TSSubQuery> entry = it.next();
+            if (entry.getValue().equals(sub)) {
+              sub_query_results.put(entry.getKey(), query_results.get(i));
+              for (final ExpressionIterator ei : expressions.values()) {
+                if (ei.getVariableNames().contains(entry.getKey())) {
+                  final TimeSyncedIterator tsi = new TimeSyncedIterator(
+                      entry.getKey(), sub.getFilterTagKs(), 
+                      query_results.get(i));
+                  final NumericFillPolicy fill = fills.get(entry.getKey());
+                  if (fill != null) {
+                    tsi.setFillPolicy(fill);
+                  }
+                  ei.addResults(entry.getKey(), tsi);
+                  if (LOG.isDebugEnabled()) {
+                    LOG.debug("Added results for " + entry.getKey() + 
+                        " to " + ei.getId());
+                  }
+                }
+              }
+            }
+          }
+        }
+
+        // handle nested expressions
+        final DirectedAcyclicGraph<String, DefaultEdge> graph = 
+            new DirectedAcyclicGraph<String, DefaultEdge>(DefaultEdge.class);
+
+        for (final Entry<String, ExpressionIterator> eii : expressions.entrySet()) {
+          if (LOG.isDebugEnabled()) {
+            LOG.debug(String.format("Expression entry key is %s, value is %s", 
+                eii.getKey(), eii.getValue().toString()));
+            LOG.debug(String.format("Time to loop through the variable names "
+                + "for %s", eii.getKey()));
+          }
+
+          if (!graph.containsVertex(eii.getKey())) {
+            if (LOG.isDebugEnabled()) {
+              LOG.debug("Adding vertex " + eii.getKey());
+            }
+            graph.addVertex(eii.getKey());
+          }
+
+          for (final String var : eii.getValue().getVariableNames()) {
+            if (LOG.isDebugEnabled()) {
+              LOG.debug(String.format("var is %s", var));
+            }
+
+            final ExpressionIterator ei = expressions.get(var);
+
+            if (ei != null) {
+              if (LOG.isDebugEnabled()) {
+                LOG.debug(String.format("The expression iterator for %s is %s", 
+                    var, ei.toString()));
+              }
+
+              // TODO - really ought to calculate this earlier
+              if (eii.getKey().equals(var)) {
+                throw new IllegalArgumentException(
+                    "Self referencing expression found: " + eii.getKey());
+              }
+
+              if (LOG.isDebugEnabled()) {
+                LOG.debug("Nested expression detected. " + eii.getKey() + 
+                    " depends on " + var);
+              }
+
+              if (!graph.containsVertex(eii.getKey())) {
+                if (LOG.isDebugEnabled()) {
+                  LOG.debug("Added vertex " + eii.getKey());
+                }
+                graph.addVertex(eii.getKey());
+              } else if (LOG.isDebugEnabled()) {
+                LOG.debug("Already contains vertex " + eii.getKey());
+              }
+
+              if (!graph.containsVertex(var)) {
+                if (LOG.isDebugEnabled()) {
+                  LOG.debug("Added vertex " + var);
+                }
+                graph.addVertex(var);
+              } else if (LOG.isDebugEnabled()) {
+                LOG.debug("Already contains vertex " + var);
+              }
+
+              try {
+                if (LOG.isDebugEnabled()) {
+                  LOG.debug("Added Edge " + eii.getKey() + " - " + var);
+                }
+                graph.addDagEdge(eii.getKey(), var);
+              } catch (CycleFoundException cfe) {
+                throw new IllegalArgumentException("Circular reference found: " + 
+                    eii.getKey(), cfe);
+              }
+            } else if (LOG.isDebugEnabled()) {
+              LOG.debug(String.format("The expression iterator for %s is null", var));
+            }
+          }
+        }
+
+        // compile all of the expressions
+        final long intersect_start = DateTime.currentTimeMillis();
+
+        final Integer expressionLength = expressions.size();
+        final ExpressionIterator[] compile_stack = 
+            new ExpressionIterator[expressionLength];
+        final TopologicalOrderIterator<String, DefaultEdge> it = 
+            new TopologicalOrderIterator<String, DefaultEdge>(graph);
+
+        if (LOG.isDebugEnabled()) {
+          LOG.debug(String.format("Expressions Size is %d", expressionLength));
+          LOG.debug(String.format("Topology Iterator %s", it.toString()));
+        }
+
+        int i = 0;
+        while (it.hasNext()) {
+          String next = it.next();
+          if (LOG.isDebugEnabled()) {
+            LOG.debug(String.format("Expression: %s", next));
+          }
+          ExpressionIterator ei = expressions.get(next);
+          if (LOG.isDebugEnabled()) {
+            LOG.debug(String.format("Expression Iterator: %s", ei.toString()));
+          }
+          if (ei == null) {
+            LOG.error(String.format("The expression iterator for %s is null", next));
+          }
+          compile_stack[i] = ei;
+          if (LOG.isDebugEnabled()) {
+            LOG.debug(String.format("Added expression %s to compile_stack[%d]", 
+                next, i));
+          }
+          i++;
+        }
+
+        if (i != expressionLength) {
+          throw new IOException(String.format(" Internal Error: Fewer "
+              + "expressions where added to the compile stack than "
+              + "expressions.size (%d instead of %d)", i, expressionLength));
+        }
+
+        if (LOG.isDebugEnabled()) {
+          LOG.debug(String.format("compile stack length: %d", compile_stack.length));
+        }
+
+        for (int x = compile_stack.length - 1; x >= 0; x--) {
+          if (compile_stack[x] == null) {
+            throw new NullPointerException(String.format("Item %d in "
+                + "compile_stack[] is null", x));
+          }
+          // look for and add expressions
+          for (final String var : compile_stack[x].getVariableNames()) {
+            if (LOG.isDebugEnabled()) {
+              LOG.debug(String.format("Looking for variable %s for %s", var, 
+                  compile_stack[x].getId()));
+            }
+            ExpressionIterator source = expressions.get(var);
+            if (source != null) {
+              compile_stack[x].addResults(var, source.getCopy());
+              if (LOG.isDebugEnabled()) {
+                LOG.debug(String.format("Adding expression %s to %s", 
+                    source.getId(), compile_stack[x].getId()));
+              }
+            }
+          }
+          compile_stack[x].compile();
+          if (LOG.isDebugEnabled()) {
+            LOG.debug(String.format("Successfully compiled %s", 
+                compile_stack[x].getId()));
+          }
+        }
+
+        if (LOG.isDebugEnabled()) {
+          LOG.debug("Finished compilations in " +
+              (DateTime.currentTimeMillis() - intersect_start) + " ms");
+        }
+        
+        return serialize()
+            .addCallback(new CompleteCB())
+            .addErrback(new ErrorCB());
+      }
+    }
+    
+    /**
+     * Callback executed after we have resolved the metric, tag names and tag
+     * values to their respective UIDs. This callback then runs the actual 
+     * queries and fetches their results.
+     */
+    class BuildCB implements Callback<Deferred<Object>, net.opentsdb.core.Query[]> {
+      @Override
+      public Deferred<Object> call(final net.opentsdb.core.Query[] queries) {
+        final ArrayList<Deferred<DataPoints[]>> deferreds = 
+            new ArrayList<Deferred<DataPoints[]>>(queries.length);
+        
+        for (final net.opentsdb.core.Query query : queries) {
+          deferreds.add(query.runAsync());
+        }
+        return Deferred.groupInOrder(deferreds).addCallback(new QueriesCB())
+            .addErrback(new ErrorCB());
+      }
+    }
+    
+    // TODO - only run the ones that will be involved in an output. Folks WILL
+    // ask for stuff they don't need.... *sigh*
+    ts_query.buildQueriesAsync(tsdb)
+      .addCallback(new BuildCB())
+      .addErrback(new ErrorCB());
+  }
+  
+  /**
+   * Writes the results to a ChannelBuffer to return to the caller. This will
+   * iterate over all of the outputs and drop in meta data where appropriate.
+   * @throws Exception if something went pear shaped
+   */
+  private Deferred<ChannelBuffer> serialize() throws Exception {
+    final long start = System.currentTimeMillis();
+    // buffers and an array list to stored the deferreds
+    final ChannelBuffer response = ChannelBuffers.dynamicBuffer();
+    final OutputStream output_stream = new ChannelBufferOutputStream(response);
+
+    final JsonGenerator json = JSON.getFactory().createGenerator(output_stream);
+    json.writeStartObject();
+    json.writeFieldName("outputs");
+    json.writeStartArray();
+
+    // We want the serializer to execute serially so we need to create a callback
+    // chain so that when one DPsResolver is finished, it triggers the next to
+    // start serializing.
+    final Deferred<Object> cb_chain = new Deferred<Object>();
+
+    // default to the expressions if there, or fall back to the metrics
+    final List<Output> outputs;
+    if (query.getOutputs() == null || query.getOutputs().isEmpty()) {
+      if (query.getExpressions() != null && !query.getExpressions().isEmpty()) {
+        outputs = new ArrayList<Output>(query.getExpressions().size());
+        for (final Expression exp : query.getExpressions()) {
+          outputs.add(Output.Builder().setId(exp.getId()).build());
+        }
+      } else if (query.getMetrics() != null && !query.getMetrics().isEmpty()) {
+        outputs = new ArrayList<Output>(query.getMetrics().size());
+        for (final Metric metric : query.getMetrics()) {
+          outputs.add(Output.Builder().setId(metric.getId()).build());
+        }
+      } else {
+        throw new IllegalArgumentException(
+            "How did we get here?? No metrics or expressions??");
+      }
+    } else {
+      outputs = query.getOutputs();
+    }
+
+    for (final Output output : outputs) {
+      if (expressions != null) {
+        final ExpressionIterator it = expressions.get(output.getId());
+        if (it != null) {
+          cb_chain.addCallback(new SerializeExpressionIterator(tsdb, json, 
+              output, it, ts_query));
+          continue;
+        }
+      }
+
+      if (query.getMetrics() != null && !query.getMetrics().isEmpty()) {
+        final TSSubQuery sub = sub_queries.get(output.getId());
+        if (sub != null) {
+          final TimeSyncedIterator it = new TimeSyncedIterator(output.getId(), 
+              sub.getFilterTagKs(), sub_query_results.get(output.getId()));
+          cb_chain.addCallback(new SerializeSubIterator(tsdb, json, output, it));
+          continue;
+        }
+      } else {
+        LOG.warn("Couldn't find a variable matching: " + output.getId() + 
+            " in query " + query);
+      }
+    }
+  
+    /** Final callback to close out the JSON array and return our results */
+    class FinalCB implements Callback<ChannelBuffer, Object> {
+      public ChannelBuffer call(final Object obj)
+          throws Exception {
+        json.writeEndArray();
+        
+//        ts_query.getQueryStats().setTimeSerialization(
+//            DateTime.currentTimeMillis() - start);
+        ts_query.getQueryStats().markSerializationSuccessful();
+
+        // dump overall stats as an extra object in the array
+//        if (true) {
+//          final QueryStats stats = ts_query.getQueryStats();
+//          json.writeFieldName("statsSummary");
+//          json.writeStartObject();
+//          //json.writeStringField("hostname", TSDB.getHostname());
+//          //json.writeNumberField("runningQueries", stats.getNumRunningQueries());
+//          json.writeNumberField("datapoints", stats.getAggregatedSize());
+//          json.writeNumberField("rawDatapoints", stats.getSize());
+//          //json.writeNumberField("rowsFetched", stats.getRowsFetched());
+//          json.writeNumberField("aggregationTime", stats.getTimeAggregation());
+//          json.writeNumberField("serializationTime", stats.getTimeSerialization());
+//          json.writeNumberField("storageTime", stats.getTimeStorage());
+//          json.writeNumberField("timeTotal", 
+//              ((double)stats.getTimeTotal() / (double)1000000));
+//          json.writeEndObject();
+//        }
+        
+        // dump the original query
+        if (true) {
+          json.writeFieldName("query");
+          json.writeObject(QueryExecutor.this.query);
+        }
+        // IMPORTANT Make sure the close the JSON array and the generator
+        json.writeEndObject();
+        json.close();
+        return response;
+      }
+    }
+
+    // trigger the callback chain here
+    cb_chain.callback(null);
+    return cb_chain.addCallback(new FinalCB());
+  }
+  
+  /** This has to be attached to callbacks or we may never respond to clients */
+  class ErrorCB implements Callback<Object, Exception> {
+    public Object call(final Exception e) throws Exception {
+      QueryRpc.query_exceptions.incrementAndGet();
+      Throwable ex = e;
+      try {
+        LOG.error("Query exception: ", e);
+        if (e instanceof DeferredGroupException) {
+          ex = e.getCause();
+          while (ex != null && ex instanceof DeferredGroupException) {
+            ex = ex.getCause();
+          }
+          if (ex == null) {
+            LOG.error("The deferred group exception didn't have a cause???");
+          }
+        }
+        if (ex instanceof RpcTimedOutException) {
+          QueryExecutor.this.http_query.badRequest(new BadRequestException(
+              HttpResponseStatus.REQUEST_TIMEOUT, ex.getMessage()));
+        } else if (ex instanceof HBaseException) {
+          QueryExecutor.this.http_query.badRequest(new BadRequestException(
+              HttpResponseStatus.FAILED_DEPENDENCY, ex.getMessage()));
+        } else if (ex instanceof QueryException) {
+          QueryExecutor.this.http_query.badRequest(new BadRequestException(
+              ((QueryException)ex).getStatus(), ex.getMessage()));
+        } else if (ex instanceof BadRequestException) {
+          QueryExecutor.this.http_query.badRequest((BadRequestException)ex);
+        } else if (ex instanceof NoSuchUniqueName) {
+          QueryExecutor.this.http_query.badRequest(new BadRequestException(ex));
+        } else {
+          QueryExecutor.this.http_query.badRequest(new BadRequestException(ex));
+        }
+        
+      } catch (RuntimeException ex2) {
+        LOG.error("Exception thrown during exception handling", ex2);
+        QueryExecutor.this.http_query.sendReply
+          (HttpResponseStatus.INTERNAL_SERVER_ERROR, ex2.getMessage().getBytes());
+      }
+      return null;
+    }
+  }
+  
+  /**
+   * Handles serializing the output of an expression iterator
+   */
+  private class SerializeExpressionIterator 
+    implements Callback<Deferred<Object>, Object> {
+    final TSDB tsdb;
+    final JsonGenerator json;
+    final Output output;
+    final ExpressionIterator iterator;
+    final ExpressionDataPoint[] dps;
+    final TSQuery query;
+
+    // WARNING: Make sure to write an endObject() before triggering this guy
+    final Deferred<Object> completed;
+    
+    /**
+     * The default ctor to setup the serializer
+     * @param tsdb The TSDB to use for name resolution
+     * @param json The JSON generator to write to
+     * @param output The Output spec associated with this expression
+     * @param iterator The iterator to run through
+     * @param query The original TSQuery
+     */
+    public SerializeExpressionIterator(final TSDB tsdb, final JsonGenerator json, 
+        final Output output, final ExpressionIterator iterator, final TSQuery query) {
+      this.tsdb = tsdb;
+      this.json = json;
+      this.output = output;
+      this.iterator = iterator;
+      this.query = query;
+      dps = iterator.values();
+      completed = new Deferred<Object>();
+    }
+
+    /** Super simple closer that tells the upstream chain we're done with this */
+    class MetaCB implements Callback<Object, Object> {
+      @Override
+      public Object call(final Object ignored) throws Exception {
+        completed.callback(null);
+        return completed;
+      }
+    }
+    
+    @Override
+    public Deferred<Object> call(final Object ignored) throws Exception {
+      //result set opening
+      json.writeStartObject();
+      
+      json.writeStringField("id", output.getId());
+      if (output.getAlias() != null) {
+        json.writeStringField("alias", output.getAlias());
+      }
+      json.writeFieldName("dps");
+      json.writeStartArray();
+      
+      long first_ts = Long.MIN_VALUE;
+      long last_ts = 0;
+      long count = 0;
+      long ts = iterator.nextTimestamp();
+      long qs = query.startTime();
+      long qe = query.endTime();
+      while (iterator.hasNext()) {
+        iterator.next(ts);
+        
+        long timestamp = dps[0].timestamp();
+        if (timestamp >= qs && timestamp <= qe) {
+          json.writeStartArray();
+          if (dps.length > 0) {
+            json.writeNumber(timestamp);
+            if (first_ts == Long.MIN_VALUE) {
+              first_ts = timestamp;
+            } else {
+              last_ts = timestamp;
+            }
+            ++count;
+          }
+          for (int i = 0; i < dps.length; i++) {
+            json.writeNumber(dps[i].toDouble());
+          }
+          
+          json.writeEndArray();
+        }
+        ts = iterator.nextTimestamp();
+      }
+      json.writeEndArray();
+      
+      // data points meta
+      json.writeFieldName("dpsMeta");
+      json.writeStartObject();
+      json.writeNumberField("firstTimestamp", first_ts < 0 ? 0 : first_ts);
+      json.writeNumberField("lastTimestamp", last_ts);
+      json.writeNumberField("setCount", count);
+      json.writeNumberField("series", dps.length);
+      json.writeEndObject();
+      
+      // resolve meta LAST since we may not even need it
+      if (dps.length > 0) {
+        final MetaSerializer meta_serializer = 
+            new MetaSerializer(tsdb, json, iterator.values());
+        meta_serializer.call(null).addCallback(new MetaCB())
+          .addErrback(QueryExecutor.this.new ErrorCB());
+      } else {
+        // done, not dumping any more info
+        json.writeEndObject();
+        //json.writeEndArray();
+        completed.callback(null);
+      }
+      
+      return completed;
+    }
+    
+  }
+  
+  /**
+   * Serializes a raw, non expression result set.
+   */
+  private class SerializeSubIterator implements 
+    Callback<Deferred<Object>, Object> {
+    final TSDB tsdb;
+    final JsonGenerator json;
+    final Output output;
+    final TimeSyncedIterator iterator;
+    
+    // WARNING: Make sure to write an endObject() before triggering this guy
+    final Deferred<Object> completed;
+    
+    public SerializeSubIterator(final TSDB tsdb, final JsonGenerator json, 
+        final Output output, final TimeSyncedIterator iterator) {
+      this.tsdb = tsdb;
+      this.json = json;
+      this.output = output;
+      this.iterator = iterator;
+      completed = new Deferred<Object>();
+    }
+    
+    class MetaCB implements Callback<Object, Object> {
+      @Override
+      public Object call(final Object ignored) throws Exception {
+        completed.callback(null);
+        return completed;
+      }
+    }
+    
+    @Override
+    public Deferred<Object> call(final Object ignored) throws Exception {
+      //result set opening
+      json.writeStartObject();
+      
+      json.writeStringField("id", output.getId());
+      if (output.getAlias() != null) {
+        json.writeStringField("alias", output.getAlias());
+      }
+      json.writeFieldName("dps");
+      json.writeStartArray();
+      
+      final long first_ts = iterator.nextTimestamp();
+      long ts = first_ts;
+      long last_ts = 0;
+      long count = 0;
+      final DataPoint[] dps = iterator.values();
+      while (iterator.hasNext()) {
+        iterator.next(ts);
+        json.writeStartArray();
+        
+        if (dps.length > 0) {
+          json.writeNumber(dps[0].timestamp());
+          last_ts = dps[0].timestamp();
+          ++count;
+        }
+        for (int i = 0; i < dps.length; i++) {
+          json.writeNumber(dps[i].toDouble());
+        }
+        
+        json.writeEndArray();
+        ts = iterator.nextTimestamp();
+      }
+      json.writeEndArray();
+      
+      // data points meta
+      json.writeFieldName("dpsMeta");
+      json.writeStartObject();
+      json.writeNumberField("firstTimestamp", first_ts);
+      json.writeNumberField("lastTimestamp", last_ts);
+      json.writeNumberField("setCount", count);
+      json.writeNumberField("series", dps.length);
+      json.writeEndObject();
+      
+      // resolve meta LAST since we may not even need it
+      if (dps.length > 0) {
+        final DataPoints[] odps = iterator.getDataPoints();
+        final ExpressionDataPoint[] edps = new ExpressionDataPoint[dps.length];
+        for (int i = 0; i < dps.length; i++) {
+          edps[i] = new ExpressionDataPoint(odps[i]);
+        }
+        final MetaSerializer meta_serializer = 
+            new MetaSerializer(tsdb, json, edps);
+        meta_serializer.call(null).addCallback(new MetaCB());
+      } else {
+        // done, not dumping any more info
+        json.writeEndObject();
+        completed.callback(null);
+      }
+      
+      return completed;
+    }
+    
+  }
+  
+  /**
+   * Handles resolving metrics, tags, aggregated tags and other meta data 
+   * associated with a result set.
+   */
+  private class MetaSerializer implements Callback<Deferred<Object>, Object> {
+    final TSDB tsdb;
+    final JsonGenerator json;
+    final ExpressionDataPoint[] dps;
+    final List<String> metrics;
+    final Map<String, String>[] tags;
+    final List<String>[] agg_tags;
+
+    final Deferred<Object> completed;
+    
+    @SuppressWarnings("unchecked")
+    public MetaSerializer(final TSDB tsdb, final JsonGenerator json, 
+        final ExpressionDataPoint[] dps) {
+      this.tsdb = tsdb;
+      this.json = json;
+      this.dps = dps;
+      completed = new Deferred<Object>();
+      metrics = new ArrayList<String>();
+      tags = new Map[dps.length];
+      agg_tags = new List[dps.length];
+    }
+    
+    class MetricsCB implements Callback<Object, ArrayList<String>> {
+      @Override
+      public Object call(final ArrayList<String> names) throws Exception {
+        metrics.addAll(names);
+        Collections.sort(metrics);
+        return null;
+      }
+    }
+    
+    class AggTagsCB implements Callback<Object, ArrayList<String>> {
+      final int index;
+      public AggTagsCB(final int index) {
+        this.index = index;
+      }
+      @Override
+      public Object call(final ArrayList<String> tags) throws Exception {
+        agg_tags[index] = tags;
+        return null;
+      }
+    }
+    
+    class TagsCB implements Callback<Object, Map<String, String>> {
+      final int index;
+      public TagsCB(final int index) {
+        this.index = index;
+      }
+      @Override
+      public Object call(final Map<String, String> tags) throws Exception {
+        MetaSerializer.this.tags[index] = tags;
+        return null;
+      }
+    }
+    
+    class MetaCB implements Callback<Object, ArrayList<Object>> {
+      @Override
+      public Object call(final ArrayList<Object> ignored) throws Exception {
+        json.writeFieldName("meta");
+        json.writeStartArray();
+        
+        // first field is the timestamp
+        json.writeStartObject();
+        json.writeNumberField("index", 0);
+        json.writeFieldName("metrics");
+        json.writeStartArray();
+        json.writeString("timestamp");
+        json.writeEndArray();
+        json.writeEndObject();
+        
+        for (int i = 0; i < dps.length; i++) {
+          json.writeStartObject();
+          
+          json.writeNumberField("index", i + 1);
+          json.writeFieldName("metrics");
+          json.writeObject(metrics);
+          
+          json.writeFieldName("commonTags");
+          if (tags[i] == null) {
+            json.writeObject(Collections.emptyMap());
+          } else {
+            json.writeObject(tags[i]);
+          }
+          
+          json.writeFieldName("aggregatedTags");
+          if (agg_tags[i] == null) {
+            json.writeObject(Collections.emptyList());
+          } else {
+            json.writeObject(agg_tags[i]);
+          }
+          
+          // TODO restore when we can calculate size efficiently
+          //json.writeNumberField("dps", dps[i].size());
+          //json.writeNumberField("rawDps", dps[i].rawSize());
+          
+          json.writeEndObject();
+        }
+        
+        json.writeEndArray();
+
+        // all done with this series of results
+        json.writeEndObject();
+        completed.callback(null);
+        return null;
+      }
+    }
+    
+    @Override
+    public Deferred<Object> call(final Object ignored) throws Exception {
+      final List<Deferred<Object>> deferreds = 
+          new ArrayList<Deferred<Object>>();
+      
+      final List<Deferred<String>> metric_deferreds = 
+          new ArrayList<Deferred<String>>(dps[0].metricUIDs().size());
+      
+      for (final byte[] uid : dps[0].metricUIDs()) {
+        metric_deferreds.add(tsdb.getUidName(UniqueIdType.METRIC, uid));
+      }
+      
+      deferreds.add(Deferred.group(metric_deferreds)
+          .addCallback(new MetricsCB()));
+      
+      for (int i = 0; i < dps.length; i++) {
+        if (dps[i].aggregatedTags().size() > 0) {
+          final List<Deferred<String>> agg_deferreds =
+              new ArrayList<Deferred<String>>(dps[i].aggregatedTags().size());
+          for (final byte[] uid : dps[i].aggregatedTags()) {
+            agg_deferreds.add(tsdb.getUidName(UniqueIdType.TAGK, uid));
+          }
+          deferreds.add(Deferred.group(agg_deferreds)
+              .addCallback(new AggTagsCB(i)));
+        }
+        
+        deferreds.add(Tags.getTagsAsync(tsdb, dps[i].tags())
+            .addCallback(new TagsCB(i)));
+      }
+      
+      Deferred.groupInOrder(deferreds).addCallback(new MetaCB())
+        .addErrback(QueryExecutor.this.new ErrorCB());
+      return completed;
+    }
+    
+  }
+
+}
diff --git a/src/tsd/QueryRpc.java b/src/tsd/QueryRpc.java
index 40c80a7e05..2f6d92be24 100644
--- a/src/tsd/QueryRpc.java
+++ b/src/tsd/QueryRpc.java
@@ -45,12 +45,15 @@
 import net.opentsdb.core.Tags;
 import net.opentsdb.meta.Annotation;
 import net.opentsdb.meta.TSUIDQuery;
+import net.opentsdb.query.expression.ExpressionTree;
+import net.opentsdb.query.expression.Expressions;
 import net.opentsdb.query.filter.TagVFilter;
 import net.opentsdb.stats.QueryStats;
 import net.opentsdb.stats.StatsCollector;
 import net.opentsdb.uid.NoSuchUniqueName;
 import net.opentsdb.uid.UniqueId;
 import net.opentsdb.utils.DateTime;
+import net.opentsdb.utils.JSON;
 
 /**
  * Handles queries for timeseries datapoints. Each request is parsed into a
@@ -99,8 +102,13 @@ public void execute(final TSDB tsdb, final HttpQuery query)
     
     if (endpoint.toLowerCase().equals("last")) {
       handleLastDataPointQuery(tsdb, query);
+    } else if (endpoint.toLowerCase().equals("gexp")){
+      handleQuery(tsdb, query, true);
+    } else if (endpoint.toLowerCase().equals("exp")) {
+      handleExpressionQuery(tsdb, query);
+      return;
     } else {
-      handleQuery(tsdb, query);
+      handleQuery(tsdb, query, false);
     }
   }
 
@@ -108,10 +116,14 @@ public void execute(final TSDB tsdb, final HttpQuery query)
    * Processing for a data point query
    * @param tsdb The TSDB to which we belong
    * @param query The HTTP query to parse/respond
+   * @param allow_expressions Whether or not expressions should be parsed
+   * (based on the endpoint)
    */
-  private void handleQuery(final TSDB tsdb, final HttpQuery query) {
+  private void handleQuery(final TSDB tsdb, final HttpQuery query, 
+      final boolean allow_expressions) {
     final long start = DateTime.currentTimeMillis();
     final TSQuery data_query;
+    final List<ExpressionTree> expressions;
     if (query.method() == HttpMethod.POST) {
       switch (query.apiVersion()) {
       case 0:
@@ -124,8 +136,10 @@ private void handleQuery(final TSDB tsdb, final HttpQuery query) {
             "Requested API version not implemented", "Version " + 
             query.apiVersion() + " is not implemented");
       }
+      expressions = null;
     } else {
-      data_query = parseQuery(tsdb, query);
+      expressions = new ArrayList<ExpressionTree>();
+      data_query = parseQuery(tsdb, query, expressions);
     }
     
     if (query.getAPIMethod() == HttpMethod.DELETE &&
@@ -217,8 +231,20 @@ public Object call(final Exception e) throws Exception {
     class QueriesCB implements Callback<Object, ArrayList<DataPoints[]>> {
       public Object call(final ArrayList<DataPoints[]> query_results) 
         throws Exception {
-        results.addAll(query_results);
-
+        if (allow_expressions) {
+          // process each of the expressions into a new list, then merge it
+          // with the original. This avoids possible recursion loops.
+          final List<DataPoints[]> expression_results = 
+              new ArrayList<DataPoints[]>(expressions.size());
+          // let exceptions bubble up
+          for (final ExpressionTree expression : expressions) {
+            expression_results.add(expression.evaluate(query_results));
+          }
+          results.addAll(expression_results);
+        } else {
+          results.addAll(query_results);
+        }
+        
         /** Simply returns the buffer once serialization is complete and logs it */
         class SendIt implements Callback<Object, ChannelBuffer> {
           public Object call(final ChannelBuffer buffer) throws Exception {
@@ -282,6 +308,20 @@ public Object call(final List<Annotation> annotations) throws Exception {
     }
   }
   
+  /**
+   * Handles an expression query
+   * @param tsdb The TSDB to which we belong
+   * @param query The HTTP query to parse/respond
+   * @since 2.3
+   */
+  private void handleExpressionQuery(final TSDB tsdb, final HttpQuery query) {
+    final net.opentsdb.query.pojo.Query v2_query = 
+        JSON.parseToObject(query.getContent(), net.opentsdb.query.pojo.Query.class);
+    v2_query.validate();
+    final QueryExecutor executor = new QueryExecutor(tsdb, v2_query);
+    executor.execute(query);
+  }
+  
   /**
    * Processes a last data point query
    * @param tsdb The TSDB to which we belong
@@ -460,8 +500,24 @@ public String toString() {
    * @param query The HTTP Query for parsing
    * @return A TSQuery if parsing was successful
    * @throws BadRequestException if parsing was unsuccessful
+   * @since 2.3
    */
   public static TSQuery parseQuery(final TSDB tsdb, final HttpQuery query) {
+    return parseQuery(tsdb, query, null);
+  }
+  
+  /**
+   * Parses a query string legacy style query from the URI
+   * @param tsdb The TSDB we belong to
+   * @param query The HTTP Query for parsing
+   * @param expressions A list of parsed expression trees filled from the URI.
+   * If this is null, it means any expressions in the URI will be skipped.
+   * @return A TSQuery if parsing was successful
+   * @throws BadRequestException if parsing was unsuccessful
+   * @since 2.3
+   */
+  public static TSQuery parseQuery(final TSDB tsdb, final HttpQuery query,
+      final List<ExpressionTree> expressions) {
     final TSQuery data_query = new TSQuery();
     
     data_query.setStart(query.getRequiredQueryStringParam("start"));
@@ -514,6 +570,30 @@ public static TSQuery parseQuery(final TSDB tsdb, final HttpQuery query) {
       }
     }
     
+    // TODO - testing out the graphite style expressions here with the "exp" 
+    // param that could stand for experimental or expression ;)
+    if (expressions != null) {
+      if (query.hasQueryStringParam("exp")) {
+        final List<String> uri_expressions = query.getQueryStringParams("exp");
+        final List<String> metric_queries = new ArrayList<String>(
+            uri_expressions.size());
+        // parse the expressions into their trees. If one or more expressions 
+        // are improper then it will toss an exception up
+        expressions.addAll(Expressions.parseExpressions(
+            uri_expressions, data_query, metric_queries));
+        // iterate over each of the parsed metric queries and store it in the
+        // TSQuery list so that we fetch the data for them.
+        for (final String mq: metric_queries) {
+          parseMTypeSubQuery(mq, data_query);
+        }
+      }
+    } else {
+      if (LOG.isDebugEnabled()) {
+        LOG.debug("Received a request with an expression but at the "
+            + "wrong endpoint: " + query);
+      }
+    }
+    
     if (data_query.getQueries() == null || data_query.getQueries().size() < 1) {
       throw new BadRequestException("Missing sub queries");
     }
@@ -563,6 +643,8 @@ private static void parseMTypeSubQuery(final String query_string,
         }
       } else if (Character.isDigit(parts[x].charAt(0))) {
         sub_query.setDownsample(parts[x]);
+      } else if (parts[x].toLowerCase().startsWith("explicit_tags")) {
+        sub_query.setExplicitTags(true);
       }
     }
     
diff --git a/src/tsd/RpcManager.java b/src/tsd/RpcManager.java
index 61ff738dfe..86638c1a12 100644
--- a/src/tsd/RpcManager.java
+++ b/src/tsd/RpcManager.java
@@ -52,36 +52,36 @@
 /**
  * Manager for the lifecycle of <code>HttpRpc</code>s, <code>TelnetRpc</code>s,
  * <code>RpcPlugin</code>s, and <code>HttpRpcPlugin</code>.  This is a
- * singleton.  Its lifecycle must be managed by the "container".  If you are 
- * launching via {@code TSDMain} then shutdown (and non-lazy initialization) 
+ * singleton.  Its lifecycle must be managed by the "container".  If you are
+ * launching via {@code TSDMain} then shutdown (and non-lazy initialization)
  * is taken care of. Outside of the use of {@code TSDMain}, you are responsible
  * for shutdown, at least.
- * 
+ *
  * <p> Here's an example of how to correctly handle shutdown manually:
- * 
+ *
  * <pre>
  * // Startup our TSDB instance...
  * TSDB tsdb_instance = ...;
- * 
+ *
  * // ... later, during shtudown ..
- * 
+ *
  * if (RpcManager.isInitialized()) {
  *   // Check that its actually been initialized.  We don't want to
  *   // create a new instance only to shutdown!
  *   RpcManager.instance(tsdb_instance).shutdown().join();
  * }
  * </pre>
- * 
+ *
  * @since 2.2
  */
 public final class RpcManager {
   private static final Logger LOG = LoggerFactory.getLogger(RpcManager.class);
-  
+
   /** This is base path where {@link HttpRpcPlugin}s are rooted.  It's used
    * to match incoming requests. */
   @VisibleForTesting
   protected static final String PLUGIN_BASE_WEBPATH = "plugin";
-  
+
   /** Splitter for web paths.  Removes empty strings to handle trailing or
    * leading slashes.  For instance, all of <code>/plugin/mytest</code>,
    * <code>plugin/mytest/</code>, and <code>plugin/mytest</code> will be
@@ -89,13 +89,13 @@ public final class RpcManager {
   private static final Splitter WEBPATH_SPLITTER = Splitter.on('/')
       .trimResults()
       .omitEmptyStrings();
-  
+
   /** Matches paths declared by {@link HttpRpcPlugin}s that are rooted in
    * the system's plugins path. */
   private static final Pattern HAS_PLUGIN_BASE_WEBPATH = Pattern.compile(
-      "^/?" + PLUGIN_BASE_WEBPATH + "/?.*", 
+      "^/?" + PLUGIN_BASE_WEBPATH + "/?.*",
       Pattern.CASE_INSENSITIVE | Pattern.DOTALL);
-  
+
   /** Reference to our singleton instance.  Set in {@link #initialize}. */
   private static final AtomicReference<RpcManager> INSTANCE = Atomics.newReference();
 
@@ -107,10 +107,10 @@ public final class RpcManager {
   private ImmutableMap<String, HttpRpcPlugin> http_plugin_commands;
   /** List of activated RPC plugins */
   private ImmutableList<RpcPlugin> rpc_plugins;
-  
+
   /** The TSDB that owns us. */
   private TSDB tsdb;
-  
+
   /**
    * Constructor used by singleton factory method.
    * @param tsdb the owning TSDB instance.
@@ -118,7 +118,7 @@ public final class RpcManager {
   private RpcManager(final TSDB tsdb) {
     this.tsdb = tsdb;
   }
-  
+
   /**
    * Get or create the singleton instance of the manager, loading all the
    * plugins enabled in the given TSDB's {@link Config}.
@@ -133,9 +133,9 @@ public static synchronized RpcManager instance(final TSDB tsdb) {
 
     final RpcManager manager = new RpcManager(tsdb);
     final String mode = Strings.nullToEmpty(tsdb.getConfig().getString("tsd.mode"));
-    
+
     // Load any plugins that are enabled via Config.  Fail if any plugin cannot be loaded.
-  
+
     final ImmutableList.Builder<RpcPlugin> rpcBuilder = ImmutableList.builder();
     if (tsdb.getConfig().hasProperty("tsd.rpc.plugins")) {
       final String[] plugins = tsdb.getConfig().getString("tsd.rpc.plugins").split(",");
@@ -155,13 +155,13 @@ public static synchronized RpcManager instance(final TSDB tsdb) {
       manager.initializeHttpRpcPlugins(mode, plugins, httpPluginsBuilder);
     }
     manager.http_plugin_commands = httpPluginsBuilder.build();
-    
+
     INSTANCE.set(manager);
     return manager;
   }
-  
+
   /**
-   * @return {@code true} if the shared instance has been initialized; 
+   * @return {@code true} if the shared instance has been initialized;
    * {@code false} otherwise.
    */
   public static synchronized boolean isInitialized() {
@@ -169,17 +169,17 @@ public static synchronized boolean isInitialized() {
   }
 
   /**
-   * @return list of loaded {@link RpcPlugin}s.  Possibly empty but 
+   * @return list of loaded {@link RpcPlugin}s.  Possibly empty but
    * never {@code null}.
    */
   @VisibleForTesting
   protected ImmutableList<RpcPlugin> getRpcPlugins() {
     return rpc_plugins;
   }
-  
+
   /**
    * Lookup a {@link TelnetRpc} based on given command name.  Note that this
-   * lookup is case sensitive in that the {@code command} passed in must 
+   * lookup is case sensitive in that the {@code command} passed in must
    * match a registered RPC command exactly.
    * @param command a telnet API command name.
    * @return the {@link TelnetRpc} for the given {@code command} or {@code null}
@@ -188,36 +188,36 @@ protected ImmutableList<RpcPlugin> getRpcPlugins() {
   TelnetRpc lookupTelnetRpc(final String command) {
     return telnet_commands.get(command);
   }
-  
+
   /**
    * Lookup a built-in {@link HttpRpc} based on the given {@code queryBaseRoute}.
    * The lookup is based on exact match of the input parameter and the registered
    * {@link HttpRpc}s.
-   * @param queryBaseRoute the HTTP query's base route, with no trailing or 
+   * @param queryBaseRoute the HTTP query's base route, with no trailing or
    * leading slashes.  For example: {@code api/query}
-   * @return the {@link HttpRpc} for the given {@code queryBaseRoute} or 
+   * @return the {@link HttpRpc} for the given {@code queryBaseRoute} or
    * {@code null} if not found.
    */
   HttpRpc lookupHttpRpc(final String queryBaseRoute) {
     return http_commands.get(queryBaseRoute);
   }
-  
+
   /**
-   * Lookup a user-supplied {@link HttpRpcPlugin} for the given 
-   * {@code queryBaseRoute}. The lookup is based on exact match of the input 
+   * Lookup a user-supplied {@link HttpRpcPlugin} for the given
+   * {@code queryBaseRoute}. The lookup is based on exact match of the input
    * parameter and the registered {@link HttpRpcPlugin}s.
    * @param queryBaseRoute the value of {@link HttpRpcPlugin#getPath()} with no
    * trailing or leading slashes.
-   * @return the {@link HttpRpcPlugin} for the given {@code queryBaseRoute} or 
+   * @return the {@link HttpRpcPlugin} for the given {@code queryBaseRoute} or
    * {@code null} if not found.
    */
   HttpRpcPlugin lookupHttpRpcPlugin(final String queryBaseRoute) {
     return http_plugin_commands.get(queryBaseRoute);
   }
-  
+
   /**
    * @param uri HTTP request URI, with or without query parameters.
-   * @return {@code true} if the URI represents a request for a 
+   * @return {@code true} if the URI represents a request for a
    * {@link HttpRpcPlugin}; {@code false} otherwise.  Note that this
    * method returning true <strong>says nothing</strong> about
    * whether or not there is a {@link HttpRpcPlugin} registered
@@ -233,12 +233,12 @@ boolean isHttpRpcPluginPath(final String uri) {
       if (qmark != -1) {
         path = uri.substring(0, qmark);
       }
-      
+
       final List<String> parts = WEBPATH_SPLITTER.splitToList(path);
       return (parts.size() > 1 && parts.get(0).equals(PLUGIN_BASE_WEBPATH));
     }
   }
-  
+
   /**
    * Load and init instances of {@link TelnetRpc}s and {@link HttpRpc}s.
    * These are not generally configurable via TSDB config.
@@ -248,67 +248,75 @@ boolean isHttpRpcPluginPath(final String uri) {
    * instances.
    * @param http a map of API endpoints to {@link HttpRpc} instances.
    */
-  private void initializeBuiltinRpcs(final String mode, 
+  private void initializeBuiltinRpcs(final String mode,
         final ImmutableMap.Builder<String, TelnetRpc> telnet,
         final ImmutableMap.Builder<String, HttpRpc> http) {
+
+    final Boolean enableApi = tsdb.getConfig().getString("tsd.core.enable_api").equals("true");
+    final Boolean enableUi = tsdb.getConfig().getString("tsd.core.enable_ui").equals("true");
+    final Boolean enableDieDieDie = tsdb.getConfig().getString("tsd.no_diediedie").equals("false");
+
+    LOG.info("Mode: {}, HTTP UI Enabled: {}, HTTP API Enabled: {}", mode, enableUi, enableApi);
+
     if (mode.equals("rw") || mode.equals("wo")) {
       final PutDataPointRpc put = new PutDataPointRpc();
       telnet.put("put", put);
-      http.put("api/put", put);
+      if (enableApi) {
+        http.put("api/put", put);
+      }
     }
-    
+
     if (mode.equals("rw") || mode.equals("ro")) {
-      http.put("", new HomePage());
       final StaticFileRpc staticfile = new StaticFileRpc();
-      http.put("favicon.ico", staticfile);
-      http.put("s", staticfile);
-
       final StatsRpc stats = new StatsRpc();
-      telnet.put("stats", stats);
-      http.put("stats", stats);
-      http.put("api/stats", stats);
+      final DropCachesRpc dropcaches = new DropCachesRpc();
+      final ListAggregators aggregators = new ListAggregators();
+      final SuggestRpc suggest_rpc = new SuggestRpc();
+      final AnnotationRpc annotation_rpc = new AnnotationRpc();
+      final Version version = new Version();
 
-      final DropCaches dropcaches = new DropCaches();
+      telnet.put("stats", stats);
       telnet.put("dropcaches", dropcaches);
-      http.put("dropcaches", dropcaches);
-      http.put("api/dropcaches", dropcaches);
+      telnet.put("version", version);
+      telnet.put("exit", new Exit());
+      telnet.put("help", new Help());
 
-      final ListAggregators aggregators = new ListAggregators();
-      http.put("aggregators", aggregators);
-      http.put("api/aggregators", aggregators);
+      if (enableUi) {
+        http.put("", new HomePage());
+        http.put("aggregators", aggregators);
+        http.put("dropcaches", dropcaches);
+        http.put("favicon.ico", staticfile);
+        http.put("logs", new LogsRpc());
+        http.put("q", new GraphHandler());
+        http.put("s", staticfile);
+        http.put("stats", stats);
+        http.put("suggest", suggest_rpc);
+        http.put("version", version);
+      }
 
-      final SuggestRpc suggest_rpc = new SuggestRpc();
-      http.put("suggest", suggest_rpc);
-      http.put("api/suggest", suggest_rpc);
-
-      http.put("logs", new LogsRpc());
-      http.put("q", new GraphHandler());
-      http.put("api/serializers", new Serializers());
-      http.put("api/uid", new UniqueIdRpc());
-      http.put("api/query", new QueryRpc());
-      http.put("api/tree", new TreeRpc());
-      {
-        final AnnotationRpc annotation_rpc = new AnnotationRpc();
+      if (enableApi) {
+        http.put("api/aggregators", aggregators);
         http.put("api/annotation", annotation_rpc);
         http.put("api/annotations", annotation_rpc);
-      }
-      http.put("api/search", new SearchRpc());
-      http.put("api/config", new ShowConfig());
-      
-      if (tsdb.getConfig().getString("tsd.no_diediedie").equals("false")) {
-        final DieDieDie diediedie = new DieDieDie();
-        telnet.put("diediedie", diediedie);
-        http.put("diediedie", diediedie);
-      }
-      {
-        final Version version = new Version();
-        telnet.put("version", version);
-        http.put("version", version);
+        http.put("api/config", new ShowConfig());
+        http.put("api/dropcaches", dropcaches);
+        http.put("api/query", new QueryRpc());
+        http.put("api/search", new SearchRpc());
+        http.put("api/serializers", new Serializers());
+        http.put("api/stats", stats);
+        http.put("api/suggest", suggest_rpc);
+        http.put("api/tree", new TreeRpc());
+        http.put("api/uid", new UniqueIdRpc());
         http.put("api/version", version);
       }
+    }
 
-      telnet.put("exit", new Exit());
-      telnet.put("help", new Help());
+    if (enableDieDieDie) {
+      final DieDieDie diediedie = new DieDieDie();
+      telnet.put("diediedie", diediedie);
+      if (enableUi) {
+        http.put("diediedie", diediedie);
+      }
     }
   }
 
@@ -317,10 +325,10 @@ private void initializeBuiltinRpcs(final String mode,
    * {@code pluginClassNames}.
    * @param mode is this TSD in read/write ("rw") or read-only ("ro")
    * mode?
-   * @param pluginClassNames fully-qualified class names that are 
+   * @param pluginClassNames fully-qualified class names that are
    * instances of {@link HttpRpcPlugin}s
-   * @param http a map of canonicalized paths 
-   * (obtained via {@link #canonicalizePluginPath(String)}) 
+   * @param http a map of canonicalized paths
+   * (obtained via {@link #canonicalizePluginPath(String)})
    * to {@link HttpRpcPlugin} instance.
    */
   @VisibleForTesting
@@ -338,7 +346,7 @@ protected void initializeHttpRpcPlugins(final String mode,
   }
 
   /**
-   * Ensure that the given path for an {@link HttpRpcPlugin} is valid.  This 
+   * Ensure that the given path for an {@link HttpRpcPlugin} is valid.  This
    * method simply returns for valid inputs; throws and exception otherwise.
    * @param path a request path, no query parameters, etc.
    * @throws IllegalArgumentException on invalid paths.
@@ -349,9 +357,9 @@ protected void validateHttpRpcPluginPath(final String path) {
         "Invalid HttpRpcPlugin path. Path is null or empty.");
     final String testPath = path.trim();
     Preconditions.checkArgument(!HAS_PLUGIN_BASE_WEBPATH.matcher(path).matches(),
-        "Invalid HttpRpcPlugin path %s. Path contains system's plugin base path.", 
+        "Invalid HttpRpcPlugin path %s. Path contains system's plugin base path.",
         testPath);
-    
+
     URI uri = URI.create(testPath);
     Preconditions.checkArgument(!Strings.isNullOrEmpty(uri.getPath()),
         "Invalid HttpRpcPlugin path %s. Parsed path is null or empty.", testPath);
@@ -384,18 +392,18 @@ protected String canonicalizePluginPath(final String origPath) {
   /**
    * Load and init the {@link RpcPlugin}s provided as an array of
    * {@code pluginClassNames}.
-   * @param pluginClassNames fully-qualified class names that are 
+   * @param pluginClassNames fully-qualified class names that are
    * instances of {@link RpcPlugin}s
    * @param rpcs a list of loaded and initialized plugins
    */
-  private void initializeRpcPlugins(final String[] pluginClassNames, 
+  private void initializeRpcPlugins(final String[] pluginClassNames,
         final ImmutableList.Builder<RpcPlugin> rpcs) {
     for (final String plugin : pluginClassNames) {
       final RpcPlugin rpc = createAndInitialize(plugin, RpcPlugin.class);
       rpcs.add(rpc);
     }
   }
-  
+
   /**
    * Helper method to load and initialize a given plugin class. This uses reflection
    * because plugins share no common interfaces. (They could though!)
@@ -406,7 +414,7 @@ private void initializeRpcPlugins(final String[] pluginClassNames,
   @VisibleForTesting
   protected <T> T createAndInitialize(final String pluginClassName, final Class<T> pluginClass) {
     final T instance = PluginLoader.loadSpecificPlugin(pluginClassName, pluginClass);
-    Preconditions.checkState(instance != null, 
+    Preconditions.checkState(instance != null,
         "Unable to locate %s using name '%s", pluginClass, pluginClassName);
     try {
       final Method initMeth = instance.getClass().getMethod("initialize", TSDB.class);
@@ -421,9 +429,9 @@ protected <T> T createAndInitialize(final String pluginClassName, final Class<T>
       throw new RuntimeException("Failed to initialize " + instance.getClass(), e);
     }
   }
-  
+
   /**
-   * Called to gracefully shutdown the plugin. Implementations should close 
+   * Called to gracefully shutdown the plugin. Implementations should close
    * any IO they have open
    * @return A deferred object that indicates the completion of the request.
    * The {@link Object} has not special meaning and can be {@code null}
@@ -434,22 +442,22 @@ public Deferred<ArrayList<Object>> shutdown() {
     INSTANCE.set(null);
 
     final Collection<Deferred<Object>> deferreds = Lists.newArrayList();
-    
+
     if (http_plugin_commands != null) {
       for (final Map.Entry<String, HttpRpcPlugin> entry : http_plugin_commands.entrySet()) {
         deferreds.add(entry.getValue().shutdown());
       }
     }
-    
+
     if (rpc_plugins != null) {
       for (final RpcPlugin rpc : rpc_plugins) {
         deferreds.add(rpc.shutdown());
       }
     }
-    
+
     return Deferred.groupInOrder(deferreds);
   }
-  
+
   /**
    * Collect stats on the shared instance of {@link RpcManager}.
    */
@@ -470,7 +478,7 @@ static void collectStats(final StatsCollector collector) {
       if (manager.http_plugin_commands != null) {
         try {
           collector.addExtraTag("plugin", "httprpc");
-          for (final Map.Entry<String, HttpRpcPlugin> entry 
+          for (final Map.Entry<String, HttpRpcPlugin> entry
               : manager.http_plugin_commands.entrySet()) {
             entry.getValue().collectStats(collector);
           }
@@ -480,7 +488,7 @@ static void collectStats(final StatsCollector collector) {
       }
     }
   }
-  
+
   // ---------------------------- //
   // Individual command handlers. //
   // ---------------------------- //
@@ -557,7 +565,7 @@ public Deferred<Object> execute(final TSDB tsdb, final Channel chan,
 
   /** The home page ("GET /"). */
   private static final class HomePage implements HttpRpc {
-    public void execute(final TSDB tsdb, final HttpQuery query) 
+    public void execute(final TSDB tsdb, final HttpQuery query)
       throws IOException {
       final StringBuilder buf = new StringBuilder(2048);
       buf.append("<div id=queryuimain></div>"
@@ -571,19 +579,15 @@ public void execute(final TSDB tsdb, final HttpQuery query)
         "OpenTSDB", "", buf.toString()));
     }
   }
-  
+
   /** The "/aggregators" endpoint. */
   private static final class ListAggregators implements HttpRpc {
-    public void execute(final TSDB tsdb, final HttpQuery query) 
+    public void execute(final TSDB tsdb, final HttpQuery query)
       throws IOException {
-      
-      // only accept GET/POST
-      if (query.method() != HttpMethod.GET && query.method() != HttpMethod.POST) {
-        throw new BadRequestException(HttpResponseStatus.METHOD_NOT_ALLOWED, 
-            "Method not allowed", "The HTTP method [" + query.method().getName() +
-            "] is not permitted for this endpoint");
-      }
-      
+
+      // only accept GET / POST
+      RpcUtil.allowedMethods(query.method(), HttpMethod.GET.getName(), HttpMethod.POST.getName());
+
       if (query.apiVersion() > 0) {
         query.sendReply(
             query.serializer().formatAggregatorsV1(Aggregators.set()));
@@ -604,16 +608,12 @@ public Deferred<Object> execute(final TSDB tsdb, final Channel chan,
       return Deferred.fromResult(null);
     }
 
-    public void execute(final TSDB tsdb, final HttpQuery query) throws 
+    public void execute(final TSDB tsdb, final HttpQuery query) throws
       IOException {
-      
-      // only accept GET/POST
-      if (query.method() != HttpMethod.GET && query.method() != HttpMethod.POST) {
-        throw new BadRequestException(HttpResponseStatus.METHOD_NOT_ALLOWED, 
-            "Method not allowed", "The HTTP method [" + query.method().getName() +
-            "] is not permitted for this endpoint");
-      }
-      
+
+      // only accept GET / POST
+      RpcUtil.allowedMethods(query.method(), HttpMethod.GET.getName(), HttpMethod.POST.getName());
+
       final HashMap<String, String> version = new HashMap<String, String>();
       version.put("version", BuildData.version);
       version.put("short_revision", BuildData.short_revision);
@@ -623,11 +623,12 @@ public void execute(final TSDB tsdb, final HttpQuery query) throws
       version.put("user", BuildData.user);
       version.put("host", BuildData.host);
       version.put("repo", BuildData.repo);
-      
+      version.put("branch", BuildData.branch);
+
       if (query.apiVersion() > 0) {
         query.sendReply(query.serializer().formatVersionV1(version));
       } else {
-        final boolean json = query.request().getUri().endsWith("json");      
+        final boolean json = query.request().getUri().endsWith("json");
         if (json) {
           query.sendReply(JSON.serializeToBytes(version));
         } else {
@@ -642,82 +643,37 @@ public void execute(final TSDB tsdb, final HttpQuery query) throws
       }
     }
   }
-  
-  /** The "dropcaches" command. */
-  private static final class DropCaches implements TelnetRpc, HttpRpc {
-    public Deferred<Object> execute(final TSDB tsdb, final Channel chan,
-                                    final String[] cmd) {
-      dropCaches(tsdb, chan);
-      chan.write("Caches dropped.\n");
-      return Deferred.fromResult(null);
-    }
-
-    public void execute(final TSDB tsdb, final HttpQuery query) 
-      throws IOException {
-      dropCaches(tsdb, query.channel());
-      
-      // only accept GET/POST
-      if (query.method() != HttpMethod.GET && query.method() != HttpMethod.POST) {
-        throw new BadRequestException(HttpResponseStatus.METHOD_NOT_ALLOWED, 
-            "Method not allowed", "The HTTP method [" + query.method().getName() +
-            "] is not permitted for this endpoint");
-      }
-      
-      if (query.apiVersion() > 0) {
-        final HashMap<String, String> response = new HashMap<String, String>();
-        response.put("status", "200");
-        response.put("message", "Caches dropped");
-        query.sendReply(query.serializer().formatDropCachesV1(response));
-      } else { // deprecated API
-        query.sendReply("Caches dropped.\n");
-      }
-    }
-
-    /** Drops in memory caches.  */
-    private void dropCaches(final TSDB tsdb, final Channel chan) {
-      LOG.warn(chan + " Dropping all in-memory caches.");
-      tsdb.dropCaches();
-    }
-  }
 
-  /** The /api/formatters endpoint 
+  /** The /api/formatters endpoint
    * @since 2.0 */
   private static final class Serializers implements HttpRpc {
-    public void execute(final TSDB tsdb, final HttpQuery query) 
+    public void execute(final TSDB tsdb, final HttpQuery query)
       throws IOException {
-      // only accept GET/POST
-      if (query.method() != HttpMethod.GET && query.method() != HttpMethod.POST) {
-        throw new BadRequestException(HttpResponseStatus.METHOD_NOT_ALLOWED, 
-            "Method not allowed", "The HTTP method [" + query.method().getName() +
-            "] is not permitted for this endpoint");
-      }
-      
+      // only accept GET / POST
+      RpcUtil.allowedMethods(query.method(), HttpMethod.GET.getName(), HttpMethod.POST.getName());
+
       switch (query.apiVersion()) {
         case 0:
         case 1:
           query.sendReply(query.serializer().formatSerializersV1());
           break;
-        default: 
-          throw new BadRequestException(HttpResponseStatus.NOT_IMPLEMENTED, 
-              "Requested API version not implemented", "Version " + 
+        default:
+          throw new BadRequestException(HttpResponseStatus.NOT_IMPLEMENTED,
+              "Requested API version not implemented", "Version " +
               query.apiVersion() + " is not implemented");
       }
     }
   }
-  
+
   private static final class ShowConfig implements HttpRpc {
     @Override
     public void execute(TSDB tsdb, HttpQuery query) throws IOException {
       // only accept GET/POST
-      if (query.method() != HttpMethod.GET && query.method() != HttpMethod.POST) {
-        throw new BadRequestException(HttpResponseStatus.METHOD_NOT_ALLOWED, 
-            "Method not allowed", "The HTTP method [" + query.method().getName() +
-            "] is not permitted for this endpoint");
-      }
-      
+      RpcUtil.allowedMethods(query.method(), HttpMethod.GET.getName(), HttpMethod.POST.getName());
+
       final String[] uri = query.explodeAPIPath();
       final String endpoint = uri.length > 1 ? uri[1].toLowerCase() : "";
-      
+
       if (endpoint.equals("filters")) {
         switch (query.apiVersion()) {
         case 0:
@@ -725,9 +681,9 @@ public void execute(TSDB tsdb, HttpQuery query) throws IOException {
           query.sendReply(query.serializer().formatFilterConfigV1(
               TagVFilter.loadedFilters()));
           break;
-        default: 
-          throw new BadRequestException(HttpResponseStatus.NOT_IMPLEMENTED, 
-              "Requested API version not implemented", "Version " + 
+        default:
+          throw new BadRequestException(HttpResponseStatus.NOT_IMPLEMENTED,
+              "Requested API version not implemented", "Version " +
               query.apiVersion() + " is not implemented");
         }
       } else {
@@ -736,9 +692,9 @@ public void execute(TSDB tsdb, HttpQuery query) throws IOException {
           case 1:
             query.sendReply(query.serializer().formatConfigV1(tsdb.getConfig()));
             break;
-          default: 
-            throw new BadRequestException(HttpResponseStatus.NOT_IMPLEMENTED, 
-                "Requested API version not implemented", "Version " + 
+          default:
+            throw new BadRequestException(HttpResponseStatus.NOT_IMPLEMENTED,
+                "Requested API version not implemented", "Version " +
                 query.apiVersion() + " is not implemented");
         }
       }
diff --git a/src/tsd/RpcUtil.java b/src/tsd/RpcUtil.java
new file mode 100644
index 0000000000..07660e208f
--- /dev/null
+++ b/src/tsd/RpcUtil.java
@@ -0,0 +1,37 @@
+// This file is part of OpenTSDB.
+// Copyright (C) 2010-2014  The OpenTSDB Authors.
+//
+// This program is free software: you can redistribute it and/or modify it
+// under the terms of the GNU Lesser General Public License as published by
+// the Free Software Foundation, either version 2.1 of the License, or (at your
+// option) any later version.  This program is distributed in the hope that it
+// will be useful, but WITHOUT ANY WARRANTY; without even the implied warranty
+// of MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser
+// General Public License for more details.  You should have received a copy
+// of the GNU Lesser General Public License along with this program.  If not,
+// see <http://www.gnu.org/licenses/>.
+package net.opentsdb.tsd;
+
+import org.jboss.netty.handler.codec.http.HttpMethod;
+import org.jboss.netty.handler.codec.http.HttpResponseStatus;
+import org.slf4j.Logger;
+import org.slf4j.LoggerFactory;
+
+import java.util.List;
+
+public class RpcUtil {
+
+    private static final Logger LOG = LoggerFactory.getLogger(RpcUtil.class);
+
+    public static void allowedMethods(HttpMethod requestMethod, String... allowedMethods) {
+        for(String method : allowedMethods) {
+            LOG.debug(String.format("Trying Method: %s", method));
+            if (requestMethod.getName() == method) {
+                LOG.debug(String.format("Method Allowed: %s", method));
+                return;
+            }
+        }
+        throw new BadRequestException(HttpResponseStatus.METHOD_NOT_ALLOWED,
+                "Method not allowed", "The HTTP method [" + requestMethod.getName() + "] is not permitted for this endpoint");
+    }
+}
diff --git a/src/tsd/UniqueIdRpc.java b/src/tsd/UniqueIdRpc.java
index 60ff461341..a9057866f8 100644
--- a/src/tsd/UniqueIdRpc.java
+++ b/src/tsd/UniqueIdRpc.java
@@ -63,6 +63,9 @@ public void execute(TSDB tsdb, HttpQuery query) throws IOException {
     } else if (endpoint.toLowerCase().equals("tsmeta")) {
       this.handleTSMeta(tsdb, query);
       return;
+    } else if (endpoint.toLowerCase().equals("rename")) {
+      this.handleRename(tsdb, query);
+      return;
     } else {
       throw new BadRequestException(HttpResponseStatus.NOT_IMPLEMENTED, 
           "Other UID endpoints have not been implemented yet");
@@ -478,6 +481,70 @@ private UIDMeta parseUIDMetaQS(final HttpQuery query) {
     return meta;
   }
   
+  /**
+   * Rename UID to a new name of the given metric, tagk or tagv names
+   * <p>
+   * This handler supports GET and POST whereby the GET command can parse query
+   * strings with the {@code type} and {@code name} as their parameters.
+   * <p>
+   * @param tsdb The TSDB from the RPC router
+   * @param query The query for this request
+   */
+  private void handleRename(final TSDB tsdb, final HttpQuery query) {
+    // only accept GET and POST
+    if (query.method() != HttpMethod.GET && query.method() != HttpMethod.POST) {
+      throw new BadRequestException(HttpResponseStatus.METHOD_NOT_ALLOWED,
+          "Method not allowed", "The HTTP method[" + query.method().getName() +
+          "] is not permitted for this endpoint");
+    }
+
+    final HashMap<String, String> source;
+    if (query.method() == HttpMethod.POST) {
+      source = query.serializer().parseUidRenameV1();
+    } else {
+      source = new HashMap<String, String>(3);
+      final String[] types = {"metric", "tagk", "tagv", "name"};
+      for (int i = 0; i < types.length; i++) {
+        final String value = query.getQueryStringParam(types[i]);
+        if (value!= null && !value.isEmpty()) {
+          source.put(types[i], value);
+        }
+      }
+    }
+    String type = null;
+    String oldname = null;
+    String newname = null;
+    for (Map.Entry<String, String> entry : source.entrySet()) {
+      if (entry.getKey().equals("name")) {
+        newname = entry.getValue();
+      } else {
+        type = entry.getKey();
+        oldname = entry.getValue();
+      }
+    }
+
+    // we need a type/value and new name
+    if (type == null || oldname == null || newname == null) {
+      throw new BadRequestException("Missing necessary values to rename UID");
+    }
+
+    HashMap<String, String> response = new HashMap<String, String>(2);
+    try {
+      tsdb.renameUid(type, oldname, newname);
+      response.put("result", "true");
+    } catch (IllegalArgumentException e) {
+      response.put("result", "false");
+      response.put("error", e.getMessage());
+    }
+
+    if (!response.containsKey("error")) {
+      query.sendReply(query.serializer().formatUidRenameV1(response));
+    } else {
+      query.sendReply(HttpResponseStatus.BAD_REQUEST,
+          query.serializer().formatUidRenameV1(response));
+    }
+  }
+
   /**
    * Used with verb overrides to parse out values from a query string
    * @param query The query to parse
diff --git a/src/tsd/client/QueryUi.java b/src/tsd/client/QueryUi.java
index e81a50ac70..23e4952c1c 100644
--- a/src/tsd/client/QueryUi.java
+++ b/src/tsd/client/QueryUi.java
@@ -138,6 +138,7 @@ public class QueryUi implements EntryPoint, HistoryListener {
   private final ValidatedTextBox yformat = new ValidatedTextBox();
   private final ValidatedTextBox y2format = new ValidatedTextBox();
   private final ValidatedTextBox wxh = new ValidatedTextBox();
+  private final CheckBox global_annotations = new CheckBox("Global annotations");
 
   private String keypos = "";  // Position of the key on the graph.
   private final CheckBox horizontalkey = new CheckBox("Horizontal layout");
@@ -290,6 +291,8 @@ public void onValueChange(final ValueChangeEvent<Date> event) {
     y2format.addKeyPressHandler(refreshgraph);
     wxh.addBlurHandler(refreshgraph);
     wxh.addKeyPressHandler(refreshgraph);
+    global_annotations.addBlurHandler(refreshgraph);
+    global_annotations.addKeyPressHandler(refreshgraph);
     horizontalkey.addClickHandler(refreshgraph);
     keybox.addClickHandler(refreshgraph);
     nokey.addClickHandler(refreshgraph);
@@ -382,6 +385,11 @@ public void onValueChange(final ValueChangeEvent<Boolean> event) {
       hbox.add(wxh);
       table.setWidget(0, 3, hbox);
     }
+    {
+      final HorizontalPanel hbox = new HorizontalPanel();
+      hbox.add(global_annotations);
+      table.setWidget(0, 4, hbox);
+    }
     {
       addMetricForm("metric 1", 0);
       metrics.selectTab(0);
@@ -408,6 +416,7 @@ public void onBeforeSelection(final BeforeSelectionEvent<Integer> event) {
     optpanel.add(makeStylePanel(), "Style");
     optpanel.selectTab(0);
     table.setWidget(1, 3, optpanel);
+    table.getFlexCellFormatter().setColSpan(1, 3, 2);
 
     final DecoratorPanel decorator = new DecoratorPanel();
     decorator.setWidget(table);
@@ -789,6 +798,7 @@ private void refreshFromQueryString() {
     maybeSetTextbox(qs, "start", start_datebox.getTextBox());
     maybeSetTextbox(qs, "end", end_datebox.getTextBox());
     setTextbox(qs, "wxh", wxh);
+    global_annotations.setValue(qs.containsKey("global_annotations"));
     autoreload.setValue(qs.containsKey("autoreload"), true);
     maybeSetTextbox(qs, "autoreload", autoreoload_interval);
 
@@ -908,6 +918,9 @@ private void refreshGraph() {
       // a special parameter that the server will delete from the query.
       url.append("&ignore=" + nrequests++);
     }
+    if (global_annotations.getValue()) {
+      url.append("&global_annotations");
+    }
 
     if(timezone.length() > 1)
       url.append("&tz=").append(timezone);
diff --git a/src/uid/FailedToAssignUniqueIdException.java b/src/uid/FailedToAssignUniqueIdException.java
index 7ffa1a999d..fb79e6355c 100644
--- a/src/uid/FailedToAssignUniqueIdException.java
+++ b/src/uid/FailedToAssignUniqueIdException.java
@@ -28,6 +28,23 @@ public FailedToAssignUniqueIdException(final String kind, final String name,
     this.attempts = attempts;
   }
 
+  /**
+   * CTor
+   * @param kind The kind of object that couldn't be assigned
+   * @param name The name of the object that couldn't be assigned
+   * @param attempts How many attempts were made to assign
+   * @param msg A message to append
+   * @since 2.3
+   */
+  public FailedToAssignUniqueIdException(final String kind, final String name, 
+      final int attempts, final String msg) {
+    super("Failed to assign ID for kind='" + kind + "' name='" + 
+      name + "' after " + attempts + " attempts due to: " + msg);
+    this.kind = kind;
+    this.name = name;
+    this.attempts = attempts;
+  }
+  
   /**
    * CTor
    * @param kind The kind of object that couldn't be assigned
@@ -44,6 +61,7 @@ public FailedToAssignUniqueIdException(final String kind, final String name,
     this.attempts = attempts;
   }
   
+  
   /** @return Returns the kind of unique ID that couldn't be assigned.  */
   public String kind() {
     return kind;
diff --git a/src/uid/UniqueId.java b/src/uid/UniqueId.java
index e94c988648..22a384fc82 100644
--- a/src/uid/UniqueId.java
+++ b/src/uid/UniqueId.java
@@ -15,10 +15,13 @@
 import java.nio.charset.Charset;
 import java.util.ArrayList;
 import java.util.Arrays;
+import java.util.Collections;
 import java.util.HashMap;
+import java.util.HashSet;
 import java.util.LinkedList;
 import java.util.List;
 import java.util.Map;
+import java.util.Set;
 import java.util.concurrent.ConcurrentHashMap;
 
 import javax.xml.bind.DatatypeConverter;
@@ -104,6 +107,9 @@ public enum UniqueIdType {
   /** Map of pending UID assignments */
   private final HashMap<String, Deferred<byte[]>> pending_assignments =
     new HashMap<String, Deferred<byte[]>>();
+  /** Set of UID rename */
+  private final Set<String> renaming_id_names =
+    Collections.synchronizedSet(new HashSet<String>());
 
   /** Number of times we avoided reading from HBase thanks to the cache. */
   private volatile int cache_hits;
@@ -112,8 +118,10 @@ public enum UniqueIdType {
   /** How many times we collided with an existing ID when attempting to 
    * generate a new UID */
   private volatile int random_id_collisions;
-
-  /** Whether or not to generate new UIDMetas */
+  /** How many times assignments have been rejected by the UID filter */
+  private volatile int rejected_assignments;
+  
+  /** TSDB object used for filtering and/or meta generation. */
   private TSDB tsdb;
   
   /**
@@ -156,6 +164,34 @@ public UniqueId(final HBaseClient client, final byte[] table, final String kind,
     this.id_width = (short) width;
     this.randomize_id = randomize_id;
   }
+  
+  /**
+   * Constructor.
+   * @param tsdb The TSDB this UID object belongs to
+   * @param table The name of the HBase table to use.
+   * @param kind The kind of Unique ID this instance will deal with.
+   * @param width The number of bytes on which Unique IDs should be encoded.
+   * @param Whether or not to randomize new UIDs
+   * @throws IllegalArgumentException if width is negative or too small/large
+   * or if kind is an empty string.
+   * @since 2.3
+   */
+  public UniqueId(final TSDB tsdb, final byte[] table, final String kind,
+                  final int width, final boolean randomize_id) {
+    this.client = tsdb.getClient();
+    this.tsdb = tsdb;
+    this.table = table;
+    if (kind.isEmpty()) {
+      throw new IllegalArgumentException("Empty string as 'kind' argument!");
+    }
+    this.kind = toBytes(kind);
+    type = stringToUniqueIdType(kind);
+    if (width < 1 || width > 8) {
+      throw new IllegalArgumentException("Invalid width: " + width);
+    }
+    this.id_width = (short) width;
+    this.randomize_id = randomize_id;
+  }
 
   /** The number of times we avoided reading from HBase thanks to the cache. */
   public int cacheHits() {
@@ -177,6 +213,11 @@ public int randomIdCollisions() {
     return random_id_collisions;
   }
   
+  /** Returns the number of UID assignments rejected by the filter */
+  public int rejectedAssignments() {
+    return rejected_assignments;
+  }
+  
   public String kind() {
     return fromBytes(kind);
   }
@@ -631,6 +672,25 @@ public byte[] getOrCreateId(final String name) throws HBaseException {
     try {
       return getIdAsync(name).joinUninterruptibly();
     } catch (NoSuchUniqueName e) {
+      if (tsdb != null && tsdb.getUidFilter() != null && 
+          tsdb.getUidFilter().fillterUIDAssignments()) {
+        try {
+          if (!tsdb.getUidFilter().allowUIDAssignment(type, name, null, null)
+                .join()) {
+            rejected_assignments++;
+            throw new FailedToAssignUniqueIdException(new String(kind), name, 0, 
+                "Blocked by UID filter.");
+          }
+        } catch (FailedToAssignUniqueIdException e1) {
+          throw e1;
+        } catch (InterruptedException e1) {
+          LOG.error("Interrupted", e1);
+          Thread.currentThread().interrupt();
+        } catch (Exception e1) {
+          throw new RuntimeException("Should never be here", e1);
+        }
+      }
+      
       Deferred<byte[]> assignment = null;
       boolean pending = false;
       synchronized (pending_assignments) {
@@ -677,7 +737,7 @@ public byte[] getOrCreateId(final String name) throws HBaseException {
       throw new RuntimeException("Should never be here", e);
     }
   }
-
+  
   /**
    * Finds the ID associated with a given name or creates it.
    * <p>
@@ -691,6 +751,25 @@ public byte[] getOrCreateId(final String name) throws HBaseException {
    * @since 1.2
    */
   public Deferred<byte[]> getOrCreateIdAsync(final String name) {
+    return getOrCreateIdAsync(name, null, null);
+  }
+  
+  /**
+   * Finds the ID associated with a given name or creates it.
+   * <p>
+   * The length of the byte array is fixed in advance by the implementation.
+   *
+   * @param name The name to lookup in the table or to assign an ID to.
+   * @param metric Name of the metric associated with the UID for filtering.
+   * @param tags Tag set associated with the UID for filtering.
+   * @throws HBaseException if there is a problem communicating with HBase.
+   * @throws IllegalStateException if all possible IDs are already assigned.
+   * @throws IllegalStateException if the ID found in HBase is encoded on the
+   * wrong number of bytes.
+   * @since 2.3
+   */
+  public Deferred<byte[]> getOrCreateIdAsync(final String name, 
+      final String metric, final Map<String, String> tags) {
     // Look in the cache first.
     final byte[] id = getIdFromCache(name);
     if (id != null) {
@@ -699,29 +778,62 @@ public Deferred<byte[]> getOrCreateIdAsync(final String name) {
     }
     // Not found in our cache, so look in HBase instead.
 
+    /** Triggers the assignment if allowed through the filter */
+    class AssignmentAllowedCB implements  Callback<Deferred<byte[]>, Boolean> {
+      @Override
+      public Deferred<byte[]> call(final Boolean allowed) throws Exception {
+        if (!allowed) {
+          rejected_assignments++;
+          return Deferred.fromError(new FailedToAssignUniqueIdException(
+              new String(kind), name, 0, "Blocked by UID filter."));
+        }
+        
+        Deferred<byte[]> assignment = null;
+        synchronized (pending_assignments) {
+          assignment = pending_assignments.get(name);
+          if (assignment == null) {
+            // to prevent UID leaks that can be caused when multiple time
+            // series for the same metric or tags arrive, we need to write a 
+            // deferred to the pending map as quickly as possible. Then we can 
+            // start the assignment process after we've stashed the deferred 
+            // and released the lock
+            assignment = new Deferred<byte[]>();
+            pending_assignments.put(name, assignment);
+          } else {
+            LOG.info("Already waiting for UID assignment: " + name);
+            return assignment;
+          }
+        }
+        
+        // start the assignment dance after stashing the deferred
+        if (metric != null && LOG.isDebugEnabled()) {
+          LOG.debug("Assigning UID for '" + name + "' of type '" + type + 
+              "' for series '" + metric + ", " + tags + "'");
+        }
+        
+        // start the assignment dance after stashing the deferred
+        return new UniqueIdAllocator(name, assignment).tryAllocate();
+      }
+      @Override
+      public String toString() {
+        return "AssignmentAllowedCB";
+      }
+    }
+    
+    /** Triggers an assignment (possibly through the filter) if the exception 
+     * returned was a NoSuchUniqueName. */
     class HandleNoSuchUniqueNameCB implements Callback<Object, Exception> {
       public Object call(final Exception e) {
         if (e instanceof NoSuchUniqueName) {
-          
-          Deferred<byte[]> assignment = null;
-          synchronized (pending_assignments) {
-            assignment = pending_assignments.get(name);
-            if (assignment == null) {
-              // to prevent UID leaks that can be caused when multiple time
-              // series for the same metric or tags arrive, we need to write a 
-              // deferred to the pending map as quickly as possible. Then we can 
-              // start the assignment process after we've stashed the deferred 
-              // and released the lock
-              assignment = new Deferred<byte[]>();
-              pending_assignments.put(name, assignment);
-            } else {
-              LOG.info("Already waiting for UID assignment: " + name);
-              return assignment;
-            }
+          if (tsdb != null && tsdb.getUidFilter() != null && 
+              tsdb.getUidFilter().fillterUIDAssignments()) {
+            return tsdb.getUidFilter()
+                .allowUIDAssignment(type, name, metric, tags)
+                .addCallbackDeferring(new AssignmentAllowedCB());
+          } else {
+            return Deferred.fromResult(true)
+                .addCallbackDeferring(new AssignmentAllowedCB());
           }
-          
-          // start the assignment dance after stashing the deferred
-          return new UniqueIdAllocator(name, assignment).tryAllocate();
         }
         return e;  // Other unexpected exception, let it bubble up.
       }
@@ -869,6 +981,7 @@ public Object call(Object ignored) throws Exception {
    */
   public void rename(final String oldname, final String newname) {
     final byte[] row = getId(oldname);
+    final String row_string = fromBytes(row);
     {
       byte[] id = null;
       try {
@@ -883,6 +996,15 @@ public void rename(final String oldname, final String newname) {
       }
     }
 
+    if (renaming_id_names.contains(row_string)
+        || renaming_id_names.contains(newname)) {
+      throw new IllegalArgumentException("Ongoing rename on the same ID(\""
+        + Arrays.toString(row) + "\") or an identical new name(\"" + newname
+        + "\")");
+    }
+    renaming_id_names.add(row_string);
+    renaming_id_names.add(newname);
+
     final byte[] newnameb = toBytes(newname);
 
     // Update the reverse mapping first, so that if we die before updating
@@ -898,6 +1020,8 @@ public void rename(final String oldname, final String newname) {
       LOG.error("When trying rename(\"" + oldname
         + "\", \"" + newname + "\") on " + this + ": Failed to update reverse"
         + " mapping for ID=" + Arrays.toString(row), e);
+      renaming_id_names.remove(row_string);
+      renaming_id_names.remove(newname);
       throw e;
     }
 
@@ -911,6 +1035,8 @@ public void rename(final String oldname, final String newname) {
       LOG.error("When trying rename(\"" + oldname
         + "\", \"" + newname + "\") on " + this + ": Failed to create the"
         + " new forward mapping with ID=" + Arrays.toString(row), e);
+      renaming_id_names.remove(row_string);
+      renaming_id_names.remove(newname);
       throw e;
     }
 
@@ -935,6 +1061,9 @@ public void rename(final String oldname, final String newname) {
         + " old forward mapping for ID=" + Arrays.toString(row);
       LOG.error("WTF?  " + msg, e);
       throw new RuntimeException(msg, e);
+    } finally {
+      renaming_id_names.remove(row_string);
+      renaming_id_names.remove(newname);
     }
     // Success!
   }
diff --git a/src/uid/UniqueIdFilterPlugin.java b/src/uid/UniqueIdFilterPlugin.java
new file mode 100644
index 0000000000..b0fd0c5e2a
--- /dev/null
+++ b/src/uid/UniqueIdFilterPlugin.java
@@ -0,0 +1,101 @@
+// This file is part of OpenTSDB.
+// Copyright (C) 2016  The OpenTSDB Authors.
+//
+// This program is free software: you can redistribute it and/or modify it
+// under the terms of the GNU Lesser General Public License as published by
+// the Free Software Foundation, either version 2.1 of the License, or (at your
+// option) any later version.  This program is distributed in the hope that it
+// will be useful, but WITHOUT ANY WARRANTY; without even the implied warranty
+// of MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser
+// General Public License for more details.  You should have received a copy
+// of the GNU Lesser General Public License along with this program.  If not,
+// see <http://www.gnu.org/licenses/>.
+package net.opentsdb.uid;
+
+import java.util.Map;
+
+import com.stumbleupon.async.Deferred;
+
+import net.opentsdb.core.TSDB;
+import net.opentsdb.stats.StatsCollector;
+import net.opentsdb.uid.UniqueId.UniqueIdType;
+
+/**
+ * A filter that can determine whether or not UIDs should be allowed assignment
+ * based on their metric and tags. This is useful for such situations as:
+ * <ul><li>Enforcing naming standards</li>
+ * <li>Blacklisting certain names or properties</li>
+ * <li>Preventing cardinality explosions</li></ul>
+ * <b>Note:</b> Implementations must have a parameterless constructor. The 
+ * {@link #initialize(TSDB)} method will be called immediately after the plugin is
+ * instantiated and before any other methods are called.
+ * @since 2.3
+ */
+public abstract class UniqueIdFilterPlugin {
+  
+  /**
+   * Called by TSDB to initialize the plugin
+   * Implementations are responsible for setting up any IO they need as well
+   * as starting any required background threads.
+   * <b>Note:</b> Implementations should throw exceptions if they can't start
+   * up properly. The TSD will then shutdown so the operator can fix the 
+   * problem. Please use IllegalArgumentException for configuration issues.
+   * @param tsdb The parent TSDB object
+   * @throws IllegalArgumentException if required configuration parameters are 
+   * missing
+   * @throws Exception if something else goes wrong
+   */
+  public abstract void initialize(final TSDB tsdb);
+
+  /**
+   * Called to gracefully shutdown the plugin. Implementations should close 
+   * any IO they have open
+   * @return A deferred object that indicates the completion of the request.
+   * The {@link Object} has not special meaning and can be {@code null}
+   * (think of it as {@code Deferred<Void>}).
+   */
+  public abstract Deferred<Object> shutdown();
+  
+  /**
+   * Should return the version of this plugin in the format:
+   * MAJOR.MINOR.MAINT, e.g. "2.3.1". The MAJOR version should match the major
+   * version of OpenTSDB the plugin is meant to work with.
+   * @return A version string used to log the loaded version
+   */
+  public abstract String version();
+  
+  /**
+   * Called by the TSD when a request for statistics collection has come in. The
+   * implementation may provide one or more statistics. If no statistics are
+   * available for the implementation, simply stub the method.
+   * @param collector The collector used for emitting statistics
+   */
+  public abstract void collectStats(final StatsCollector collector);
+  
+  /**
+   * Determine whether or not the UID should be assigned.
+   * If the UID should not be assigned a value, the implementation can return 
+   * false or an exception in the deferred object. Otherwise it should return 
+   * true and the UID will proceed with assignment.
+   * NOTE: In some cases the metric and tags may be null, particularly if the
+   * synchronous APIs were called. In such a situation, make sure the 
+   * implementation handles it properly.
+   * @param type The type of UID being assigned
+   * @param value The string value of the UID
+   * @param metric The metric name associated with the UID for assignment
+   * @param tags The tag set associated with the UID
+   * @return True if the UID should be assigned, false if not.
+   */
+  public abstract Deferred<Boolean> allowUIDAssignment(
+      final UniqueIdType type, 
+      final String value, 
+      final String metric, 
+      final Map<String, String> tags);
+  
+  /**
+   * Whether or not the filter should process UIDs. 
+   * @return True if {@link #allowUIDAssignment(UniqueIdType, String, String, Map)}
+   * should be called, false if not.
+   */
+  public abstract boolean fillterUIDAssignments();
+}
diff --git a/src/uid/UniqueIdWhitelistFilter.java b/src/uid/UniqueIdWhitelistFilter.java
new file mode 100644
index 0000000000..371ea7bd50
--- /dev/null
+++ b/src/uid/UniqueIdWhitelistFilter.java
@@ -0,0 +1,200 @@
+// This file is part of OpenTSDB.
+// Copyright (C) 2016  The OpenTSDB Authors.
+//
+// This program is free software: you can redistribute it and/or modify it
+// under the terms of the GNU Lesser General Public License as published by
+// the Free Software Foundation, either version 2.1 of the License, or (at your
+// option) any later version.  This program is distributed in the hope that it
+// will be useful, but WITHOUT ANY WARRANTY; without even the implied warranty
+// of MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser
+// General Public License for more details.  You should have received a copy
+// of the GNU Lesser General Public License along with this program.  If not,
+// see <http://www.gnu.org/licenses/>.
+package net.opentsdb.uid;
+
+import java.util.ArrayList;
+import java.util.List;
+import java.util.Map;
+import java.util.concurrent.atomic.AtomicLong;
+import java.util.regex.Pattern;
+import java.util.regex.PatternSyntaxException;
+
+import com.google.common.annotations.VisibleForTesting;
+import com.stumbleupon.async.Deferred;
+
+import net.opentsdb.core.TSDB;
+import net.opentsdb.stats.StatsCollector;
+import net.opentsdb.uid.UniqueId.UniqueIdType;
+import net.opentsdb.utils.Config;
+
+/**
+ * A UID filter implementation using regular expression based whitelists.
+ * Multiple regular expressions can be provided in the configuration file with
+ * a configurable delimiter. Each expression is compiled into a list per UID
+ * type and when a new UID passes through the filter, each expression in the
+ * list is compared to make sure the name satisfies all expressions.
+ */
+public class UniqueIdWhitelistFilter extends UniqueIdFilterPlugin {
+
+  /** Default delimiter */
+  public static final String DEFAULT_REGEX_DELIMITER = ",";
+  
+  /** Lists of patterns for each type. */
+  private List<Pattern> metric_patterns;
+  private List<Pattern> tagk_patterns;
+  private List<Pattern> tagv_patterns;
+  
+  /** Counters for tracking stats */
+  private final AtomicLong metrics_rejected = new AtomicLong();
+  private final AtomicLong metrics_allowed = new AtomicLong();
+  private final AtomicLong tagks_rejected = new AtomicLong();
+  private final AtomicLong tagks_allowed = new AtomicLong();
+  private final AtomicLong tagvs_rejected = new AtomicLong();
+  private final AtomicLong tagvs_allowed = new AtomicLong();
+  
+  @Override
+  public void initialize(final TSDB tsdb) {
+    final Config config = tsdb.getConfig();
+    String delimiter = config.getString("tsd.uidfilter.whitelist.delimiter");
+    if (delimiter == null) {
+      delimiter = DEFAULT_REGEX_DELIMITER;
+    }
+    
+    String raw = config.getString("tsd.uidfilter.whitelist.metric_patterns");
+    if (raw != null) {
+      final String[] splits = raw.split(delimiter);
+      metric_patterns = new ArrayList<Pattern>(splits.length);
+      for (final String pattern : splits) {
+        try {
+          metric_patterns.add(Pattern.compile(pattern));
+        } catch (PatternSyntaxException e) {
+          throw new IllegalArgumentException("The metric whitelist pattern [" + 
+              pattern + "] does not compile.", e);
+        }
+      }
+    }
+    
+    raw = config.getString("tsd.uidfilter.whitelist.tagk_patterns");
+    if (raw != null) {
+      final String[] splits = raw.split(delimiter);
+      tagk_patterns = new ArrayList<Pattern>(splits.length);
+      for (final String pattern : splits) {
+        try {
+          tagk_patterns.add(Pattern.compile(pattern));
+        } catch (PatternSyntaxException e) {
+          throw new IllegalArgumentException("The tagk whitelist pattern [" + 
+              pattern + "] does not compile.", e);
+        }
+      }
+    }
+    
+    raw = config.getString("tsd.uidfilter.whitelist.tagv_patterns");
+    if (raw != null) {
+      final String[] splits = raw.split(delimiter);
+      tagv_patterns = new ArrayList<Pattern>(splits.length);
+      for (final String pattern : splits) {
+        try {
+          tagv_patterns.add(Pattern.compile(pattern));
+        } catch (PatternSyntaxException e) {
+          throw new IllegalArgumentException("The tagv whitelist pattern [" + 
+              pattern + "] does not compile.", e);
+        }
+      }
+    }
+  }
+
+  @Override
+  public Deferred<Object> shutdown() {
+    return Deferred.fromResult(null);
+  }
+
+  @Override
+  public String version() {
+    return "2.3.0";
+  }
+
+  @Override
+  public void collectStats(final StatsCollector collector) {
+    collector.record("uid.filter.whitelist.accepted", metrics_allowed.get(), 
+        "type=metrics");
+    collector.record("uid.filter.whitelist.accepted", tagks_allowed.get(), 
+        "type=tagk");
+    collector.record("uid.filter.whitelist.accepted", tagvs_allowed.get(), 
+        "type=tagv");
+    collector.record("uid.filter.whitelist.rejected", metrics_rejected.get(), 
+        "type=metrics");
+    collector.record("uid.filter.whitelist.rejected", tagks_rejected.get(), 
+        "type=tagk");
+    collector.record("uid.filter.whitelist.rejected", tagvs_rejected.get(), 
+        "type=tagv");
+  }
+
+  @Override
+  public Deferred<Boolean> allowUIDAssignment(
+      final UniqueIdType type, 
+      final String value,
+      final String metric, 
+      final Map<String, String> tags) {
+    
+    switch (type) {
+      case METRIC:
+        if (metric_patterns != null) {
+          for (final Pattern pattern : metric_patterns) {
+            if (!pattern.matcher(value).find()) {
+              metrics_rejected.incrementAndGet();
+              return Deferred.fromResult(false);
+            }
+          }
+        }
+        metrics_allowed.incrementAndGet();
+        break;
+        
+      case TAGK:
+        if (tagk_patterns != null) {
+          for (final Pattern pattern : tagk_patterns) {
+            if (!pattern.matcher(value).find()) {
+              tagks_rejected.incrementAndGet();
+              return Deferred.fromResult(false);
+            }
+          }
+        }
+        tagks_allowed.incrementAndGet();
+        break;
+        
+      case TAGV:
+        if (tagv_patterns != null) {
+          for (final Pattern pattern : tagv_patterns) {
+            if (!pattern.matcher(value).find()) {
+              tagvs_rejected.incrementAndGet();
+              return Deferred.fromResult(false);
+            }
+          }
+        }
+        tagvs_allowed.incrementAndGet();
+        break;
+    }
+    
+    // all patterns passed, yay!
+    return Deferred.fromResult(true);
+  }
+
+  @Override
+  public boolean fillterUIDAssignments() {
+    return true;
+  }
+
+  @VisibleForTesting
+  List<Pattern> metricPatterns() {
+    return metric_patterns;
+  }
+  
+  @VisibleForTesting
+  List<Pattern> tagkPatterns() {
+    return tagk_patterns;
+  }
+  
+  @VisibleForTesting
+  List<Pattern> tagvPatterns() {
+    return tagv_patterns;
+  }
+}
diff --git a/src/utils/ByteSet.java b/src/utils/ByteSet.java
new file mode 100644
index 0000000000..6a1bad1d41
--- /dev/null
+++ b/src/utils/ByteSet.java
@@ -0,0 +1,110 @@
+// This file is part of OpenTSDB.
+// Copyright (C) 2015  The OpenTSDB Authors.
+//
+// This program is free software: you can redistribute it and/or modify it
+// under the terms of the GNU Lesser General Public License as published by
+// the Free Software Foundation, either version 2.1 of the License, or (at your
+// option) any later version.  This program is distributed in the hope that it
+// will be useful, but WITHOUT ANY WARRANTY; without even the implied warranty
+// of MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser
+// General Public License for more details.  You should have received a copy
+// of the GNU Lesser General Public License along with this program.  If not,
+// see <http://www.gnu.org/licenses/>.
+package net.opentsdb.utils;
+
+import java.util.AbstractSet;
+import java.util.Arrays;
+import java.util.Iterator;
+import java.util.Set;
+
+import org.hbase.async.Bytes.ByteMap;
+
+/**
+ * An implementation of a set based on the AsyncHBase ByteMap. This provides
+ * a unique set implementation of byte arrays, matching on the contents of
+ * the arrays, not on the hash codes. 
+ */
+public class ByteSet extends AbstractSet<byte[]> 
+  implements Set<byte[]>, Cloneable, java.io.Serializable {
+
+  private static final long serialVersionUID = -496061795957902656L;
+
+  // Dummy value to associate with an Object in the backing Map
+  private static final Object PRESENT = new Object();
+  
+  private transient ByteMap<Object> map;
+  
+  /**
+   * Instantiates a unique set of byte arrays based on the array contents.
+   */
+  public ByteSet() {
+    map = new ByteMap<Object>();
+  }
+  
+  @Override
+  public Iterator<byte[]> iterator() {
+    return map.keySet().iterator();
+  }
+
+  @Override
+  public int size() {
+    return map.size();
+  }
+  
+  @Override
+  public boolean isEmpty() {
+    return map.isEmpty();
+  }
+  
+  @Override
+  public boolean contains(final Object key) {
+    return map.containsKey(key);
+  }
+  
+  @Override
+  public boolean add(final byte[] key) {
+    return map.put(key, PRESENT) == null;
+  }
+  
+  @Override
+  public boolean remove(final Object key) {
+    return map.remove(key) == PRESENT;
+  }
+  
+  @Override
+  public void clear() {
+    map.clear();
+  }
+  
+  @Override
+  public ByteSet clone() {
+    try {
+      ByteSet new_set = (ByteSet) super.clone();
+      new_set.map = (ByteMap<Object>) map.clone();
+      return new_set;
+    } catch (CloneNotSupportedException e) {
+      throw new InternalError();
+    }
+  }
+  
+  @Override
+  public String toString() {
+    final Iterator<byte[]> it = map.keySet().iterator();
+    if (!it.hasNext()) {
+      return "[]";
+    }
+    
+    final StringBuilder buf = new StringBuilder();
+    buf.append('[');
+    for (;;) {
+      final byte[] array = it.next();
+      buf.append(Arrays.toString(array));
+      if (!it.hasNext()) {
+        return buf.append(']').toString();
+      }
+      buf.append(',');
+    }
+  }
+  
+  // TODO - writeObject, readObject
+}
diff --git a/src/utils/Config.java b/src/utils/Config.java
index 2227800017..782bf36430 100644
--- a/src/utils/Config.java
+++ b/src/utils/Config.java
@@ -102,6 +102,9 @@ public class Config {
   
   /** tsd.core.tree.enable_processing */
   private boolean enable_tree_processing = false;
+
+  /** tsd.storage.hbase.scanner.maxNumRows */
+  private int scanner_max_num_rows = 128;
   
   /**
    * The list of properties configured to their defaults or modified by users
@@ -219,6 +222,11 @@ public boolean enable_tsuid_incrementing() {
   public boolean enable_tsuid_tracking() {
     return enable_tsuid_tracking;
   }
+
+  /** @return maximum number of rows to be fetched per round trip while scanning HBase */
+  public int scanner_maxNumRows() {
+    return scanner_max_num_rows;
+  }
   
   /** @return whether or not chunked requests are supported */
   public boolean enable_chunked_requests() {
@@ -479,10 +487,14 @@ protected void setDefaults() {
     default_map.put("tsd.core.auto_create_metrics", "false");
     default_map.put("tsd.core.auto_create_tagks", "true");
     default_map.put("tsd.core.auto_create_tagvs", "true");
+    default_map.put("tsd.core.connections.limit", "0");
+    default_map.put("tsd.core.enable_api", "true");
+    default_map.put("tsd.core.enable_ui", "true");
     default_map.put("tsd.core.meta.enable_realtime_ts", "false");
     default_map.put("tsd.core.meta.enable_realtime_uid", "false");
     default_map.put("tsd.core.meta.enable_tsuid_incrementing", "false");
     default_map.put("tsd.core.meta.enable_tsuid_tracking", "false");
+    default_map.put("tsd.core.meta.cache.enable", "false");
     default_map.put("tsd.core.plugin_path", "");
     default_map.put("tsd.core.socket.timeout", "0");
     default_map.put("tsd.core.tree.enable_processing", "false");
@@ -493,11 +505,15 @@ protected void setDefaults() {
     default_map.put("tsd.query.filter.expansion_limit", "4096");
     default_map.put("tsd.query.skip_unresolved_tagvs", "false");
     default_map.put("tsd.query.allow_simultaneous_duplicates", "true");
+    default_map.put("tsd.query.enable_fuzzy_filter", "true");
     default_map.put("tsd.rtpublisher.enable", "false");
     default_map.put("tsd.rtpublisher.plugin", "");
     default_map.put("tsd.search.enable", "false");
     default_map.put("tsd.search.plugin", "");
     default_map.put("tsd.stats.canonical", "false");
+    default_map.put("tsd.startup.enable", "false");
+    default_map.put("tsd.startup.plugin", "");
+    default_map.put("tsd.storage.hbase.scanner.maxNumRows", "128");
     default_map.put("tsd.storage.fix_duplicates", "false");
     default_map.put("tsd.storage.flush_interval", "1000");
     default_map.put("tsd.storage.hbase.data_table", "tsdb");
@@ -514,6 +530,9 @@ protected void setDefaults() {
     default_map.put("tsd.storage.compaction.min_flush_threshold", "100");
     default_map.put("tsd.storage.compaction.max_concurrent_flushes", "10000");
     default_map.put("tsd.storage.compaction.flush_speed", "2");
+    default_map.put("tsd.timeseriesfilter.enable", "false");
+    default_map.put("tsd.uidfilter.enable", "false");
+    default_map.put("tsd.core.stats_with_port", "false");    
     default_map.put("tsd.http.show_stack_trace", "true");
     default_map.put("tsd.http.query.allow_delete", "false");
     default_map.put("tsd.http.request.enable_chunked", "false");
@@ -635,6 +654,7 @@ protected void loadStaticVariables() {
     }
     enable_tree_processing = this.getBoolean("tsd.core.tree.enable_processing");
     fix_duplicates = this.getBoolean("tsd.storage.fix_duplicates");
+    scanner_max_num_rows = this.getInt("tsd.storage.hbase.scanner.maxNumRows");
   }
   
   /**
diff --git a/src/utils/DateTime.java b/src/utils/DateTime.java
index 793b97b369..41c10ed805 100644
--- a/src/utils/DateTime.java
+++ b/src/utils/DateTime.java
@@ -14,6 +14,7 @@
 
 import java.text.ParseException;
 import java.text.SimpleDateFormat;
+import java.util.Calendar;
 import java.util.HashMap;
 import java.util.TimeZone;
 
@@ -26,7 +27,9 @@
  * @since 2.0
  */
 public class DateTime {
-
+  /** ID of the UTC timezone */
+  public static final String UTC_ID = "UTC";
+  
   /**
    * Immutable cache mapping a timezone name to its object.
    * We do this because the JDK's TimeZone class was implemented by retards,
@@ -72,6 +75,15 @@ public static final long parseDateTimeString(final String datetime,
       final String tz) {
     if (datetime == null || datetime.isEmpty())
       return -1;
+
+    if (datetime.matches("^[0-9]+ms$")) {
+      return Tags.parseLong(datetime.replaceFirst("^([0-9]+)(ms)$", "$1"));
+    }
+
+    if (datetime.toLowerCase().equals("now")) {
+      return System.currentTimeMillis();
+    }
+
     if (datetime.toLowerCase().endsWith("-ago")) {
       long interval = DateTime.parseDuration(
         datetime.substring(0, datetime.length() - 4));
@@ -177,6 +189,10 @@ public static final long parseDuration(final String duration) {
     int unit = 0;
     while (Character.isDigit(duration.charAt(unit))) {
       unit++;
+      if (unit >= duration.length()) {
+        throw new IllegalArgumentException("Invalid duration, must have an "
+            + "integer and unit: " + duration);
+      }
     }
     try {
       interval = Long.parseLong(duration.substring(0, unit));
@@ -312,4 +328,254 @@ public static double msFromNanoDiff(final long end, final long start) {
     }
     return ((double) end - (double) start) / 1000000;
   }
+  
+  /**
+   * Returns a calendar set to the previous interval time based on the 
+   * units and UTC the timezone. This allows for snapping to day, week, 
+   * monthly, etc. boundaries. 
+   * NOTE: It uses a calendar for snapping so isn't as efficient as a simple
+   * modulo calculation.
+   * NOTE: For intervals that don't nicely divide into their given unit (e.g.
+   * a 23s interval where 60 seconds is not divisible by 23) the base time may
+   * start at the top of the day (for ms and s) or from Unix epoch 0. In the
+   * latter case, setting up the base timestamp may be slow if the caller does
+   * something silly like "23m" where we iterate 23 minutes at a time from 0
+   * till we find the proper timestamp.
+   * TODO - There is likely a better way to do all of this 
+   * @param ts The timestamp to find an interval for, in milliseconds as
+   * a Unix epoch.
+   * @param interval The interval as a measure of units.
+   * @param unit The unit. This must cast to a Calendar time unit.
+   * @return A calendar set to the timestamp aligned to the proper interval
+   * before the given ts
+   * @throws IllegalArgumentException if the timestamp is negative, if the 
+   * interval is less than 1 or the unit is unrecognized.
+   * @since 2.3
+   */
+  public static Calendar previousInterval(final long ts, final int interval, 
+      final int unit) {
+    return previousInterval(ts, interval, unit, null);
+  }
+  
+  /**
+   * Returns a calendar set to the previous interval time based on the 
+   * units and timezone. This allows for snapping to day, week, monthly, etc.
+   * boundaries. 
+   * NOTE: It uses a calendar for snapping so isn't as efficient as a simple
+   * modulo calculation.
+   * NOTE: For intervals that don't nicely divide into their given unit (e.g.
+   * a 23s interval where 60 seconds is not divisible by 23) the base time may
+   * start at the top of the day (for ms and s) or from Unix epoch 0. In the
+   * latter case, setting up the base timestamp may be slow if the caller does
+   * something silly like "23m" where we iterate 23 minutes at a time from 0
+   * till we find the proper timestamp.
+   * TODO - There is likely a better way to do all of this 
+   * @param ts The timestamp to find an interval for, in milliseconds as
+   * a Unix epoch.
+   * @param interval The interval as a measure of units.
+   * @param unit The unit. This must cast to a Calendar time unit.
+   * @param tz An optional timezone.
+   * @return A calendar set to the timestamp aligned to the proper interval
+   * before the given ts
+   * @throws IllegalArgumentException if the timestamp is negative, if the 
+   * interval is less than 1 or the unit is unrecognized.
+   * @since 2.3
+   */
+  public static Calendar previousInterval(final long ts, final int interval, 
+      final int unit, final TimeZone tz) {
+    if (ts < 0) {
+      throw new IllegalArgumentException("Timestamp cannot be less than zero");
+    }
+    if (interval < 1) {
+      throw new IllegalArgumentException("Interval must be greater than zero");
+    }
+    
+    int unit_override = unit;
+    int interval_override = interval;
+    final Calendar calendar;
+    if (tz == null) {
+      calendar = Calendar.getInstance(timezones.get(UTC_ID));
+    } else {
+      calendar = Calendar.getInstance(tz);
+    }
+    
+    switch (unit_override) {
+    case Calendar.MILLISECOND:
+      if (1000 % interval_override == 0) {
+        calendar.setTimeInMillis(ts);
+        calendar.set(Calendar.MILLISECOND, 0);
+        if (interval_override > 1000) {
+          calendar.add(Calendar.MILLISECOND, -interval_override);
+        }
+      } else {
+        // from top of minute
+        calendar.setTimeInMillis(ts);
+        calendar.set(Calendar.MILLISECOND, 0);
+        calendar.set(Calendar.SECOND, 0);
+      }
+      break;
+    case Calendar.SECOND:
+      if (60 % interval_override == 0) {
+        calendar.setTimeInMillis(ts);
+        calendar.set(Calendar.MILLISECOND, 0);
+        calendar.set(Calendar.SECOND, 0);
+        if (interval_override > 60) {
+          calendar.add(Calendar.SECOND, -interval_override);
+        }
+      } else {
+        // from top of hour
+        calendar.setTimeInMillis(ts);
+        calendar.set(Calendar.MILLISECOND, 0);
+        calendar.set(Calendar.SECOND, 0);
+        calendar.set(Calendar.MINUTE, 0);
+      }
+      break;
+    case Calendar.MINUTE:
+      if (60 % interval_override == 0) {
+        calendar.setTimeInMillis(ts);
+        calendar.set(Calendar.MILLISECOND, 0);
+        calendar.set(Calendar.SECOND, 0);
+        calendar.set(Calendar.MINUTE, 0);
+        if (interval_override > 60) {
+          calendar.add(Calendar.MINUTE, -interval_override);
+        }
+      } else {
+        // from top of day
+        calendar.setTimeInMillis(ts);
+        calendar.set(Calendar.MILLISECOND, 0);
+        calendar.set(Calendar.SECOND, 0);
+        calendar.set(Calendar.MINUTE, 0);
+        calendar.set(Calendar.HOUR_OF_DAY, 0);
+      }
+      break;
+    case Calendar.HOUR_OF_DAY:
+      if (24 % interval_override == 0) {
+        calendar.setTimeInMillis(ts);
+        calendar.set(Calendar.MILLISECOND, 0);
+        calendar.set(Calendar.SECOND, 0);
+        calendar.set(Calendar.MINUTE, 0);
+        calendar.set(Calendar.HOUR_OF_DAY, 0);
+        if (interval_override > 24) {
+          calendar.add(Calendar.HOUR_OF_DAY, -interval_override);
+        }
+      } else {
+        // from top of month
+        calendar.setTimeInMillis(ts);
+        calendar.set(Calendar.MILLISECOND, 0);
+        calendar.set(Calendar.SECOND, 0);
+        calendar.set(Calendar.MINUTE, 0);
+        calendar.set(Calendar.HOUR_OF_DAY, 0);
+        calendar.set(Calendar.DAY_OF_MONTH, 1);
+      }
+      break;
+    case Calendar.DAY_OF_MONTH:
+      if (interval_override == 1) {
+        calendar.setTimeInMillis(ts);
+        calendar.set(Calendar.MILLISECOND, 0);
+        calendar.set(Calendar.SECOND, 0);
+        calendar.set(Calendar.MINUTE, 0);
+        calendar.set(Calendar.HOUR_OF_DAY, 0);
+        calendar.set(Calendar.DAY_OF_MONTH, 1);
+      } else {
+        // from top of year
+        calendar.setTimeInMillis(ts);
+        calendar.set(Calendar.MILLISECOND, 0);
+        calendar.set(Calendar.SECOND, 0);
+        calendar.set(Calendar.MINUTE, 0);
+        calendar.set(Calendar.HOUR_OF_DAY, 0);
+        calendar.set(Calendar.DAY_OF_MONTH, 1);
+        calendar.set(Calendar.MONTH, 0);
+      }
+      break;
+    case Calendar.DAY_OF_WEEK:
+      if (2 % interval_override == 0) {
+        calendar.setTimeInMillis(ts);
+        calendar.set(Calendar.MILLISECOND, 0);
+        calendar.set(Calendar.SECOND, 0);
+        calendar.set(Calendar.MINUTE, 0);
+        calendar.set(Calendar.HOUR_OF_DAY, 0);
+        calendar.set(Calendar.DAY_OF_WEEK, calendar.getFirstDayOfWeek());
+      } else {
+        // from top of year
+        calendar.setTimeInMillis(ts);
+        calendar.set(Calendar.MILLISECOND, 0);
+        calendar.set(Calendar.SECOND, 0);
+        calendar.set(Calendar.MINUTE, 0);
+        calendar.set(Calendar.HOUR_OF_DAY, 0);
+        calendar.set(Calendar.MONTH, 0);
+        calendar.set(Calendar.DAY_OF_WEEK, calendar.getFirstDayOfWeek());
+      }
+      unit_override = Calendar.DAY_OF_MONTH;
+      interval_override = 7;
+      break;
+    case Calendar.WEEK_OF_YEAR:
+      // from top of year
+      calendar.setTimeInMillis(ts);
+      calendar.set(Calendar.MILLISECOND, 0);
+      calendar.set(Calendar.SECOND, 0);
+      calendar.set(Calendar.MINUTE, 0);
+      calendar.set(Calendar.HOUR_OF_DAY, 0);
+      calendar.set(Calendar.DAY_OF_MONTH, 1);
+      calendar.set(Calendar.MONTH, 0);
+      break;
+    case Calendar.MONTH:
+    case Calendar.YEAR:
+      calendar.setTimeInMillis(ts);
+      calendar.set(Calendar.MILLISECOND, 0);
+      calendar.set(Calendar.SECOND, 0);
+      calendar.set(Calendar.MINUTE, 0);
+      calendar.set(Calendar.HOUR_OF_DAY, 0);
+      calendar.set(Calendar.DAY_OF_MONTH, 1);
+      calendar.set(Calendar.MONTH, 0);
+      break;
+    default:
+      throw new IllegalArgumentException("Unexpected unit_overrides of type: "
+          + unit_override);
+    }
+    
+    if (calendar.getTimeInMillis() == ts) {
+      return calendar;
+    }
+    // TODO optimize a bit. We probably don't need to go past then back.
+    while (calendar.getTimeInMillis() <= ts) {
+      calendar.add(unit_override, interval_override);
+    }
+    calendar.add(unit_override, -interval_override);
+    return calendar;
+  }
+
+  /**
+   * Return the proper Calendar time unit as an integer given the string
+   * @param units The unit to parse
+   * @return An integer matching a Calendar.<UNIT> enum
+   * @throws IllegalArgumentException if the unit is null, empty or doesn't 
+   * match one of the configured units.
+   * @since 2.3
+   */
+  public static int unitsToCalendarType(final String units) {
+    if (units == null || units.isEmpty()) {
+      throw new IllegalArgumentException("Units cannot be null or empty");
+    }
+    
+    final String lc = units.toLowerCase();
+    if (lc.equals("ms")) {
+      return Calendar.MILLISECOND;
+    } else if (lc.equals("s")) {
+      return Calendar.SECOND;
+    } else if (lc.equals("m")) {
+      return Calendar.MINUTE;
+    } else if (lc.equals("h")) {
+      return Calendar.HOUR_OF_DAY;
+    } else if (lc.equals("d")) {
+      return Calendar.DAY_OF_MONTH;
+    } else if (lc.equals("w")) {
+      return Calendar.DAY_OF_WEEK;
+    } else if (lc.equals("n")) {
+      return Calendar.MONTH;
+    } else if (lc.equals("y")) {
+      return Calendar.YEAR;
+    }
+    throw new IllegalArgumentException("Unrecognized unit type: " + units);
+  }
+
 }
diff --git a/src/utils/PluginLoader.java b/src/utils/PluginLoader.java
index 8dadfc5ec3..d66c75f0c9 100644
--- a/src/utils/PluginLoader.java
+++ b/src/utils/PluginLoader.java
@@ -104,7 +104,7 @@ public static <T> T loadSpecificPlugin(final String name,
     
     while(it.hasNext()) {
       T plugin = it.next();
-      if (plugin.getClass().getName().equals(name)) {
+      if (plugin.getClass().getName().equals(name) || plugin.getClass().getSuperclass().getName().equals(name)) {
         return plugin;
       }
     }
diff --git a/test/core/BaseTsdbTest.java b/test/core/BaseTsdbTest.java
index d51efd5601..7c5f209abb 100644
--- a/test/core/BaseTsdbTest.java
+++ b/test/core/BaseTsdbTest.java
@@ -59,6 +59,25 @@
 @PrepareForTest({TSDB.class, Config.class, UniqueId.class, HBaseClient.class, 
   HashedWheelTimer.class, Scanner.class, Const.class })
 public class BaseTsdbTest {
+  /** A list of UIDs from A to Z for unit testing UIDs values */
+  public static final Map<String, byte[]> METRIC_UIDS = 
+      new HashMap<String, byte[]>(26);
+  public static final Map<String, byte[]> TAGK_UIDS = 
+      new HashMap<String, byte[]>(26);
+  public static final Map<String, byte[]> TAGV_UIDS = 
+      new HashMap<String, byte[]>(26);
+  static {
+    char letter = 'A';
+    int uid = 10;
+    for (int i = 0; i < 26; i++) {
+      METRIC_UIDS.put(Character.toString(letter), 
+          UniqueId.longToUID(uid, TSDB.metrics_width()));
+      TAGK_UIDS.put(Character.toString(letter), 
+          UniqueId.longToUID(uid, TSDB.tagk_width()));
+      TAGV_UIDS.put(Character.toString(letter++), 
+          UniqueId.longToUID(uid++, TSDB.tagv_width()));
+    }
+  }
   
   public static final String METRIC_STRING = "sys.cpu.user";
   public static final byte[] METRIC_BYTES = new byte[] { 0, 0, 1 };
@@ -124,6 +143,7 @@ public void before() throws Exception {
     tags.put(TAGK_STRING, TAGV_STRING);
   }
   
+  /** Adds the static UIDs to the metrics UID mock object */
   void setupMetricMaps() {
     when(metrics.getId(METRIC_STRING)).thenReturn(METRIC_BYTES);
     when(metrics.getIdAsync(METRIC_STRING))
@@ -174,8 +194,32 @@ public Deferred<String> answer(InvocationOnMock invocation)
     when(metrics.getIdAsync(NSUN_METRIC))
       .thenReturn(Deferred.<byte[]>fromError(nsun));
     when(metrics.getOrCreateId(NSUN_METRIC)).thenThrow(nsun);
+    
+    // Iterate over the metric UIDs and handle both forward and reverse
+    for (final Map.Entry<String, byte[]> uid : METRIC_UIDS.entrySet()) {
+      when(metrics.getId(uid.getKey())).thenReturn(uid.getValue());
+      when(metrics.getIdAsync(uid.getKey()))
+        .thenAnswer(new Answer<Deferred<byte[]>>() {
+            @Override
+            public Deferred<byte[]> answer(InvocationOnMock invocation)
+                throws Throwable {
+              return Deferred.fromResult(uid.getValue());
+            }
+        });
+      when(metrics.getOrCreateId(uid.getKey()))
+        .thenReturn(uid.getValue());
+      when(metrics.getNameAsync(uid.getValue()))
+        .thenAnswer(new Answer<Deferred<String>>() {
+            @Override
+            public Deferred<String> answer(InvocationOnMock invocation)
+                throws Throwable {
+              return Deferred.fromResult(uid.getKey());
+            }
+        });
+    }
   }
   
+  /** Adds the static UIDs to the tag keys UID mock object */
   void setupTagkMaps() {
     when(tag_names.getId(TAGK_STRING)).thenReturn(TAGK_BYTES);
     when(tag_names.getOrCreateId(TAGK_STRING)).thenReturn(TAGK_BYTES);
@@ -228,8 +272,32 @@ public Deferred<String> answer(InvocationOnMock invocation)
       .thenThrow(nsun);
     when(tag_names.getIdAsync(NSUN_TAGK))
       .thenReturn(Deferred.<byte[]>fromError(nsun));
+    
+    // Iterate over the tagk UIDs and handle both forward and reverse
+    for (final Map.Entry<String, byte[]> uid : TAGK_UIDS.entrySet()) {
+      when(tag_names.getId(uid.getKey())).thenReturn(uid.getValue());
+      when(tag_names.getIdAsync(uid.getKey()))
+        .thenAnswer(new Answer<Deferred<byte[]>>() {
+            @Override
+            public Deferred<byte[]> answer(InvocationOnMock invocation)
+                throws Throwable {
+              return Deferred.fromResult(uid.getValue());
+            }
+        });
+      when(tag_names.getOrCreateId(uid.getKey()))
+        .thenReturn(uid.getValue());
+      when(tag_names.getNameAsync(uid.getValue()))
+        .thenAnswer(new Answer<Deferred<String>>() {
+            @Override
+            public Deferred<String> answer(InvocationOnMock invocation)
+                throws Throwable {
+              return Deferred.fromResult(uid.getKey());
+            }
+        });
+    }
   }
   
+  /** Adds the static UIDs to the tag values UID mock object */
   void setupTagvMaps() {
     when(tag_values.getId(TAGV_STRING)).thenReturn(TAGV_BYTES);
     when(tag_values.getOrCreateId(TAGV_STRING)).thenReturn(TAGV_BYTES);
@@ -269,6 +337,29 @@ public Deferred<byte[]> answer(InvocationOnMock invocation)
     when(tag_values.getId(NSUN_TAGV)).thenThrow(nsun);
     when(tag_values.getIdAsync(NSUN_TAGV))
       .thenReturn(Deferred.<byte[]>fromError(nsun));
+    
+    // Iterate over the tagv UIDs and handle both forward and reverse
+    for (final Map.Entry<String, byte[]> uid : TAGV_UIDS.entrySet()) {
+      when(tag_values.getId(uid.getKey())).thenReturn(uid.getValue());
+      when(tag_values.getIdAsync(uid.getKey()))
+        .thenAnswer(new Answer<Deferred<byte[]>>() {
+            @Override
+            public Deferred<byte[]> answer(InvocationOnMock invocation)
+                throws Throwable {
+              return Deferred.fromResult(uid.getValue());
+            }
+        });
+      when(tag_values.getOrCreateId(uid.getKey()))
+        .thenReturn(uid.getValue());
+      when(tag_values.getNameAsync(uid.getValue()))
+        .thenAnswer(new Answer<Deferred<String>>() {
+            @Override
+            public Deferred<String> answer(InvocationOnMock invocation)
+                throws Throwable {
+              return Deferred.fromResult(uid.getKey());
+            }
+        });
+    }
   }
 
   // ----------------- //
@@ -583,4 +674,16 @@ public boolean continuePausedTask() {
       }
     }
   }
+
+  /**
+   * A little class used to throw a very specific type of exception for matching
+   * in Unit Tests.
+   */
+  public static class UnitTestException extends RuntimeException {
+    public UnitTestException() { }
+    public UnitTestException(final String msg) {
+      super(msg);
+    }
+    private static final long serialVersionUID = -4404095849459619922L;
+  }
 }
\ No newline at end of file
diff --git a/test/core/SeekableViewsForTest.java b/test/core/SeekableViewsForTest.java
index dab66d7c37..bc6463da1c 100644
--- a/test/core/SeekableViewsForTest.java
+++ b/test/core/SeekableViewsForTest.java
@@ -32,7 +32,8 @@ public static SeekableView fromArray(final DataPoint[] data_points) {
   }
 
   /**
-   * Creates a {@link SeekableView} that generates a sequence of data points.
+   * Creates a {@link SeekableView} that generates a sequence of data points
+   * where the starting value is 1 and it is incremented by 1 each iteration.
    * @param start_time Starting timestamp
    * @param sample_period Average sample period of data points
    * @param num_data_points Total number of data points to generate
@@ -43,12 +44,56 @@ public static SeekableView generator(final long start_time,
                                        final long sample_period,
                                        final int num_data_points,
                                        final boolean is_integer) {
+    return generator(start_time, sample_period, num_data_points,
+                                  is_integer, 0, 1);
+  }
+  
+  /**
+   * Creates a {@link SeekableView} that generates a sequence of data points.
+   * @param start_time Starting timestamp
+   * @param sample_period Average sample period of data points
+   * @param num_data_points Total number of data points to generate
+   * @param is_integer True to generate a sequence of integer data points.
+   * @param starting_value The starting data point value.
+   * @param increment How much to increment the values each iteration.
+   * @return A {@link SeekableView} object
+   */
+  public static SeekableView generator(final long start_time,
+                                       final long sample_period,
+                                       final int num_data_points,
+                                       final boolean is_integer,
+                                       final double starting_value,
+                                       final double increment) {
+    return generator(start_time, sample_period, num_data_points,
+     is_integer, starting_value, increment, false);
+  }
+  
+  /**
+   * Creates a {@link SeekableView} that generates a sequence of data points.
+   * @param start_time Starting timestamp
+   * @param sample_period Average sample period of data points
+   * @param num_data_points Total number of data points to generate
+   * @param is_integer True to generate a sequence of integer data points.
+   * @param starting_value The starting data point value.
+   * @param increment How much to increment the values each iteration.
+   * @param wholes_as_integer Whether or not to return whole numbers (1.0, 2.0, 
+   * etc) as integers to test for functions that should support both.
+   * Note: Ignored if is_integer is true.
+   * @return A {@link SeekableView} object
+   */
+  public static SeekableView generator(final long start_time,
+                                       final long sample_period,
+                                       final int num_data_points,
+                                       final boolean is_integer,
+                                       final double starting_value,
+                                       final double increment,
+                                       final boolean wholes_as_integer) {
     return new DataPointGenerator(start_time, sample_period, num_data_points,
-                                  is_integer);
+     is_integer, starting_value, increment, wholes_as_integer);
   }
 
   /** Iterates an array of data points. */
-  private static class MockSeekableView implements SeekableView {
+  public static class MockSeekableView implements SeekableView {
 
     private final DataPoint[] data_points;
     private int index = 0;
@@ -83,37 +128,56 @@ public void seek(long timestamp) {
         }
       }
     }
+  
+    public void resetIndex() {
+      index = 0;
+    }
   }
 
   /** Generates a sequence of data points. */
   private static class DataPointGenerator implements SeekableView {
 
-    private final long start_time_ms;
     private final long sample_period_ms;
     private final int num_data_points;
     private final boolean is_integer;
+    private final double increment;
     private final MutableDataPoint current_data = new MutableDataPoint();
-    private int current = 0;
-
+    private final MutableDataPoint next_data = new MutableDataPoint();
+    private final boolean wholes_as_integer;
+    private int dps_emitted = 0;
+    
     DataPointGenerator(final long start_time_ms, final long sample_period_ms,
-                       final int num_data_points, final boolean is_integer) {
-      this.start_time_ms = start_time_ms;
+        final int num_data_points, final boolean is_integer, 
+        final double starting_value, final double increment,
+        final boolean wholes_as_integer) {
       this.sample_period_ms = sample_period_ms;
       this.num_data_points = num_data_points;
       this.is_integer = is_integer;
-      rewind();
+      this.increment = increment;
+      this.wholes_as_integer = wholes_as_integer;
+      if (is_integer) {
+        next_data.reset(start_time_ms, (long)starting_value);
+      } else {
+        if (wholes_as_integer && 
+            (starting_value == Math.floor(starting_value)) && 
+            !Double.isInfinite(starting_value)) {
+          next_data.reset(start_time_ms, (long)starting_value);
+        } else {
+          next_data.reset(start_time_ms, starting_value);
+        }
+      }
     }
 
     @Override
     public boolean hasNext() {
-      return current < num_data_points;
+      return dps_emitted < num_data_points;
     }
 
     @Override
     public DataPoint next() {
       if (hasNext()) {
-        generateData();
-        ++current;
+        current_data.reset(next_data);
+        advance();
         return current_data;
       }
       throw new NoSuchElementException("no more values");
@@ -126,44 +190,39 @@ public void remove() {
 
     @Override
     public void seek(long timestamp) {
-      rewind();
-      current = (int)((timestamp -1 - start_time_ms) / sample_period_ms);
-      if (current < 0) {
-        current = 0;
-      }
-      while (generateTimestamp() < timestamp) {
-        ++current;
+      while (next_data.timestamp() < timestamp && dps_emitted < num_data_points) {
+        advance();
       }
     }
-
-    private void rewind() {
-      current = 0;
-      generateData();
-    }
-
-    private void generateData() {
+    
+    private void advance() {
       if (is_integer) {
-        current_data.reset(generateTimestamp(), current);
+        next_data.reset(next_data.timestamp() + sample_period_ms, 
+            next_data.longValue() + (long)increment);
       } else {
-        current_data.reset(generateTimestamp(), (double)current);
+        final double next = next_data.toDouble() + increment;
+        if (wholes_as_integer && 
+            (next == Math.floor(next)) && !Double.isInfinite(next)) {
+          next_data.reset(next_data.timestamp() + sample_period_ms, (long)next);
+        } else {
+          next_data.reset(next_data.timestamp() + sample_period_ms, next);
+        }
       }
+      dps_emitted++;
     }
-
-    private long generateTimestamp() {
-      long timestamp = start_time_ms + sample_period_ms * current;
-      return timestamp + (((current % 2) == 0) ? -1000 : 1000);
-    }
+    
+    
   }
-
+  
   @Test
   public void testDataPointGenerator() {
-    DataPointGenerator dpg = new DataPointGenerator(100000, 10000, 5, true);
+    SeekableView dpg = generator(100000, 10000, 5, true);
     DataPoint[] expected_data_points = new DataPoint[] {
-        MutableDataPoint.ofLongValue(99000, 0),
-        MutableDataPoint.ofLongValue(111000, 1),
-        MutableDataPoint.ofLongValue(119000, 2),
-        MutableDataPoint.ofLongValue(131000, 3),
-        MutableDataPoint.ofLongValue(139000, 4),
+        MutableDataPoint.ofLongValue(100000, 0),
+        MutableDataPoint.ofLongValue(110000, 1),
+        MutableDataPoint.ofLongValue(120000, 2),
+        MutableDataPoint.ofLongValue(130000, 3),
+        MutableDataPoint.ofLongValue(140000, 4),
     };
     for (DataPoint expected: expected_data_points) {
       assertTrue(dpg.hasNext());
@@ -176,13 +235,13 @@ public void testDataPointGenerator() {
 
   @Test
   public void testDataPointGenerator_double() {
-    DataPointGenerator dpg = new DataPointGenerator(100000, 10000, 5, false);
+    SeekableView dpg = generator(100000, 10000, 5, false);
     DataPoint[] expected_data_points = new DataPoint[] {
-        MutableDataPoint.ofDoubleValue(99000, 0),
-        MutableDataPoint.ofDoubleValue(111000, 1),
-        MutableDataPoint.ofDoubleValue(119000, 2),
-        MutableDataPoint.ofDoubleValue(131000, 3),
-        MutableDataPoint.ofDoubleValue(139000, 4),
+        MutableDataPoint.ofDoubleValue(100000, 0),
+        MutableDataPoint.ofDoubleValue(110000, 1),
+        MutableDataPoint.ofDoubleValue(120000, 2),
+        MutableDataPoint.ofDoubleValue(130000, 3),
+        MutableDataPoint.ofDoubleValue(140000, 4),
     };
     for (DataPoint expected: expected_data_points) {
       assertTrue(dpg.hasNext());
@@ -195,12 +254,12 @@ public void testDataPointGenerator_double() {
 
   @Test
   public void testDataPointGenerator_seek() {
-    DataPointGenerator dpg = new DataPointGenerator(100000, 10000, 5, true);
+    SeekableView dpg = generator(100000, 10000, 5, true);
     dpg.seek(119000);
     DataPoint[] expected_data_points = new DataPoint[] {
-        MutableDataPoint.ofLongValue(119000, 2),
-        MutableDataPoint.ofLongValue(131000, 3),
-        MutableDataPoint.ofLongValue(139000, 4),
+        MutableDataPoint.ofLongValue(120000, 2),
+        MutableDataPoint.ofLongValue(130000, 3),
+        MutableDataPoint.ofLongValue(140000, 4),
     };
     for (DataPoint expected: expected_data_points) {
       assertTrue(dpg.hasNext());
@@ -213,13 +272,14 @@ public void testDataPointGenerator_seek() {
 
   @Test
   public void testDataPointGenerator_seekToFirst() {
-    DataPointGenerator dpg = new DataPointGenerator(100000, 10000, 5, true);
+    SeekableView dpg = generator(100000, 10000, 5, true);
     dpg.seek(100000);
     DataPoint[] expected_data_points = new DataPoint[] {
-        MutableDataPoint.ofLongValue(111000, 1),
-        MutableDataPoint.ofLongValue(119000, 2),
-        MutableDataPoint.ofLongValue(131000, 3),
-        MutableDataPoint.ofLongValue(139000, 4),
+        MutableDataPoint.ofLongValue(100000, 0),
+        MutableDataPoint.ofLongValue(110000, 1),
+        MutableDataPoint.ofLongValue(120000, 2),
+        MutableDataPoint.ofLongValue(130000, 3),
+        MutableDataPoint.ofLongValue(140000, 4),
     };
     for (DataPoint expected: expected_data_points) {
       assertTrue(dpg.hasNext());
@@ -232,13 +292,13 @@ public void testDataPointGenerator_seekToFirst() {
 
   @Test
   public void testDataPointGenerator_seekToSecond() {
-    DataPointGenerator dpg = new DataPointGenerator(100000, 10000, 5, true);
+    SeekableView dpg = generator(100000, 10000, 5, true);
     dpg.seek(100001);
     DataPoint[] expected_data_points = new DataPoint[] {
-        MutableDataPoint.ofLongValue(111000, 1),
-        MutableDataPoint.ofLongValue(119000, 2),
-        MutableDataPoint.ofLongValue(131000, 3),
-        MutableDataPoint.ofLongValue(139000, 4),
+        MutableDataPoint.ofLongValue(110000, 1),
+        MutableDataPoint.ofLongValue(120000, 2),
+        MutableDataPoint.ofLongValue(130000, 3),
+        MutableDataPoint.ofLongValue(140000, 4),
     };
     for (DataPoint expected: expected_data_points) {
       assertTrue(dpg.hasNext());
@@ -248,4 +308,27 @@ public void testDataPointGenerator_seekToSecond() {
     }
     assertFalse(dpg.hasNext());
   }
+
+  @Test
+  public void testDataPointGeneratorWholes() {
+    SeekableView dpg = generator(100000, 10000, 5, false, 0, 1.5, true);
+    DataPoint[] expected_data_points = new DataPoint[] {
+        MutableDataPoint.ofLongValue(100000, 0),
+        MutableDataPoint.ofDoubleValue(110000, 1.5),
+        MutableDataPoint.ofLongValue(120000, 3),
+        MutableDataPoint.ofDoubleValue(130000, 4.5),
+        MutableDataPoint.ofLongValue(140000, 6),
+    };
+    for (DataPoint expected: expected_data_points) {
+      assertTrue(dpg.hasNext());
+      DataPoint dp = dpg.next();
+      assertEquals(expected.timestamp(), dp.timestamp());
+      if (expected.isInteger()) {
+        assertEquals(expected.longValue(), dp.longValue());
+      } else {
+        assertEquals(expected.doubleValue(), dp.doubleValue(), 0.001);
+      }
+    }
+    assertFalse(dpg.hasNext());
+  }
 }
diff --git a/test/core/TestAggregators.java b/test/core/TestAggregators.java
index 5f51327046..7f4f843517 100644
--- a/test/core/TestAggregators.java
+++ b/test/core/TestAggregators.java
@@ -12,6 +12,8 @@
 // see <http://www.gnu.org/licenses/>.
 package net.opentsdb.core;
 
+import static org.junit.Assert.assertEquals;
+
 import java.util.Random;
 
 import org.junit.Assert;
@@ -36,26 +38,37 @@ public final class TestAggregators {
 
   /** Helper class to hold a bunch of numbers we can iterate on.  */
   private static final class Numbers implements Aggregator.Longs, Aggregator.Doubles {
-    private final long[] numbers;
+    private final long[] longs;
+    private final double[] doubles;
     private int i = 0;
 
     public Numbers(final long[] numbers) {
-      this.numbers = numbers;
+      longs = numbers;
+      doubles = null;
+    }
+    
+    public Numbers(final double[] numbers) {
+      longs = null;
+      doubles = numbers;
     }
 
+    public boolean isInteger() {
+      return longs != null ? true : false;
+    }
+    
     @Override
     public boolean hasNextValue() {
-      return i < numbers.length;
+      return longs != null ? i < longs.length : i < doubles.length; 
     }
 
     @Override
     public long nextLongValue() {
-      return numbers[i++];
+      return longs[i++];
     }
 
     @Override
     public double nextDoubleValue() {
-      return numbers[i++];
+      return doubles[i++];
     }
 
     void reset() {
@@ -112,9 +125,6 @@ private static void checkSimilarStdDev(final long[] values,
                                          final double epsilon) {
     final Numbers numbers = new Numbers(values);
     final Aggregator agg = Aggregators.get("dev");
-
-    Assert.assertEquals(expected, agg.runDouble(numbers), epsilon);
-    numbers.reset();
     Assert.assertEquals(expected, agg.runLong(numbers), Math.max(epsilon, 1.0));
   }
 
@@ -141,32 +151,76 @@ public void testPercentiles() {
     }
 
     Numbers values = new Numbers(longValues);
-    assertEquals(500, Aggregators.get("p50"), values);
-    assertEquals(750, Aggregators.get("p75"), values);
-    assertEquals(900, Aggregators.get("p90"), values);
-    assertEquals(950, Aggregators.get("p95"), values);
-    assertEquals(990, Aggregators.get("p99"), values);
-    assertEquals(999, Aggregators.get("p999"), values);
-
-    assertEquals(500, Aggregators.get("ep50r3"), values);
-    assertEquals(750, Aggregators.get("ep75r3"), values);
-    assertEquals(900, Aggregators.get("ep90r3"), values);
-    assertEquals(950, Aggregators.get("ep95r3"), values);
-    assertEquals(990, Aggregators.get("ep99r3"), values);
-    assertEquals(999, Aggregators.get("ep999r3"), values);
+    assertAggregatorEquals(500, Aggregators.get("p50"), values);
+    assertAggregatorEquals(750, Aggregators.get("p75"), values);
+    assertAggregatorEquals(900, Aggregators.get("p90"), values);
+    assertAggregatorEquals(950, Aggregators.get("p95"), values);
+    assertAggregatorEquals(990, Aggregators.get("p99"), values);
+    assertAggregatorEquals(999, Aggregators.get("p999"), values);
+
+    assertAggregatorEquals(500, Aggregators.get("ep50r3"), values);
+    assertAggregatorEquals(750, Aggregators.get("ep75r3"), values);
+    assertAggregatorEquals(900, Aggregators.get("ep90r3"), values);
+    assertAggregatorEquals(950, Aggregators.get("ep95r3"), values);
+    assertAggregatorEquals(990, Aggregators.get("ep99r3"), values);
+    assertAggregatorEquals(999, Aggregators.get("ep999r3"), values);
     
-    assertEquals(500, Aggregators.get("ep50r7"), values);
-    assertEquals(750, Aggregators.get("ep75r7"), values);
-    assertEquals(900, Aggregators.get("ep90r7"), values);
-    assertEquals(950, Aggregators.get("ep95r7"), values);
-    assertEquals(990, Aggregators.get("ep99r7"), values);
-    assertEquals(999, Aggregators.get("ep999r7"), values);
+    assertAggregatorEquals(500, Aggregators.get("ep50r7"), values);
+    assertAggregatorEquals(750, Aggregators.get("ep75r7"), values);
+    assertAggregatorEquals(900, Aggregators.get("ep90r7"), values);
+    assertAggregatorEquals(950, Aggregators.get("ep95r7"), values);
+    assertAggregatorEquals(990, Aggregators.get("ep99r7"), values);
+    assertAggregatorEquals(999, Aggregators.get("ep999r7"), values);
   }
 
-  private void assertEquals(long value, Aggregator agg, Numbers numbers) {
-    Assert.assertEquals(value, agg.runLong(numbers));
-    numbers.reset();
-    Assert.assertEquals((double)value, agg.runDouble(numbers), 1.0);
+  @Test
+  public void testFirst() {
+    final long[] values = new long[10];
+    for (int i = 0; i < values.length; i++) {
+      values[i] = i;
+    }
+    
+    Aggregator agg = Aggregators.FIRST;
+    Numbers numbers = new Numbers(values);
+    assertEquals(0, agg.runLong(numbers));
+    
+    final double[] doubles = new double[10];
+    double val = 0.5;
+    for (int i = 0; i < doubles.length; i++) {
+      doubles[i] = val++;
+    }
+    
+    numbers = new Numbers(doubles);
+    assertEquals(0.5, agg.runDouble(numbers), EPSILON_PERCENTAGE);
+  }
+  
+  @Test
+  public void testLast() {
+    final long[] values = new long[10];
+    for (int i = 0; i < values.length; i++) {
+      values[i] = i;
+    }
+    
+    Aggregator agg = Aggregators.LAST;
+    Numbers numbers = new Numbers(values);
+    assertEquals(9, agg.runLong(numbers));
+    
+    final double[] doubles = new double[10];
+    double val = 0.5;
+    for (int i = 0; i < doubles.length; i++) {
+      doubles[i] = val++;
+    }
+    
+    numbers = new Numbers(doubles);
+    assertEquals(9.5, agg.runDouble(numbers), EPSILON_PERCENTAGE);
+  }
+  
+  private void assertAggregatorEquals(long value, Aggregator agg, Numbers numbers) {
+    if (numbers.isInteger()) {
+      Assert.assertEquals(value, agg.runLong(numbers));
+    } else {
+      Assert.assertEquals((double)value, agg.runDouble(numbers), 1.0);
+    }
     numbers.reset();
   }
 }
diff --git a/test/core/TestDownsampler.java b/test/core/TestDownsampler.java
index 32e94c8d2a..07f7296cdd 100644
--- a/test/core/TestDownsampler.java
+++ b/test/core/TestDownsampler.java
@@ -12,7 +12,6 @@
 // see <http://www.gnu.org/licenses/>.
 package net.opentsdb.core;
 
-
 import static org.junit.Assert.assertEquals;
 import static org.junit.Assert.assertFalse;
 import static org.junit.Assert.assertTrue;
@@ -20,16 +19,18 @@
 import static org.mockito.Mockito.spy;
 import static org.mockito.Mockito.verify;
 
+import java.util.Calendar;
 import java.util.List;
+import java.util.TimeZone;
 
 import com.google.common.collect.Lists;
 
+import net.opentsdb.core.SeekableViewsForTest.MockSeekableView;
 import net.opentsdb.utils.DateTime;
 
 import org.junit.Before;
 import org.junit.Test;
 
-
 /** Tests {@link Downsampler}. */
 public class TestDownsampler {
 
@@ -54,9 +55,19 @@ public class TestDownsampler {
       (int)DateTime.parseDuration("10s");
   private static final Aggregator AVG = Aggregators.get("avg");
   private static final Aggregator SUM = Aggregators.get("sum");
-
+  private static final TimeZone EST_TIME_ZONE = DateTime.timezones.get("EST");
+  //30 minute offset
+  final static TimeZone AF = DateTime.timezones.get("Asia/Kabul");
+  // 12h offset w/o DST
+  final static TimeZone TV = DateTime.timezones.get("Pacific/Funafuti");
+  // 12h offset w DST
+  final static TimeZone FJ = DateTime.timezones.get("Pacific/Fiji");
+  // Tue, 15 Dec 2015 04:02:25.123 UTC
+  final static long DST_TS = 1450137600000L;
+ 
   private SeekableView source;
   private Downsampler downsampler;
+  private DownsamplingSpecification specification;
 
   @Before
   public void before() {
@@ -65,7 +76,8 @@ public void before() {
 
   @Test
   public void testDownsampler() {
-    downsampler = new Downsampler(source, THOUSAND_SEC_INTERVAL, AVG);
+    specification = new DownsamplingSpecification("1000s-avg");
+    downsampler = new Downsampler(source, specification, 0, Long.MAX_VALUE);
     verify(source, never()).next();
     List<Double> values = Lists.newArrayList();
     List<Long> timestamps_in_millis = Lists.newArrayList();
@@ -90,7 +102,7 @@ public void testDownsampler() {
   }
 
   @Test
-  public void testDownsampler_10seconds() {
+  public void testDownsamplerDeprecated_10seconds() {
     source = spy(SeekableViewsForTest.fromArray(new DataPoint[] {
         MutableDataPoint.ofDoubleValue(BASE_TIME + 5000L * 0, 1),
         MutableDataPoint.ofDoubleValue(BASE_TIME + 5000L * 1, 2),
@@ -131,7 +143,49 @@ public void testDownsampler_10seconds() {
   }
 
   @Test
-  public void testDownsampler_15seconds() {
+  public void testDownsampler_10seconds() {
+    source = spy(SeekableViewsForTest.fromArray(new DataPoint[] {
+        MutableDataPoint.ofDoubleValue(BASE_TIME + 5000L * 0, 1),
+        MutableDataPoint.ofDoubleValue(BASE_TIME + 5000L * 1, 2),
+        MutableDataPoint.ofDoubleValue(BASE_TIME + 5000L * 2, 4),
+        MutableDataPoint.ofDoubleValue(BASE_TIME + 5000L * 3, 8),
+        MutableDataPoint.ofDoubleValue(BASE_TIME + 5000L * 4, 16),
+        MutableDataPoint.ofDoubleValue(BASE_TIME + 5000L * 5, 32),
+        MutableDataPoint.ofDoubleValue(BASE_TIME + 5000L * 6, 64),
+        MutableDataPoint.ofDoubleValue(BASE_TIME + 5000L * 7, 128),
+        MutableDataPoint.ofDoubleValue(BASE_TIME + 5000L * 8, 256),
+        MutableDataPoint.ofDoubleValue(BASE_TIME + 5000L * 9, 512),
+        MutableDataPoint.ofDoubleValue(BASE_TIME + 5000L * 10, 1024)
+    }));
+    specification = new DownsamplingSpecification("10s-sum");
+    downsampler = new Downsampler(source, specification, 0, Long.MAX_VALUE);
+    verify(source, never()).next();
+    List<Double> values = Lists.newArrayList();
+    List<Long> timestamps_in_millis = Lists.newArrayList();
+    while (downsampler.hasNext()) {
+      DataPoint dp = downsampler.next();
+      assertFalse(dp.isInteger());
+      values.add(dp.doubleValue());
+      timestamps_in_millis.add(dp.timestamp());
+    }
+
+    assertEquals(6, values.size());
+    assertEquals(3, values.get(0), 0.0000001);
+    assertEquals(BASE_TIME + 00000L, timestamps_in_millis.get(0).longValue());
+    assertEquals(12, values.get(1), 0.0000001);
+    assertEquals(BASE_TIME + 10000L, timestamps_in_millis.get(1).longValue());
+    assertEquals(48, values.get(2), 0.0000001);
+    assertEquals(BASE_TIME + 20000L, timestamps_in_millis.get(2).longValue());
+    assertEquals(192, values.get(3), 0.0000001);
+    assertEquals(BASE_TIME + 30000L, timestamps_in_millis.get(3).longValue());
+    assertEquals(768, values.get(4), 0.0000001);
+    assertEquals(BASE_TIME + 40000L, timestamps_in_millis.get(4).longValue());
+    assertEquals(1024, values.get(5), 0.0000001);
+    assertEquals(BASE_TIME + 50000L, timestamps_in_millis.get(5).longValue());
+  }
+  
+  @Test
+  public void testDownsamplerDeprecated_15seconds() {
     source = spy(SeekableViewsForTest.fromArray(new DataPoint[] {
         MutableDataPoint.ofLongValue(BASE_TIME + 5000L, 1),
         MutableDataPoint.ofLongValue(BASE_TIME + 15000L, 2),
@@ -162,6 +216,937 @@ public void testDownsampler_15seconds() {
     assertEquals(BASE_TIME + 45000L, timestamps_in_millis.get(3).longValue());
   }
 
+  @Test
+  public void testDownsampler_15seconds() {
+    source = spy(SeekableViewsForTest.fromArray(new DataPoint[] {
+        MutableDataPoint.ofLongValue(BASE_TIME + 5000L, 1),
+        MutableDataPoint.ofLongValue(BASE_TIME + 15000L, 2),
+        MutableDataPoint.ofLongValue(BASE_TIME + 25000L, 4),
+        MutableDataPoint.ofLongValue(BASE_TIME + 35000L, 8),
+        MutableDataPoint.ofLongValue(BASE_TIME + 45000L, 16),
+        MutableDataPoint.ofLongValue(BASE_TIME + 55000L, 32)
+    }));
+    specification = new DownsamplingSpecification("15s-sum");
+    downsampler = new Downsampler(source, specification, 0, Long.MAX_VALUE);
+    verify(source, never()).next();
+    List<Double> values = Lists.newArrayList();
+    List<Long> timestamps_in_millis = Lists.newArrayList();
+    while (downsampler.hasNext()) {
+      DataPoint dp = downsampler.next();
+      assertFalse(dp.isInteger());
+      values.add(dp.doubleValue());
+      timestamps_in_millis.add(dp.timestamp());
+    }
+
+    assertEquals(4, values.size());
+    assertEquals(1, values.get(0), 0.0000001);
+    assertEquals(BASE_TIME + 00000L, timestamps_in_millis.get(0).longValue());
+    assertEquals(6, values.get(1), 0.0000001);
+    assertEquals(BASE_TIME + 15000L, timestamps_in_millis.get(1).longValue());
+    assertEquals(8, values.get(2), 0.0000001);
+    assertEquals(BASE_TIME + 30000L, timestamps_in_millis.get(2).longValue());
+    assertEquals(48, values.get(3), 0.0000001);
+    assertEquals(BASE_TIME + 45000L, timestamps_in_millis.get(3).longValue());
+  }
+  
+  @Test
+  public void testDownsampler_allFullRange() {
+    source = spy(SeekableViewsForTest.fromArray(new DataPoint[] {
+        MutableDataPoint.ofLongValue(BASE_TIME + 5000L, 1),
+        MutableDataPoint.ofLongValue(BASE_TIME + 15000L, 2),
+        MutableDataPoint.ofLongValue(BASE_TIME + 25000L, 4),
+        MutableDataPoint.ofLongValue(BASE_TIME + 35000L, 8),
+        MutableDataPoint.ofLongValue(BASE_TIME + 45000L, 16),
+        MutableDataPoint.ofLongValue(BASE_TIME + 55000L, 32)
+    }));
+    specification = new DownsamplingSpecification("0all-sum");
+    downsampler = new Downsampler(source, specification, 0, Long.MAX_VALUE);
+    
+    verify(source, never()).next();
+    List<Double> values = Lists.newArrayList();
+    List<Long> timestamps_in_millis = Lists.newArrayList();
+    while (downsampler.hasNext()) {
+      DataPoint dp = downsampler.next();
+      assertFalse(dp.isInteger());
+      values.add(dp.doubleValue());
+      timestamps_in_millis.add(dp.timestamp());
+    }
+
+    assertEquals(1, values.size());
+    assertEquals(63, values.get(0), 0.0000001);
+    assertEquals(0L, timestamps_in_millis.get(0).longValue());
+  }
+  
+  @Test
+  public void testDownsampler_allFilterOnQuery() {
+    source = spy(SeekableViewsForTest.fromArray(new DataPoint[] {
+        MutableDataPoint.ofLongValue(BASE_TIME + 5000L, 1),
+        MutableDataPoint.ofLongValue(BASE_TIME + 15000L, 2),
+        MutableDataPoint.ofLongValue(BASE_TIME + 25000L, 4),
+        MutableDataPoint.ofLongValue(BASE_TIME + 35000L, 8),
+        MutableDataPoint.ofLongValue(BASE_TIME + 45000L, 16),
+        MutableDataPoint.ofLongValue(BASE_TIME + 55000L, 32)
+    }));
+    specification = new DownsamplingSpecification("0all-sum");
+    downsampler = new Downsampler(source, specification, 
+        BASE_TIME + 15000L, BASE_TIME + 45000L);
+    verify(source, never()).next();
+    List<Double> values = Lists.newArrayList();
+    List<Long> timestamps_in_millis = Lists.newArrayList();
+    while (downsampler.hasNext()) {
+      DataPoint dp = downsampler.next();
+      assertFalse(dp.isInteger());
+      values.add(dp.doubleValue());
+      timestamps_in_millis.add(dp.timestamp());
+    }
+
+    assertEquals(1, values.size());
+    assertEquals(14, values.get(0), 0.0000001);
+    assertEquals(BASE_TIME + 15000L, timestamps_in_millis.get(0).longValue());
+  }
+  
+  @Test
+  public void testDownsampler_allFilterOnQueryOutOfRangeEarly() {
+    source = spy(SeekableViewsForTest.fromArray(new DataPoint[] {
+        MutableDataPoint.ofLongValue(BASE_TIME + 5000L, 1),
+        MutableDataPoint.ofLongValue(BASE_TIME + 15000L, 2),
+        MutableDataPoint.ofLongValue(BASE_TIME + 25000L, 4),
+        MutableDataPoint.ofLongValue(BASE_TIME + 35000L, 8),
+        MutableDataPoint.ofLongValue(BASE_TIME + 45000L, 16),
+        MutableDataPoint.ofLongValue(BASE_TIME + 55000L, 32)
+    }));
+    specification = new DownsamplingSpecification("0all-sum");
+    downsampler = new Downsampler(source, specification, 
+        BASE_TIME + 65000L, BASE_TIME + 75000L);
+    verify(source, never()).next();
+    List<Double> values = Lists.newArrayList();
+    List<Long> timestamps_in_millis = Lists.newArrayList();
+    while (downsampler.hasNext()) {
+      DataPoint dp = downsampler.next();
+      assertFalse(dp.isInteger());
+      values.add(dp.doubleValue());
+      timestamps_in_millis.add(dp.timestamp());
+    }
+
+    assertEquals(0, values.size());
+  }
+  
+  @Test
+  public void testDownsampler_allFilterOnQueryOutOfRangeLate() {
+    source = spy(SeekableViewsForTest.fromArray(new DataPoint[] {
+        MutableDataPoint.ofLongValue(BASE_TIME + 5000L, 1),
+        MutableDataPoint.ofLongValue(BASE_TIME + 15000L, 2),
+        MutableDataPoint.ofLongValue(BASE_TIME + 25000L, 4),
+        MutableDataPoint.ofLongValue(BASE_TIME + 35000L, 8),
+        MutableDataPoint.ofLongValue(BASE_TIME + 45000L, 16),
+        MutableDataPoint.ofLongValue(BASE_TIME + 55000L, 32)
+    }));
+    specification = new DownsamplingSpecification("0all-sum");
+    downsampler = new Downsampler(source, specification, 
+        BASE_TIME - 15000L, BASE_TIME - 5000L);
+    verify(source, never()).next();
+    List<Double> values = Lists.newArrayList();
+    List<Long> timestamps_in_millis = Lists.newArrayList();
+    while (downsampler.hasNext()) {
+      DataPoint dp = downsampler.next();
+      assertFalse(dp.isInteger());
+      values.add(dp.doubleValue());
+      timestamps_in_millis.add(dp.timestamp());
+    }
+
+    assertEquals(0, values.size());
+  }
+  
+  @Test
+  public void testDownsampler_calendar() {
+    source = spy(SeekableViewsForTest.fromArray(new DataPoint[] {
+        MutableDataPoint.ofLongValue(BASE_TIME + 5000L, 1),
+        MutableDataPoint.ofLongValue(BASE_TIME + 15000L, 2),
+        MutableDataPoint.ofLongValue(BASE_TIME + 25000L, 4),
+        MutableDataPoint.ofLongValue(BASE_TIME + 35000L, 8),
+        MutableDataPoint.ofLongValue(BASE_TIME + 45000L, 16),
+        MutableDataPoint.ofLongValue(BASE_TIME + 55000L, 32)
+    }));
+    specification = new DownsamplingSpecification("1dc-sum");
+    specification.setTimezone(DateTime.timezones.get("America/Denver"));
+    downsampler = new Downsampler(source, specification, 0, Long.MAX_VALUE);
+    verify(source, never()).next();
+    List<Double> values = Lists.newArrayList();
+    List<Long> timestamps_in_millis = Lists.newArrayList();
+    while (downsampler.hasNext()) {
+      DataPoint dp = downsampler.next();
+      assertFalse(dp.isInteger());
+      values.add(dp.doubleValue());
+      timestamps_in_millis.add(dp.timestamp());
+    }
+
+    assertEquals(1, values.size());
+    assertEquals(63, values.get(0), 0.0000001);
+    assertEquals(1356937200000L, timestamps_in_millis.get(0).longValue());
+  }
+  
+  @Test
+  public void testDownsampler_calendarHour() {
+    source = spy(SeekableViewsForTest.fromArray(new DataPoint[] {
+        MutableDataPoint.ofLongValue(BASE_TIME, 1),
+        MutableDataPoint.ofLongValue(BASE_TIME + 1800000, 2),
+        MutableDataPoint.ofLongValue(BASE_TIME + 3599000L, 3),
+        MutableDataPoint.ofLongValue(BASE_TIME + 3600000L, 4),
+        MutableDataPoint.ofLongValue(BASE_TIME + 5400000L, 5),
+        MutableDataPoint.ofLongValue(BASE_TIME + 7199000L, 6)
+    }));
+    specification = new DownsamplingSpecification("1hc-sum");
+    specification.setTimezone(TV);
+    downsampler = new Downsampler(source, specification, 0, Long.MAX_VALUE);
+
+    long ts = BASE_TIME;
+    double value = 6;
+    while (downsampler.hasNext()) {
+      DataPoint dp = downsampler.next();
+      assertFalse(dp.isInteger());
+      assertEquals(ts, dp.timestamp());
+      assertEquals(value, dp.doubleValue(), 0.001);
+      ts += 3600000;
+      value = 15;
+    }
+
+    // hour offset by 30m
+    ((MockSeekableView)source).resetIndex();
+    specification = new DownsamplingSpecification("1hc-sum");
+    specification.setTimezone(AF);
+    downsampler = new Downsampler(source, specification, 0, Long.MAX_VALUE);
+
+    ts = 1356996600000L;
+    value = 1;
+    while (downsampler.hasNext()) {
+      DataPoint dp = downsampler.next();
+      assertFalse(dp.isInteger());
+      assertEquals(ts, dp.timestamp());
+      assertEquals(value, dp.doubleValue(), 0.001);
+      ts += 3600000;
+      if (value == 1) {
+        value = 9;
+      } else {
+        value = 11;
+      }
+    }
+    
+    // multiple hours
+    ((MockSeekableView)source).resetIndex();
+    specification = new DownsamplingSpecification("4hc-sum");
+    specification.setTimezone(AF);
+    downsampler = new Downsampler(source, specification, 0, Long.MAX_VALUE);
+
+    ts = 1356996600000L;
+    value = 21;
+    while (downsampler.hasNext()) {
+      DataPoint dp = downsampler.next();
+      assertFalse(dp.isInteger());
+      assertEquals(ts, dp.timestamp());
+      assertEquals(value, dp.doubleValue(), 0.001);
+    }
+  }
+  
+  @Test
+  public void testDownsampler_calendarDay() {
+    source = spy(SeekableViewsForTest.fromArray(new DataPoint[] {
+        MutableDataPoint.ofLongValue(DST_TS, 1),
+        MutableDataPoint.ofLongValue(DST_TS + 86399000, 2),
+        MutableDataPoint.ofLongValue(DST_TS + 126001000L, 3), // falls to the next in FJ
+        MutableDataPoint.ofLongValue(DST_TS + 172799000L, 4),
+        MutableDataPoint.ofLongValue(DST_TS + 172800000L, 5),
+        MutableDataPoint.ofLongValue(DST_TS + 242999000L, 6) // falls within 30m offset
+    }));
+    
+    // control
+    specification = new DownsamplingSpecification("1dc-sum");
+    downsampler = new Downsampler(source, specification, 0, Long.MAX_VALUE);
+
+    long ts = DST_TS;
+    double value = 3;
+    while (downsampler.hasNext()) {
+      DataPoint dp = downsampler.next();
+      assertFalse(dp.isInteger());
+      assertEquals(ts, dp.timestamp());
+      assertEquals(value, dp.doubleValue(), 0.001);
+      ts += 86400000;
+      if (value == 3) {
+        value = 7;
+      } else if (value == 7) {
+        value = 11;
+      }
+    }
+
+    // 12 hour offset from UTC
+    ((MockSeekableView)source).resetIndex();
+    specification = new DownsamplingSpecification("1dc-sum");
+    specification.setTimezone(TV);
+    downsampler = new Downsampler(source, specification, 0, Long.MAX_VALUE);
+
+    ts = 1450094400000L;
+    value = 1;
+    while (downsampler.hasNext()) {
+      DataPoint dp = downsampler.next();
+      assertFalse(dp.isInteger());
+      assertEquals(ts, dp.timestamp());
+      assertEquals(value, dp.doubleValue(), 0.001);
+      ts += 86400000;
+      if (value == 1) {
+        value = 5;
+      } else if (value == 5) {
+        value = 9;
+      } else {
+        value = 6;
+      }
+    }
+    
+    // 11 hour offset from UTC
+    ((MockSeekableView)source).resetIndex();
+    specification = new DownsamplingSpecification("1dc-sum");
+    specification.setTimezone(FJ);
+    downsampler = new Downsampler(source, specification, 0, Long.MAX_VALUE);
+
+    ts = 1450090800000L;
+    value = 1;
+    while (downsampler.hasNext()) {
+      DataPoint dp = downsampler.next();
+      assertFalse(dp.isInteger());
+      assertEquals(ts, dp.timestamp());
+      assertEquals(value, dp.doubleValue(), 0.001);
+      ts += 86400000;
+      if (value == 1) {
+        value = 2;
+      } else if (value == 2) {
+        value = 12;
+      } else {
+        value = 6;
+      }
+    }
+    
+    // 30m offset
+    ((MockSeekableView)source).resetIndex();
+    specification = new DownsamplingSpecification("1dc-sum");
+    specification.setTimezone(AF);
+    downsampler = new Downsampler(source, specification, 0, Long.MAX_VALUE);
+
+    ts = 1450121400000L;
+    value = 1;
+    while (downsampler.hasNext()) {
+      DataPoint dp = downsampler.next();
+      assertFalse(dp.isInteger());
+      assertEquals(ts, dp.timestamp());
+      assertEquals(value, dp.doubleValue(), 0.001);
+      ts += 86400000;
+      if (value == 1) {
+        value = 5;
+      } else if (value == 5) {
+        value = 15;
+      }
+    }
+    
+    // multiple days
+    ((MockSeekableView)source).resetIndex();
+    specification = new DownsamplingSpecification("3dc-sum");
+    specification.setTimezone(AF);
+    downsampler = new Downsampler(source, specification, 0, Long.MAX_VALUE);
+
+    ts = 1450121400000L;
+    value = 21;
+    while (downsampler.hasNext()) {
+      DataPoint dp = downsampler.next();
+      assertFalse(dp.isInteger());
+      assertEquals(ts, dp.timestamp());
+      assertEquals(value, dp.doubleValue(), 0.001);
+    }
+  }
+  
+  @Test
+  public void testDownsampler_calendarWeek() {
+    source = SeekableViewsForTest.fromArray(new DataPoint[] {
+        MutableDataPoint.ofLongValue(DST_TS, 1), // a Tuesday in UTC land
+        MutableDataPoint.ofLongValue(DST_TS + (86400000L * 7), 2),
+        MutableDataPoint.ofLongValue(1451129400000L, 3), // falls to the next in FJ
+        MutableDataPoint.ofLongValue(DST_TS + (86400000L * 21), 4),
+        MutableDataPoint.ofLongValue(1452367799000L, 5) // falls within 30m offset
+    });
+    // control
+    specification = new DownsamplingSpecification("1wc-sum");
+    downsampler = new Downsampler(source, specification, 0, Long.MAX_VALUE);
+    
+    long ts = 1449964800000L;
+    double value = 1;
+    while (downsampler.hasNext()) {
+      DataPoint dp = downsampler.next();
+      assertFalse(dp.isInteger());
+      assertEquals(ts, dp.timestamp());
+      assertEquals(value, dp.doubleValue(), 0.001);
+      if (ts == 1450569600000L) {
+        ts = 1451779200000L; // skips a week
+      } else {
+        ts += 86400000L * 7;
+      }
+      if (value == 1) {
+        value = 5;
+      } else {
+        value = 9;
+      }
+    }
+
+    // 12 hour offset from UTC
+    ((MockSeekableView)source).resetIndex();
+    specification = new DownsamplingSpecification("1wc-sum");
+    specification.setTimezone(TV);
+    downsampler = new Downsampler(source, specification, 0, Long.MAX_VALUE);
+
+    ts = 1449921600000L;
+    value = 1;
+    while (downsampler.hasNext()) {
+      DataPoint dp = downsampler.next();
+      assertFalse(dp.isInteger());
+      assertEquals(ts, dp.timestamp());
+      assertEquals(value, dp.doubleValue(), 0.001);
+      if (ts == 1450526400000L) {
+        ts = 1451736000000L; // skip a week
+      } else {
+        ts += 86400000L * 7;
+      }
+      if (value == 1) {
+        value = 5;
+      } else if (value == 5) {
+        value = 4;
+      } else {
+        value = 5;
+      }
+    }
+    
+    // 11 hour offset from UTC
+    ((MockSeekableView)source).resetIndex();
+    specification = new DownsamplingSpecification("1wc-sum");
+    specification.setTimezone(FJ);
+    downsampler = new Downsampler(source, specification, 0, Long.MAX_VALUE);
+
+    ts = 1449918000000L;
+    value = 1;
+    while (downsampler.hasNext()) {
+      DataPoint dp = downsampler.next();
+      assertFalse(dp.isInteger());
+      assertEquals(ts, dp.timestamp());
+      assertEquals(value, dp.doubleValue(), 0.001);
+      ts += 86400000L * 7;
+      value++;
+    }
+    
+    // 30m offset
+    ((MockSeekableView)source).resetIndex();
+    specification = new DownsamplingSpecification("1wc-sum");
+    specification.setTimezone(AF);
+    downsampler = new Downsampler(source, specification, 0, Long.MAX_VALUE);
+
+    ts = 1449948600000L;
+    value = 1;
+    while (downsampler.hasNext()) {
+      DataPoint dp = downsampler.next();
+      assertFalse(dp.isInteger());
+      assertEquals(ts, dp.timestamp());
+      assertEquals(value, dp.doubleValue(), 0.001);
+      if (ts == 1449948600000L) {
+        ts = 1450553400000L;
+      } else {
+        ts = 1451763000000L;
+      }
+      if (value == 1) {
+        value = 5;
+      } else {
+        value = 9;
+      }
+    }
+    
+    // multiple weeks
+    ((MockSeekableView)source).resetIndex();
+    specification = new DownsamplingSpecification("2wc-sum");
+    specification.setTimezone(AF);
+    downsampler = new Downsampler(source, specification, 0, Long.MAX_VALUE);
+
+    ts = 1449948600000L;
+    value = 6;
+    while (downsampler.hasNext()) {
+      DataPoint dp = downsampler.next();
+      assertFalse(dp.isInteger());
+      assertEquals(ts, dp.timestamp());
+      assertEquals(value, dp.doubleValue(), 0.001);
+      ts = 1451158200000L;
+      value = 9;
+    }
+  }
+  
+  @Test
+  public void testDownsampler_calendarMonth() {
+    final long dec_1st = 1448928000000L;
+    source = spy(SeekableViewsForTest.fromArray(new DataPoint[] {
+        MutableDataPoint.ofLongValue(dec_1st, 1),
+        MutableDataPoint.ofLongValue(1451559600000L, 2), // falls to the next in FJ
+        MutableDataPoint.ofLongValue(1451606400000L, 3), // jan 1st
+        MutableDataPoint.ofLongValue(1454284800000L, 4), // feb 1st
+        MutableDataPoint.ofLongValue(1456704000000L, 5), // feb 29th (leap year)
+        MutableDataPoint.ofLongValue(1456772400000L, 6)  // falls within 30m offset AF
+    }));
+    
+    // control
+    specification = new DownsamplingSpecification("1nc-sum");
+    downsampler = new Downsampler(source, specification, 0, Long.MAX_VALUE);
+
+    long ts = dec_1st;
+    double value = 3;
+    while (downsampler.hasNext()) {
+      DataPoint dp = downsampler.next();
+      assertFalse(dp.isInteger());
+      assertEquals(ts, dp.timestamp());
+      assertEquals(value, dp.doubleValue(), 0.001);
+      if (ts == 1448928000000L) {
+        ts = 1451606400000L;
+      } else {
+        ts = 1454284800000L;
+        value = 15;
+      }
+    }
+    
+    // 12h offset
+    ((MockSeekableView)source).resetIndex();
+    specification = new DownsamplingSpecification("1nc-sum");
+    specification.setTimezone(TV);
+    downsampler = new Downsampler(source, specification, 0, Long.MAX_VALUE);
+
+    ts = 1448884800000L;
+    value = 3;
+    while (downsampler.hasNext()) {
+      DataPoint dp = downsampler.next();
+      assertFalse(dp.isInteger());
+      assertEquals(ts, dp.timestamp());
+      assertEquals(value, dp.doubleValue(), 0.001);
+      if (ts == 1448884800000L) {
+        ts = 1451563200000L;
+      } else if (ts == 1451563200000L) {
+        value = 9;
+        ts = 1454241600000L;
+      } else {
+        ts = 1456747200000L;
+        value = 6;
+      }
+    }
+    
+    // 11h offset
+    ((MockSeekableView)source).resetIndex();
+    specification = new DownsamplingSpecification("1nc-sum");
+    specification.setTimezone(FJ);
+    downsampler = new Downsampler(source, specification, 0, Long.MAX_VALUE);
+
+    ts = 1448881200000L;
+    value = 1;
+    while (downsampler.hasNext()) {
+      DataPoint dp = downsampler.next();
+      assertFalse(dp.isInteger());
+      assertEquals(ts, dp.timestamp());
+      if (ts == 1448881200000L) {
+        ts = 1451559600000L;
+        value = 5;
+      } else if (ts == 1451559600000L) {
+        ts = 1454241600000L;
+        value = 9;
+      } else {
+        ts = 1456747200000L;
+        value = 6;
+      }
+    }
+    
+    // 30m offset
+    ((MockSeekableView)source).resetIndex();
+    specification = new DownsamplingSpecification("1nc-sum");
+    specification.setTimezone(AF);
+    downsampler = new Downsampler(source, specification, 0, Long.MAX_VALUE);
+
+    ts = 1448911800000L;
+    value = 3;
+    while (downsampler.hasNext()) {
+      DataPoint dp = downsampler.next();
+      assertFalse(dp.isInteger());
+      assertEquals(ts, dp.timestamp());
+      assertEquals(value, dp.doubleValue(), 0.001);
+      if (ts == 1448911800000L) {
+        ts = 1451590200000L;
+      } else {
+        ts = 1454268600000L;
+        value = 15;
+      }
+    }
+    
+    // multiple months
+    ((MockSeekableView)source).resetIndex();
+    specification = new DownsamplingSpecification("3nc-sum");
+    specification.setTimezone(TV);
+    downsampler = new Downsampler(source, specification, 0, Long.MAX_VALUE);
+
+    ts = 1443614400000L;
+    value = 3;
+    while (downsampler.hasNext()) {
+      DataPoint dp = downsampler.next();
+      assertFalse(dp.isInteger());
+      assertEquals(ts, dp.timestamp());
+      assertEquals(value, dp.doubleValue(), 0.001);
+      ts = 1451563200000L;
+      value = 18;
+    }
+  }
+  
+  @Test
+  public void testDownsampler_noData() {
+    source = spy(SeekableViewsForTest.fromArray(new DataPoint[] { }));
+    specification = new DownsamplingSpecification("1d-sum");
+    downsampler = new Downsampler(source, specification, 0, Long.MAX_VALUE);
+    verify(source, never()).next();
+    assertFalse(downsampler.hasNext());
+  }
+  
+  @Test
+  public void testDownsampler_noDataCalendar() {
+    source = spy(SeekableViewsForTest.fromArray(new DataPoint[] { }));
+    specification = new DownsamplingSpecification("1mc-sum");
+    downsampler = new Downsampler(source, specification, 0, Long.MAX_VALUE);
+    verify(source, never()).next();
+    assertFalse(downsampler.hasNext());
+  }
+  
+  @Test
+  public void testDownsampler_1day() {
+    source = spy(SeekableViewsForTest.fromArray(new DataPoint[] {
+        MutableDataPoint.ofLongValue(BASE_TIME, 1),
+        MutableDataPoint.ofLongValue(BASE_TIME + 43200000L, 2),
+        MutableDataPoint.ofLongValue(BASE_TIME + 86400000L, 4),
+        MutableDataPoint.ofLongValue(BASE_TIME + 129600000L, 8)
+    }));
+    
+    downsampler = new Downsampler(source, 86400000, SUM);
+    verify(source, never()).next();
+    long timestamp = BASE_TIME;
+    double value = 3;
+    while (downsampler.hasNext()) {
+      DataPoint dp = downsampler.next();
+      assertFalse(dp.isInteger());
+      assertEquals(timestamp, dp.timestamp());
+      assertEquals(value, dp.doubleValue(), 0.000001);
+      timestamp = 1357084800000L;
+      value = 12;
+    }
+  }
+
+  @Test
+  public void testDownsampler_1day_timezone() {
+    source = spy(SeekableViewsForTest.fromArray(new DataPoint[] {
+        MutableDataPoint.ofLongValue(1357016400000L, 1),
+        MutableDataPoint.ofLongValue(1357059600000L, 2),
+        MutableDataPoint.ofLongValue(1357102800000L, 4),
+        MutableDataPoint.ofLongValue(1357146000000L, 8)
+    }));
+    
+    specification = new DownsamplingSpecification("1dc-sum");
+    specification.setTimezone(EST_TIME_ZONE);
+    downsampler = new Downsampler(source, specification, 0, Long.MAX_VALUE);
+    verify(source, never()).next();
+    
+    long timestamp = 1357016400000L;
+    double value = 3;
+    while (downsampler.hasNext()) {
+      DataPoint dp = downsampler.next();
+      assertFalse(dp.isInteger());
+      assertEquals(timestamp, dp.timestamp());
+      assertEquals(value, dp.doubleValue(), 0.000001);
+      timestamp = 1357102800000L;
+      value = 12;
+    }
+  }
+  
+  @Test
+  public void testDownsampler_1week() {
+    source = spy(SeekableViewsForTest.fromArray(new DataPoint[] {
+        MutableDataPoint.ofLongValue(1356825600000L, 1),
+        MutableDataPoint.ofLongValue(1357128000000L, 2),
+        MutableDataPoint.ofLongValue(1357430400000L, 4),
+        MutableDataPoint.ofLongValue(1357732800000L, 8)
+    }));
+    
+    specification = new DownsamplingSpecification("1wc-sum");
+    downsampler = new Downsampler(source, specification, 0, Long.MAX_VALUE);
+    verify(source, never()).next();
+    long timestamp = 1356825600000L;
+    double value = 3;
+    while (downsampler.hasNext()) {
+      DataPoint dp = downsampler.next();
+      assertFalse(dp.isInteger());
+      assertEquals(timestamp, dp.timestamp());
+      assertEquals(value, dp.doubleValue(), 0.000001);
+      timestamp = 1357430400000L;
+      value = 12;
+    }
+  }
+
+  @Test
+  public void testDownsampler_1week_timezone() {
+    source = spy(SeekableViewsForTest.fromArray(new DataPoint[] {
+        MutableDataPoint.ofLongValue(1356843600000L, 1),
+        MutableDataPoint.ofLongValue(1357146000000L, 2),
+        MutableDataPoint.ofLongValue(1357448400000L, 4),
+        MutableDataPoint.ofLongValue(1357750800000L, 8)
+    }));
+    
+    specification = new DownsamplingSpecification("1wc-sum");
+    specification.setTimezone(EST_TIME_ZONE);
+    downsampler = new Downsampler(source, specification, 0, Long.MAX_VALUE);
+    verify(source, never()).next();
+    long timestamp = 1356843600000L;
+    double value = 3;
+    while (downsampler.hasNext()) {
+      DataPoint dp = downsampler.next();
+      assertFalse(dp.isInteger());
+      assertEquals(timestamp, dp.timestamp());
+      assertEquals(value, dp.doubleValue(), 0.000001);
+      timestamp = 1357448400000L;
+      value = 12;
+    }
+  }
+
+  @Test
+  public void testDownsampler_1month() {
+    final int field = DateTime.unitsToCalendarType("n");
+    final DataPoint [] data_points = new DataPoint[24];
+    Calendar c = DateTime.previousInterval(BASE_TIME, 1, field);
+    //long timestamp = DateTime.toStartOfMonth(BASE_TIME, UTC_TIME_ZONE);
+    long timestamp = c.getTimeInMillis();
+    for (int i = 0; i < data_points.length; i++) {
+      long value = 1 << i;
+      data_points[i] = MutableDataPoint.ofLongValue(timestamp, value);
+
+      i += 1;
+      c.add(field, 1);
+      long startOfNextInterval = c.getTimeInMillis() + 1;
+      timestamp = timestamp + (startOfNextInterval - timestamp) / 2;
+      value = 1 << i;
+      data_points[i] = MutableDataPoint.ofLongValue(timestamp, value);
+      timestamp = startOfNextInterval;
+    }
+    
+    source = spy(SeekableViewsForTest.fromArray(data_points));
+
+    specification = new DownsamplingSpecification("1nc-sum");
+    downsampler = new Downsampler(source, specification, 0, Long.MAX_VALUE);
+    verify(source, never()).next();
+    c = DateTime.previousInterval(BASE_TIME, 1, field);
+    int j = 0;
+    while (downsampler.hasNext()) {
+      DataPoint dp = downsampler.next();
+      assertFalse(dp.isInteger());
+      assertEquals((1 << j++) + (1 << j++), dp.doubleValue(), 0.0000001);
+      assertEquals(c.getTimeInMillis(), dp.timestamp());
+      c.add(field, 1);
+    }
+  }
+  
+  @Test
+  public void testDownsampler_1month_alt() {
+    /*
+    1380600000 -> 2013-10-01T04:00:00Z
+    1383278400 -> 2013-11-01T04:00:00Z
+    1385874000 -> 2013-12-01T05:00:00Z
+    1388552400 -> 2014-01-01T05:00:00Z
+    1391230800 -> 2014-02-01T05:00:00Z
+    1393650000 -> 2014-03-01T05:00:00Z
+    1396324800 -> 2014-04-01T04:00:00Z
+    1398916800 -> 2014-05-01T04:00:00Z
+    1401595200 -> 2014-06-01T04:00:00Z
+    1404187200 -> 2014-07-01T04:00:00Z
+    1406865600 -> 2014-08-01T04:00:00Z
+    1409544000 -> 2014-09-01T04:00:00Z
+    */
+
+    int value = 1;
+    final DataPoint [] data_points = new DataPoint[] {
+      MutableDataPoint.ofLongValue(1380600000000L, value), 
+      MutableDataPoint.ofLongValue(1383278400000L, value), 
+      MutableDataPoint.ofLongValue(1385874000000L, value), 
+      MutableDataPoint.ofLongValue(1388552400000L, value), 
+      MutableDataPoint.ofLongValue(1391230800000L, value), 
+      MutableDataPoint.ofLongValue(1393650000000L, value), 
+      MutableDataPoint.ofLongValue(1396324800000L, value), 
+      MutableDataPoint.ofLongValue(1398916800000L, value), 
+      MutableDataPoint.ofLongValue(1401595200000L, value), 
+      MutableDataPoint.ofLongValue(1404187200000L, value), 
+      MutableDataPoint.ofLongValue(1406865600000L, value), 
+      MutableDataPoint.ofLongValue(1409544000000L, value), 
+    };
+    
+    source = spy(SeekableViewsForTest.fromArray(data_points));
+    
+    specification = new DownsamplingSpecification("1dc-sum");
+    downsampler = new Downsampler(source, specification, 0, Long.MAX_VALUE);
+    verify(source, never()).next();
+    final int field = DateTime.unitsToCalendarType("n");
+    final Calendar c = DateTime.previousInterval(1380585600000L, 1, field);
+    long timestamp = c.getTimeInMillis();
+    while (downsampler.hasNext()) {
+      DataPoint dp = downsampler.next();
+      assertFalse(dp.isInteger());
+      assertEquals(1, dp.doubleValue(), 0.0000001);
+      assertEquals(timestamp, dp.timestamp());
+      c.add(field, 1);
+      timestamp = c.getTimeInMillis();
+    }
+  }
+  
+  @Test
+  public void testDownsampler_2months() {
+    final int field = DateTime.unitsToCalendarType("n");
+    final DataPoint [] data_points = new DataPoint[24];
+    Calendar c = DateTime.previousInterval(BASE_TIME, 1, field);
+    long timestamp = c.getTimeInMillis();
+    for (int i = 0; i < data_points.length; i++) {
+      long value = 1 << i;
+      data_points[i] = MutableDataPoint.ofLongValue(timestamp, value);
+
+      i += 1;
+      c.add(field, 1);
+      long startOfNextInterval = c.getTimeInMillis();
+      timestamp = timestamp + (startOfNextInterval - timestamp) / 2;
+      value = 1 << i;
+      data_points[i] = MutableDataPoint.ofLongValue(timestamp, value);
+      timestamp = startOfNextInterval;
+    }
+    
+    source = spy(SeekableViewsForTest.fromArray(data_points));
+    
+    specification = new DownsamplingSpecification("2nc-sum");
+    downsampler = new Downsampler(source, specification, 0, Long.MAX_VALUE);
+    verify(source, never()).next();
+    int j = 0;
+    c = DateTime.previousInterval(BASE_TIME, 1, field);
+    while (downsampler.hasNext()) {
+      DataPoint dp = downsampler.next();
+      assertFalse(dp.isInteger());
+      long value = 0;
+      for (int k = 0; k < 4; k++) {
+        value += (1 << j++);
+      }
+      assertEquals(value, dp.doubleValue(), 0.0000001);
+      assertEquals(c.getTimeInMillis(), dp.timestamp());
+      c.add(field, 2);
+    }
+  }
+  
+  @Test
+  public void testDownsampler_1month_timezone() {
+    final int field = DateTime.unitsToCalendarType("n");
+    final DataPoint [] data_points = new DataPoint[24];
+    Calendar c = DateTime.previousInterval(1357016400000L, 1, field, EST_TIME_ZONE);
+    long timestamp = c.getTimeInMillis();
+    for (int i = 0; i < data_points.length; i++) {
+      long value = 1 << i;
+      data_points[i] = MutableDataPoint.ofLongValue(timestamp, value);
+
+      i += 1;
+      c.add(field, 1);
+      long startOfNextInterval = c.getTimeInMillis();
+      timestamp = timestamp + (startOfNextInterval - timestamp) / 2;
+      value = 1 << i;
+      data_points[i] = MutableDataPoint.ofLongValue(timestamp, value);
+      timestamp = startOfNextInterval;
+    }
+    
+    source = spy(SeekableViewsForTest.fromArray(data_points));
+    
+    specification = new DownsamplingSpecification("1nc-sum");
+    specification.setTimezone(EST_TIME_ZONE);
+    downsampler = new Downsampler(source, specification, 0, Long.MAX_VALUE);
+    verify(source, never()).next();
+    int j = 0;
+    c = DateTime.previousInterval(1357016400000L, 1, field, EST_TIME_ZONE);
+    while (downsampler.hasNext()) {
+      DataPoint dp = downsampler.next();
+      assertFalse(dp.isInteger());
+      assertEquals((1 << j++) + (1 << j++), dp.doubleValue(), 0.0000001);
+      assertEquals(c.getTimeInMillis(), dp.timestamp());
+      c.add(field, 1);
+    }
+  }
+
+  @Test
+  public void testDownsampler_1year() {
+    final int field = DateTime.unitsToCalendarType("y");
+    final DataPoint [] data_points = new DataPoint[4];
+    Calendar c = DateTime.previousInterval(BASE_TIME, 1, field);
+    long timestamp = c.getTimeInMillis();
+    for (int i = 0; i < data_points.length; i++) {
+      long value = 1 << i;
+      data_points[i] = MutableDataPoint.ofLongValue(timestamp, value);
+
+      i += 1;
+      c.add(field, 1);
+      long startOfNextInterval = c.getTimeInMillis();
+      timestamp = timestamp + (startOfNextInterval - timestamp) / 2;
+      value = 1 << i;
+      data_points[i] = MutableDataPoint.ofLongValue(timestamp, value);
+      timestamp = startOfNextInterval;
+    }
+    
+    source = spy(SeekableViewsForTest.fromArray(data_points));
+    
+    specification = new DownsamplingSpecification("1yc-sum");
+    downsampler = new Downsampler(source, specification, 0, Long.MAX_VALUE);
+    verify(source, never()).next();
+    int j = 0;
+    c = DateTime.previousInterval(BASE_TIME, 1, field);
+    while (downsampler.hasNext()) {
+      DataPoint dp = downsampler.next();
+      assertFalse(dp.isInteger());
+      assertEquals((1 << j++) + (1 << j++), dp.doubleValue(), 0.0000001);
+      assertEquals(c.getTimeInMillis(), dp.timestamp());
+      c.add(field, 1);
+    }
+  }
+
+  @Test
+  public void testDownsampler_1year_timezone() {
+    final int field = DateTime.unitsToCalendarType("y");
+    final DataPoint [] data_points = new DataPoint[4];
+    Calendar c = DateTime.previousInterval(1357016400000L, 1, field, 
+        EST_TIME_ZONE);
+    long timestamp = c.getTimeInMillis();
+    for (int i = 0; i < data_points.length; i++) {
+      long value = 1 << i;
+      data_points[i] = MutableDataPoint.ofLongValue(timestamp, value);
+
+      i += 1;
+      c.add(field, 1);
+      long startOfNextInterval = c.getTimeInMillis();
+      timestamp = timestamp + (startOfNextInterval - timestamp) / 2;
+      value = 1 << i;
+      data_points[i] = MutableDataPoint.ofLongValue(timestamp, value);
+      timestamp = startOfNextInterval;
+    }
+    
+    source = spy(SeekableViewsForTest.fromArray(data_points));
+    
+    specification = new DownsamplingSpecification("1yc-sum");
+    specification.setTimezone(EST_TIME_ZONE);
+    downsampler = new Downsampler(source, specification, 0, Long.MAX_VALUE);
+    verify(source, never()).next();
+    int j = 0;
+    c = DateTime.previousInterval(1357016400000L, 1, field, EST_TIME_ZONE);
+    while (downsampler.hasNext()) {
+      DataPoint dp = downsampler.next();
+      assertFalse(dp.isInteger());
+      assertEquals((1 << j++) + (1 << j++), dp.doubleValue(), 0.0000001);
+      assertEquals(c.getTimeInMillis(), dp.timestamp());
+      c.add(field, 1);
+    }
+  }
+  
   @Test(expected = UnsupportedOperationException.class)
   public void testRemove() {
     new Downsampler(source, THOUSAND_SEC_INTERVAL, AVG).remove();
@@ -190,6 +1175,46 @@ public void testSeek() {
     assertEquals(BASE_TIME + 8600000L, timestamps_in_millis.get(2).longValue());
   }
 
+  @Test
+  public void testSeek_useCalendar() {
+    source = spy(SeekableViewsForTest.fromArray(new DataPoint[] {
+        MutableDataPoint.ofLongValue(1356998400000L, 1),
+        MutableDataPoint.ofLongValue(1388534400000L, 2),
+        MutableDataPoint.ofLongValue(1420070400000L, 4),
+        MutableDataPoint.ofLongValue(1451606400000L, 8)
+    }));
+    
+    specification = new DownsamplingSpecification("1y-sum");
+    specification.setUseCalendar(true);
+    downsampler = new Downsampler(source, specification, 0, Long.MAX_VALUE);
+    
+    downsampler.seek(1420070400000L);
+    verify(source, never()).next();
+    
+    long timestamp = 1420070400000L;
+    double value = 4;
+    while (downsampler.hasNext()) {
+      DataPoint dp = downsampler.next();
+      assertFalse(dp.isInteger());
+      assertEquals(timestamp, dp.timestamp());
+      assertEquals(value, dp.doubleValue(), 0.0000001);
+      timestamp = 1451606400000L;
+      value = 8;
+    }
+    
+    ((MockSeekableView)source).resetIndex();
+    specification = new DownsamplingSpecification("1yc-sum");
+    downsampler = new Downsampler(source, specification, 0, Long.MAX_VALUE);
+    downsampler.seek(1420070400001L);
+    
+    while (downsampler.hasNext()) {
+      DataPoint dp = downsampler.next();
+      assertFalse(dp.isInteger());
+      assertEquals(timestamp, dp.timestamp());
+      assertEquals(value, dp.doubleValue(), 0.0000001);
+    }
+  }
+  
   @Test
   public void testSeek_skipPartialInterval() {
     downsampler = new Downsampler(source, THOUSAND_SEC_INTERVAL, AVG);
@@ -284,7 +1309,6 @@ public void testSeek_abandoningIncompleteInterval() {
   public void testToString() {
     downsampler = new Downsampler(source, THOUSAND_SEC_INTERVAL, AVG);
     DataPoint dp = downsampler.next();
-    System.out.println(downsampler.toString());
     assertTrue(downsampler.toString().contains(dp.toString()));
   }
 }
diff --git a/test/core/TestDownsamplingSpecification.java b/test/core/TestDownsamplingSpecification.java
index a149a08c34..9e541f55ec 100644
--- a/test/core/TestDownsamplingSpecification.java
+++ b/test/core/TestDownsamplingSpecification.java
@@ -14,9 +14,20 @@
 
 import org.junit.Test;
 
+import net.opentsdb.utils.DateTime;
+
 import static org.junit.Assert.assertEquals;
+import static org.junit.Assert.assertFalse;
+import static org.junit.Assert.assertTrue;
+
+import java.util.TimeZone;
 
 public class TestDownsamplingSpecification {
+  final long interval = 60000L;
+  final FillPolicy fill_policy = FillPolicy.ZERO;
+  final Aggregator function = Aggregators.SUM;
+  final TimeZone timezone = DateTime.timezones.get(DateTime.UTC_ID);
+  
   @Test
   public void testCtor() {
     final long interval = 1234567L;
@@ -41,16 +52,6 @@ public void testStringCtor() {
     assertEquals(FillPolicy.NOT_A_NUMBER, ds.getFillPolicy());
   }
 
-  @Test
-  public void testToString() {
-    assertEquals("DownsamplingSpecification{interval=4532019, function=zimsum, "
-        + "fillPolicy=NOT_A_NUMBER}",
-      new DownsamplingSpecification(
-        4532019L,
-        Aggregators.ZIMSUM,
-        FillPolicy.NOT_A_NUMBER).toString());
-  }
-
   @Test(expected = RuntimeException.class)
   public void testBadInterval() {
     new DownsamplingSpecification("blah-avg-lerp");
@@ -65,5 +66,119 @@ public void testBadFunction() {
   public void testBadFillPolicy() {
     new DownsamplingSpecification("10m-avg-max");
   }
+
+  @Test (expected = IllegalArgumentException.class)
+  public void testNoneAgg() {
+    new DownsamplingSpecification("1m-none-lerp");
+  }
+  
+  @Test (expected = IllegalArgumentException.class)
+  public void testCtorNegativeInterval() {
+    new DownsamplingSpecification(-1, function, fill_policy);
+  }
+  
+  @Test (expected = IllegalArgumentException.class)
+  public void testCtorZeroInterval() {
+    new DownsamplingSpecification(DownsamplingSpecification.NO_INTERVAL, 
+        function, fill_policy);
+  }
+  
+  @Test (expected = IllegalArgumentException.class)
+  public void testCtorNullFunction() {
+    new DownsamplingSpecification(interval, null, fill_policy);
+  }
+
+  @Test(expected = IllegalArgumentException.class)
+  public void testStringCtorNull() {
+    new DownsamplingSpecification(null);
+  }
+  
+  @Test(expected = IllegalArgumentException.class)
+  public void testStringCtorEmpty() {
+    new DownsamplingSpecification("");
+  }
+  
+  @Test(expected = IllegalArgumentException.class)
+  public void testStringCtorNoIntervalString() {
+    new DownsamplingSpecification("blah-avg-lerp");
+  }
+  
+  @Test(expected = IllegalArgumentException.class)
+  public void testStringCtorZeroInterval() {
+    new DownsamplingSpecification("0m-avg-lerp");
+  }
+  
+  @Test(expected = IllegalArgumentException.class)
+  public void testStringCtorNegativeInterval() {
+    new DownsamplingSpecification("-60m-avg-lerp");
+  }
+
+  @Test(expected = IllegalArgumentException.class)
+  public void testStringCtorUnknownUnits() {
+    new DownsamplingSpecification("1j-avg-lerp");
+  }
+  
+  @Test(expected = IllegalArgumentException.class)
+  public void testStringCtorMissingUnits() {
+    new DownsamplingSpecification("1-avg-lerp");
+  }
+  
+  @Test(expected = IllegalArgumentException.class)
+  public void testStringCtorBadFunction() {
+    new DownsamplingSpecification("1m-hurp-lerp");
+  }
+  
+  @Test(expected = IllegalArgumentException.class)
+  public void testStringCtorMissingFunction() {
+    new DownsamplingSpecification("1m");
+  }
+
+  @Test(expected = IllegalArgumentException.class)
+  public void testStringCtorBadFillPolicy() {
+    new DownsamplingSpecification("10m-avg-max");
+  }
+  
+  @Test
+  public void testSetCalendar() {
+    DownsamplingSpecification ds = new DownsamplingSpecification("15m-avg");
+    assertFalse(ds.useCalendar());
+    
+    ds.setUseCalendar(true);
+    assertTrue(ds.useCalendar());
+    
+    ds.setUseCalendar(false);
+    assertFalse(ds.useCalendar());
+  }
+  
+  @Test
+  public void setTimezone() {
+    DownsamplingSpecification ds = new DownsamplingSpecification("15m-avg");
+    assertEquals(timezone, ds.getTimezone());
+    
+    final TimeZone tz = DateTime.timezones.get("America/Denver"); 
+    ds.setTimezone(tz);
+    assertEquals(tz, ds.getTimezone());
+  }
+  
+  @Test (expected = IllegalArgumentException.class)
+  public void setTimezoneNull() {
+    DownsamplingSpecification ds = new DownsamplingSpecification("15m-avg");
+    ds.setTimezone(null);
+  }
+  
+  @Test
+  public void testToString() {
+    final String string = new DownsamplingSpecification(
+        4532019L,
+        Aggregators.ZIMSUM,
+        FillPolicy.NOT_A_NUMBER).toString();
+    
+    assertTrue(string.contains("interval=4532019"));
+    assertTrue(string.contains("function=zimsum"));
+    assertTrue(string.contains("fillPolicy=NOT_A_NUMBER"));
+    assertTrue(string.contains("useCalendar=false"));
+    assertTrue(string.contains("timeZone=UTC"));
+  }
+
 }
 
diff --git a/test/core/TestFillingDownsampler.java b/test/core/TestFillingDownsampler.java
index 70dd698aca..ef42ebc963 100644
--- a/test/core/TestFillingDownsampler.java
+++ b/test/core/TestFillingDownsampler.java
@@ -14,18 +14,32 @@
 
 import org.junit.Test;
 
+import net.opentsdb.core.SeekableViewsForTest.MockSeekableView;
+import net.opentsdb.utils.DateTime;
+
 import static org.junit.Assert.assertEquals;
 import static org.junit.Assert.assertFalse;
-import static org.junit.Assert.assertNotNull;
 import static org.junit.Assert.assertTrue;
+import static org.mockito.Mockito.spy;
+
+import java.util.TimeZone;
 
 /** Tests {@link FillingDownsampler}. */
 public class TestFillingDownsampler {
-  private static final Aggregator SUM = Aggregators.get("sum");
-
-  private static final FillPolicy NAN = FillPolicy.fromString("nan");
-  private static final FillPolicy ZERO = FillPolicy.fromString("zero");
-
+  private static final long BASE_TIME = 1356998400000L;
+  //30 minute offset
+  final static TimeZone AF = DateTime.timezones.get("Asia/Kabul");
+  // 12h offset w/o DST
+  final static TimeZone TV = DateTime.timezones.get("Pacific/Funafuti");
+  // 12h offset w DST
+  final static TimeZone FJ = DateTime.timezones.get("Pacific/Fiji");
+  // Tue, 15 Dec 2015 04:02:25.123 UTC
+  final static long DST_TS = 1450137600000L;
+ 
+  private SeekableView source;
+  private Downsampler downsampler;
+  private DownsamplingSpecification specification;
+  
   /** Data with gaps: before, during, and after. */
   @Test
   public void testNaNMissingInterval() {
@@ -43,18 +57,20 @@ public void testNaNMissingInterval() {
         MutableDataPoint.ofDoubleValue(baseTime + 25L * 27L, 1.),
       });
 
+    specification = new DownsamplingSpecification("100ms-sum-nan");
     final Downsampler downsampler = new FillingDownsampler(source, baseTime,
-      baseTime + 36 * 25L, 100L, SUM, NAN);
-
-    step(downsampler, Double.NaN);
-    step(downsampler, 3.);
-    step(downsampler, Double.NaN);
-    step(downsampler, 2.);
-    step(downsampler, Double.NaN);
-    step(downsampler, Double.NaN);
-    step(downsampler, 4.);
-    step(downsampler, Double.NaN);
-    step(downsampler, Double.NaN);
+      baseTime + 36 * 25L, specification, 0, 0);
+    
+    long timestamp = baseTime;
+    step(downsampler, timestamp, Double.NaN);
+    step(downsampler, timestamp += 100, 3.);
+    step(downsampler, timestamp += 100, Double.NaN);
+    step(downsampler, timestamp += 100, 2.);
+    step(downsampler, timestamp += 100, Double.NaN);
+    step(downsampler, timestamp += 100, Double.NaN);
+    step(downsampler, timestamp += 100, 4.);
+    step(downsampler, timestamp += 100, Double.NaN);
+    step(downsampler, timestamp += 100, Double.NaN);
     assertFalse(downsampler.hasNext());
   }
 
@@ -73,19 +89,21 @@ public void testZeroMissingInterval() {
         MutableDataPoint.ofDoubleValue(baseTime + 25L * 26L, 1.),
         MutableDataPoint.ofDoubleValue(baseTime + 25L * 27L, 1.),
       });
-
+    
+    specification = new DownsamplingSpecification("100ms-sum-zero");
     final Downsampler downsampler = new FillingDownsampler(source, baseTime,
-      baseTime + 36 * 25L, 100L, SUM, ZERO);
-
-    step(downsampler, 0.);
-    step(downsampler, 3.);
-    step(downsampler, 0.);
-    step(downsampler, 2.);
-    step(downsampler, 0.);
-    step(downsampler, 0.);
-    step(downsampler, 4.);
-    step(downsampler, 0.);
-    step(downsampler, 0.);
+      baseTime + 36 * 25L, specification, 0, 0);
+    
+    long timestamp = baseTime;
+    step(downsampler, timestamp, 0.);
+    step(downsampler, timestamp += 100, 3.);
+    step(downsampler, timestamp += 100, 0.);
+    step(downsampler, timestamp += 100, 2.);
+    step(downsampler, timestamp += 100, 0.);
+    step(downsampler, timestamp += 100, 0.);
+    step(downsampler, timestamp += 100, 4.);
+    step(downsampler, timestamp += 100, 0.);
+    step(downsampler, timestamp += 100, 0.);
     assertFalse(downsampler.hasNext());
   }
 
@@ -109,12 +127,14 @@ public void testWithoutMissingIntervals() {
         MutableDataPoint.ofDoubleValue(baseTime + 25L * 11L,  1.),
       });
 
+    specification = new DownsamplingSpecification("100ms-sum-nan");
     final Downsampler downsampler = new FillingDownsampler(source, baseTime,
-      baseTime + 12L * 25L, 100L, SUM, NAN);
+      baseTime + 12L * 25L, specification, 0, 0);
 
-    step(downsampler, 42.);
-    step(downsampler, 26.);
-    step(downsampler, 10.);
+    long timestamp = baseTime;
+    step(downsampler, timestamp, 42.);
+    step(downsampler, timestamp += 100, 26.);
+    step(downsampler, timestamp += 100, 10.);
     assertFalse(downsampler.hasNext());
   }
 
@@ -139,20 +159,667 @@ public void testWithOutOfBoundsData() {
         MutableDataPoint.ofDoubleValue(baseTime + 60000L * 2L + 30384L, 37.),
         MutableDataPoint.ofDoubleValue(baseTime + 60000L * 4L +  1530L, 86.)
       });
+    
+    specification = new DownsamplingSpecification("1m-sum-nan");
+    final Downsampler downsampler = new FillingDownsampler(source, baseTime,
+      baseTime + 60000L * 2L, specification, 0, 0);
+    
+    long timestamp = 1425335880000L;
+    step(downsampler, timestamp, 30.);
+    step(downsampler, timestamp += 60000, 9.);
+    assertFalse(downsampler.hasNext());
+  }
+  
+  @Test
+  public void testWithOutOfBoundsDataEarly() {
+    final long baseTime = 1425335895000L;
+    final SeekableView source =
+      SeekableViewsForTest.fromArray(new DataPoint[] {
+        MutableDataPoint.ofDoubleValue(baseTime - 60000L * 5L +   320L, 53.),
+        MutableDataPoint.ofDoubleValue(baseTime - 60000L * 2L +  8839L, 16.)
+      });
 
+    specification = new DownsamplingSpecification("1m-sum-nan");
     final Downsampler downsampler = new FillingDownsampler(source, baseTime,
-      baseTime + 60000L * 2L, 60000L, SUM, NAN);
+      baseTime + 60000L * 2L, specification, 0, 0);
+    
+    long timestamp = 1425335880000L;
+    step(downsampler, timestamp, Double.NaN);
+    step(downsampler, timestamp += 60000, Double.NaN);
+    assertFalse(downsampler.hasNext());
+  }
+  
+  @Test
+  public void testWithOutOfBoundsDataLate() {
+    final long baseTime = 1425335895000L;
+    final SeekableView source =
+      SeekableViewsForTest.fromArray(new DataPoint[] {
+          MutableDataPoint.ofDoubleValue(baseTime + 60000L * 2L + 30384L, 37.),
+          MutableDataPoint.ofDoubleValue(baseTime + 60000L * 4L +  1530L, 86.)
+      });
 
-    step(downsampler, 30.);
-    step(downsampler,  9.);
+    specification = new DownsamplingSpecification("1m-sum-nan");
+    final Downsampler downsampler = new FillingDownsampler(source, baseTime,
+      baseTime + 60000L * 2L, specification, 0, 0);
+    
+    long timestamp = 1425335880000L;
+    step(downsampler, timestamp, Double.NaN);
+    step(downsampler, timestamp += 60000, Double.NaN);
+    assertFalse(downsampler.hasNext());
+  }
+
+  @Test
+  public void testDownsampler_allFullRange() {
+    final SeekableView source = SeekableViewsForTest.fromArray(new DataPoint[] {
+        MutableDataPoint.ofLongValue(BASE_TIME + 5000L, 1),
+        MutableDataPoint.ofLongValue(BASE_TIME + 15000L, 2),
+        MutableDataPoint.ofLongValue(BASE_TIME + 25000L, 4),
+        MutableDataPoint.ofLongValue(BASE_TIME + 35000L, 8),
+        MutableDataPoint.ofLongValue(BASE_TIME + 45000L, 16),
+        MutableDataPoint.ofLongValue(BASE_TIME + 55000L, 32)
+    });
+    
+    specification = new DownsamplingSpecification("0all-sum-nan");
+    final Downsampler downsampler = new FillingDownsampler(source, 
+        BASE_TIME + 5000L,BASE_TIME + 55000L, specification, 0, 
+        Long.MAX_VALUE);
+    
+    step(downsampler, 0, 63);
+    assertFalse(downsampler.hasNext());
+  }
+  
+  @Test
+  public void testDownsampler_allFilterOnQuery() {
+    final SeekableView source = SeekableViewsForTest.fromArray(new DataPoint[] {
+        MutableDataPoint.ofLongValue(BASE_TIME + 5000L, 1),
+        MutableDataPoint.ofLongValue(BASE_TIME + 15000L, 2),
+        MutableDataPoint.ofLongValue(BASE_TIME + 25000L, 4),
+        MutableDataPoint.ofLongValue(BASE_TIME + 35000L, 8),
+        MutableDataPoint.ofLongValue(BASE_TIME + 45000L, 16),
+        MutableDataPoint.ofLongValue(BASE_TIME + 55000L, 32)
+    });
+    
+    specification = new DownsamplingSpecification("0all-sum-nan");
+    final Downsampler downsampler = new FillingDownsampler(source, 
+        BASE_TIME + 5000L,BASE_TIME + 55000L, specification, 
+        BASE_TIME + 15000L, BASE_TIME + 45000L);
+    
+    step(downsampler, BASE_TIME + 15000L, 14);
+    assertFalse(downsampler.hasNext());
+  }
+  
+  @Test
+  public void testDownsampler_allFilterOnQueryOutOfRangeEarly() {
+    final SeekableView source = SeekableViewsForTest.fromArray(new DataPoint[] {
+        MutableDataPoint.ofLongValue(BASE_TIME + 5000L, 1),
+        MutableDataPoint.ofLongValue(BASE_TIME + 15000L, 2),
+        MutableDataPoint.ofLongValue(BASE_TIME + 25000L, 4),
+        MutableDataPoint.ofLongValue(BASE_TIME + 35000L, 8),
+        MutableDataPoint.ofLongValue(BASE_TIME + 45000L, 16),
+        MutableDataPoint.ofLongValue(BASE_TIME + 55000L, 32)
+    });
+    
+    specification = new DownsamplingSpecification("0all-sum-nan");
+    final Downsampler downsampler = new FillingDownsampler(source, 
+        BASE_TIME + 5000L,BASE_TIME + 55000L, specification, 
+        BASE_TIME + 65000L, BASE_TIME + 75000L);
+    
+    assertFalse(downsampler.hasNext());
+  }
+  
+  @Test
+  public void testDownsampler_allFilterOnQueryOutOfRangeLate() {
+    final SeekableView source = SeekableViewsForTest.fromArray(new DataPoint[] {
+        MutableDataPoint.ofLongValue(BASE_TIME + 5000L, 1),
+        MutableDataPoint.ofLongValue(BASE_TIME + 15000L, 2),
+        MutableDataPoint.ofLongValue(BASE_TIME + 25000L, 4),
+        MutableDataPoint.ofLongValue(BASE_TIME + 35000L, 8),
+        MutableDataPoint.ofLongValue(BASE_TIME + 45000L, 16),
+        MutableDataPoint.ofLongValue(BASE_TIME + 55000L, 32)
+    });
+    
+    specification = new DownsamplingSpecification("0all-sum-nan");
+    final Downsampler downsampler = new FillingDownsampler(source, 
+        BASE_TIME + 5000L,BASE_TIME + 55000L, specification, 
+        BASE_TIME - 15000L, BASE_TIME - 5000L);
+    
     assertFalse(downsampler.hasNext());
   }
+  
+  @Test
+  public void testDownsampler_calendarHour() {
+    source = SeekableViewsForTest.fromArray(new DataPoint[] {
+        MutableDataPoint.ofLongValue(BASE_TIME, 1),
+        MutableDataPoint.ofLongValue(BASE_TIME + 1800000, 2),
+        MutableDataPoint.ofLongValue(BASE_TIME + 3599000L, 3),
+        MutableDataPoint.ofLongValue(BASE_TIME + 3600000L, 4),
+        MutableDataPoint.ofLongValue(BASE_TIME + 5400000L, 5),
+        MutableDataPoint.ofLongValue(BASE_TIME + 7199000L, 6)
+    });
+    specification = new DownsamplingSpecification("1hc-sum-nan");
+    specification.setTimezone(TV);
+    downsampler = new FillingDownsampler(source, 
+        BASE_TIME, BASE_TIME + (3600000 * 3), specification, 0, Long.MAX_VALUE);
+
+    long ts = BASE_TIME;
+    double value = 6;
+    while (downsampler.hasNext()) {
+      DataPoint dp = downsampler.next();
+      assertFalse(dp.isInteger());
+      assertEquals(ts, dp.timestamp());
+      assertEquals(value, dp.doubleValue(), 0.001);
+      ts += 3600000;
+      if (value == 6) {
+        value = 15;
+      } else {
+        value = Double.NaN;
+      }
+    }
+
+    // hour offset by 30m
+    ((MockSeekableView)source).resetIndex();
+    specification = new DownsamplingSpecification("1hc-sum-nan");
+    specification.setTimezone(AF);
+    downsampler = new FillingDownsampler(source, 1356996600000L, 
+        1356996600000L + (3600000 * 4), specification, 0, Long.MAX_VALUE);
+
+    ts = 1356996600000L;
+    value = 1;
+    while (downsampler.hasNext()) {
+      DataPoint dp = downsampler.next();
+      assertFalse(dp.isInteger());
+      assertEquals(ts, dp.timestamp());
+      assertEquals(value, dp.doubleValue(), 0.001);
+      ts += 3600000;
+      if (value == 1) {
+        value = 9;
+      } else if (value == 9) {
+        value = 11;
+      } else {
+        value = Double.NaN;
+      }
+    }
+    
+    // multiple hours
+    ((MockSeekableView)source).resetIndex();
+    specification = new DownsamplingSpecification("4hc-sum-nan");
+    specification.setTimezone(AF);
+    downsampler = new FillingDownsampler(source, 1356996600000L, 
+        1356996600000L + (3600000 * 8), specification, 0, Long.MAX_VALUE);
+
+    ts = 1356996600000L;
+    value = 21;
+    while (downsampler.hasNext()) {
+      DataPoint dp = downsampler.next();
+      assertFalse(dp.isInteger());
+      assertEquals(ts, dp.timestamp());
+      assertEquals(value, dp.doubleValue(), 0.001);
+      ts = 1357011000000L;
+      value = Double.NaN;
+    }
+  }
+  
+  @Test
+  public void testDownsampler_calendarDay() {
+    source = SeekableViewsForTest.fromArray(new DataPoint[] {
+        MutableDataPoint.ofLongValue(DST_TS, 1),
+        MutableDataPoint.ofLongValue(DST_TS + 86399000, 2),
+        MutableDataPoint.ofLongValue(DST_TS + 126001000L, 3), // falls to the next in FJ
+        MutableDataPoint.ofLongValue(DST_TS + 172799000L, 4),
+        MutableDataPoint.ofLongValue(DST_TS + 172800000L, 5),
+        MutableDataPoint.ofLongValue(DST_TS + 242999000L, 6) // falls within 30m offset
+    });
+    
+    // control
+    specification = new DownsamplingSpecification("1d-sum-nan");
+    downsampler = new FillingDownsampler(source, DST_TS, 
+        DST_TS + (86400000 * 4), specification, 0, Long.MAX_VALUE);
+
+    long ts = DST_TS;
+    double value = 3;
+    while (downsampler.hasNext()) {
+      DataPoint dp = downsampler.next();
+      assertFalse(dp.isInteger());
+      assertEquals(ts, dp.timestamp());
+      assertEquals(value, dp.doubleValue(), 0.001);
+      ts += 86400000;
+      if (value == 3) {
+        value = 7;
+      } else if (value == 7) {
+        value = 11;
+      } else {
+        value = Double.NaN;
+      }
+    }
+
+    // 12 hour offset from UTC
+    ((MockSeekableView)source).resetIndex();
+    specification = new DownsamplingSpecification("1dc-sum-nan");
+    specification.setTimezone(TV);
+    downsampler = new FillingDownsampler(source, 1450094400000L - 86400000, 
+        DST_TS + (86400000 * 5), specification, 0, Long.MAX_VALUE);
+
+    ts = 1450094400000L - 86400000; // make sure we front-fill too
+    value = Double.NaN;
+    while (downsampler.hasNext()) {
+      DataPoint dp = downsampler.next();
+      assertFalse(dp.isInteger());
+      assertEquals(ts, dp.timestamp());
+      assertEquals(value, dp.doubleValue(), 0.001);
+      ts += 86400000;
+      if (Double.isNaN(value)) {
+        value = 1;
+      } else if (value == 1) {
+        value = 5;
+      } else if (value == 5) {
+        value = 9;
+      } else if (value == 9) {
+        value = 6;
+      } else {
+        value = Double.NaN;
+      }
+    }
+    
+    // 11 hour offset from UTC
+    ((MockSeekableView)source).resetIndex();
+    specification = new DownsamplingSpecification("1dc-sum-nan");
+    specification.setTimezone(FJ);
+    downsampler = new FillingDownsampler(source, 1450094400000L, 
+        DST_TS + (86400000 * 5), specification, 0, Long.MAX_VALUE);
+
+    ts = 1450090800000L;
+    value = 1;
+    while (downsampler.hasNext()) {
+      DataPoint dp = downsampler.next();
+      assertFalse(dp.isInteger());
+      assertEquals(ts, dp.timestamp());
+      assertEquals(value, dp.doubleValue(), 0.001);
+      ts += 86400000;
+      if (value == 1) {
+        value = 2;
+      } else if (value == 2) {
+        value = 12;
+      } else if (value == 12) {
+        value = 6;
+      } else {
+        value = Double.NaN;
+      }
+    }
+    
+    // 30m offset
+    ((MockSeekableView)source).resetIndex();
+    specification = new DownsamplingSpecification("1dc-sum-nan");
+    specification.setTimezone(AF);
+    downsampler = new FillingDownsampler(source, 1450121400000L, 
+        DST_TS + (86400000 * 4), specification, 0, Long.MAX_VALUE);
+
+    ts = 1450121400000L;
+    value = 1;
+    while (downsampler.hasNext()) {
+      DataPoint dp = downsampler.next();
+      assertFalse(dp.isInteger());
+      assertEquals(ts, dp.timestamp());
+      assertEquals(value, dp.doubleValue(), 0.001);
+      ts += 86400000;
+      if (value == 1) {
+        value = 5;
+      } else if (value == 5) {
+        value = 15;
+      } else {
+        value = Double.NaN;
+      }
+    }
+    
+    // multiple days
+    ((MockSeekableView)source).resetIndex();
+    specification = new DownsamplingSpecification("3dc-sum-nan");
+    specification.setTimezone(AF);
+    downsampler = new FillingDownsampler(source, 1450121400000L, 
+        DST_TS + (86400000 * 6), specification, 0, Long.MAX_VALUE);
+
+    ts = 1450121400000L;
+    value = 21;
+    while (downsampler.hasNext()) {
+      DataPoint dp = downsampler.next();
+      assertFalse(dp.isInteger());
+      assertEquals(ts, dp.timestamp());
+      assertEquals(value, dp.doubleValue(), 0.001);
+      ts += 86400000L * 3;
+      value = Double.NaN;
+    }
+  }
+  
+  @Test
+  public void testDownsampler_calendarWeek() {
+    source = SeekableViewsForTest.fromArray(new DataPoint[] {
+        MutableDataPoint.ofLongValue(DST_TS, 1), // a Tuesday in UTC land
+        MutableDataPoint.ofLongValue(DST_TS + (86400000L * 7), 2),
+        MutableDataPoint.ofLongValue(1451129400000L, 3), // falls to the next in FJ
+        MutableDataPoint.ofLongValue(DST_TS + (86400000L * 21), 4),
+        MutableDataPoint.ofLongValue(1452367799000L, 5) // falls within 30m offset
+    });
+    // control
+    specification = new DownsamplingSpecification("1wc-sum-nan");
+    downsampler = new FillingDownsampler(source, 1449964800000L, 
+        DST_TS + (86400000L * 35), specification, 0, Long.MAX_VALUE);
+    
+    long ts = 1449964800000L;
+    double value = 1;
+    while (downsampler.hasNext()) {
+      DataPoint dp = downsampler.next();
+      assertFalse(dp.isInteger());
+      assertEquals(ts, dp.timestamp());
+      assertEquals(value, dp.doubleValue(), 0.001);
+      ts += 86400000L * 7;
+      if (value == 1) {
+        value = 5;
+      } else if (value == 5) {
+        value = Double.NaN;
+      } else if (Double.isNaN(value)) {
+        value = 9;
+      } else {
+        value = Double.NaN;
+      }
+    }
+    
+    // 12 hour offset from UTC
+    ((MockSeekableView)source).resetIndex();
+    specification = new DownsamplingSpecification("1wc-sum-nan");
+    specification.setTimezone(TV);
+    downsampler = new FillingDownsampler(source, 1449964800000L, 
+        DST_TS + (86400000L * 35), specification, 0, Long.MAX_VALUE);
+
+    ts = 1449921600000L;
+    value = 1;
+    while (downsampler.hasNext()) {
+      DataPoint dp = downsampler.next();
+      assertFalse(dp.isInteger());
+      assertEquals(ts, dp.timestamp());
+      assertEquals(value, dp.doubleValue(), 0.001);
+      ts += 86400000L * 7;
+      if (value == 1) {
+        value = 5;
+      } else if (value == 5) {
+        value = Double.NaN;
+      } else if (Double.isNaN(value)) {
+        value = 4;
+      } else {
+        value = 5;
+      }
+    }
+    
+    // 11 hour offset from UTC
+    ((MockSeekableView)source).resetIndex();
+    specification = new DownsamplingSpecification("1wc-sum-nan");
+    specification.setTimezone(FJ);
+    downsampler = new FillingDownsampler(source, 1449964800000L, 
+        DST_TS + (86400000L * 35), specification, 0, Long.MAX_VALUE);
+
+    ts = 1449918000000L;
+    value = 1;
+    while (downsampler.hasNext()) {
+      DataPoint dp = downsampler.next();
+      assertFalse(dp.isInteger());
+      assertEquals(ts, dp.timestamp());
+      assertEquals(value, dp.doubleValue(), 0.001);
+      ts += 86400000L * 7;
+      value++;
+    }
+    
+    // 30m offset
+    ((MockSeekableView)source).resetIndex();
+    specification = new DownsamplingSpecification("1wc-sum-nan");
+    specification.setTimezone(AF);
+    downsampler = new FillingDownsampler(source, 1449964800000L, 
+        DST_TS + (86400000L * 35), specification, 0, Long.MAX_VALUE);
+
+    ts = 1449948600000L;
+    value = 1;
+    while (downsampler.hasNext()) {
+      DataPoint dp = downsampler.next();
+      assertFalse(dp.isInteger());
+      assertEquals(ts, dp.timestamp());
+      assertEquals(value, dp.doubleValue(), 0.001);
+      ts += 86400000L * 7;
+      if (value == 1) {
+        value = 5;
+      } else if (value == 5) {
+        value = Double.NaN;
+      } else if (Double.isNaN(value)) {
+        value = 9;
+      } else {
+        value = Double.NaN;
+      }
+    }
+    
+    // multiple weeks
+    ((MockSeekableView)source).resetIndex();
+    specification = new DownsamplingSpecification("2wc-sum-nan");
+    specification.setTimezone(AF);
+    downsampler = new FillingDownsampler(source, 1449964800000L, 
+        DST_TS + (86400000L * 35), specification, 0, Long.MAX_VALUE);
 
-  private void step(final Downsampler downsampler, final double expected) {
+    ts = 1449948600000L;
+    value = 6;
+    while (downsampler.hasNext()) {
+      DataPoint dp = downsampler.next();
+      assertFalse(dp.isInteger());
+      assertEquals(ts, dp.timestamp());
+      assertEquals(value, dp.doubleValue(), 0.001);
+      ts += 86400000L * 14;
+      if (value == 6) {
+        value = 9;
+      } else {
+        value = Double.NaN;
+      }
+    }
+  }
+  
+  @Test
+  public void testDownsampler_calendarMonth() {
+    final long dec_1st = 1448928000000L;
+    source = spy(SeekableViewsForTest.fromArray(new DataPoint[] {
+        MutableDataPoint.ofLongValue(dec_1st, 1),
+        MutableDataPoint.ofLongValue(1451559600000L, 2), // falls to the next in FJ
+        MutableDataPoint.ofLongValue(1451606400000L, 3), // jan 1st
+        MutableDataPoint.ofLongValue(1454284800000L, 4), // feb 1st
+        MutableDataPoint.ofLongValue(1456704000000L, 5), // feb 29th (leap year)
+        MutableDataPoint.ofLongValue(1456772400000L, 6)  // falls within 30m offset AF
+    }));
+    
+    // control
+    specification = new DownsamplingSpecification("1n-sum-nan");
+    downsampler = new FillingDownsampler(source, dec_1st, 
+        dec_1st + (2592000000L * 5), specification, 0, Long.MAX_VALUE);
+
+    long ts = dec_1st;
+    double value = 1;
+    while (downsampler.hasNext()) {
+      DataPoint dp = downsampler.next();
+      assertFalse(dp.isInteger());
+      assertEquals(ts, dp.timestamp());
+      assertEquals(value, dp.doubleValue(), 0.001);
+      ts += 2592000000L;
+      if (value == 1) {
+        value = 5;
+      } else if (value == 5) {
+        value = 4;
+      } else if (value == 4) {
+        value = 11;
+      } else {
+        value = Double.NaN;
+      }
+    }
+    
+    // 12h offset
+    ((MockSeekableView)source).resetIndex();
+    specification = new DownsamplingSpecification("1nc-sum-nan");
+    specification.setTimezone(TV);
+    downsampler = new FillingDownsampler(source, dec_1st, 
+        dec_1st + (2592000000L * 6), specification, 0, Long.MAX_VALUE);
+
+    ts = 1448884800000L;
+    value = 3;
+    while (downsampler.hasNext()) {
+      DataPoint dp = downsampler.next();
+      assertFalse(dp.isInteger());
+      assertEquals(ts, dp.timestamp());
+      assertEquals(value, dp.doubleValue(), 0.001);
+      if (ts == 1448884800000L) {
+        ts = 1451563200000L;
+      } else if (ts == 1451563200000L) {
+        ts = 1454241600000L;
+        value = 9;
+      } else if (ts == 1454241600000L) {
+        ts = 1456747200000L;
+        value = 6;
+      } else {
+        ts = 1459425600000L;
+        value = Double.NaN;
+      }
+    }
+    
+    // 11h offset
+    ((MockSeekableView)source).resetIndex();
+    specification = new DownsamplingSpecification("1nc-sum-nan");
+    specification.setTimezone(FJ);
+    downsampler = new FillingDownsampler(source, dec_1st, 
+        dec_1st + (2592000000L * 6), specification, 0, Long.MAX_VALUE);
+
+    ts = 1448881200000L;
+    value = 1;
+    while (downsampler.hasNext()) {
+      DataPoint dp = downsampler.next();
+      assertFalse(dp.isInteger());
+      assertEquals(ts, dp.timestamp());
+      assertEquals(value, dp.doubleValue(), 0.001);
+      if (ts == 1448881200000L) {
+        ts = 1451559600000L;
+        value = 5;
+      } else if (ts == 1451559600000L) {
+        ts = 1454241600000L;
+        value = 9;
+      } else if (ts == 1454241600000L) {
+        ts = 1456747200000L;
+        value = 6;
+      } else {
+        ts = 1459425600000L;
+        value = Double.NaN;
+      }
+    }
+    
+    // 30m offset
+    ((MockSeekableView)source).resetIndex();
+    specification = new DownsamplingSpecification("1nc-sum-nan");
+    specification.setTimezone(AF);
+    downsampler = new FillingDownsampler(source, dec_1st, 
+        dec_1st + (2592000000L * 5), specification, 0, Long.MAX_VALUE);
+
+    ts = 1448911800000L;
+    value = 3;
+    while (downsampler.hasNext()) {
+      DataPoint dp = downsampler.next();
+      assertFalse(dp.isInteger());
+      assertEquals(ts, dp.timestamp());
+      assertEquals(value, dp.doubleValue(), 0.001);
+      if (ts == 1448911800000L) {
+        ts = 1451590200000L;
+      } else if (ts == 1451590200000L) {
+        ts = 1454268600000L;
+        value = 15;
+      } else {
+        ts = 1456774200000L;
+        value = Double.NaN;
+      }
+    }
+    
+    // multiple months
+    ((MockSeekableView)source).resetIndex();
+    specification = new DownsamplingSpecification("3nc-sum-nan");
+    specification.setTimezone(TV);
+    downsampler = new FillingDownsampler(source, dec_1st, 
+        dec_1st + (2592000000L * 9), specification, 0, Long.MAX_VALUE);
+
+    ts = 1443614400000L;
+    value = 3;
+    while (downsampler.hasNext()) {
+      DataPoint dp = downsampler.next();
+      assertFalse(dp.isInteger());
+      assertEquals(ts, dp.timestamp());
+      assertEquals(value, dp.doubleValue(), 0.001);
+      if (ts == 1443614400000L) {
+        ts = 1451563200000L;
+        value = 18;
+      } else {
+        ts = 1459425600000L;
+        value = Double.NaN;
+      }
+    }
+  }
+  
+  @Test
+  public void testDownsampler_calendarSkipSomePoints() {
+    source = SeekableViewsForTest.fromArray(new DataPoint[] {
+        MutableDataPoint.ofLongValue(BASE_TIME, 1),
+        MutableDataPoint.ofLongValue(BASE_TIME + 1800000, 2),
+        // skip an hour
+        MutableDataPoint.ofLongValue(BASE_TIME + 7200000, 6)
+    });
+    specification = new DownsamplingSpecification("1hc-sum-nan");
+    specification.setTimezone(TV);
+    downsampler = new FillingDownsampler(source, 1356998400000L, 1357009200000L, 
+        specification, 0, Long.MAX_VALUE);
+
+    long ts = BASE_TIME;
+    double value = 3;
+    while (downsampler.hasNext()) {
+      DataPoint dp = downsampler.next();
+      assertFalse(dp.isInteger());
+      assertEquals(ts, dp.timestamp());
+      assertEquals(value, dp.doubleValue(), 0.001);
+      ts += 3600000;
+      if (value == 3) {
+        value = Double.NaN;
+      } else {
+        value = 6;
+      }
+    }
+  }
+  
+  @Test
+  public void testDownsampler_noData() {
+    final SeekableView source = 
+        SeekableViewsForTest.fromArray(new DataPoint[] { });
+    specification = new DownsamplingSpecification("1m-sum-nan");
+    final Downsampler downsampler = new FillingDownsampler(source, BASE_TIME,
+        BASE_TIME + 60000L * 2L, specification, 0, 0);
+    
+    long timestamp = 1356998400000L;
+    step(downsampler, timestamp, Double.NaN);
+    step(downsampler, timestamp += 60000, Double.NaN);
+    assertFalse(downsampler.hasNext());
+  }
+  
+  @Test
+  public void testDownsampler_noDataCalendar() {
+    final SeekableView source = 
+        SeekableViewsForTest.fromArray(new DataPoint[] { });
+    specification = new DownsamplingSpecification("1mc-sum-nan");
+    final Downsampler downsampler = new FillingDownsampler(source, BASE_TIME,
+        BASE_TIME + 60000L * 2L, specification, 0, 0);
+    
+    long timestamp = 1356998400000L;
+    step(downsampler, timestamp, Double.NaN);
+    step(downsampler, timestamp += 60000, Double.NaN);
+    assertFalse(downsampler.hasNext());
+  }
+  
+  private void step(final Downsampler downsampler, final long expected_timestamp, 
+      final double expected_value) {
     assertTrue(downsampler.hasNext());
     final DataPoint point = downsampler.next();
-    assertNotNull(point);
-    assertEquals(expected, point.doubleValue(), 0.01);
+    assertEquals(expected_timestamp, point.timestamp());
+    assertEquals(expected_value, point.doubleValue(), 0.01);
   }
 }
 
diff --git a/test/core/TestRowSeq.java b/test/core/TestRowSeq.java
index db9eb1b913..1a3792759b 100644
--- a/test/core/TestRowSeq.java
+++ b/test/core/TestRowSeq.java
@@ -12,6 +12,7 @@
 // see <http://www.gnu.org/licenses/>.
 package net.opentsdb.core;
 
+import static org.junit.Assert.assertArrayEquals;
 import static org.junit.Assert.assertEquals;
 import static org.junit.Assert.assertFalse;
 import static org.junit.Assert.assertTrue;
@@ -27,6 +28,7 @@
 
 import org.hbase.async.Bytes;
 import org.hbase.async.KeyValue;
+import org.hbase.async.Bytes.ByteMap;
 import org.junit.Before;
 import org.junit.Test;
 import org.junit.runner.RunWith;
@@ -814,8 +816,118 @@ public void seekMsPastLastDp() throws Exception {
     it.next();
   }
   
+  @Test
+  public void metricUID() throws Exception {
+    final byte[] qual1 = { 0x00, 0x07 };
+    final byte[] val1 = Bytes.fromLong(4L);
+    final byte[] qual2 = { 0x00, 0x27 };
+    final byte[] val2 = Bytes.fromLong(5L);
+    final byte[] qual12 = MockBase.concatByteArrays(qual1, qual2);
+    final KeyValue kv = makekv(qual12, 
+        MockBase.concatByteArrays(val1, val2, ZERO));
+    
+    final RowSeq rs = new RowSeq(tsdb);
+    rs.setRow(kv);
+    
+    assertArrayEquals(new byte[] { 0, 0, 1 }, rs.metricUID());
+  }
+  
+  @Test
+  public void metricUIDSalted() throws Exception {
+    setupSalt();
+    final byte[] qual1 = { 0x00, 0x07 };
+    final byte[] val1 = Bytes.fromLong(4L);
+    final byte[] qual2 = { 0x00, 0x27 };
+    final byte[] val2 = Bytes.fromLong(5L);
+    final byte[] qual12 = MockBase.concatByteArrays(qual1, qual2);
+    final KeyValue kv = makekv(qual12, 
+        MockBase.concatByteArrays(val1, val2, ZERO));
+    
+    final RowSeq rs = new RowSeq(tsdb);
+    rs.setRow(kv);
+    
+    assertArrayEquals(new byte[] { 0, 0, 1 }, rs.metricUID());
+  }
+  
+  @Test (expected = NullPointerException.class)
+  public void metricUIDKeyNotSet() throws Exception {
+    final RowSeq rs = new RowSeq(tsdb);
+    rs.metricUID();
+  }
+  
+  @Test
+  public void getTagUids() throws Exception {
+    final byte[] qual1 = { 0x00, 0x07 };
+    final byte[] val1 = Bytes.fromLong(4L);
+    final byte[] qual2 = { 0x00, 0x27 };
+    final byte[] val2 = Bytes.fromLong(5L);
+    final byte[] qual12 = MockBase.concatByteArrays(qual1, qual2);
+    final KeyValue kv = makekv(qual12, 
+        MockBase.concatByteArrays(val1, val2, ZERO));
+    
+    final RowSeq rs = new RowSeq(tsdb);
+    rs.setRow(kv);
+    
+    final ByteMap<byte[]> uids = rs.getTagUids();
+    assertEquals(1, uids.size());
+    assertArrayEquals(new byte[] { 0, 0, 1 }, uids.firstKey());
+    assertArrayEquals(new byte[] { 0, 0, 2 }, 
+        uids.firstEntry().getValue());
+  }
+  
+  @Test
+  public void getTagUidsSalted() throws Exception {
+    setupSalt();
+    final byte[] qual1 = { 0x00, 0x07 };
+    final byte[] val1 = Bytes.fromLong(4L);
+    final byte[] qual2 = { 0x00, 0x27 };
+    final byte[] val2 = Bytes.fromLong(5L);
+    final byte[] qual12 = MockBase.concatByteArrays(qual1, qual2);
+    final KeyValue kv = makekv(qual12, 
+        MockBase.concatByteArrays(val1, val2, ZERO));
+    
+    final RowSeq rs = new RowSeq(tsdb);
+    rs.setRow(kv);
+    
+    final ByteMap<byte[]> uids = rs.getTagUids();
+    assertEquals(1, uids.size());
+    assertEquals(0, Bytes.memcmp(new byte[] { 0, 0, 1 }, uids.firstKey()));
+    assertEquals(0, Bytes.memcmp(new byte[] { 0, 0, 2 }, 
+        uids.firstEntry().getValue()));
+  }
+  
+  @Test (expected = NullPointerException.class)
+  public void getTagUidsNotSet() throws Exception {
+    final RowSeq rs = new RowSeq(tsdb);
+    rs.getTagUids();
+  }
+  
+  @Test
+  public void getAggregatedTagUids() throws Exception {
+    final byte[] qual1 = { 0x00, 0x07 };
+    final byte[] val1 = Bytes.fromLong(4L);
+    final byte[] qual2 = { 0x00, 0x27 };
+    final byte[] val2 = Bytes.fromLong(5L);
+    final byte[] qual12 = MockBase.concatByteArrays(qual1, qual2);
+    final KeyValue kv = makekv(qual12, 
+        MockBase.concatByteArrays(val1, val2, ZERO));
+    
+    final RowSeq rs = new RowSeq(tsdb);
+    rs.setRow(kv);
+    
+    assertEquals(0, rs.getAggregatedTagUids().size());
+  }
+  
+  /** Shorthand to create a {@link KeyValue}.  */
+  public static KeyValue makekv(final byte[] qualifier, final byte[] value) {
+    if (Const.SALT_WIDTH() > 0) {
+      return new KeyValue(SALTED_KEY, FAMILY, qualifier, value);
+    }
+    return new KeyValue(KEY, FAMILY, qualifier, value);
+  }
+  
   /** Shorthand to create a {@link KeyValue}.  */
-  private static KeyValue makekv(final byte[] key, final byte[] qualifier, 
+  public static KeyValue makekv(final byte[] key, final byte[] qualifier, 
       final byte[] value) {
     return new KeyValue(key, FAMILY, qualifier, value);
   }
diff --git a/test/core/TestSpan.java b/test/core/TestSpan.java
index dbfc247ce5..b9c1b668f3 100644
--- a/test/core/TestSpan.java
+++ b/test/core/TestSpan.java
@@ -12,8 +12,10 @@
 // see <http://www.gnu.org/licenses/>.
 package net.opentsdb.core;
 
+import static org.junit.Assert.assertArrayEquals;
 import static org.junit.Assert.assertEquals;
 import static org.junit.Assert.assertFalse;
+import static org.junit.Assert.assertTrue;
 import static org.mockito.Mockito.when;
 import static org.powermock.api.mockito.PowerMockito.mock;
 
@@ -25,6 +27,7 @@
 
 import org.hbase.async.Bytes;
 import org.hbase.async.KeyValue;
+import org.hbase.async.Bytes.ByteMap;
 import org.junit.Before;
 import org.junit.Test;
 import org.junit.runner.RunWith;
@@ -408,4 +411,120 @@ public void lastTimestampInRowMs() throws Exception {
     
     assertEquals(1356998400008L, Span.lastTimestampInRow((short) 3, kv));
   }
+  
+  @Test
+  public void metricUID() throws Exception {
+    final byte[] qual1 = { 0x00, 0x07 };
+    final byte[] val1 = Bytes.fromLong(4L);
+    final byte[] qual2 = { 0x00, 0x27 };
+    final byte[] val2 = Bytes.fromLong(5L);
+    final byte[] qual12 = MockBase.concatByteArrays(qual1, qual2);
+    
+    final Span span = new Span(tsdb);
+    span.addRow(new KeyValue(HOUR1, FAMILY, qual12, 
+        MockBase.concatByteArrays(val1, val2, ZERO)));
+    
+    assertEquals(2, span.size());
+    
+    assertArrayEquals(new byte[] { 0, 0, 1 }, span.metricUID());
+  }
+  
+  @Test
+  public void metricUIDSalted() throws Exception {
+    PowerMockito.mockStatic(Const.class);
+    PowerMockito.when(Const.SALT_WIDTH()).thenReturn(1);
+    PowerMockito.when(Const.SALT_BUCKETS()).thenReturn(2);
+    
+    final byte[] qual1 = { 0x00, 0x07 };
+    final byte[] val1 = Bytes.fromLong(4L);
+    final byte[] qual2 = { 0x00, 0x27 };
+    final byte[] val2 = Bytes.fromLong(5L);
+    final byte[] qual12 = MockBase.concatByteArrays(qual1, qual2);
+    
+    final Span span = new Span(tsdb);
+    final byte[] key = new byte[HOUR1.length + 1];
+    System.arraycopy(HOUR1, 0, key, 1, HOUR1.length);
+    span.addRow(new KeyValue(key, FAMILY, qual12, 
+        MockBase.concatByteArrays(val1, val2, ZERO)));
+    
+    assertEquals(2, span.size());
+    
+    assertArrayEquals(new byte[] { 0, 0, 1 }, span.metricUID());
+  }
+  
+  @Test
+  public void getTagUids() {
+    final byte[] qual1 = { 0x00, 0x07 };
+    final byte[] val1 = Bytes.fromLong(4L);
+    final byte[] qual2 = { 0x00, 0x27 };
+    final byte[] val2 = Bytes.fromLong(5L);
+    final byte[] qual12 = MockBase.concatByteArrays(qual1, qual2);
+    
+    final Span span = new Span(tsdb);
+    span.addRow(new KeyValue(HOUR1, FAMILY, qual12, 
+        MockBase.concatByteArrays(val1, val2, ZERO)));
+    
+    assertEquals(2, span.size());
+    final ByteMap<byte[]> uids = span.getTagUids();
+    assertEquals(1, uids.size());
+    assertArrayEquals(new byte[] { 0, 0, 1 }, uids.firstKey());
+    assertArrayEquals(new byte[] { 0, 0, 2 }, 
+        uids.firstEntry().getValue());
+  }
+  
+  @Test
+  public void getTagUidsSalted() {
+    PowerMockito.mockStatic(Const.class);
+    PowerMockito.when(Const.SALT_WIDTH()).thenReturn(1);
+    PowerMockito.when(Const.SALT_BUCKETS()).thenReturn(2);
+    
+    final byte[] qual1 = { 0x00, 0x07 };
+    final byte[] val1 = Bytes.fromLong(4L);
+    final byte[] qual2 = { 0x00, 0x27 };
+    final byte[] val2 = Bytes.fromLong(5L);
+    final byte[] qual12 = MockBase.concatByteArrays(qual1, qual2);
+    
+    final Span span = new Span(tsdb);
+    final byte[] key = new byte[HOUR1.length + 1];
+    System.arraycopy(HOUR1, 0, key, 1, HOUR1.length);
+    span.addRow(new KeyValue(key, FAMILY, qual12, 
+        MockBase.concatByteArrays(val1, val2, ZERO)));
+    
+    assertEquals(2, span.size());
+    final ByteMap<byte[]> uids = span.getTagUids();
+    assertEquals(1, uids.size());
+    assertArrayEquals(new byte[] { 0, 0, 1 }, uids.firstKey());
+    assertArrayEquals(new byte[] { 0, 0, 2 }, 
+        uids.firstEntry().getValue());
+  }
+  
+  @Test (expected = IllegalStateException.class)
+  public void getTagUidsNotSet() {
+    final Span span = new Span(tsdb);
+    span.getTagUids();
+  }
+
+  @Test
+  public void getAggregatedTagUids() {
+    final byte[] qual1 = { 0x00, 0x07 };
+    final byte[] val1 = Bytes.fromLong(4L);
+    final byte[] qual2 = { 0x00, 0x27 };
+    final byte[] val2 = Bytes.fromLong(5L);
+    final byte[] qual12 = MockBase.concatByteArrays(qual1, qual2);
+    
+    final Span span = new Span(tsdb);
+    span.addRow(new KeyValue(HOUR1, FAMILY, qual12, 
+        MockBase.concatByteArrays(val1, val2, ZERO)));
+    
+    assertEquals(2, span.size());
+    final List<byte[]> uids = span.getAggregatedTagUids();
+    assertEquals(0, uids.size());
+  }
+  
+  @Test
+  public void getAggregatedTagUidsNotSet() {
+    final Span span = new Span(tsdb);
+    assertTrue(span.getAggregatedTagUids().isEmpty());
+  }
+
 }
diff --git a/test/core/TestSpanGroup.java b/test/core/TestSpanGroup.java
index 8b0d9d848e..f24458c4c9 100644
--- a/test/core/TestSpanGroup.java
+++ b/test/core/TestSpanGroup.java
@@ -12,15 +12,16 @@
 // see <http://www.gnu.org/licenses/>.
 package net.opentsdb.core;
 
+import static org.junit.Assert.assertArrayEquals;
 import static org.junit.Assert.assertEquals;
 import static org.mockito.Mockito.mock;
 import static org.mockito.Mockito.when;
 
 import java.util.ArrayList;
+import java.util.List;
 
 import net.opentsdb.utils.Config;
 
-import org.hbase.async.Bytes;
 import org.hbase.async.Bytes.ByteMap;
 import org.hbase.async.HBaseClient;
 import org.junit.Before;
@@ -45,6 +46,19 @@ public void before() {
     tsdb = PowerMockito.mock(TSDB.class);
   }
   
+  @Test
+  public void metricUID() throws Exception {
+    final Span span = mock(Span.class);
+    when(span.metricUID()).thenReturn(new byte[] { 0, 0, 1 });
+    
+    final SpanGroup group = PowerMockito.spy(new SpanGroup(tsdb, start_ts, 
+        end_ts, null, false, Aggregators.SUM, 0, null));
+    final ArrayList<Span> spans = Whitebox.getInternalState(group, "spans");
+    spans.add(span);
+    
+    assertArrayEquals(new byte[] { 0, 0, 1 }, group.metricUID());
+  }
+  
   @Test
   public void getTagUids() throws Exception {
     final ByteMap<byte[]> uids = new ByteMap<byte[]>();
@@ -59,9 +73,9 @@ public void getTagUids() throws Exception {
     
     final ByteMap<byte[]> uids_read = group.getTagUids();
     assertEquals(1, uids_read.size());
-    assertEquals(0, Bytes.memcmp(new byte[] { 0, 0, 1 }, uids_read.firstKey()));
-    assertEquals(0, Bytes.memcmp(new byte[] { 0, 0, 2 }, 
-        uids_read.firstEntry().getValue()));
+    assertArrayEquals(new byte[] { 0, 0, 1 }, uids_read.firstKey());
+    assertArrayEquals(new byte[] { 0, 0, 2 }, 
+        uids_read.firstEntry().getValue());
   }
   
   @Test
@@ -94,4 +108,53 @@ public void getTagUidsNoSpans() throws Exception {
     final ByteMap<byte[]> uids_read = group.getTagUids();
     assertEquals(0, uids_read.size());
   }
+  
+  @Test
+  public void getAggregatedTagUidsNotAgged() throws Exception {
+    final ByteMap<byte[]> uids = new ByteMap<byte[]>();
+    uids.put(new byte[] { 0, 0, 1 }, new byte[] { 0, 0, 2 });
+    final Span span = mock(Span.class);
+    when(span.getTagUids()).thenReturn(uids);
+    
+    final SpanGroup group = PowerMockito.spy(new SpanGroup(tsdb, start_ts, 
+        end_ts, null, false, Aggregators.SUM, 0, null));
+    final ArrayList<Span> spans = Whitebox.getInternalState(group, "spans");
+    spans.add(span);
+    
+    final List<byte[]> uids_read = group.getAggregatedTagUids();
+    assertEquals(0, uids_read.size());
+  }
+  
+  @Test
+  public void getAggregatedTagUids() throws Exception {
+    final ByteMap<byte[]> uids = new ByteMap<byte[]>();
+    uids.put(new byte[] { 0, 0, 1 }, new byte[] { 0, 0, 2 });
+    final Span span = mock(Span.class);
+    when(span.getTagUids()).thenReturn(uids);
+    
+    final ByteMap<byte[]> uids2 = new ByteMap<byte[]>();
+    uids2.put(new byte[] { 0, 0, 1 }, new byte[] { 0, 0, 0, 3 });
+    final Span span2 = mock(Span.class);
+    when(span2.getTagUids()).thenReturn(uids2);
+    
+    final SpanGroup group = PowerMockito.spy(new SpanGroup(tsdb, start_ts, 
+        end_ts, null, false, Aggregators.SUM, 0, null));
+    final ArrayList<Span> spans = Whitebox.getInternalState(group, "spans");
+    spans.add(span);
+    spans.add(span2);
+    
+    final List<byte[]> uids_read = group.getAggregatedTagUids();
+    assertEquals(1, uids_read.size());
+    assertArrayEquals(new byte[] { 0, 0, 1 }, uids_read.get(0));
+  }
+  
+  @Test
+  public void getAggregatedTagUidsNoSpans() throws Exception {
+    final SpanGroup group = new SpanGroup(tsdb, start_ts, end_ts, null, 
+        false, Aggregators.SUM, 0, null);
+    
+    final List<byte[]> uids_read = group.getAggregatedTagUids();
+    assertEquals(0, uids_read.size());
+  }
+
 }
diff --git a/test/core/TestTSDB.java b/test/core/TestTSDB.java
index ae3fc98230..64c4e64738 100644
--- a/test/core/TestTSDB.java
+++ b/test/core/TestTSDB.java
@@ -28,7 +28,6 @@
 import net.opentsdb.utils.Config;
 
 import org.hbase.async.AtomicIncrementRequest;
-import org.hbase.async.Bytes;
 import org.hbase.async.GetRequest;
 import org.hbase.async.HBaseClient;
 import org.hbase.async.KeyValue;
@@ -37,11 +36,9 @@
 import org.junit.Before;
 import org.junit.Test;
 import org.junit.runner.RunWith;
-import org.powermock.api.mockito.PowerMockito;
 import org.powermock.core.classloader.annotations.PowerMockIgnore;
 import org.powermock.core.classloader.annotations.PrepareForTest;
 import org.powermock.modules.junit4.PowerMockRunner;
-import org.powermock.reflect.Whitebox;
 
 import com.stumbleupon.async.Deferred;
 
@@ -401,638 +398,58 @@ public void assignUidInvalidCharacter() {
     tsdb.assignUid("metric", "Not!A:Valid@Name");
   }
   
-  @Test
-  public void uidTable() {
-    assertNotNull(tsdb.uidTable());
-    assertArrayEquals("tsdb-uid".getBytes(), tsdb.uidTable());
-  }
-
-  @Test
-  public void addPointLong1Byte() throws Exception {
-    setupAddPointStorage();
-
-    tsdb.addPoint(METRIC_STRING, 1356998400, 42, tags).joinUninterruptibly();
-    final byte[] row = new byte[] { 0, 0, 1, 0x50, (byte) 0xE2, 0x27, 0, 
-        0, 0, 1, 0, 0, 1};
-    final byte[] value = storage.getColumn(row, new byte[] { 0, 0 });
-    assertNotNull(value);
-    assertEquals(42, value[0]);
-  }
-  
-  @Test
-  public void addPointLong1ByteNegative() throws Exception {
-    setupAddPointStorage();
-    
-    tsdb.addPoint(METRIC_STRING, 1356998400, -42, tags).joinUninterruptibly();
-    final byte[] row = new byte[] { 0, 0, 1, 0x50, (byte) 0xE2, 0x27, 0, 
-        0, 0, 1, 0, 0, 1};
-    final byte[] value = storage.getColumn(row, new byte[] { 0, 0 });
-    assertNotNull(value);
-    assertEquals(-42, value[0]);
-  }
-  
-  @Test
-  public void addPointLong2Bytes() throws Exception {
-    setupAddPointStorage();
-
-    tsdb.addPoint(METRIC_STRING, 1356998400, 257, tags).joinUninterruptibly();
-    final byte[] row = new byte[] { 0, 0, 1, 0x50, (byte) 0xE2, 0x27, 0, 
-        0, 0, 1, 0, 0, 1};
-    final byte[] value = storage.getColumn(row, new byte[] { 0, 1 });
-    assertNotNull(value);
-    assertEquals(257, Bytes.getShort(value));
-  }
-  
-  @Test
-  public void addPointLong2BytesNegative() throws Exception {
-    setupAddPointStorage();
-
-    tsdb.addPoint(METRIC_STRING, 1356998400, -257, tags).joinUninterruptibly();
-    final byte[] row = new byte[] { 0, 0, 1, 0x50, (byte) 0xE2, 0x27, 0, 
-        0, 0, 1, 0, 0, 1};
-    final byte[] value = storage.getColumn(row, new byte[] { 0, 1 });
-    assertNotNull(value);
-    assertEquals(-257, Bytes.getShort(value));
-  }
-  
-  @Test
-  public void addPointLong4Bytes() throws Exception {
-    setupAddPointStorage();
-
-    tsdb.addPoint(METRIC_STRING, 1356998400, 65537, tags).joinUninterruptibly();
-    final byte[] row = new byte[] { 0, 0, 1, 0x50, (byte) 0xE2, 0x27, 0, 
-        0, 0, 1, 0, 0, 1};
-    final byte[] value = storage.getColumn(row, new byte[] { 0, 3 });
-    assertNotNull(value);
-    assertEquals(65537, Bytes.getInt(value));
-  }
-  
-  @Test
-  public void addPointLong4BytesNegative() throws Exception {
-    setupAddPointStorage();
-
-    tsdb.addPoint(METRIC_STRING, 1356998400, -65537, tags).joinUninterruptibly();
-    final byte[] row = new byte[] { 0, 0, 1, 0x50, (byte) 0xE2, 0x27, 0, 
-        0, 0, 1, 0, 0, 1};
-    final byte[] value = storage.getColumn(row, new byte[] { 0, 3 });
-    assertNotNull(value);
-    assertEquals(-65537, Bytes.getInt(value));
-  }
-  
-  @Test
-  public void addPointLong8Bytes() throws Exception {
-    setupAddPointStorage();
-
-    tsdb.addPoint(METRIC_STRING, 1356998400, 4294967296L, tags).joinUninterruptibly();
-    final byte[] row = new byte[] { 0, 0, 1, 0x50, (byte) 0xE2, 0x27, 0, 
-        0, 0, 1, 0, 0, 1};
-    final byte[] value = storage.getColumn(row, new byte[] { 0, 7 });
-    assertNotNull(value);
-    assertEquals(4294967296L, Bytes.getLong(value));
-  }
-  
-  @Test
-  public void addPointLong8BytesNegative() throws Exception {
-    setupAddPointStorage();
-
-    tsdb.addPoint(METRIC_STRING, 1356998400, -4294967296L, tags).joinUninterruptibly();
-    final byte[] row = new byte[] { 0, 0, 1, 0x50, (byte) 0xE2, 0x27, 0, 
-        0, 0, 1, 0, 0, 1};
-    final byte[] value = storage.getColumn(row, new byte[] { 0, 7 });
-    assertNotNull(value);
-    assertEquals(-4294967296L, Bytes.getLong(value));
-  }
-  
-  @Test
-  public void addPointLongMs() throws Exception {
-    setupAddPointStorage();
-
-    tsdb.addPoint(METRIC_STRING, 1356998400500L, 42, tags).joinUninterruptibly();
-    final byte[] row = new byte[] { 0, 0, 1, 0x50, (byte) 0xE2, 0x27, 0, 
-        0, 0, 1, 0, 0, 1};
-    final byte[] value = storage.getColumn(row, 
-        new byte[] { (byte) 0xF0, 0, 0x7D, 0 });
-    assertNotNull(value);
-    assertEquals(42, value[0]);
-  }
-  
-  @Test
-  public void addPointLongMany() throws Exception {
-    setupAddPointStorage();
-
-    long timestamp = 1356998400;
-    for (int i = 1; i <= 50; i++) {
-      tsdb.addPoint(METRIC_STRING, timestamp++, i, tags).joinUninterruptibly();
-    }
-    final byte[] row = new byte[] { 0, 0, 1, 0x50, (byte) 0xE2, 0x27, 0, 
-        0, 0, 1, 0, 0, 1};
-    final byte[] value = storage.getColumn(row, new byte[] { 0, 0 });
-    assertNotNull(value);
-    assertEquals(1, value[0]);
-    assertEquals(50, storage.numColumns(row));
-  }
-  
-  @Test
-  public void addPointLongManyMs() throws Exception {
-    setupAddPointStorage();
-
-    long timestamp = 1356998400500L;
-    for (int i = 1; i <= 50; i++) {
-      tsdb.addPoint(METRIC_STRING, timestamp++, i, tags).joinUninterruptibly();
-    }
-    final byte[] row = new byte[] { 0, 0, 1, 0x50, (byte) 0xE2, 0x27, 0, 
-        0, 0, 1, 0, 0, 1};
-    final byte[] value = storage.getColumn(row, 
-        new byte[] { (byte) 0xF0, 0, 0x7D, 0 });
-    assertNotNull(value);
-    assertEquals(1, value[0]);
-    assertEquals(50, storage.numColumns(row));
-  }
-  
-  @Test
-  public void addPointLongEndOfRow() throws Exception {
-    setupAddPointStorage();
-
-    tsdb.addPoint(METRIC_STRING, 1357001999, 42, tags).joinUninterruptibly();
-    final byte[] row = new byte[] { 0, 0, 1, 0x50, (byte) 0xE2, 0x27, 0, 
-        0, 0, 1, 0, 0, 1};
-    final byte[] value = storage.getColumn(row, new byte[] { (byte) 0xE0, 
-        (byte) 0xF0 });
-    assertNotNull(value);
-    assertEquals(42, value[0]);
-  }
-  
-  @Test
-  public void addPointLongOverwrite() throws Exception {
-    setupAddPointStorage();
-
-    tsdb.addPoint(METRIC_STRING, 1356998400, 42, tags).joinUninterruptibly();
-    tsdb.addPoint(METRIC_STRING, 1356998400, 24, tags).joinUninterruptibly();
-    final byte[] row = new byte[] { 0, 0, 1, 0x50, (byte) 0xE2, 0x27, 0, 
-        0, 0, 1, 0, 0, 1};
-    final byte[] value = storage.getColumn(row, new byte[] { 0, 0 });
-    assertNotNull(value);
-    assertEquals(24, value[0]);
-  }
-  
-  @Test (expected = NoSuchUniqueName.class)
-  public void addPointNoAutoMetric() throws Exception {
-    setupAddPointStorage();
-    tsdb.addPoint(NSUN_METRIC, 1356998400, 42, tags).joinUninterruptibly();
-  }
-
-  @Test
-  public void addPointSecondZero() throws Exception {
-    // Thu, 01 Jan 1970 00:00:00 GMT
-    setupAddPointStorage();
-
-    tsdb.addPoint(METRIC_STRING, 0, 42, tags).joinUninterruptibly();
-    final byte[] row = new byte[] { 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1};
-    final byte[] value = storage.getColumn(row, new byte[] { 0, 0 });
-    assertNotNull(value);
-    assertEquals(42, value[0]);
-  }
-  
-  @Test
-  public void addPointSecondOne() throws Exception {
-    // hey, it's valid *shrug* Thu, 01 Jan 1970 00:00:01 GMT
-    setupAddPointStorage();
-
-    tsdb.addPoint(METRIC_STRING, 1, 42, tags).joinUninterruptibly();
-    final byte[] row = new byte[] { 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1};
-    final byte[] value = storage.getColumn(row, new byte[] { 0, 16 });
-    assertNotNull(value);
-    assertEquals(42, value[0]);
-  }
-  
-  @Test
-  public void addPointSecond2106() throws Exception {
-    // Sun, 07 Feb 2106 06:28:15 GMT
-    setupAddPointStorage();
-
-    tsdb.addPoint(METRIC_STRING, 4294967295L, 42, tags).joinUninterruptibly();
-    final byte[] row = new byte[] { 0, 0, 1, (byte) 0xFF, (byte) 0xFF, (byte) 0xF9, 
-        0x60, 0, 0, 1, 0, 0, 1};
-    final byte[] value = storage.getColumn(row, new byte[] { 0x69, (byte) 0xF0 });
-    assertNotNull(value);
-    assertEquals(42, value[0]);
-  }
-  
   @Test (expected = IllegalArgumentException.class)
-  public void addPointSecondNegative() throws Exception {
-    // Fri, 13 Dec 1901 20:45:52 GMT
-    // may support in the future, but 1.0 didn't
-    setupAddPointStorage();
-
-    tsdb.addPoint(METRIC_STRING, -2147483648, 42, tags).joinUninterruptibly();
-  }
-  
-  @Test (expected = IllegalArgumentException.class)
-  public void emptyTagValue() throws Exception {
-    setupAddPointStorage();
-    
-    tags.put(TAGK_STRING, "");
-    tsdb.addPoint(METRIC_STRING, 1234567890, 42, tags).joinUninterruptibly();
-  }
-
-  @Test
-  public void addPointMS1970() throws Exception {
-    // Since it's just over Integer.MAX_VALUE, OpenTSDB will treat this as
-    // a millisecond timestamp since it doesn't fit in 4 bytes.
-    // Base time is 4294800 which is Thu, 19 Feb 1970 17:00:00 GMT
-    // offset = F0A36000 or 167296 ms
-    setupAddPointStorage();
-
-    tsdb.addPoint(METRIC_STRING, 4294967296L, 42, tags).joinUninterruptibly();
-    final byte[] row = new byte[] { 0, 0, 1, 0, (byte) 0x41, (byte) 0x88, 
-        (byte) 0x90, 0, 0, 1, 0, 0, 1};
-    final byte[] value = storage.getColumn(row, new byte[] { (byte) 0xF0, 
-        (byte) 0xA3, 0x60, 0});
-    assertNotNull(value);
-    assertEquals(42, value[0]);
-  }
-  
-  @Test
-  public void addPointMS2106() throws Exception {
-    // Sun, 07 Feb 2106 06:28:15.000 GMT
-    setupAddPointStorage();
-
-    tsdb.addPoint(METRIC_STRING, 4294967295000L, 42, tags).joinUninterruptibly();
-    final byte[] row = new byte[] { 0, 0, 1, (byte) 0xFF, (byte) 0xFF, (byte) 0xF9, 
-        0x60, 0, 0, 1, 0, 0, 1};
-    final byte[] value = storage.getColumn(row, new byte[] { (byte) 0xF6, 
-        (byte) 0x77, 0x46, 0 });
-    assertNotNull(value);
-    assertEquals(42, value[0]);
+  public void renameUidInvalidNewname() {
+    tsdb.renameUid("metric", "existing", null);
   }
-  
-  @Test
-  public void addPointMS2286() throws Exception {
-    // It's an artificial limit and more thought needs to be put into it
-    setupAddPointStorage();
-
-    tsdb.addPoint(METRIC_STRING, 9999999999999L, 42, tags).joinUninterruptibly();
-    final byte[] row = new byte[] { 0, 0, 1, (byte) 0x54, (byte) 0x0B, (byte) 0xD9, 
-        0x10, 0, 0, 1, 0, 0, 1};
-    final byte[] value = storage.getColumn(row, new byte[] { (byte) 0xFA, 
-        (byte) 0xAE, 0x5F, (byte) 0xC0 });
-    assertNotNull(value);
-    assertEquals(42, value[0]);
-  }
-  
-  @Test  (expected = IllegalArgumentException.class)
-  public void addPointMSTooLarge() throws Exception {
-    // It's an artificial limit and more thought needs to be put into it
-    setupAddPointStorage();
 
-    tsdb.addPoint(METRIC_STRING, 10000000000000L, 42, tags).joinUninterruptibly();
-  }
-  
   @Test (expected = IllegalArgumentException.class)
-  public void addPointMSNegative() throws Exception {
-    // Fri, 13 Dec 1901 20:45:52 GMT
-    // may support in the future, but 1.0 didn't
-    setupAddPointStorage();
-    HashMap<String, String> tags = new HashMap<String, String>(1);
-    tags.put("host", "web01");
-    tsdb.addPoint(METRIC_STRING, -2147483648000L, 42, tags).joinUninterruptibly();
-  }
-
-  @Test
-  public void addPointFloat() throws Exception {
-    setupAddPointStorage();
-
-    tsdb.addPoint(METRIC_STRING, 1356998400, 42.5F, tags).joinUninterruptibly();
-    final byte[] row = new byte[] { 0, 0, 1, 0x50, (byte) 0xE2, 0x27, 0, 
-        0, 0, 1, 0, 0, 1};
-    final byte[] value = storage.getColumn(row, new byte[] { 0, 11 });
-    assertNotNull(value);
-    // should have 7 digits of precision
-    assertEquals(42.5F, Float.intBitsToFloat(Bytes.getInt(value)), 0.0000001);
-  }
-  
-  @Test
-  public void addPointFloatNegative() throws Exception {
-    setupAddPointStorage();
-    HashMap<String, String> tags = new HashMap<String, String>(1);
-    tags.put("host", "web01");
-    tsdb.addPoint(METRIC_STRING, 1356998400, -42.5F, tags).joinUninterruptibly();
-    final byte[] row = new byte[] { 0, 0, 1, 0x50, (byte) 0xE2, 0x27, 0, 
-        0, 0, 1, 0, 0, 1};
-    final byte[] value = storage.getColumn(row, new byte[] { 0, 11 });
-    assertNotNull(value);
-    // should have 7 digits of precision
-    assertEquals(-42.5F, Float.intBitsToFloat(Bytes.getInt(value)), 0.0000001);
-  }
-  
-  @Test
-  public void addPointFloatMs() throws Exception {
-    setupAddPointStorage();
-
-    tsdb.addPoint(METRIC_STRING, 1356998400500L, 42.5F, tags).joinUninterruptibly();
-    final byte[] row = new byte[] { 0, 0, 1, 0x50, (byte) 0xE2, 0x27, 0, 
-        0, 0, 1, 0, 0, 1};
-    final byte[] value = storage.getColumn(row, 
-        new byte[] { (byte) 0xF0, 0, 0x7D, 11 });
-    assertNotNull(value);
-    // should have 7 digits of precision
-    assertEquals(42.5F, Float.intBitsToFloat(Bytes.getInt(value)), 0.0000001);
-  }
-  
-  @Test
-  public void addPointFloatEndOfRow() throws Exception {
-    setupAddPointStorage();
-    HashMap<String, String> tags = new HashMap<String, String>(1);
-    tags.put("host", "web01");
-    tsdb.addPoint(METRIC_STRING, 1357001999, 42.5F, tags).joinUninterruptibly();
-    final byte[] row = new byte[] { 0, 0, 1, 0x50, (byte) 0xE2, 0x27, 0, 
-        0, 0, 1, 0, 0, 1};
-    final byte[] value = storage.getColumn(row, new byte[] { (byte) 0xE0, 
-        (byte) 0xFB });
-    assertNotNull(value);
-    // should have 7 digits of precision
-    assertEquals(42.5F, Float.intBitsToFloat(Bytes.getInt(value)), 0.0000001);
-  }
-  
-  @Test
-  public void addPointFloatPrecision() throws Exception {
-    setupAddPointStorage();
-
-    tsdb.addPoint(METRIC_STRING, 1356998400, 42.5123459999F, tags)
-      .joinUninterruptibly();
-    final byte[] row = new byte[] { 0, 0, 1, 0x50, (byte) 0xE2, 0x27, 0, 
-        0, 0, 1, 0, 0, 1};
-    final byte[] value = storage.getColumn(row, new byte[] { 0, 11 });
-    assertNotNull(value);
-    // should have 7 digits of precision
-    assertEquals(42.512345F, Float.intBitsToFloat(Bytes.getInt(value)), 0.0000001);
-  }
-  
-  @Test
-  public void addPointFloatOverwrite() throws Exception {
-    setupAddPointStorage();
-
-    tsdb.addPoint(METRIC_STRING, 1356998400, 42.5F, tags).joinUninterruptibly();
-    tsdb.addPoint(METRIC_STRING, 1356998400, 25.4F, tags).joinUninterruptibly();
-    final byte[] row = new byte[] { 0, 0, 1, 0x50, (byte) 0xE2, 0x27, 0, 
-        0, 0, 1, 0, 0, 1};
-    final byte[] value = storage.getColumn(row, new byte[] { 0, 11 });
-    assertNotNull(value);
-    // should have 7 digits of precision
-    assertEquals(25.4F, Float.intBitsToFloat(Bytes.getInt(value)), 0.0000001);
-  }
-  
-  @Test
-  public void addPointBothSameTimeIntAndFloat() throws Exception {
-    // this is an odd situation that can occur if the user puts an int and then
-    // a float (or vice-versa) with the same timestamp. What happens in the
-    // aggregators when this occurs? 
-    setupAddPointStorage();
-
-    tsdb.addPoint(METRIC_STRING, 1356998400, 42, tags).joinUninterruptibly();
-    tsdb.addPoint(METRIC_STRING, 1356998400, 42.5F, tags).joinUninterruptibly();
-    final byte[] row = new byte[] { 0, 0, 1, 0x50, (byte) 0xE2, 0x27, 0, 
-        0, 0, 1, 0, 0, 1};
-    byte[] value = storage.getColumn(row, new byte[] { 0, 0 });
-    assertEquals(2, storage.numColumns(row));
-    assertNotNull(value);
-    assertEquals(42, value[0]);
-    value = storage.getColumn(row, new byte[] { 0, 11 });
-    assertNotNull(value);
-    // should have 7 digits of precision
-    assertEquals(42.5F, Float.intBitsToFloat(Bytes.getInt(value)), 0.0000001);
-  }
-  
-  @Test
-  public void addPointBothSameTimeIntAndFloatMs() throws Exception {
-    // this is an odd situation that can occur if the user puts an int and then
-    // a float (or vice-versa) with the same timestamp. What happens in the
-    // aggregators when this occurs? 
-    setupAddPointStorage();
- 
-    tsdb.addPoint(METRIC_STRING, 1356998400500L, 42, tags).joinUninterruptibly();
-    tsdb.addPoint(METRIC_STRING, 1356998400500L, 42.5F, tags).joinUninterruptibly();
-    final byte[] row = new byte[] { 0, 0, 1, 0x50, (byte) 0xE2, 0x27, 0, 
-        0, 0, 1, 0, 0, 1};
-    byte[] value = storage.getColumn(row, new byte[] { (byte) 0xF0, 0, 0x7D, 0 });
-    assertEquals(2, storage.numColumns(row));
-    assertNotNull(value);
-    assertEquals(42, value[0]);
-    value = storage.getColumn(row, new byte[] { (byte) 0xF0, 0, 0x7D, 11 });
-    assertNotNull(value);
-    // should have 7 digits of precision
-    assertEquals(42.5F, Float.intBitsToFloat(Bytes.getInt(value)), 0.0000001);
-  }
-  
-  @Test
-  public void addPointBothSameTimeSecondAndMs() throws Exception {
-    // this can happen if a second and an ms data point are stored for the same
-    // timestamp.
-    setupAddPointStorage();
-
-    tsdb.addPoint(METRIC_STRING, 1356998400L, 42, tags).joinUninterruptibly();
-    tsdb.addPoint(METRIC_STRING, 1356998400000L, 42, tags).joinUninterruptibly();
-    final byte[] row = new byte[] { 0, 0, 1, 0x50, (byte) 0xE2, 0x27, 0, 
-        0, 0, 1, 0, 0, 1};
-    byte[] value = storage.getColumn(row, new byte[] { 0, 0 });
-    assertEquals(2, storage.numColumns(row));
-    assertNotNull(value);
-    assertEquals(42, value[0]);
-    value = storage.getColumn(row, new byte[] { (byte) 0xF0, 0, 0, 0 });
-    assertNotNull(value);
-    // should have 7 digits of precision
-    assertEquals(42, value[0]);
-  }
-  
-  @Test
-  public void addPointWithSalt() throws Exception {
-    PowerMockito.mockStatic(Const.class);
-    PowerMockito.when(Const.SALT_WIDTH()).thenReturn(1);
-    PowerMockito.when(Const.SALT_BUCKETS()).thenReturn(20);
-    PowerMockito.when(Const.MAX_NUM_TAGS()).thenReturn((short) 8);
-    
-    setupAddPointStorage();
-
-    tsdb.addPoint(METRIC_STRING, 1356998400, 42, tags).joinUninterruptibly();
-    final byte[] row = new byte[] { 8, 0, 0, 1, 0x50, (byte) 0xE2, 0x27, 0, 
-        0, 0, 1, 0, 0, 1};
-    final byte[] value = storage.getColumn(row, new byte[] { 0, 0 });
-    assertNotNull(value);
-    assertEquals(42, value[0]);
+  public void renameUidNonexistentMetric() {
+    when(metrics.getId("sys.cpu.1")).thenThrow(
+        new NoSuchUniqueName("metric", "sys.cpu.1"));
+    tsdb.renameUid("metric", "sys.cpu.1", "sys.cpu.2");
   }
 
   @Test
-  public void addPointWithSaltDifferentTags() throws Exception {
-    PowerMockito.mockStatic(Const.class);
-    PowerMockito.when(Const.SALT_WIDTH()).thenReturn(1);
-    PowerMockito.when(Const.SALT_BUCKETS()).thenReturn(20);
-    PowerMockito.when(Const.MAX_NUM_TAGS()).thenReturn((short) 8);
-    
-    setupAddPointStorage();
-    tags.put(TAGK_STRING, TAGV_B_STRING);
-
-    tsdb.addPoint(METRIC_STRING, 1356998400, 42, tags).joinUninterruptibly();
-    final byte[] row = new byte[] { 9, 0, 0, 1, 0x50, (byte) 0xE2, 0x27, 0, 
-        0, 0, 1, 0, 0, 2};
-    final byte[] value = storage.getColumn(row, new byte[] { 0, 0 });
-    assertNotNull(value);
-    assertEquals(42, value[0]);
+  public void renameUidMetric() {
+    tsdb.renameUid("metric", "sys.cpu.1", "sys.cpu.2");
   }
-  
-  @Test
-  public void addPointWithSaltDifferentTime() throws Exception {
-    PowerMockito.mockStatic(Const.class);
-    PowerMockito.when(Const.SALT_WIDTH()).thenReturn(1);
-    PowerMockito.when(Const.SALT_BUCKETS()).thenReturn(20);
-    PowerMockito.when(Const.MAX_NUM_TAGS()).thenReturn((short) 8);
-    
-    setupAddPointStorage();
 
-    tsdb.addPoint(METRIC_STRING, 1359680400, 42, tags).joinUninterruptibly();
-    final byte[] row = new byte[] { 8, 0, 0, 1, 0x51, (byte) 0x0B, 0x13, 
-        (byte) 0x90, 0, 0, 1, 0, 0, 1};
-    final byte[] value = storage.getColumn(row, new byte[] { 0, 0 });
-    assertNotNull(value);
-    assertEquals(42, value[0]);
+  @Test (expected = IllegalArgumentException.class)
+  public void renameUidNonexistentTagk() {
+    when(tag_names.getId("datacenter")).thenThrow(
+        new NoSuchUniqueName("tagk", "datacenter"));
+    tsdb.renameUid("tagk", "datacenter", "datacluster");
   }
-  
-  @Test
-  public void addPointAppend() throws Exception {
-    Whitebox.setInternalState(config, "enable_appends", true);
-    setupAddPointStorage();
 
-    tsdb.addPoint(METRIC_STRING, 1356998400, 42, tags).joinUninterruptibly();
-    final byte[] row = new byte[] { 0, 0, 1, 0x50, (byte) 0xE2, 0x27, 0, 
-        0, 0, 1, 0, 0, 1};
-    final byte[] value = storage.getColumn(row, 
-        AppendDataPoints.APPEND_COLUMN_QUALIFIER);
-    assertArrayEquals(new byte[] { 0, 0, 42 }, value);
-  }
-  
   @Test
-  public void addPointAppendWithOffset() throws Exception {
-    Whitebox.setInternalState(config, "enable_appends", true);
-    setupAddPointStorage();
-
-    tsdb.addPoint(METRIC_STRING, 1356998430, 42, tags).joinUninterruptibly();
-    final byte[] row = new byte[] { 0, 0, 1, 0x50, (byte) 0xE2, 0x27, 0, 
-        0, 0, 1, 0, 0, 1};
-    final byte[] value = storage.getColumn(row, 
-        AppendDataPoints.APPEND_COLUMN_QUALIFIER);
-    assertArrayEquals(new byte[] { 1, -32, 42 }, value);
+  public void renameUidTagk() {
+    tsdb.renameUid("tagk", "datacenter", "datacluster");
   }
-  
-  @Test
-  public void addPointAppendAppending() throws Exception {
-    Whitebox.setInternalState(config, "enable_appends", true);
-    setupAddPointStorage();
 
-    tsdb.addPoint(METRIC_STRING, 1356998400, 42, tags).joinUninterruptibly();
-    tsdb.addPoint(METRIC_STRING, 1356998430, 24, tags).joinUninterruptibly();
-    tsdb.addPoint(METRIC_STRING, 1356998460, 1, tags).joinUninterruptibly();
-    final byte[] row = new byte[] { 0, 0, 1, 0x50, (byte) 0xE2, 0x27, 0, 
-        0, 0, 1, 0, 0, 1};
-    final byte[] value = storage.getColumn(row, 
-        AppendDataPoints.APPEND_COLUMN_QUALIFIER);
-    assertArrayEquals(new byte[] { 0, 0, 42, 1, -32, 24, 3, -64, 1 }, value);
+  @Test (expected = IllegalArgumentException.class)
+  public void renameUidNonexistentTagv() {
+    when(tag_values.getId("localhost")).thenThrow(
+        new NoSuchUniqueName("tagv", "localhost"));
+    tsdb.renameUid("tagv", "localhost", "127.0.0.1");
   }
-  
-  @Test
-  public void addPointAppendAppendingOutOfOrder() throws Exception {
-    Whitebox.setInternalState(config, "enable_appends", true);
-    setupAddPointStorage();
-
-    tsdb.addPoint(METRIC_STRING, 1356998400, 42, tags).joinUninterruptibly();
-    tsdb.addPoint(METRIC_STRING, 1356998460, 1, tags).joinUninterruptibly();
-    tsdb.addPoint(METRIC_STRING, 1356998430, 24, tags).joinUninterruptibly();
 
-    final byte[] row = new byte[] { 0, 0, 1, 0x50, (byte) 0xE2, 0x27, 0, 
-        0, 0, 1, 0, 0, 1};
-    final byte[] value = storage.getColumn(row, 
-        AppendDataPoints.APPEND_COLUMN_QUALIFIER);
-    assertArrayEquals(new byte[] { 0, 0, 42, 3, -64, 1, 1, -32, 24 }, value);
-  }
-  
   @Test
-  public void addPointAppendAppendingDuplicates() throws Exception {
-    Whitebox.setInternalState(config, "enable_appends", true);
-    setupAddPointStorage();
-
-    tsdb.addPoint(METRIC_STRING, 1356998400, 42, tags).joinUninterruptibly();
-    tsdb.addPoint(METRIC_STRING, 1356998430, 24, tags).joinUninterruptibly();
-    tsdb.addPoint(METRIC_STRING, 1356998430, 1, tags).joinUninterruptibly();
-    final byte[] row = new byte[] { 0, 0, 1, 0x50, (byte) 0xE2, 0x27, 0, 
-        0, 0, 1, 0, 0, 1};
-    final byte[] value = storage.getColumn(row, 
-        AppendDataPoints.APPEND_COLUMN_QUALIFIER);
-    assertArrayEquals(new byte[] { 0, 0, 42, 1, -32, 24, 1, -32, 1 }, value);
+  public void renameUidTagv() {
+    tsdb.renameUid("tagv", "localhost", "127.0.0.1");
   }
-  
-  @Test
-  public void addPointAppendMS() throws Exception {
-    Whitebox.setInternalState(config, "enable_appends", true);
-    setupAddPointStorage();
 
-    tsdb.addPoint(METRIC_STRING, 1356998400050L, 42, tags).joinUninterruptibly();
-    final byte[] row = new byte[] { 0, 0, 1, 0x50, (byte) 0xE2, 0x27, 0, 
-        0, 0, 1, 0, 0, 1};
-    final byte[] value = storage.getColumn(row, 
-        AppendDataPoints.APPEND_COLUMN_QUALIFIER);
-    assertArrayEquals(new byte[] { (byte) 0xF0, 0, 12, -128, 42 }, value);
+  @Test (expected = IllegalArgumentException.class)
+  public void renameUidBadType() {
+    tsdb.renameUid("wrongtype", METRIC_STRING, METRIC_STRING);
   }
-  
-  @Test
-  public void addPointAppendAppendingMixMS() throws Exception {
-    Whitebox.setInternalState(config, "enable_appends", true);
-    setupAddPointStorage();
 
-    tsdb.addPoint(METRIC_STRING, 1356998400, 42, tags).joinUninterruptibly();
-    tsdb.addPoint(METRIC_STRING, 1356998400050L, 1, tags).joinUninterruptibly();
-    tsdb.addPoint(METRIC_STRING, 1356998430, 24, tags).joinUninterruptibly();
-    final byte[] row = new byte[] { 0, 0, 1, 0x50, (byte) 0xE2, 0x27, 0, 
-        0, 0, 1, 0, 0, 1};
-    final byte[] value = storage.getColumn(row, 
-        AppendDataPoints.APPEND_COLUMN_QUALIFIER);
-    assertArrayEquals(new byte[] { 
-        0, 0, 42, (byte) 0xF0, 0, 12, -128, 1, 1, -32, 24 }, value);
-  }
-  
   @Test
-  public void addPointAppendWithSalt() throws Exception {
-    PowerMockito.mockStatic(Const.class);
-    PowerMockito.when(Const.SALT_WIDTH()).thenReturn(1);
-    PowerMockito.when(Const.SALT_BUCKETS()).thenReturn(20);
-    PowerMockito.when(Const.MAX_NUM_TAGS()).thenReturn((short) 8);
-    Whitebox.setInternalState(config, "enable_appends", true);
-    setupAddPointStorage();
-
-    tsdb.addPoint(METRIC_STRING, 1356998400, 42, tags).joinUninterruptibly();
-    final byte[] row = new byte[] { 8, 0, 0, 1, 0x50, (byte) 0xE2, 0x27, 0, 
-        0, 0, 1, 0, 0, 1};
-    final byte[] value = storage.getColumn(row, 
-        AppendDataPoints.APPEND_COLUMN_QUALIFIER);
-    assertArrayEquals(new byte[] { 0, 0, 42 }, value);
+  public void uidTable() {
+    assertNotNull(tsdb.uidTable());
+    assertArrayEquals("tsdb-uid".getBytes(), tsdb.uidTable());
   }
-  
-  @Test
-  public void addPointAppendAppendingWithSalt() throws Exception {
-    PowerMockito.mockStatic(Const.class);
-    PowerMockito.when(Const.SALT_WIDTH()).thenReturn(1);
-    PowerMockito.when(Const.SALT_BUCKETS()).thenReturn(20);
-    PowerMockito.when(Const.MAX_NUM_TAGS()).thenReturn((short) 8);
-    Whitebox.setInternalState(config, "enable_appends", true);
-    setupAddPointStorage();
 
-    tsdb.addPoint(METRIC_STRING, 1356998400, 42, tags).joinUninterruptibly();
-    tsdb.addPoint(METRIC_STRING, 1356998430, 24, tags).joinUninterruptibly();
-    tsdb.addPoint(METRIC_STRING, 1356998460, 1, tags).joinUninterruptibly();
-    final byte[] row = new byte[] { 8, 0, 0, 1, 0x50, (byte) 0xE2, 0x27, 0, 
-        0, 0, 1, 0, 0, 1};
-    final byte[] value = storage.getColumn(row, 
-        AppendDataPoints.APPEND_COLUMN_QUALIFIER);
-    assertArrayEquals(new byte[] { 0, 0, 42, 1, -32, 24, 3, -64, 1 }, value);
-  }
-  
   /**
    * Helper to mock the UID caches with valid responses
    */
diff --git a/test/core/TestTSDBAddPoint.java b/test/core/TestTSDBAddPoint.java
new file mode 100644
index 0000000000..6e16f08622
--- /dev/null
+++ b/test/core/TestTSDBAddPoint.java
@@ -0,0 +1,690 @@
+// This file is part of OpenTSDB.
+// Copyright (C) 2016  The OpenTSDB Authors.
+//
+// This program is free software: you can redistribute it and/or modify it
+// under the terms of the GNU Lesser General Public License as published by
+// the Free Software Foundation, either version 2.1 of the License, or (at your
+// option) any later version.  This program is distributed in the hope that it
+// will be useful, but WITHOUT ANY WARRANTY; without even the implied warranty
+// of MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser
+// General Public License for more details.  You should have received a copy
+// of the GNU Lesser General Public License along with this program.  If not,
+// see <http://www.gnu.org/licenses/>.
+package net.opentsdb.core;
+
+import static org.mockito.Matchers.any;
+import static org.mockito.Matchers.anyLong;
+import static org.mockito.Matchers.anyShort;
+import static org.mockito.Matchers.eq;
+import static org.junit.Assert.assertArrayEquals;
+import static org.junit.Assert.assertEquals;
+import static org.junit.Assert.assertNotNull;
+import static org.junit.Assert.assertNull;
+import static org.junit.Assert.fail;
+import static org.mockito.Mockito.mock;
+import static org.mockito.Mockito.times;
+import static org.mockito.Mockito.verify;
+import static org.mockito.Mockito.when;
+
+import java.util.HashMap;
+
+import org.hbase.async.Bytes;
+import org.junit.Before;
+import org.junit.Test;
+import org.powermock.api.mockito.PowerMockito;
+import org.powermock.reflect.Whitebox;
+
+import com.stumbleupon.async.Deferred;
+
+import net.opentsdb.uid.NoSuchUniqueName;
+
+public class TestTSDBAddPoint extends BaseTsdbTest {
+
+  @Before
+  public void beforeLocal() throws Exception {
+    setDataPointStorage();
+  }
+  
+  @Test
+  public void addPointLong1Byte() throws Exception {
+    tsdb.addPoint(METRIC_STRING, 1356998400, 42, tags).joinUninterruptibly();
+    final byte[] row = new byte[] { 0, 0, 1, 0x50, (byte) 0xE2, 0x27, 0, 
+        0, 0, 1, 0, 0, 1};
+    final byte[] value = storage.getColumn(row, new byte[] { 0, 0 });
+    assertNotNull(value);
+    assertEquals(42, value[0]);
+  }
+  
+  @Test
+  public void addPointLong1ByteNegative() throws Exception {
+    tsdb.addPoint(METRIC_STRING, 1356998400, -42, tags).joinUninterruptibly();
+    final byte[] row = new byte[] { 0, 0, 1, 0x50, (byte) 0xE2, 0x27, 0, 
+        0, 0, 1, 0, 0, 1};
+    final byte[] value = storage.getColumn(row, new byte[] { 0, 0 });
+    assertNotNull(value);
+    assertEquals(-42, value[0]);
+  }
+  
+  @Test
+  public void addPointLong2Bytes() throws Exception {
+    tsdb.addPoint(METRIC_STRING, 1356998400, 257, tags).joinUninterruptibly();
+    final byte[] row = new byte[] { 0, 0, 1, 0x50, (byte) 0xE2, 0x27, 0, 
+        0, 0, 1, 0, 0, 1};
+    final byte[] value = storage.getColumn(row, new byte[] { 0, 1 });
+    assertNotNull(value);
+    assertEquals(257, Bytes.getShort(value));
+  }
+  
+  @Test
+  public void addPointLong2BytesNegative() throws Exception {
+    tsdb.addPoint(METRIC_STRING, 1356998400, -257, tags).joinUninterruptibly();
+    final byte[] row = new byte[] { 0, 0, 1, 0x50, (byte) 0xE2, 0x27, 0, 
+        0, 0, 1, 0, 0, 1};
+    final byte[] value = storage.getColumn(row, new byte[] { 0, 1 });
+    assertNotNull(value);
+    assertEquals(-257, Bytes.getShort(value));
+  }
+  
+  @Test
+  public void addPointLong4Bytes() throws Exception {
+    tsdb.addPoint(METRIC_STRING, 1356998400, 65537, tags).joinUninterruptibly();
+    final byte[] row = new byte[] { 0, 0, 1, 0x50, (byte) 0xE2, 0x27, 0, 
+        0, 0, 1, 0, 0, 1};
+    final byte[] value = storage.getColumn(row, new byte[] { 0, 3 });
+    assertNotNull(value);
+    assertEquals(65537, Bytes.getInt(value));
+  }
+  
+  @Test
+  public void addPointLong4BytesNegative() throws Exception {
+    tsdb.addPoint(METRIC_STRING, 1356998400, -65537, tags).joinUninterruptibly();
+    final byte[] row = new byte[] { 0, 0, 1, 0x50, (byte) 0xE2, 0x27, 0, 
+        0, 0, 1, 0, 0, 1};
+    final byte[] value = storage.getColumn(row, new byte[] { 0, 3 });
+    assertNotNull(value);
+    assertEquals(-65537, Bytes.getInt(value));
+  }
+  
+  @Test
+  public void addPointLong8Bytes() throws Exception {
+    tsdb.addPoint(METRIC_STRING, 1356998400, 4294967296L, tags).joinUninterruptibly();
+    final byte[] row = new byte[] { 0, 0, 1, 0x50, (byte) 0xE2, 0x27, 0, 
+        0, 0, 1, 0, 0, 1};
+    final byte[] value = storage.getColumn(row, new byte[] { 0, 7 });
+    assertNotNull(value);
+    assertEquals(4294967296L, Bytes.getLong(value));
+  }
+  
+  @Test
+  public void addPointLong8BytesNegative() throws Exception {
+    tsdb.addPoint(METRIC_STRING, 1356998400, -4294967296L, tags).joinUninterruptibly();
+    final byte[] row = new byte[] { 0, 0, 1, 0x50, (byte) 0xE2, 0x27, 0, 
+        0, 0, 1, 0, 0, 1};
+    final byte[] value = storage.getColumn(row, new byte[] { 0, 7 });
+    assertNotNull(value);
+    assertEquals(-4294967296L, Bytes.getLong(value));
+  }
+  
+  @Test
+  public void addPointLongMs() throws Exception {
+    tsdb.addPoint(METRIC_STRING, 1356998400500L, 42, tags).joinUninterruptibly();
+    final byte[] row = new byte[] { 0, 0, 1, 0x50, (byte) 0xE2, 0x27, 0, 
+        0, 0, 1, 0, 0, 1};
+    final byte[] value = storage.getColumn(row, 
+        new byte[] { (byte) 0xF0, 0, 0x7D, 0 });
+    assertNotNull(value);
+    assertEquals(42, value[0]);
+  }
+  
+  @Test
+  public void addPointLongMany() throws Exception {
+    long timestamp = 1356998400;
+    for (int i = 1; i <= 50; i++) {
+      tsdb.addPoint(METRIC_STRING, timestamp++, i, tags).joinUninterruptibly();
+    }
+    final byte[] row = new byte[] { 0, 0, 1, 0x50, (byte) 0xE2, 0x27, 0, 
+        0, 0, 1, 0, 0, 1};
+    final byte[] value = storage.getColumn(row, new byte[] { 0, 0 });
+    assertNotNull(value);
+    assertEquals(1, value[0]);
+    assertEquals(50, storage.numColumns(row));
+  }
+  
+  @Test
+  public void addPointLongManyMs() throws Exception {
+    long timestamp = 1356998400500L;
+    for (int i = 1; i <= 50; i++) {
+      tsdb.addPoint(METRIC_STRING, timestamp++, i, tags).joinUninterruptibly();
+    }
+    final byte[] row = new byte[] { 0, 0, 1, 0x50, (byte) 0xE2, 0x27, 0, 
+        0, 0, 1, 0, 0, 1};
+    final byte[] value = storage.getColumn(row, 
+        new byte[] { (byte) 0xF0, 0, 0x7D, 0 });
+    assertNotNull(value);
+    assertEquals(1, value[0]);
+    assertEquals(50, storage.numColumns(row));
+  }
+  
+  @Test
+  public void addPointLongEndOfRow() throws Exception {
+    tsdb.addPoint(METRIC_STRING, 1357001999, 42, tags).joinUninterruptibly();
+    final byte[] row = new byte[] { 0, 0, 1, 0x50, (byte) 0xE2, 0x27, 0, 
+        0, 0, 1, 0, 0, 1};
+    final byte[] value = storage.getColumn(row, new byte[] { (byte) 0xE0, 
+        (byte) 0xF0 });
+    assertNotNull(value);
+    assertEquals(42, value[0]);
+  }
+  
+  @Test
+  public void addPointLongOverwrite() throws Exception {
+    tsdb.addPoint(METRIC_STRING, 1356998400, 42, tags).joinUninterruptibly();
+    tsdb.addPoint(METRIC_STRING, 1356998400, 24, tags).joinUninterruptibly();
+    final byte[] row = new byte[] { 0, 0, 1, 0x50, (byte) 0xE2, 0x27, 0, 
+        0, 0, 1, 0, 0, 1};
+    final byte[] value = storage.getColumn(row, new byte[] { 0, 0 });
+    assertNotNull(value);
+    assertEquals(24, value[0]);
+  }
+  
+  @Test (expected = NoSuchUniqueName.class)
+  public void addPointNoAutoMetric() throws Exception {
+    tsdb.addPoint(NSUN_METRIC, 1356998400, 42, tags).joinUninterruptibly();
+  }
+
+  @Test
+  public void addPointSecondZero() throws Exception {
+    // Thu, 01 Jan 1970 00:00:00 GMT
+    tsdb.addPoint(METRIC_STRING, 0, 42, tags).joinUninterruptibly();
+    final byte[] row = new byte[] { 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1};
+    final byte[] value = storage.getColumn(row, new byte[] { 0, 0 });
+    assertNotNull(value);
+    assertEquals(42, value[0]);
+  }
+  
+  @Test
+  public void addPointSecondOne() throws Exception {
+    // hey, it's valid *shrug* Thu, 01 Jan 1970 00:00:01 GMT
+    tsdb.addPoint(METRIC_STRING, 1, 42, tags).joinUninterruptibly();
+    final byte[] row = new byte[] { 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1};
+    final byte[] value = storage.getColumn(row, new byte[] { 0, 16 });
+    assertNotNull(value);
+    assertEquals(42, value[0]);
+  }
+  
+  @Test
+  public void addPointSecond2106() throws Exception {
+    // Sun, 07 Feb 2106 06:28:15 GMT
+    tsdb.addPoint(METRIC_STRING, 4294967295L, 42, tags).joinUninterruptibly();
+    final byte[] row = new byte[] { 0, 0, 1, (byte) 0xFF, (byte) 0xFF, (byte) 0xF9, 
+        0x60, 0, 0, 1, 0, 0, 1};
+    final byte[] value = storage.getColumn(row, new byte[] { 0x69, (byte) 0xF0 });
+    assertNotNull(value);
+    assertEquals(42, value[0]);
+  }
+  
+  @Test (expected = IllegalArgumentException.class)
+  public void addPointSecondNegative() throws Exception {
+    // Fri, 13 Dec 1901 20:45:52 GMT
+    // may support in the future, but 1.0 didn't
+    tsdb.addPoint(METRIC_STRING, -2147483648, 42, tags).joinUninterruptibly();
+  }
+  
+  @Test (expected = IllegalArgumentException.class)
+  public void emptyTagValue() throws Exception {
+    tags.put(TAGK_STRING, "");
+    tsdb.addPoint(METRIC_STRING, 1234567890, 42, tags).joinUninterruptibly();
+  }
+
+  @Test
+  public void addPointMS1970() throws Exception {
+    // Since it's just over Integer.MAX_VALUE, OpenTSDB will treat this as
+    // a millisecond timestamp since it doesn't fit in 4 bytes.
+    // Base time is 4294800 which is Thu, 19 Feb 1970 17:00:00 GMT
+    // offset = F0A36000 or 167296 ms
+    tsdb.addPoint(METRIC_STRING, 4294967296L, 42, tags).joinUninterruptibly();
+    final byte[] row = new byte[] { 0, 0, 1, 0, (byte) 0x41, (byte) 0x88, 
+        (byte) 0x90, 0, 0, 1, 0, 0, 1};
+    final byte[] value = storage.getColumn(row, new byte[] { (byte) 0xF0, 
+        (byte) 0xA3, 0x60, 0});
+    assertNotNull(value);
+    assertEquals(42, value[0]);
+  }
+  
+  @Test
+  public void addPointMS2106() throws Exception {
+    // Sun, 07 Feb 2106 06:28:15.000 GMT
+    tsdb.addPoint(METRIC_STRING, 4294967295000L, 42, tags).joinUninterruptibly();
+    final byte[] row = new byte[] { 0, 0, 1, (byte) 0xFF, (byte) 0xFF, (byte) 0xF9, 
+        0x60, 0, 0, 1, 0, 0, 1};
+    final byte[] value = storage.getColumn(row, new byte[] { (byte) 0xF6, 
+        (byte) 0x77, 0x46, 0 });
+    assertNotNull(value);
+    assertEquals(42, value[0]);
+  }
+  
+  @Test
+  public void addPointMS2286() throws Exception {
+    // It's an artificial limit and more thought needs to be put into it
+    tsdb.addPoint(METRIC_STRING, 9999999999999L, 42, tags).joinUninterruptibly();
+    final byte[] row = new byte[] { 0, 0, 1, (byte) 0x54, (byte) 0x0B, (byte) 0xD9, 
+        0x10, 0, 0, 1, 0, 0, 1};
+    final byte[] value = storage.getColumn(row, new byte[] { (byte) 0xFA, 
+        (byte) 0xAE, 0x5F, (byte) 0xC0 });
+    assertNotNull(value);
+    assertEquals(42, value[0]);
+  }
+  
+  @Test  (expected = IllegalArgumentException.class)
+  public void addPointMSTooLarge() throws Exception {
+    // It's an artificial limit and more thought needs to be put into it
+    tsdb.addPoint(METRIC_STRING, 10000000000000L, 42, tags).joinUninterruptibly();
+  }
+  
+  @Test (expected = IllegalArgumentException.class)
+  public void addPointMSNegative() throws Exception {
+    // Fri, 13 Dec 1901 20:45:52 GMT
+    // may support in the future, but 1.0 didn't
+    HashMap<String, String> tags = new HashMap<String, String>(1);
+    tags.put("host", "web01");
+    tsdb.addPoint(METRIC_STRING, -2147483648000L, 42, tags).joinUninterruptibly();
+  }
+
+  @Test
+  public void addPointFloat() throws Exception {
+    tsdb.addPoint(METRIC_STRING, 1356998400, 42.5F, tags).joinUninterruptibly();
+    final byte[] row = new byte[] { 0, 0, 1, 0x50, (byte) 0xE2, 0x27, 0, 
+        0, 0, 1, 0, 0, 1};
+    final byte[] value = storage.getColumn(row, new byte[] { 0, 11 });
+    assertNotNull(value);
+    // should have 7 digits of precision
+    assertEquals(42.5F, Float.intBitsToFloat(Bytes.getInt(value)), 0.0000001);
+  }
+  
+  @Test
+  public void addPointFloatNegative() throws Exception {
+    HashMap<String, String> tags = new HashMap<String, String>(1);
+    tags.put("host", "web01");
+    tsdb.addPoint(METRIC_STRING, 1356998400, -42.5F, tags).joinUninterruptibly();
+    final byte[] row = new byte[] { 0, 0, 1, 0x50, (byte) 0xE2, 0x27, 0, 
+        0, 0, 1, 0, 0, 1};
+    final byte[] value = storage.getColumn(row, new byte[] { 0, 11 });
+    assertNotNull(value);
+    // should have 7 digits of precision
+    assertEquals(-42.5F, Float.intBitsToFloat(Bytes.getInt(value)), 0.0000001);
+  }
+  
+  @Test
+  public void addPointFloatMs() throws Exception {
+    tsdb.addPoint(METRIC_STRING, 1356998400500L, 42.5F, tags).joinUninterruptibly();
+    final byte[] row = new byte[] { 0, 0, 1, 0x50, (byte) 0xE2, 0x27, 0, 
+        0, 0, 1, 0, 0, 1};
+    final byte[] value = storage.getColumn(row, 
+        new byte[] { (byte) 0xF0, 0, 0x7D, 11 });
+    assertNotNull(value);
+    // should have 7 digits of precision
+    assertEquals(42.5F, Float.intBitsToFloat(Bytes.getInt(value)), 0.0000001);
+  }
+  
+  @Test
+  public void addPointFloatEndOfRow() throws Exception {
+    HashMap<String, String> tags = new HashMap<String, String>(1);
+    tags.put("host", "web01");
+    tsdb.addPoint(METRIC_STRING, 1357001999, 42.5F, tags).joinUninterruptibly();
+    final byte[] row = new byte[] { 0, 0, 1, 0x50, (byte) 0xE2, 0x27, 0, 
+        0, 0, 1, 0, 0, 1};
+    final byte[] value = storage.getColumn(row, new byte[] { (byte) 0xE0, 
+        (byte) 0xFB });
+    assertNotNull(value);
+    // should have 7 digits of precision
+    assertEquals(42.5F, Float.intBitsToFloat(Bytes.getInt(value)), 0.0000001);
+  }
+  
+  @Test
+  public void addPointFloatPrecision() throws Exception {
+    tsdb.addPoint(METRIC_STRING, 1356998400, 42.5123459999F, tags)
+      .joinUninterruptibly();
+    final byte[] row = new byte[] { 0, 0, 1, 0x50, (byte) 0xE2, 0x27, 0, 
+        0, 0, 1, 0, 0, 1};
+    final byte[] value = storage.getColumn(row, new byte[] { 0, 11 });
+    assertNotNull(value);
+    // should have 7 digits of precision
+    assertEquals(42.512345F, Float.intBitsToFloat(Bytes.getInt(value)), 0.0000001);
+  }
+  
+  @Test
+  public void addPointFloatOverwrite() throws Exception {
+    tsdb.addPoint(METRIC_STRING, 1356998400, 42.5F, tags).joinUninterruptibly();
+    tsdb.addPoint(METRIC_STRING, 1356998400, 25.4F, tags).joinUninterruptibly();
+    final byte[] row = new byte[] { 0, 0, 1, 0x50, (byte) 0xE2, 0x27, 0, 
+        0, 0, 1, 0, 0, 1};
+    final byte[] value = storage.getColumn(row, new byte[] { 0, 11 });
+    assertNotNull(value);
+    // should have 7 digits of precision
+    assertEquals(25.4F, Float.intBitsToFloat(Bytes.getInt(value)), 0.0000001);
+  }
+  
+  @Test
+  public void addPointBothSameTimeIntAndFloat() throws Exception {
+    // this is an odd situation that can occur if the user puts an int and then
+    // a float (or vice-versa) with the same timestamp. What happens in the
+    // aggregators when this occurs? 
+    tsdb.addPoint(METRIC_STRING, 1356998400, 42, tags).joinUninterruptibly();
+    tsdb.addPoint(METRIC_STRING, 1356998400, 42.5F, tags).joinUninterruptibly();
+    final byte[] row = new byte[] { 0, 0, 1, 0x50, (byte) 0xE2, 0x27, 0, 
+        0, 0, 1, 0, 0, 1};
+    byte[] value = storage.getColumn(row, new byte[] { 0, 0 });
+    assertEquals(2, storage.numColumns(row));
+    assertNotNull(value);
+    assertEquals(42, value[0]);
+    value = storage.getColumn(row, new byte[] { 0, 11 });
+    assertNotNull(value);
+    // should have 7 digits of precision
+    assertEquals(42.5F, Float.intBitsToFloat(Bytes.getInt(value)), 0.0000001);
+  }
+  
+  @Test
+  public void addPointBothSameTimeIntAndFloatMs() throws Exception {
+    // this is an odd situation that can occur if the user puts an int and then
+    // a float (or vice-versa) with the same timestamp. What happens in the
+    // aggregators when this occurs? 
+    tsdb.addPoint(METRIC_STRING, 1356998400500L, 42, tags).joinUninterruptibly();
+    tsdb.addPoint(METRIC_STRING, 1356998400500L, 42.5F, tags).joinUninterruptibly();
+    final byte[] row = new byte[] { 0, 0, 1, 0x50, (byte) 0xE2, 0x27, 0, 
+        0, 0, 1, 0, 0, 1};
+    byte[] value = storage.getColumn(row, new byte[] { (byte) 0xF0, 0, 0x7D, 0 });
+    assertEquals(2, storage.numColumns(row));
+    assertNotNull(value);
+    assertEquals(42, value[0]);
+    value = storage.getColumn(row, new byte[] { (byte) 0xF0, 0, 0x7D, 11 });
+    assertNotNull(value);
+    // should have 7 digits of precision
+    assertEquals(42.5F, Float.intBitsToFloat(Bytes.getInt(value)), 0.0000001);
+  }
+  
+  @Test
+  public void addPointBothSameTimeSecondAndMs() throws Exception {
+    // this can happen if a second and an ms data point are stored for the same
+    // timestamp.
+    tsdb.addPoint(METRIC_STRING, 1356998400L, 42, tags).joinUninterruptibly();
+    tsdb.addPoint(METRIC_STRING, 1356998400000L, 42, tags).joinUninterruptibly();
+    final byte[] row = new byte[] { 0, 0, 1, 0x50, (byte) 0xE2, 0x27, 0, 
+        0, 0, 1, 0, 0, 1};
+    byte[] value = storage.getColumn(row, new byte[] { 0, 0 });
+    assertEquals(2, storage.numColumns(row));
+    assertNotNull(value);
+    assertEquals(42, value[0]);
+    value = storage.getColumn(row, new byte[] { (byte) 0xF0, 0, 0, 0 });
+    assertNotNull(value);
+    // should have 7 digits of precision
+    assertEquals(42, value[0]);
+  }
+  
+  @Test
+  public void addPointWithSalt() throws Exception {
+    PowerMockito.mockStatic(Const.class);
+    PowerMockito.when(Const.SALT_WIDTH()).thenReturn(1);
+    PowerMockito.when(Const.SALT_BUCKETS()).thenReturn(20);
+    PowerMockito.when(Const.MAX_NUM_TAGS()).thenReturn((short) 8);
+
+    tsdb.addPoint(METRIC_STRING, 1356998400, 42, tags).joinUninterruptibly();
+    final byte[] row = new byte[] { 8, 0, 0, 1, 0x50, (byte) 0xE2, 0x27, 0, 
+        0, 0, 1, 0, 0, 1};
+    final byte[] value = storage.getColumn(row, new byte[] { 0, 0 });
+    assertNotNull(value);
+    assertEquals(42, value[0]);
+  }
+
+  @Test
+  public void addPointWithSaltDifferentTags() throws Exception {
+    PowerMockito.mockStatic(Const.class);
+    PowerMockito.when(Const.SALT_WIDTH()).thenReturn(1);
+    PowerMockito.when(Const.SALT_BUCKETS()).thenReturn(20);
+    PowerMockito.when(Const.MAX_NUM_TAGS()).thenReturn((short) 8);
+
+    tags.put(TAGK_STRING, TAGV_B_STRING);
+
+    tsdb.addPoint(METRIC_STRING, 1356998400, 42, tags).joinUninterruptibly();
+    final byte[] row = new byte[] { 9, 0, 0, 1, 0x50, (byte) 0xE2, 0x27, 0, 
+        0, 0, 1, 0, 0, 2};
+    final byte[] value = storage.getColumn(row, new byte[] { 0, 0 });
+    assertNotNull(value);
+    assertEquals(42, value[0]);
+  }
+  
+  @Test
+  public void addPointWithSaltDifferentTime() throws Exception {
+    PowerMockito.mockStatic(Const.class);
+    PowerMockito.when(Const.SALT_WIDTH()).thenReturn(1);
+    PowerMockito.when(Const.SALT_BUCKETS()).thenReturn(20);
+    PowerMockito.when(Const.MAX_NUM_TAGS()).thenReturn((short) 8);
+
+    tsdb.addPoint(METRIC_STRING, 1359680400, 42, tags).joinUninterruptibly();
+    final byte[] row = new byte[] { 8, 0, 0, 1, 0x51, (byte) 0x0B, 0x13, 
+        (byte) 0x90, 0, 0, 1, 0, 0, 1};
+    final byte[] value = storage.getColumn(row, new byte[] { 0, 0 });
+    assertNotNull(value);
+    assertEquals(42, value[0]);
+  }
+  
+  @Test
+  public void addPointAppend() throws Exception {
+    Whitebox.setInternalState(config, "enable_appends", true);
+
+    tsdb.addPoint(METRIC_STRING, 1356998400, 42, tags).joinUninterruptibly();
+    final byte[] row = new byte[] { 0, 0, 1, 0x50, (byte) 0xE2, 0x27, 0, 
+        0, 0, 1, 0, 0, 1};
+    final byte[] value = storage.getColumn(row, 
+        AppendDataPoints.APPEND_COLUMN_QUALIFIER);
+    assertArrayEquals(new byte[] { 0, 0, 42 }, value);
+  }
+  
+  @Test
+  public void addPointAppendWithOffset() throws Exception {
+    Whitebox.setInternalState(config, "enable_appends", true);
+    
+    tsdb.addPoint(METRIC_STRING, 1356998430, 42, tags).joinUninterruptibly();
+    final byte[] row = new byte[] { 0, 0, 1, 0x50, (byte) 0xE2, 0x27, 0, 
+        0, 0, 1, 0, 0, 1};
+    final byte[] value = storage.getColumn(row, 
+        AppendDataPoints.APPEND_COLUMN_QUALIFIER);
+    assertArrayEquals(new byte[] { 1, -32, 42 }, value);
+  }
+  
+  @Test
+  public void addPointAppendAppending() throws Exception {
+    Whitebox.setInternalState(config, "enable_appends", true);
+
+    tsdb.addPoint(METRIC_STRING, 1356998400, 42, tags).joinUninterruptibly();
+    tsdb.addPoint(METRIC_STRING, 1356998430, 24, tags).joinUninterruptibly();
+    tsdb.addPoint(METRIC_STRING, 1356998460, 1, tags).joinUninterruptibly();
+    final byte[] row = new byte[] { 0, 0, 1, 0x50, (byte) 0xE2, 0x27, 0, 
+        0, 0, 1, 0, 0, 1};
+    final byte[] value = storage.getColumn(row, 
+        AppendDataPoints.APPEND_COLUMN_QUALIFIER);
+    assertArrayEquals(new byte[] { 0, 0, 42, 1, -32, 24, 3, -64, 1 }, value);
+  }
+  
+  @Test
+  public void addPointAppendAppendingOutOfOrder() throws Exception {
+    Whitebox.setInternalState(config, "enable_appends", true);
+
+    tsdb.addPoint(METRIC_STRING, 1356998400, 42, tags).joinUninterruptibly();
+    tsdb.addPoint(METRIC_STRING, 1356998460, 1, tags).joinUninterruptibly();
+    tsdb.addPoint(METRIC_STRING, 1356998430, 24, tags).joinUninterruptibly();
+
+    final byte[] row = new byte[] { 0, 0, 1, 0x50, (byte) 0xE2, 0x27, 0, 
+        0, 0, 1, 0, 0, 1};
+    final byte[] value = storage.getColumn(row, 
+        AppendDataPoints.APPEND_COLUMN_QUALIFIER);
+    assertArrayEquals(new byte[] { 0, 0, 42, 3, -64, 1, 1, -32, 24 }, value);
+  }
+  
+  @Test
+  public void addPointAppendAppendingDuplicates() throws Exception {
+    Whitebox.setInternalState(config, "enable_appends", true);
+
+    tsdb.addPoint(METRIC_STRING, 1356998400, 42, tags).joinUninterruptibly();
+    tsdb.addPoint(METRIC_STRING, 1356998430, 24, tags).joinUninterruptibly();
+    tsdb.addPoint(METRIC_STRING, 1356998430, 1, tags).joinUninterruptibly();
+    final byte[] row = new byte[] { 0, 0, 1, 0x50, (byte) 0xE2, 0x27, 0, 
+        0, 0, 1, 0, 0, 1};
+    final byte[] value = storage.getColumn(row, 
+        AppendDataPoints.APPEND_COLUMN_QUALIFIER);
+    assertArrayEquals(new byte[] { 0, 0, 42, 1, -32, 24, 1, -32, 1 }, value);
+  }
+  
+  @Test
+  public void addPointAppendMS() throws Exception {
+    Whitebox.setInternalState(config, "enable_appends", true);
+
+    tsdb.addPoint(METRIC_STRING, 1356998400050L, 42, tags).joinUninterruptibly();
+    final byte[] row = new byte[] { 0, 0, 1, 0x50, (byte) 0xE2, 0x27, 0, 
+        0, 0, 1, 0, 0, 1};
+    final byte[] value = storage.getColumn(row, 
+        AppendDataPoints.APPEND_COLUMN_QUALIFIER);
+    assertArrayEquals(new byte[] { (byte) 0xF0, 0, 12, -128, 42 }, value);
+  }
+  
+  @Test
+  public void addPointAppendAppendingMixMS() throws Exception {
+    Whitebox.setInternalState(config, "enable_appends", true);
+
+    tsdb.addPoint(METRIC_STRING, 1356998400, 42, tags).joinUninterruptibly();
+    tsdb.addPoint(METRIC_STRING, 1356998400050L, 1, tags).joinUninterruptibly();
+    tsdb.addPoint(METRIC_STRING, 1356998430, 24, tags).joinUninterruptibly();
+    final byte[] row = new byte[] { 0, 0, 1, 0x50, (byte) 0xE2, 0x27, 0, 
+        0, 0, 1, 0, 0, 1};
+    final byte[] value = storage.getColumn(row, 
+        AppendDataPoints.APPEND_COLUMN_QUALIFIER);
+    assertArrayEquals(new byte[] { 
+        0, 0, 42, (byte) 0xF0, 0, 12, -128, 1, 1, -32, 24 }, value);
+  }
+  
+  @Test
+  public void addPointAppendWithSalt() throws Exception {
+    PowerMockito.mockStatic(Const.class);
+    PowerMockito.when(Const.SALT_WIDTH()).thenReturn(1);
+    PowerMockito.when(Const.SALT_BUCKETS()).thenReturn(20);
+    PowerMockito.when(Const.MAX_NUM_TAGS()).thenReturn((short) 8);
+    Whitebox.setInternalState(config, "enable_appends", true);
+
+    tsdb.addPoint(METRIC_STRING, 1356998400, 42, tags).joinUninterruptibly();
+    final byte[] row = new byte[] { 8, 0, 0, 1, 0x50, (byte) 0xE2, 0x27, 0, 
+        0, 0, 1, 0, 0, 1};
+    final byte[] value = storage.getColumn(row, 
+        AppendDataPoints.APPEND_COLUMN_QUALIFIER);
+    assertArrayEquals(new byte[] { 0, 0, 42 }, value);
+  }
+  
+  @Test
+  public void addPointAppendAppendingWithSalt() throws Exception {
+    PowerMockito.mockStatic(Const.class);
+    PowerMockito.when(Const.SALT_WIDTH()).thenReturn(1);
+    PowerMockito.when(Const.SALT_BUCKETS()).thenReturn(20);
+    PowerMockito.when(Const.MAX_NUM_TAGS()).thenReturn((short) 8);
+    Whitebox.setInternalState(config, "enable_appends", true);
+
+    tsdb.addPoint(METRIC_STRING, 1356998400, 42, tags).joinUninterruptibly();
+    tsdb.addPoint(METRIC_STRING, 1356998430, 24, tags).joinUninterruptibly();
+    tsdb.addPoint(METRIC_STRING, 1356998460, 1, tags).joinUninterruptibly();
+    final byte[] row = new byte[] { 8, 0, 0, 1, 0x50, (byte) 0xE2, 0x27, 0, 
+        0, 0, 1, 0, 0, 1};
+    final byte[] value = storage.getColumn(row, 
+        AppendDataPoints.APPEND_COLUMN_QUALIFIER);
+    assertArrayEquals(new byte[] { 0, 0, 42, 1, -32, 24, 3, -64, 1 }, value);
+  }
+  
+  @Test
+  public void dpFilterOK() throws Exception {
+    final WriteableDataPointFilterPlugin filter = 
+        mock(WriteableDataPointFilterPlugin.class);
+    when(filter.filterDataPoints()).thenReturn(true);
+    when(filter.allowDataPoint(eq(METRIC_STRING), anyLong(), 
+        any(byte[].class), eq(tags), anyShort()))
+      .thenReturn(Deferred.<Boolean>fromResult(true));
+    Whitebox.setInternalState(tsdb, "ts_filter", filter);
+    
+    tsdb.addPoint(METRIC_STRING, 1356998400, 42, tags).joinUninterruptibly();
+    final byte[] row = new byte[] { 0, 0, 1, 0x50, (byte) 0xE2, 0x27, 0, 
+        0, 0, 1, 0, 0, 1};
+    final byte[] value = storage.getColumn(row, new byte[] { 0, 0 });
+    assertNotNull(value);
+    assertEquals(42, value[0]);
+    
+    verify(filter, times(1)).filterDataPoints();
+    verify(filter, times(1)).allowDataPoint(eq(METRIC_STRING), anyLong(), 
+        any(byte[].class), eq(tags), anyShort());
+  }
+  
+  @Test
+  public void dpFilterBlocked() throws Exception {
+    final WriteableDataPointFilterPlugin filter = 
+        mock(WriteableDataPointFilterPlugin.class);
+    when(filter.filterDataPoints()).thenReturn(true);
+    when(filter.allowDataPoint(eq(METRIC_STRING), anyLong(), 
+        any(byte[].class), eq(tags), anyShort()))
+      .thenReturn(Deferred.<Boolean>fromResult(false));
+    Whitebox.setInternalState(tsdb, "ts_filter", filter);
+    
+    tsdb.addPoint(METRIC_STRING, 1356998400, 42, tags).joinUninterruptibly();
+    final byte[] row = new byte[] { 0, 0, 1, 0x50, (byte) 0xE2, 0x27, 0, 
+        0, 0, 1, 0, 0, 1};
+    final byte[] value = storage.getColumn(row, new byte[] { 0, 0 });
+    assertNull(value);
+    
+    verify(filter, times(1)).filterDataPoints();
+    verify(filter, times(1)).allowDataPoint(eq(METRIC_STRING), anyLong(), 
+        any(byte[].class), eq(tags), anyShort());
+  }
+  
+  @Test
+  public void dpFilterReturnsException() throws Exception {
+    final WriteableDataPointFilterPlugin filter = 
+        mock(WriteableDataPointFilterPlugin.class);
+    when(filter.filterDataPoints()).thenReturn(true);
+    when(filter.allowDataPoint(eq(METRIC_STRING), anyLong(), 
+        any(byte[].class), eq(tags), anyShort()))
+      .thenReturn(Deferred.<Boolean>fromError(new UnitTestException("Boo!")));
+    Whitebox.setInternalState(tsdb, "ts_filter", filter);
+    
+    final Deferred<Object> deferred = 
+        tsdb.addPoint(METRIC_STRING, 1356998400, 42, tags);
+    try {
+      deferred.join();
+      fail("Expected an UnitTestException");
+    } catch (UnitTestException e) { };
+    final byte[] row = new byte[] { 0, 0, 1, 0x50, (byte) 0xE2, 0x27, 0, 
+        0, 0, 1, 0, 0, 1};
+    final byte[] value = storage.getColumn(row, new byte[] { 0, 0 });
+    assertNull(value);
+    
+    verify(filter, times(1)).filterDataPoints();
+    verify(filter, times(1)).allowDataPoint(eq(METRIC_STRING), anyLong(), 
+        any(byte[].class), eq(tags), anyShort());
+  }
+  
+  @Test
+  public void uidFilterThrowsException() throws Exception {
+    final WriteableDataPointFilterPlugin filter = 
+        mock(WriteableDataPointFilterPlugin.class);
+    when(filter.filterDataPoints()).thenReturn(true);
+    when(filter.allowDataPoint(eq(METRIC_STRING), anyLong(), 
+        any(byte[].class), eq(tags), anyShort()))
+      .thenThrow(new UnitTestException("Boo!"));
+    Whitebox.setInternalState(tsdb, "ts_filter", filter);
+    
+    try {
+      tsdb.addPoint(METRIC_STRING, 1356998400, 42, tags);
+      fail("Expected an UnitTestException");
+    } catch (UnitTestException e) { };
+    final byte[] row = new byte[] { 0, 0, 1, 0x50, (byte) 0xE2, 0x27, 0, 
+        0, 0, 1, 0, 0, 1};
+    final byte[] value = storage.getColumn(row, new byte[] { 0, 0 });
+    assertNull(value);
+    
+    verify(filter, times(1)).filterDataPoints();
+    verify(filter, times(1)).allowDataPoint(eq(METRIC_STRING), anyLong(), 
+        any(byte[].class), eq(tags), anyShort());
+  }
+}
diff --git a/test/core/TestTSQuery.java b/test/core/TestTSQuery.java
index 9c1fdf90dd..d528eaaf56 100644
--- a/test/core/TestTSQuery.java
+++ b/test/core/TestTSQuery.java
@@ -15,6 +15,7 @@
 import static org.junit.Assert.assertEquals;
 import static org.junit.Assert.assertFalse;
 import static org.junit.Assert.assertNotNull;
+import static org.junit.Assert.assertNull;
 import static org.junit.Assert.assertTrue;
 import static org.mockito.Matchers.anyString;
 import static org.mockito.Mockito.when;
@@ -51,6 +52,51 @@ public void validate() {
     assertEquals(Aggregators.SUM, q.getQueries().get(0).aggregator());
     assertEquals(Aggregators.AVG, q.getQueries().get(0).downsampler());
     assertEquals(300000, q.getQueries().get(0).downsampleInterval());
+    assertNull(q.getTimezone());
+    assertEquals("UTC", q.getQueries().get(0).downsamplingSpecification()
+        .getTimezone().getID());
+    assertFalse(q.getQueries().get(0).downsamplingSpecification().useCalendar());
+  }
+  
+  @Test
+  public void validateWithTimezone() {
+    TSQuery q = this.getMetricForValidate();
+    q.setUseCalendar(true);
+    q.setTimezone("Pacific/Funafuti");
+    q.validateAndSetQuery();
+    assertEquals(1356998400000L, q.startTime());
+    assertEquals(1356998460000L, q.endTime());
+    assertEquals("sys.cpu.0", q.getQueries().get(0).getMetric());
+    assertEquals("wildcard(*)", q.getQueries().get(0).getTags().get("host"));
+    assertEquals("literal_or(lga)", q.getQueries().get(0).getTags().get("dc"));
+    assertEquals(Aggregators.SUM, q.getQueries().get(0).aggregator());
+    assertEquals(Aggregators.AVG, q.getQueries().get(0).downsampler());
+    assertEquals(300000, q.getQueries().get(0).downsampleInterval());
+    assertEquals("Pacific/Funafuti", q.getTimezone());
+    assertEquals("Pacific/Funafuti", q.getQueries().get(0).downsamplingSpecification()
+        .getTimezone().getID());
+    assertTrue(q.getQueries().get(0).downsamplingSpecification().useCalendar());
+  }
+  
+  @Test
+  public void validateVerifyNoDSOverrideWithCalendar() {
+    TSQuery q = this.getMetricForValidate();
+    q.setUseCalendar(true);
+    q.setTimezone("Pacific/Funafuti");
+    q.getQueries().get(0).setDownsample(null);
+    q.validateAndSetQuery();
+    assertEquals(1356998400000L, q.startTime());
+    assertEquals(1356998460000L, q.endTime());
+    assertEquals("sys.cpu.0", q.getQueries().get(0).getMetric());
+    assertEquals("wildcard(*)", q.getQueries().get(0).getTags().get("host"));
+    assertEquals("literal_or(lga)", q.getQueries().get(0).getTags().get("dc"));
+    assertEquals(Aggregators.SUM, q.getQueries().get(0).aggregator());
+    assertNull(q.getQueries().get(0).downsampler());
+    assertEquals(0, q.getQueries().get(0).downsampleInterval());
+    assertEquals("Pacific/Funafuti", q.getTimezone());
+    assertEquals("UTC", q.getQueries().get(0).downsamplingSpecification()
+        .getTimezone().getID());
+    assertFalse(q.getQueries().get(0).downsamplingSpecification().useCalendar());
   }
   
   @Test (expected = IllegalArgumentException.class)
@@ -241,6 +287,25 @@ public void testHashCodeandEqualsTimezoneInvalid() throws Exception {
     assertFalse(sub1 == sub2);
   }
   
+  @Test
+  public void testHashCodeandEqualsUseCalendar() {
+    TSQuery sub1 = getMetricForValidate();
+    
+    final int hash_a = sub1.hashCode();
+    sub1.setUseCalendar(true);
+    final int hash_b = sub1.hashCode();
+    assertTrue(hash_a != hash_b);
+    sub1.validateAndSetQuery();
+    assertEquals(hash_b, sub1.hashCode());
+    
+    TSQuery sub2 = getMetricForValidate();
+    sub2.setUseCalendar(true);
+    
+    assertEquals(hash_b, sub2.hashCode());
+    assertEquals(sub1, sub2);
+    assertFalse(sub1 == sub2);
+  }
+  
   @Test
   public void testHashCodeandEqualsOptions() {
     TSQuery sub1 = getMetricForValidate();
diff --git a/test/core/TestTSSubQuery.java b/test/core/TestTSSubQuery.java
index 743a47fbaa..a86ed8bb8f 100644
--- a/test/core/TestTSSubQuery.java
+++ b/test/core/TestTSSubQuery.java
@@ -225,6 +225,13 @@ public void validateWithFilterAndGroupByFilterSameTag() {
     assertEquals(300000, sub.downsampleInterval());
   }
   
+  @Test (expected = IllegalArgumentException.class)
+  public void validateWithDownsampleNone() {
+    TSSubQuery sub = getMetricForValidate();
+    sub.setDownsample("1m-none");
+    sub.validateAndSetQuery();
+  }
+  
   // NOTE: Each of the hash and equals  tests should make sure that we the code
   // doesn't change after validation.
   
@@ -553,6 +560,25 @@ public void testHashCodeandEqualsRateOptionsNull() {
     assertFalse(sub1 == sub2);
   }
 
+  @Test
+  public void testHashCodeandEqualsExplicitTags() {
+    final TSSubQuery sub1 = getBaseQuery();
+    final int hash_a = sub1.hashCode();
+
+    sub1.setExplicitTags(true);
+    final int hash_b = sub1.hashCode();
+    assertFalse(hash_a == sub1.hashCode());
+    sub1.validateAndSetQuery();
+    assertEquals(hash_b, sub1.hashCode());
+    
+    TSSubQuery sub2 = getBaseQuery();
+    sub2.setExplicitTags(true);
+    
+    assertEquals(hash_b, sub2.hashCode());
+    assertEquals(sub1, sub2);
+    assertFalse(sub1 == sub2);
+  }
+  
   @Test
   public void testEqualsNull() {
     final TSSubQuery sub1 = getBaseQuery();
diff --git a/test/core/TestTags.java b/test/core/TestTags.java
index 3618c1ac7f..2898807149 100644
--- a/test/core/TestTags.java
+++ b/test/core/TestTags.java
@@ -24,6 +24,7 @@
 import net.opentsdb.query.filter.TagVRegexFilter;
 import net.opentsdb.query.filter.TagVWildcardFilter;
 import net.opentsdb.storage.MockBase;
+import net.opentsdb.uid.FailedToAssignUniqueIdException;
 import net.opentsdb.uid.NoSuchUniqueId;
 import net.opentsdb.uid.NoSuchUniqueName;
 import net.opentsdb.uid.UniqueId;
@@ -45,6 +46,7 @@
 import org.powermock.modules.junit4.PowerMockRunner;
 
 import com.stumbleupon.async.Deferred;
+import com.stumbleupon.async.DeferredGroupException;
 
 import static org.junit.Assert.assertArrayEquals;
 import static org.junit.Assert.assertEquals;
@@ -52,6 +54,9 @@
 import static org.junit.Assert.assertNotNull;
 import static org.junit.Assert.assertNull;
 import static org.junit.Assert.assertTrue;
+import static org.mockito.Matchers.anyString;
+import static org.mockito.Matchers.anyMapOf;
+import static org.mockito.Matchers.eq;
 import static org.mockito.Mockito.when;
 import static org.powermock.api.mockito.PowerMockito.mock;
 
@@ -756,6 +761,32 @@ public void resolveOrCreateTagvNotAllowedBlocked() throws Exception {
     Tags.resolveOrCreateAll(tsdb, tags);
   }
   
+  @Test
+  public void resolveOrCreateAllAsync() throws Exception {
+    setupStorage();
+    setupResolveAll();
+    
+    final Map<String, String> tags = new HashMap<String, String>(1);
+    tags.put("host", "nohost");
+    final List<byte[]> uids = Tags.resolveOrCreateAllAsync(tsdb, "metric", tags).join();
+    assertEquals(1, uids.size());
+    assertArrayEquals(new byte[] { 0, 0, 1, 0, 0, 3}, uids.get(0));
+  }
+  
+  @Test (expected = DeferredGroupException.class)
+  public void resolveOrCreateAllAsyncFilterBlocked() throws Exception {
+    setupStorage();
+    setupResolveAll();
+    when(tag_names.getOrCreateIdAsync(eq("host"), anyString(), 
+        anyMapOf(String.class, String.class)))
+      .thenReturn(Deferred.<byte[]>fromError(new FailedToAssignUniqueIdException(
+          "tagk", "host", 0, "Blocked by UID filter.")));
+    
+    final Map<String, String> tags = new HashMap<String, String>(1);
+    tags.put("host", "nohost");
+    Tags.resolveOrCreateAllAsync(tsdb, "metric", tags).join();
+  }
+  
   // PRIVATE helpers to setup unit tests
   
   private void setupStorage() throws Exception {
@@ -799,16 +830,30 @@ private void setupResolveIds() throws Exception {
   }
   
   private void setupResolveAll() throws Exception {
-    when(tag_names.getOrCreateId("host")).thenReturn(new byte[] { 0, 0, 1 });
-    when(tag_names.getOrCreateId("doesnotexist"))
+    when(tag_names.getOrCreateId(eq("host")))
+      .thenReturn(new byte[] { 0, 0, 1 });
+    when(tag_names.getOrCreateIdAsync(eq("host"), anyString(), 
+        anyMapOf(String.class, String.class)))
+      .thenReturn(Deferred.fromResult(new byte[] { 0, 0, 1 }));
+    when(tag_names.getOrCreateId(eq("doesnotexist")))
       .thenReturn(new byte[] { 0, 0, 3 });
+    when(tag_names.getOrCreateIdAsync(eq("doesnotexist"), anyString(), 
+        anyMapOf(String.class, String.class)))
+      .thenReturn(Deferred.fromResult(new byte[] { 0, 0, 3 }));
     when(tag_names.getId("pop")).thenReturn(new byte[] { 0, 0, 2 });
     when(tag_names.getId("nonesuch"))
       .thenThrow(new NoSuchUniqueName("tagv", "nonesuch"));
     
-    when(tag_values.getOrCreateId("web01")).thenReturn(new byte[] { 0, 0, 1 });
-    when(tag_values.getOrCreateId("nohost"))
-      .thenReturn(new byte[] { 0, 0, 3 });
+    when(tag_values.getOrCreateId(eq("web01")))
+      .thenReturn(new byte[] { 0, 0, 1 });
+    when(tag_values.getOrCreateIdAsync(eq("web01"), anyString(), 
+        anyMapOf(String.class, String.class)))
+      .thenReturn(Deferred.fromResult(new byte[] { 0, 0, 1 }));
+    when(tag_values.getOrCreateId(eq("nohost")))
+    .thenReturn(new byte[] { 0, 0, 3 });
+    when(tag_values.getOrCreateIdAsync(eq("nohost"), anyString(), 
+        anyMapOf(String.class, String.class)))
+      .thenReturn(Deferred.fromResult(new byte[] { 0, 0, 3 }));
     when(tag_values.getId("web02")).thenReturn(new byte[] { 0, 0, 2 });
     when(tag_values.getId("invalidhost"))
       .thenThrow(new NoSuchUniqueName("tagk", "invalidhost"));
@@ -897,4 +942,20 @@ public void getTagUidsEmptyRow() throws Exception {
     final ByteMap<byte[]> uids = Tags.getTagUids(new byte[] {});
     assertEquals(0, uids.size());
   }
+
+  @Test
+  public void setAllowSpecialChars() throws Exception {
+    assertFalse(Tags.isAllowSpecialChars('!'));
+
+    Tags.setAllowSpecialChars(null);
+    assertFalse(Tags.isAllowSpecialChars('!'));
+
+    Tags.setAllowSpecialChars("");
+    assertFalse(Tags.isAllowSpecialChars('!'));
+
+    Tags.setAllowSpecialChars("!)(%");
+    assertTrue(Tags.isAllowSpecialChars('!'));
+    assertTrue(Tags.isAllowSpecialChars('('));
+    assertTrue(Tags.isAllowSpecialChars('%'));
+  }
 }
diff --git a/test/core/TestTsdbQueryDownsample.java b/test/core/TestTsdbQueryDownsample.java
index b213a73466..02bdce9469 100644
--- a/test/core/TestTsdbQueryDownsample.java
+++ b/test/core/TestTsdbQueryDownsample.java
@@ -28,7 +28,9 @@
 import org.junit.runner.RunWith;
 import org.powermock.core.classloader.annotations.PrepareForTest;
 import org.powermock.modules.junit4.PowerMockRunner;
+import org.powermock.reflect.Whitebox;
 
+import com.google.common.collect.Lists;
 import com.google.common.math.DoubleMath;
 
 /**
@@ -122,7 +124,7 @@ public void downsampleMilliseconds() throws Exception {
       TsdbQuery.ForTesting.getScanEndTimeSeconds(query));
   }
 
-  @Test (expected = NullPointerException.class)
+  @Test (expected = IllegalArgumentException.class)
   public void downsampleNullAgg() throws Exception {
     query.downsample(60, null);
   }
@@ -459,6 +461,104 @@ public void runLongSingleTSDownsampleCount() throws Exception {
     assertEquals(151, dps[0].size());
   }
   
+  @Test
+  public void runLongSingleTSDownsampleAll() throws Exception {
+    storeLongTimeSeriesSeconds(true, false);
+    final TSQuery ts_query = new TSQuery();
+    ts_query.setStart("1356998400");
+    ts_query.setEnd("1357041600");
+    
+    final HashMap<String, String> tags = new HashMap<String, String>(1);
+    tags.put("host", "web01");
+    final TSSubQuery sub = new TSSubQuery();
+    sub.setTags(tags);
+    sub.setMetric("sys.cpu.user");
+    sub.setAggregator("sum");
+    sub.setDownsample("0all-sum");
+    
+    ts_query.setQueries(Lists.newArrayList(sub));
+    ts_query.validateAndSetQuery();
+    query.configureFromQuery(ts_query, 0);
+    
+    final DataPoints[] dps = query.run();
+    assertMeta(dps, 0, false);
+
+    for (DataPoint dp : dps[0]) {
+      // Downsampler outputs just doubles.
+      assertFalse(dp.isInteger());
+      assertEquals(45150, dp.doubleValue(), 0.00001);
+      assertEquals(1356998400000L, dp.timestamp());
+    }
+    // Out of 300 values, the first and the last intervals have one value each,
+    // and the 149 intervals in the middle have two values for each.
+    assertEquals(1, dps[0].size());
+  }
+  
+  @Test
+  public void runLongSingleTSDownsampleAllSubSet() throws Exception {
+    storeLongTimeSeriesSeconds(true, false);
+    final TSQuery ts_query = new TSQuery();
+    ts_query.setStart("1356998500");
+    ts_query.setEnd("1356998600");
+    
+    final HashMap<String, String> tags = new HashMap<String, String>(1);
+    tags.put("host", "web01");
+    final TSSubQuery sub = new TSSubQuery();
+    sub.setTags(tags);
+    sub.setMetric("sys.cpu.user");
+    sub.setAggregator("sum");
+    sub.setDownsample("0all-sum");
+    
+    ts_query.setQueries(Lists.newArrayList(sub));
+    ts_query.validateAndSetQuery();
+    query.configureFromQuery(ts_query, 0);
+    
+    final DataPoints[] dps = query.run();
+    assertMeta(dps, 0, false);
+
+    for (DataPoint dp : dps[0]) {
+      // Downsampler outputs just doubles.
+      assertFalse(dp.isInteger());
+      assertEquals(15, dp.doubleValue(), 0.00001);
+      assertEquals(1356998500000L, dp.timestamp());
+    }
+    // Out of 300 values, the first and the last intervals have one value each,
+    // and the 149 intervals in the middle have two values for each.
+    assertEquals(1, dps[0].size());
+  }
+  
+  @Test
+  public void runLongSingleTSDownsampleAllNoEnd() throws Exception {
+    storeLongTimeSeriesSeconds(true, false);
+    final TSQuery ts_query = new TSQuery();
+    ts_query.setStart("1356998400");
+    
+    final HashMap<String, String> tags = new HashMap<String, String>(1);
+    tags.put("host", "web01");
+    final TSSubQuery sub = new TSSubQuery();
+    sub.setTags(tags);
+    sub.setMetric("sys.cpu.user");
+    sub.setAggregator("sum");
+    sub.setDownsample("0all-sum");
+    
+    ts_query.setQueries(Lists.newArrayList(sub));
+    ts_query.validateAndSetQuery();
+    query.configureFromQuery(ts_query, 0);
+    
+    final DataPoints[] dps = query.run();
+    assertMeta(dps, 0, false);
+
+    for (DataPoint dp : dps[0]) {
+      // Downsampler outputs just doubles.
+      assertFalse(dp.isInteger());
+      assertEquals(45150, dp.doubleValue(), 0.00001);
+      assertEquals(1356998400000L, dp.timestamp());
+    }
+    // Out of 300 values, the first and the last intervals have one value each,
+    // and the 149 intervals in the middle have two values for each.
+    assertEquals(1, dps[0].size());
+  }
+  
   // this could happen.
   @Test
   public void runFloatSingleTSDownsampleAndRateAndCount() throws Exception {
@@ -497,6 +597,43 @@ public void runFloatSingleTSDownsampleAndRateAndCount() throws Exception {
     assertEquals(150, dps[0].size());
   }
 
+  @Test (expected = IllegalArgumentException.class)
+  public void runLongSingleTSDownsampleNone() throws Exception {
+    storeLongTimeSeriesSeconds(true, false);
+    HashMap<String, String> tags = new HashMap<String, String>(1);
+    tags.put("host", "web01");
+    query.setStartTime(1356998400);
+    query.setEndTime(1357041600);
+    query.downsample(60000, Aggregators.NONE);
+    query.setTimeSeries("sys.cpu.user", tags, Aggregators.SUM, false);
+  }
+  
+  @Test (expected = RuntimeException.class)
+  public void runLongSingleTSDownsampleNoneSnuckIn() throws Exception {
+    storeLongTimeSeriesSeconds(true, false);
+    final TSQuery ts_query = new TSQuery();
+    ts_query.setStart("1356998400");
+    ts_query.setEnd("1357041600");
+    
+    final HashMap<String, String> tags = new HashMap<String, String>(1);
+    tags.put("host", "web01");
+    final TSSubQuery sub = new TSSubQuery();
+    sub.setTags(tags);
+    sub.setMetric("sys.cpu.user");
+    sub.setAggregator("sum");
+    sub.setDownsample("1m-sum");
+    
+    ts_query.setQueries(Lists.newArrayList(sub));
+    ts_query.validateAndSetQuery();
+    query.configureFromQuery(ts_query, 0);
+    Whitebox.setInternalState(query, "downsampler", Aggregators.NONE);
+    
+    final DataPoints[] dps = query.run();
+    for (DataPoint dp : dps[0]) {
+      dp.timestamp();
+    }
+  }
+  
   /**
    * A helper interface to be used by the filling-test code. 
    */ 
diff --git a/test/core/TestTsdbQueryQueries.java b/test/core/TestTsdbQueryQueries.java
index 0f8c84551d..4deaea7daf 100644
--- a/test/core/TestTsdbQueryQueries.java
+++ b/test/core/TestTsdbQueryQueries.java
@@ -14,6 +14,8 @@
 
 import static org.junit.Assert.assertEquals;
 import static org.junit.Assert.assertNotNull;
+import static org.junit.Assert.assertNull;
+import static org.junit.Assert.assertTrue;
 import static org.junit.Assert.fail;
 import static org.mockito.Mockito.atLeast;
 import static org.mockito.Mockito.never;
@@ -28,10 +30,12 @@
 import java.util.Map;
 
 import net.opentsdb.storage.MockBase;
+import net.opentsdb.storage.MockBase.MockScanner;
 import net.opentsdb.uid.NoSuchUniqueId;
 import net.opentsdb.utils.Config;
 
 import org.hbase.async.Bytes;
+import org.hbase.async.FilterList;
 import org.hbase.async.Scanner;
 import org.junit.Before;
 import org.junit.Test;
@@ -39,6 +43,8 @@
 import org.powermock.core.classloader.annotations.PrepareForTest;
 import org.powermock.modules.junit4.PowerMockRunner;
 
+import com.stumbleupon.async.Deferred;
+
 /**
  * An integration test class that makes sure our query path is up to snuff.
  * This class should have tests for different data point types, rates, 
@@ -296,6 +302,41 @@ public void runFloatTwoAggSum() throws Exception {
     assertEquals(300, dps[0].size());
   }
   
+  @Test
+  public void runFloatTwoAggNoneAgg() throws Exception {
+    storeFloatTimeSeriesSeconds(true, false);
+    
+    tags.clear();
+    query.setStartTime(1356998400);
+    query.setEndTime(1357041600);
+    query.setTimeSeries(METRIC_STRING, tags, Aggregators.NONE, false);
+    
+    final DataPoints[] dps = query.run();
+    assertMeta(dps, 0, false);
+    assertMeta(dps, 1, false);
+    assertEquals(2, dps.length);
+
+    double value = 1.25D;
+    long timestamp = 1356998430000L;
+    for (DataPoint dp : dps[0]) {
+      assertEquals(value, dp.doubleValue(), 0.0001);
+      assertEquals(timestamp, dp.timestamp());
+      value += 0.25D;
+      timestamp += 30000;
+    }
+    assertEquals(300, dps[0].size());
+    
+    value = 75D;
+    timestamp = 1356998430000L;
+    for (DataPoint dp : dps[1]) {
+      assertEquals(value, dp.doubleValue(), 0.0001);
+      assertEquals(timestamp, dp.timestamp());
+      value -= 0.25d;
+      timestamp += 30000;
+    }
+    assertEquals(300, dps[1].size());
+  }
+  
   @Test
   public void runFloatTwoAggSumMs() throws Exception {
     storeFloatTimeSeriesMs();
@@ -1446,4 +1487,93 @@ public void runRegexpNoMatch() throws Exception {
     verify(tag_values, atLeast(1)).getNameAsync(TAGV_B_BYTES);
     assertEquals(0, dps.length);
   }
+
+  @Test
+  public void filterExplicitTagsOK() throws Exception {
+    tsdb.getConfig().overrideConfig("tsd.query.enable_fuzzy", "true");
+    storeLongTimeSeriesSeconds(true, false);
+    HashMap<String, String> tags = new HashMap<String, String>(1);
+    tags.put("host", "web01");
+    query.setStartTime(1356998400);
+    query.setEndTime(1357041600);
+    query.setExplicitTags(true);
+    query.setTimeSeries("sys.cpu.user", tags, Aggregators.SUM, false);
+
+    final DataPoints[] dps = query.run();
+    
+    assertNotNull(dps);
+    assertEquals("sys.cpu.user", dps[0].metricName());
+    assertTrue(dps[0].getAggregatedTags().isEmpty());
+    assertNull(dps[0].getAnnotations());
+    assertEquals("web01", dps[0].getTags().get("host"));
+    
+    int value = 1;
+    for (DataPoint dp : dps[0]) {
+      assertEquals(value, dp.longValue());
+      value++;
+    }
+    assertEquals(300, dps[0].aggregatedSize());
+    // assert fuzzy
+    for (final MockScanner scanner : storage.getScanners()) {
+      assertTrue(scanner.getFilter() instanceof FilterList);
+    }
+  }
+  
+  @Test
+  public void filterExplicitTagsGroupByOK() throws Exception {
+    tsdb.getConfig().overrideConfig("tsd.query.enable_fuzzy", "true");
+    storeLongTimeSeriesSeconds(true, false);
+    HashMap<String, String> tags = new HashMap<String, String>(1);
+    tags.put("host", "*");
+    query.setStartTime(1356998400);
+    query.setEndTime(1357041600);
+    query.setExplicitTags(true);
+    query.setTimeSeries("sys.cpu.user", tags, Aggregators.SUM, false);
+
+    final DataPoints[] dps = query.run();
+    
+    assertNotNull(dps);
+    assertEquals("sys.cpu.user", dps[0].metricName());
+    assertTrue(dps[0].getAggregatedTags().isEmpty());
+    assertNull(dps[0].getAnnotations());
+    assertEquals("web01", dps[0].getTags().get("host"));
+    
+    int value = 1;
+    for (DataPoint dp : dps[0]) {
+      assertEquals(value, dp.longValue());
+      value++;
+    }
+    assertEquals(300, dps[0].aggregatedSize());
+    // assert fuzzy
+    for (final MockScanner scanner : storage.getScanners()) {
+      assertTrue(scanner.getFilter() instanceof FilterList);
+    }
+  }
+  
+  @Test
+  public void filterExplicitTagsMissing() throws Exception {
+    tsdb.getConfig().overrideConfig("tsd.query.enable_fuzzy", "true");
+    when(tag_names.getIdAsync("colo"))
+      .thenReturn(Deferred.fromResult(new byte[] { 0, 0, 0, 4 }));
+    when(tag_values.getIdAsync("lga"))
+    .thenReturn(Deferred.fromResult(new byte[] { 0, 0, 0, 4 }));
+    storeLongTimeSeriesSeconds(true, false);
+    HashMap<String, String> tags = new HashMap<String, String>(1);
+    tags.put("host", "web01");
+    tags.put("colo", "lga");
+    query.setStartTime(1356998400);
+    query.setEndTime(1357041600);
+    query.setExplicitTags(true);
+    query.setTimeSeries("sys.cpu.user", tags, Aggregators.SUM, false);
+
+    final DataPoints[] dps = query.run();
+    
+    assertNotNull(dps);
+    assertEquals(0, dps.length);
+    // assert fuzzy
+    for (final MockScanner scanner : storage.getScanners()) {
+      assertTrue(scanner.getFilter() instanceof FilterList);
+    }
+  }
+  
 }
diff --git a/test/query/TestQueryUtil.java b/test/query/TestQueryUtil.java
new file mode 100644
index 0000000000..03760e8499
--- /dev/null
+++ b/test/query/TestQueryUtil.java
@@ -0,0 +1,148 @@
+// This file is part of OpenTSDB.
+// Copyright (C) 2016  The OpenTSDB Authors.
+//
+// This program is free software: you can redistribute it and/or modify it
+// under the terms of the GNU Lesser General Public License as published by
+// the Free Software Foundation, either version 2.1 of the License, or (at your
+// option) any later version.  This program is distributed in the hope that it
+// will be useful, but WITHOUT ANY WARRANTY; without even the implied warranty
+// of MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser
+// General Public License for more details.  You should have received a copy
+// of the GNU Lesser General Public License along with this program.  If not,
+// see <http://www.gnu.org/licenses/>.
+package net.opentsdb.query;
+
+import static org.mockito.Matchers.any;
+import static org.mockito.Mockito.mock;
+import static org.mockito.Mockito.never;
+import static org.mockito.Mockito.times;
+import static org.mockito.Mockito.verify;
+import static org.mockito.Mockito.when;
+
+import org.hbase.async.Bytes.ByteMap;
+import org.hbase.async.FilterList;
+import org.hbase.async.KeyRegexpFilter;
+import org.hbase.async.ScanFilter;
+import org.hbase.async.Scanner;
+import org.junit.Before;
+import org.junit.Test;
+import org.junit.runner.RunWith;
+import org.powermock.core.classloader.annotations.PrepareForTest;
+import org.powermock.modules.junit4.PowerMockRunner;
+
+import com.google.common.collect.Lists;
+
+@RunWith(PowerMockRunner.class)
+@PrepareForTest({ Scanner.class })
+public class TestQueryUtil {
+  private Scanner scanner;
+  
+  @Before
+  public void before() throws Exception {
+    scanner = mock(Scanner.class);
+  }
+  
+  @Test
+  public void setDataTableScanFilterNoOp() throws Exception {
+    QueryUtil.setDataTableScanFilter(
+        scanner,
+        Lists.<byte[]>newArrayList(), 
+        new ByteMap<byte[][]>(),
+        false,
+        false,
+        0);
+    verify(scanner, never()).getCurrentKey();
+    verify(scanner, never()).setFilter(any(ScanFilter.class));
+    verify(scanner, never()).setStartKey(any(byte[].class));
+    verify(scanner, never()).setStopKey(any(byte[].class));
+  }
+  
+  @Test
+  public void setDataTableScanFilterGroupBy() throws Exception {
+    QueryUtil.setDataTableScanFilter(
+        scanner,
+        Lists.<byte[]>newArrayList(new byte[] { 0, 0, 1 }), 
+        new ByteMap<byte[][]>(),
+        false,
+        false,
+        0);
+    verify(scanner, never()).getCurrentKey();
+    // TODO - validate the regex
+    verify(scanner, times(1)).setFilter(any(KeyRegexpFilter.class));
+    verify(scanner, never()).setStartKey(any(byte[].class));
+    verify(scanner, never()).setStopKey(any(byte[].class));
+  }
+  
+  @Test
+  public void setDataTableScanFilterTags() throws Exception {
+    final ByteMap<byte[][]> tags = new ByteMap<byte[][]>();
+    tags.put(new byte[] { 0, 0, 1 }, new byte[][] { new byte[] {0, 0, 1} });
+    QueryUtil.setDataTableScanFilter(
+        scanner,
+        Lists.<byte[]>newArrayList(), 
+        tags,
+        false,
+        false,
+        0);
+    verify(scanner, never()).getCurrentKey();
+    // TODO - validate the regex
+    verify(scanner, times(1)).setFilter(any(KeyRegexpFilter.class));
+    verify(scanner, never()).setStartKey(any(byte[].class));
+    verify(scanner, never()).setStopKey(any(byte[].class));
+  }
+  
+  @Test
+  public void setDataTableScanFilterEnableFuzzy() throws Exception {
+    final ByteMap<byte[][]> tags = new ByteMap<byte[][]>();
+    tags.put(new byte[] { 0, 0, 1 }, new byte[][] { new byte[] {0, 0, 1} });
+    QueryUtil.setDataTableScanFilter(
+        scanner,
+        Lists.<byte[]>newArrayList(), 
+        tags,
+        false,
+        true,
+        0);
+    verify(scanner, never()).getCurrentKey();
+    // TODO - validate the regex
+    verify(scanner, times(1)).setFilter(any(KeyRegexpFilter.class));
+    verify(scanner, never()).setStartKey(any(byte[].class));
+    verify(scanner, never()).setStopKey(any(byte[].class));
+  }
+  
+  @Test
+  public void setDataTableScanFilterEnableExplicit() throws Exception {
+    final ByteMap<byte[][]> tags = new ByteMap<byte[][]>();
+    tags.put(new byte[] { 0, 0, 1 }, new byte[][] { new byte[] {0, 0, 1} });
+    QueryUtil.setDataTableScanFilter(
+        scanner,
+        Lists.<byte[]>newArrayList(), 
+        tags,
+        true,
+        false,
+        0);
+    verify(scanner, never()).getCurrentKey();
+    // TODO - validate the regex
+    verify(scanner, times(1)).setFilter(any(KeyRegexpFilter.class));
+    verify(scanner, never()).setStartKey(any(byte[].class));
+    verify(scanner, never()).setStopKey(any(byte[].class));
+  }
+  
+  @Test
+  public void setDataTableScanFilterEnableBoth() throws Exception {
+    when(scanner.getCurrentKey()).thenReturn(new byte[] { 0, 0, 0, 1 });
+    final ByteMap<byte[][]> tags = new ByteMap<byte[][]>();
+    tags.put(new byte[] { 0, 0, 1 }, new byte[][] { new byte[] {0, 0, 1} });
+    QueryUtil.setDataTableScanFilter(
+        scanner,
+        Lists.<byte[]>newArrayList(), 
+        tags,
+        true,
+        true,
+        0);
+    verify(scanner, times(2)).getCurrentKey();
+    // TODO - validate the regex and fuzzy filter
+    verify(scanner, times(1)).setFilter(any(FilterList.class));
+    verify(scanner, times(1)).setStartKey(any(byte[].class));
+    verify(scanner, times(1)).setStopKey(any(byte[].class));
+  }
+}
diff --git a/test/query/expression/BaseTimeSyncedIteratorTest.java b/test/query/expression/BaseTimeSyncedIteratorTest.java
new file mode 100644
index 0000000000..252fbb8796
--- /dev/null
+++ b/test/query/expression/BaseTimeSyncedIteratorTest.java
@@ -0,0 +1,651 @@
+// This file is part of OpenTSDB.
+// Copyright (C) 2015  The OpenTSDB Authors.
+//
+// This program is free software: you can redistribute it and/or modify it
+// under the terms of the GNU Lesser General Public License as published by
+// the Free Software Foundation, either version 2.1 of the License, or (at your
+// option) any later version.  This program is distributed in the hope that it
+// will be useful, but WITHOUT ANY WARRANTY; without even the implied warranty
+// of MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser
+// General Public License for more details.  You should have received a copy
+// of the GNU Lesser General Public License along with this program.  If not,
+// see <http://www.gnu.org/licenses/>.
+package net.opentsdb.query.expression;
+
+import java.util.ArrayList;
+import java.util.HashMap;
+import java.util.Map;
+
+import net.opentsdb.core.BaseTsdbTest;
+import net.opentsdb.core.DataPoints;
+import net.opentsdb.core.FillPolicy;
+import net.opentsdb.core.Query;
+import net.opentsdb.core.TSQuery;
+import net.opentsdb.core.TSSubQuery;
+import net.opentsdb.utils.Pair;
+
+/**
+ * A class for setting up a number of time series and queries for expression
+ * testing.
+ */
+public class BaseTimeSyncedIteratorTest extends BaseTsdbTest {
+
+  /** Start time across all queries */
+  protected static final long START_TS = 1388534400;
+  
+  /** The query object compiled after calling {@link #runQueries(ArrayList)} */
+  protected TSQuery query;
+  
+  /** The results of our queries after calling {@link #runQueries(ArrayList)} */
+  protected Map<String, Pair<TSSubQuery, DataPoints[]>> results;
+
+  /** List of iterators */
+  protected Map<String, ITimeSyncedIterator> iterators;
+  
+  /**
+   * Queries for metrics A and B with a group by all on the D tag
+   */
+  protected void queryAB_Dstar() throws Exception {
+    final ArrayList<TSSubQuery> subs = new ArrayList<TSSubQuery>(2);
+    TSSubQuery sub = new TSSubQuery();
+    
+    HashMap<String, String> query_tags = new HashMap<String, String>(1);
+    query_tags.put("D", "*");
+    
+    sub = new TSSubQuery();
+    sub.setMetric("A");
+    sub.setTags(query_tags);
+    sub.setAggregator("sum");
+    subs.add(sub);
+    
+    sub = new TSSubQuery();
+    sub.setMetric("B");
+    query_tags = new HashMap<String, String>(1);
+    query_tags.put("D", "*");
+    sub.setTags(query_tags);
+    sub.setAggregator("sum");
+    subs.add(sub);
+    
+    runQueries(subs);
+  }
+  
+  /**
+   * Queries for A and B but without a tag specifier, thus agging em all
+   */
+  protected void queryAB_AggAll() throws Exception {
+    final ArrayList<TSSubQuery> subs = new ArrayList<TSSubQuery>(2);
+    TSSubQuery sub = new TSSubQuery();
+    
+    HashMap<String, String> query_tags = new HashMap<String, String>(1);
+    
+    sub = new TSSubQuery();
+    sub.setMetric("A");
+    sub.setTags(query_tags);
+    sub.setAggregator("sum");
+    subs.add(sub);
+    
+    sub = new TSSubQuery();
+    sub.setMetric("B");
+    query_tags = new HashMap<String, String>(1);
+    sub.setTags(query_tags);
+    sub.setAggregator("sum");
+    subs.add(sub);
+    
+    runQueries(subs);
+  }
+  
+  /**
+   * Queries for A only with a filter of tag value "D" for tag key "D"
+   */
+  protected void queryA_DD() throws Exception {
+    final ArrayList<TSSubQuery> subs = new ArrayList<TSSubQuery>(2);
+    TSSubQuery sub = new TSSubQuery();
+    final HashMap<String, String> query_tags = new HashMap<String, String>(1);
+    query_tags.put("D", "D");
+    sub = new TSSubQuery();
+    sub.setMetric("A");
+    sub.setTags(query_tags);
+    sub.setAggregator("sum");
+    subs.add(sub);
+    
+    runQueries(subs);
+  }
+  
+  /**
+   * Executes the queries against MockBase through the regular pipeline and stores
+   * the results in {@linke #results}
+   * @param subs The queries to execute
+   */
+  protected void runQueries(final ArrayList<TSSubQuery> subs) throws Exception {
+    query = new TSQuery();
+    query.setStart(Long.toString(START_TS));
+    query.setQueries(subs);
+    query.validateAndSetQuery();
+
+    final Query[] compiled = query.buildQueries(tsdb);
+    results = new HashMap<String, Pair<TSSubQuery, DataPoints[]>>(
+        compiled.length);
+    iterators = new HashMap<String, ITimeSyncedIterator>(compiled.length);
+    
+    int index = 0;
+    for (final Query q : compiled) {
+      final DataPoints[] dps = q.runAsync().join();
+      results.put(Integer.toString(index), 
+          new Pair<TSSubQuery, DataPoints[]>(
+              query.getQueries().get(index), dps));
+      final ITimeSyncedIterator it = new TimeSyncedIterator(Integer.toString(index), 
+          query.getQueries().get(index).getFilterTagKs(), dps);
+      it.setFillPolicy(new NumericFillPolicy(FillPolicy.NOT_A_NUMBER));
+      iterators.put(Integer.toString(index), it);
+      index++;
+    }
+  }
+
+  /**
+   * A and B, each with two series. Common D values, different E values
+   */
+  protected void twoSeriesAggedE() throws Exception {
+    setDataPointStorage();
+    HashMap<String, String> tags = new HashMap<String, String>(2);
+    tags.put("D", "D");
+    tags.put("E", "E");
+    
+    tsdb.addPoint("A", 1431561600, 1, tags).joinUninterruptibly();
+    tsdb.addPoint("A", 1431561660, 2, tags).joinUninterruptibly();
+    tsdb.addPoint("A", 1431561720, 3, tags).joinUninterruptibly();
+
+    tags = new HashMap<String, String>(2);
+    tags.put("D", "D");
+    tags.put("E", "F");
+    
+    tsdb.addPoint("A", 1431561600, 1, tags).joinUninterruptibly();
+    tsdb.addPoint("A", 1431561660, 2, tags).joinUninterruptibly();
+    tsdb.addPoint("A", 1431561720, 3, tags).joinUninterruptibly();
+    
+    tags = new HashMap<String, String>(2);
+    tags.put("D", "D");
+    tags.put("E", "E");
+    tsdb.addPoint("B", 1431561600, 11, tags).joinUninterruptibly();
+    tsdb.addPoint("B", 1431561660, 12, tags).joinUninterruptibly();
+    tsdb.addPoint("B", 1431561720, 13, tags).joinUninterruptibly();
+    
+    tags = new HashMap<String, String>(2);
+    tags.put("D", "D");
+    tags.put("E", "F");
+    tsdb.addPoint("B", 1431561600, 11, tags).joinUninterruptibly();
+    tsdb.addPoint("B", 1431561660, 12, tags).joinUninterruptibly();
+    tsdb.addPoint("B", 1431561720, 13, tags).joinUninterruptibly();
+  }
+  
+  /**
+   * A and B, each with two series. Common D, different E values and the B metric
+   * series have an extra Z tag with different values. 
+   */
+  protected void twoSeriesAggedEandExtraTagK() throws Exception {
+    setDataPointStorage();
+    HashMap<String, String> tags = new HashMap<String, String>(2);
+    tags.put("D", "D");
+    tags.put("E", "E");
+    
+    tsdb.addPoint("A", 1431561600, 1, tags).joinUninterruptibly();
+    tsdb.addPoint("A", 1431561660, 2, tags).joinUninterruptibly();
+    tsdb.addPoint("A", 1431561720, 3, tags).joinUninterruptibly();
+
+    tags = new HashMap<String, String>(2);
+    tags.put("D", "D");
+    tags.put("E", "F");
+    
+    tsdb.addPoint("A", 1431561600, 1, tags).joinUninterruptibly();
+    tsdb.addPoint("A", 1431561660, 2, tags).joinUninterruptibly();
+    tsdb.addPoint("A", 1431561720, 3, tags).joinUninterruptibly();
+    
+    tags = new HashMap<String, String>(2);
+    tags.put("D", "D");
+    tags.put("E", "E");
+    tags.put("Z", "A");
+    tsdb.addPoint("B", 1431561600, 11, tags).joinUninterruptibly();
+    tsdb.addPoint("B", 1431561660, 12, tags).joinUninterruptibly();
+    tsdb.addPoint("B", 1431561720, 13, tags).joinUninterruptibly();
+    
+    tags = new HashMap<String, String>(2);
+    tags.put("D", "D");
+    tags.put("E", "F");
+    tags.put("Z", "B");
+    tsdb.addPoint("B", 1431561600, 11, tags).joinUninterruptibly();
+    tsdb.addPoint("B", 1431561660, 12, tags).joinUninterruptibly();
+    tsdb.addPoint("B", 1431561720, 13, tags).joinUninterruptibly();
+  }
+  
+  /**
+   * A and B where A has two series and B only has one. Series A has two D 
+   * values that will be agged. Different D and E values.
+   */
+  protected void oneAggedTheOtherTagged() throws Exception {
+    setDataPointStorage();
+    HashMap<String, String> tags = new HashMap<String, String>(2);
+    tags.put("D", "D");
+    tags.put("E", "E");
+    
+    tsdb.addPoint("A", 1431561600, 1, tags).joinUninterruptibly();
+    tsdb.addPoint("A", 1431561660, 2, tags).joinUninterruptibly();
+    tsdb.addPoint("A", 1431561720, 3, tags).joinUninterruptibly();
+
+    tags = new HashMap<String, String>(2);
+    tags.put("D", "E");
+    tags.put("E", "F");
+    
+    tsdb.addPoint("A", 1431561600, 1, tags).joinUninterruptibly();
+    tsdb.addPoint("A", 1431561660, 2, tags).joinUninterruptibly();
+    tsdb.addPoint("A", 1431561720, 3, tags).joinUninterruptibly();
+    
+    tags = new HashMap<String, String>(2);
+    tags.put("D", "D");
+    tags.put("E", "E");
+    
+    tsdb.addPoint("B", 1431561600, 11, tags).joinUninterruptibly();
+    tsdb.addPoint("B", 1431561660, 12, tags).joinUninterruptibly();
+    tsdb.addPoint("B", 1431561720, 13, tags).joinUninterruptibly();
+  }
+  
+  /**
+   * A only with three series. Different D values, commong E values.
+   */
+  protected void threeSameENoB() throws Exception {
+    setDataPointStorage();
+    HashMap<String, String> tags = new HashMap<String, String>(2);
+    tags.put("D", "D");
+    tags.put("E", "E");
+    
+    tsdb.addPoint("A", 1431561600, 1, tags).joinUninterruptibly();
+    tsdb.addPoint("A", 1431561660, 2, tags).joinUninterruptibly();
+    tsdb.addPoint("A", 1431561720, 3, tags).joinUninterruptibly();
+    
+    tags = new HashMap<String, String>(2);
+    tags.put("D", "F");
+    tags.put("E", "E");
+    tsdb.addPoint("A", 1431561600, 4, tags).joinUninterruptibly();
+    tsdb.addPoint("A", 1431561660, 5, tags).joinUninterruptibly();
+    tsdb.addPoint("A", 1431561720, 6, tags).joinUninterruptibly();
+    
+    tags = new HashMap<String, String>(2);
+    tags.put("D", "G");
+    tags.put("E", "E");
+    tsdb.addPoint("A", 1431561600, 7, tags).joinUninterruptibly();
+    tsdb.addPoint("A", 1431561660, 8, tags).joinUninterruptibly();
+    tsdb.addPoint("A", 1431561720, 9, tags).joinUninterruptibly();
+  }
+  
+  /**
+   * A and B where A has two series, B has three. Different D values, common E.
+   */
+  protected void oneExtraSameE() throws Exception {
+    setDataPointStorage();
+    HashMap<String, String> tags = new HashMap<String, String>(2);
+    tags.put("D", "D");
+    tags.put("E", "E");
+    
+    tsdb.addPoint("A", 1431561600, 1, tags).joinUninterruptibly();
+    tsdb.addPoint("A", 1431561660, 2, tags).joinUninterruptibly();
+    tsdb.addPoint("A", 1431561720, 3, tags).joinUninterruptibly();
+    
+    tags = new HashMap<String, String>(2);
+    tags.put("D", "F");
+    tags.put("E", "E");
+    tsdb.addPoint("A", 1431561600, 4, tags).joinUninterruptibly();
+    tsdb.addPoint("A", 1431561660, 5, tags).joinUninterruptibly();
+    tsdb.addPoint("A", 1431561720, 6, tags).joinUninterruptibly();
+    
+    tags = new HashMap<String, String>(2);
+    tags.put("D", "D");
+    tags.put("E", "E");
+    tsdb.addPoint("B", 1431561600, 11, tags).joinUninterruptibly();
+    tsdb.addPoint("B", 1431561660, 12, tags).joinUninterruptibly();
+    tsdb.addPoint("B", 1431561720, 13, tags).joinUninterruptibly();
+    
+    tags = new HashMap<String, String>(2);
+    tags.put("D", "F");
+    tags.put("E", "E");
+    tsdb.addPoint("B", 1431561600, 14, tags).joinUninterruptibly();
+    tsdb.addPoint("B", 1431561660, 15, tags).joinUninterruptibly();
+    tsdb.addPoint("B", 1431561720, 16, tags).joinUninterruptibly();
+    
+    // all by myself......
+    tags = new HashMap<String, String>(2);
+    tags.put("D", "G");
+    tags.put("E", "E");
+    tsdb.addPoint("B", 1431561600, 17, tags).joinUninterruptibly();
+    tsdb.addPoint("B", 1431561660, 18, tags).joinUninterruptibly();
+    tsdb.addPoint("B", 1431561720, 19, tags).joinUninterruptibly();
+  }
+  
+  /**
+   * A and B with two series each. Different D values, common E. 
+   * A has values at T0 and T1, but then B has values at T2 and T3. Should
+   * throw NaNs after the intersection.
+   */
+  protected void timeOffset() throws Exception {
+    setDataPointStorage();
+    HashMap<String, String> tags = new HashMap<String, String>(2);
+    tags.put("D", "D");
+    tags.put("E", "E");
+    
+    tsdb.addPoint("A", 1431561600, 1, tags).joinUninterruptibly();
+    tsdb.addPoint("A", 1431561660, 2, tags).joinUninterruptibly();
+    
+    tags = new HashMap<String, String>(2);
+    tags.put("D", "F");
+    tags.put("E", "E");
+    tsdb.addPoint("A", 1431561600, 4, tags).joinUninterruptibly();
+    tsdb.addPoint("A", 1431561660, 5, tags).joinUninterruptibly();
+    
+    tags = new HashMap<String, String>(2);
+    tags.put("D", "D");
+    tags.put("E", "E");
+    tsdb.addPoint("B", 1431561720, 13, tags).joinUninterruptibly();
+    tsdb.addPoint("B", 1431561780, 14, tags).joinUninterruptibly();
+    
+    tags = new HashMap<String, String>(2);
+    tags.put("D", "F");
+    tags.put("E", "E");
+    tsdb.addPoint("B", 1431561720, 16, tags).joinUninterruptibly();
+    tsdb.addPoint("B", 1431561780, 17, tags).joinUninterruptibly();
+  }
+  
+  /**
+   * A and B, each with three series. Different D values, commong E.
+   */
+  protected void threeSameE() throws Exception {
+    setDataPointStorage();
+    HashMap<String, String> tags = new HashMap<String, String>(2);
+    tags.put("D", "D");
+    tags.put("E", "E");
+    
+    tsdb.addPoint("A", 1431561600, 1, tags).joinUninterruptibly();
+    tsdb.addPoint("A", 1431561660, 2, tags).joinUninterruptibly();
+    tsdb.addPoint("A", 1431561720, 3, tags).joinUninterruptibly();
+    
+    tags = new HashMap<String, String>(2);
+    tags.put("D", "F");
+    tags.put("E", "E");
+    tsdb.addPoint("A", 1431561600, 4, tags).joinUninterruptibly();
+    tsdb.addPoint("A", 1431561660, 5, tags).joinUninterruptibly();
+    tsdb.addPoint("A", 1431561720, 6, tags).joinUninterruptibly();
+    
+    tags = new HashMap<String, String>(2);
+    tags.put("D", "G");
+    tags.put("E", "E");
+    tsdb.addPoint("A", 1431561600, 7, tags).joinUninterruptibly();
+    tsdb.addPoint("A", 1431561660, 8, tags).joinUninterruptibly();
+    tsdb.addPoint("A", 1431561720, 9, tags).joinUninterruptibly();
+    
+    tags = new HashMap<String, String>(2);
+    tags.put("D", "D");
+    tags.put("E", "E");
+    tsdb.addPoint("B", 1431561600, 11, tags).joinUninterruptibly();
+    tsdb.addPoint("B", 1431561660, 12, tags).joinUninterruptibly();
+    tsdb.addPoint("B", 1431561720, 13, tags).joinUninterruptibly();
+    
+    tags = new HashMap<String, String>(2);
+    tags.put("D", "F");
+    tags.put("E", "E");
+    tsdb.addPoint("B", 1431561600, 14, tags).joinUninterruptibly();
+    tsdb.addPoint("B", 1431561660, 15, tags).joinUninterruptibly();
+    tsdb.addPoint("B", 1431561720, 16, tags).joinUninterruptibly();
+
+    tags = new HashMap<String, String>(2);
+    tags.put("D", "G");
+    tags.put("E", "E");
+    tsdb.addPoint("B", 1431561600, 17, tags).joinUninterruptibly();
+    tsdb.addPoint("B", 1431561660, 18, tags).joinUninterruptibly();
+    tsdb.addPoint("B", 1431561720, 19, tags).joinUninterruptibly();
+  }
+  
+  /**
+   * A and B, each with three series. Different D values. Series in A are missing
+   * the E tag. Common values in E for B.
+   */
+  protected void threeAMissingE() throws Exception {
+    setDataPointStorage();
+    HashMap<String, String> tags = new HashMap<String, String>(2);
+    tags.put("D", "D");
+    tsdb.addPoint("A", 1431561600, 1, tags).joinUninterruptibly();
+    tsdb.addPoint("A", 1431561660, 2, tags).joinUninterruptibly();
+    tsdb.addPoint("A", 1431561720, 3, tags).joinUninterruptibly();
+    
+    tags = new HashMap<String, String>(2);
+    tags.put("D", "F");
+    tsdb.addPoint("A", 1431561600, 4, tags).joinUninterruptibly();
+    tsdb.addPoint("A", 1431561660, 5, tags).joinUninterruptibly();
+    tsdb.addPoint("A", 1431561720, 6, tags).joinUninterruptibly();
+    
+    tags = new HashMap<String, String>(2);
+    tags.put("D", "G");
+    tsdb.addPoint("A", 1431561600, 7, tags).joinUninterruptibly();
+    tsdb.addPoint("A", 1431561660, 8, tags).joinUninterruptibly();
+    tsdb.addPoint("A", 1431561720, 9, tags).joinUninterruptibly();
+    
+    tags = new HashMap<String, String>(2);
+    tags.put("D", "D");
+    tags.put("E", "E");
+    tsdb.addPoint("B", 1431561600, 11, tags).joinUninterruptibly();
+    tsdb.addPoint("B", 1431561660, 12, tags).joinUninterruptibly();
+    tsdb.addPoint("B", 1431561720, 13, tags).joinUninterruptibly();
+    
+    tags = new HashMap<String, String>(2);
+    tags.put("D", "F");
+    tags.put("E", "E");
+    tsdb.addPoint("B", 1431561600, 14, tags).joinUninterruptibly();
+    tsdb.addPoint("B", 1431561660, 15, tags).joinUninterruptibly();
+    tsdb.addPoint("B", 1431561720, 16, tags).joinUninterruptibly();
+
+    tags = new HashMap<String, String>(2);
+    tags.put("D", "G");
+    tags.put("E", "E");
+    tsdb.addPoint("B", 1431561600, 17, tags).joinUninterruptibly();
+    tsdb.addPoint("B", 1431561660, 18, tags).joinUninterruptibly();
+    tsdb.addPoint("B", 1431561720, 19, tags).joinUninterruptibly();
+  }
+  
+  /**
+   * A and B, each with three series. Different D and E values
+   */
+  protected void threeDifE() throws Exception {
+    setDataPointStorage();
+    HashMap<String, String> tags = new HashMap<String, String>(2);
+    tags.put("D", "D");
+    tags.put("E", "A");
+    tsdb.addPoint("A", 1431561600, 1, tags).joinUninterruptibly();
+    tsdb.addPoint("A", 1431561660, 2, tags).joinUninterruptibly();
+    tsdb.addPoint("A", 1431561720, 3, tags).joinUninterruptibly();
+    
+    tags = new HashMap<String, String>(2);
+    tags.put("D", "F");
+    tags.put("E", "B");
+    tsdb.addPoint("A", 1431561600, 4, tags).joinUninterruptibly();
+    tsdb.addPoint("A", 1431561660, 5, tags).joinUninterruptibly();
+    tsdb.addPoint("A", 1431561720, 6, tags).joinUninterruptibly();
+    
+    tags = new HashMap<String, String>(2);
+    tags.put("D", "G");
+    tags.put("E", "C");
+    tsdb.addPoint("A", 1431561600, 7, tags).joinUninterruptibly();
+    tsdb.addPoint("A", 1431561660, 8, tags).joinUninterruptibly();
+    tsdb.addPoint("A", 1431561720, 9, tags).joinUninterruptibly();
+    
+    tags = new HashMap<String, String>(2);
+    tags.put("D", "D");
+    tags.put("E", "D");
+    tsdb.addPoint("B", 1431561600, 11, tags).joinUninterruptibly();
+    tsdb.addPoint("B", 1431561660, 12, tags).joinUninterruptibly();
+    tsdb.addPoint("B", 1431561720, 13, tags).joinUninterruptibly();
+    
+    tags = new HashMap<String, String>(2);
+    tags.put("D", "F");
+    tags.put("E", "F");
+    tsdb.addPoint("B", 1431561600, 14, tags).joinUninterruptibly();
+    tsdb.addPoint("B", 1431561660, 15, tags).joinUninterruptibly();
+    tsdb.addPoint("B", 1431561720, 16, tags).joinUninterruptibly();
+
+    tags = new HashMap<String, String>(2);
+    tags.put("D", "G");
+    tags.put("E", "G");
+    tsdb.addPoint("B", 1431561600, 17, tags).joinUninterruptibly();
+    tsdb.addPoint("B", 1431561660, 18, tags).joinUninterruptibly();
+    tsdb.addPoint("B", 1431561720, 19, tags).joinUninterruptibly();
+  }
+
+  /**
+   * A and B, each with 3 series. Different D values, common E. 
+   * Each set has one series that isn't in the other. D=G in A and D=Q in B.
+   */
+  protected void threeDisjointSameE() throws Exception {
+    setDataPointStorage();
+    
+    HashMap<String, String> tags = new HashMap<String, String>(2);
+    tags.put("D", "D");
+    tags.put("E", "E");
+    tsdb.addPoint("A", 1431561600, 1, tags).joinUninterruptibly();
+    tsdb.addPoint("A", 1431561660, 2, tags).joinUninterruptibly();
+    tsdb.addPoint("A", 1431561720, 3, tags).joinUninterruptibly();
+    
+    // not in set 2
+    tags = new HashMap<String, String>(2);
+    tags.put("D", "F");
+    tags.put("E", "E");
+    tsdb.addPoint("A", 1431561600, 4, tags).joinUninterruptibly();
+    tsdb.addPoint("A", 1431561660, 5, tags).joinUninterruptibly();
+    tsdb.addPoint("A", 1431561720, 6, tags).joinUninterruptibly();
+    
+    tags = new HashMap<String, String>(2);
+    tags.put("D", "G");
+    tags.put("E", "E");
+    tsdb.addPoint("A", 1431561600, 7, tags).joinUninterruptibly();
+    tsdb.addPoint("A", 1431561660, 8, tags).joinUninterruptibly();
+    tsdb.addPoint("A", 1431561720, 9, tags).joinUninterruptibly();
+    
+    tags = new HashMap<String, String>(2);
+    tags.put("D", "D");
+    tags.put("E", "E");
+    tsdb.addPoint("B", 1431561600, 11, tags).joinUninterruptibly();
+    tsdb.addPoint("B", 1431561660, 12, tags).joinUninterruptibly();
+    tsdb.addPoint("B", 1431561720, 13, tags).joinUninterruptibly();
+    
+    // not in set 1
+    tags = new HashMap<String, String>(2);
+    tags.put("D", "Q");
+    tags.put("E", "E");
+    tsdb.addPoint("B", 1431561600, 14, tags).joinUninterruptibly();
+    tsdb.addPoint("B", 1431561660, 15, tags).joinUninterruptibly();
+    tsdb.addPoint("B", 1431561720, 16, tags).joinUninterruptibly();
+
+    tags = new HashMap<String, String>(2);
+    tags.put("D", "G");
+    tags.put("E", "E");
+    tsdb.addPoint("B", 1431561600, 17, tags).joinUninterruptibly();
+    tsdb.addPoint("B", 1431561660, 18, tags).joinUninterruptibly();
+    tsdb.addPoint("B", 1431561720, 19, tags).joinUninterruptibly();
+  }
+  
+  /**
+   * A and B, each with three series. Different D values, common E values.
+   * D=G is the only common series between the sets
+   */
+  protected void reduceToOne() throws Exception {
+    setDataPointStorage();
+    HashMap<String, String> tags = new HashMap<String, String>(2);
+    tags.put("D", "D");
+    tags.put("E", "E");
+    
+    tsdb.addPoint("A", 1431561600, 1, tags).joinUninterruptibly();
+    tsdb.addPoint("A", 1431561660, 2, tags).joinUninterruptibly();
+    tsdb.addPoint("A", 1431561720, 3, tags).joinUninterruptibly();
+    
+    // not in set 2
+    tags = new HashMap<String, String>(2);
+    tags.put("D", "F");
+    tags.put("E", "E");
+    tsdb.addPoint("A", 1431561600, 4, tags).joinUninterruptibly();
+    tsdb.addPoint("A", 1431561660, 5, tags).joinUninterruptibly();
+    tsdb.addPoint("A", 1431561720, 6, tags).joinUninterruptibly();
+    
+    tags = new HashMap<String, String>(2);
+    tags.put("D", "G");
+    tags.put("E", "E");
+    tsdb.addPoint("A", 1431561600, 7, tags).joinUninterruptibly();
+    tsdb.addPoint("A", 1431561660, 8, tags).joinUninterruptibly();
+    tsdb.addPoint("A", 1431561720, 9, tags).joinUninterruptibly();
+    
+    tags = new HashMap<String, String>(2);
+    tags.put("D", "P");
+    tags.put("E", "E");
+    tsdb.addPoint("B", 1431561600, 11, tags).joinUninterruptibly();
+    tsdb.addPoint("B", 1431561660, 12, tags).joinUninterruptibly();
+    tsdb.addPoint("B", 1431561720, 13, tags).joinUninterruptibly();
+    
+    // not in set 1
+    tags = new HashMap<String, String>(2);
+    tags.put("D", "Q");
+    tags.put("E", "E");
+    tsdb.addPoint("B", 1431561600, 14, tags).joinUninterruptibly();
+    tsdb.addPoint("B", 1431561660, 15, tags).joinUninterruptibly();
+    tsdb.addPoint("B", 1431561720, 16, tags).joinUninterruptibly();
+
+    tags = new HashMap<String, String>(2);
+    tags.put("D", "G");
+    tags.put("E", "E");
+    tsdb.addPoint("B", 1431561600, 17, tags).joinUninterruptibly();
+    tsdb.addPoint("B", 1431561660, 18, tags).joinUninterruptibly();
+    tsdb.addPoint("B", 1431561720, 19, tags).joinUninterruptibly();
+  }
+ 
+  /**
+   * A and B, each with three series. Different D values, common E values.
+   * Each series is "missing" a data point so that we can test time sync.  
+   */
+  protected void threeSameEGaps() throws Exception {
+    setDataPointStorage();
+    HashMap<String, String> tags = new HashMap<String, String>(2);
+    tags.put("D", "D");
+    tags.put("E", "E");
+    
+    tsdb.addPoint("A", 1431561600, 1, tags).joinUninterruptibly();
+    //tsdb.addPoint("A", 1431561660, 2, tags).joinUninterruptibly();
+    tsdb.addPoint("A", 1431561720, 3, tags).joinUninterruptibly();
+    
+    tags = new HashMap<String, String>(2);
+    tags.put("D", "F");
+    tags.put("E", "E");
+    tsdb.addPoint("A", 1431561600, 4, tags).joinUninterruptibly();
+    tsdb.addPoint("A", 1431561660, 5, tags).joinUninterruptibly();
+    //tsdb.addPoint("A", 1431561720, 6, tags).joinUninterruptibly();
+    
+    tags = new HashMap<String, String>(2);
+    tags.put("D", "G");
+    tags.put("E", "E");
+    //tsdb.addPoint("A", 1431561600, 7, tags).joinUninterruptibly();
+    tsdb.addPoint("A", 1431561660, 8, tags).joinUninterruptibly();
+    tsdb.addPoint("A", 1431561720, 9, tags).joinUninterruptibly();
+    
+    tags = new HashMap<String, String>(2);
+    tags.put("D", "D");
+    tags.put("E", "E");
+    //tsdb.addPoint("B", 1431561600, 11, tags).joinUninterruptibly();
+    //tsdb.addPoint("B", 1431561660, 12, tags).joinUninterruptibly();
+    tsdb.addPoint("B", 1431561720, 13, tags).joinUninterruptibly();
+    
+    tags = new HashMap<String, String>(2);
+    tags.put("D", "F");
+    tags.put("E", "E");
+    //tsdb.addPoint("B", 1431561600, 14, tags).joinUninterruptibly();
+    tsdb.addPoint("B", 1431561660, 15, tags).joinUninterruptibly();
+    //tsdb.addPoint("B", 1431561720, 16, tags).joinUninterruptibly();
+
+    tags = new HashMap<String, String>(2);
+    tags.put("D", "G");
+    tags.put("E", "E");
+    //tsdb.addPoint("B", 1431561600, 17, tags).joinUninterruptibly();
+    //tsdb.addPoint("B", 1431561660, 18, tags).joinUninterruptibly();
+    tsdb.addPoint("B", 1431561720, 19, tags).joinUninterruptibly();
+  }
+ 
+}
diff --git a/test/query/expression/TestAbsolute.java b/test/query/expression/TestAbsolute.java
new file mode 100644
index 0000000000..7d822fe4f4
--- /dev/null
+++ b/test/query/expression/TestAbsolute.java
@@ -0,0 +1,309 @@
+// This file is part of OpenTSDB.
+// Copyright (C) 2015  The OpenTSDB Authors.
+//
+// This program is free software: you can redistribute it and/or modify it
+// under the terms of the GNU Lesser General Public License as published by
+// the Free Software Foundation, either version 2.1 of the License, or (at your
+// option) any later version.  This program is distributed in the hope that it
+// will be useful, but WITHOUT ANY WARRANTY; without even the implied warranty
+// of MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser
+// General Public License for more details.  You should have received a copy
+// of the GNU Lesser General Public License along with this program.  If not,
+// see <http://www.gnu.org/licenses/>.
+package net.opentsdb.query.expression;
+
+import static org.junit.Assert.assertEquals;
+import static org.junit.Assert.assertFalse;
+import static org.junit.Assert.assertNotNull;
+import static org.junit.Assert.assertTrue;
+import static org.mockito.Mockito.mock;
+import static org.mockito.Mockito.when;
+
+import java.util.ArrayList;
+import java.util.Collections;
+import java.util.List;
+
+import net.opentsdb.core.DataPoint;
+import net.opentsdb.core.DataPoints;
+import net.opentsdb.core.SeekableView;
+import net.opentsdb.core.SeekableViewsForTest;
+import net.opentsdb.core.TSQuery;
+
+import org.junit.Before;
+import org.junit.Test;
+import org.junit.runner.RunWith;
+import org.powermock.api.mockito.PowerMockito;
+import org.powermock.core.classloader.annotations.PowerMockIgnore;
+import org.powermock.core.classloader.annotations.PrepareForTest;
+import org.powermock.modules.junit4.PowerMockRunner;
+
+import com.stumbleupon.async.Deferred;
+
+@RunWith(PowerMockRunner.class)
+@PowerMockIgnore({"javax.management.*", "javax.xml.*",
+  "ch.qos.*", "org.slf4j.*",
+  "com.sum.*", "org.xml.*"})
+@PrepareForTest({ TSQuery.class })
+public class TestAbsolute {
+
+  private static long START_TIME = 1356998400000L;
+  private static int INTERVAL = 60000;
+  private static int NUM_POINTS = 5;
+  private static String METRIC = "sys.cpu";
+  
+  private TSQuery data_query;
+  private SeekableView view;
+  private DataPoints dps;
+  private DataPoints[] group_bys;
+  private List<DataPoints[]> query_results;
+  private List<String> params;
+  private Absolute func;
+  
+  @Before
+  public void before() throws Exception {
+    view = SeekableViewsForTest.generator(START_TIME, INTERVAL, 
+        NUM_POINTS, true, 1, 1);
+    data_query = mock(TSQuery.class);
+    when(data_query.startTime()).thenReturn(START_TIME);
+    when(data_query.endTime()).thenReturn(START_TIME + (INTERVAL * NUM_POINTS));
+    
+    dps = PowerMockito.mock(DataPoints.class);
+    when(dps.iterator()).thenReturn(view);
+    when(dps.metricNameAsync()).thenReturn(Deferred.fromResult(METRIC));
+    
+    group_bys = new DataPoints[] { dps };
+    
+    query_results = new ArrayList<DataPoints[]>(1);
+    query_results.add(group_bys);
+    
+    params = new ArrayList<String>(1);
+    func = new Absolute();
+  }
+  
+  @Test
+  public void evaluatePositiveGroupByLong() throws Exception {
+    SeekableView view2 = SeekableViewsForTest.generator(START_TIME, INTERVAL, 
+        NUM_POINTS, true, 10, 1);
+    DataPoints dps2 = PowerMockito.mock(DataPoints.class);
+    when(dps2.iterator()).thenReturn(view2);
+    when(dps2.metricNameAsync()).thenReturn(Deferred.fromResult("sys.mem"));
+    group_bys = new DataPoints[] { dps, dps2 };
+    query_results.clear();
+    query_results.add(group_bys);
+    
+    final DataPoints[] results = func.evaluate(data_query, query_results, params);
+    
+    assertEquals(2, results.length);
+    assertEquals(METRIC, results[0].metricName());
+    assertEquals("sys.mem", results[1].metricName());
+    
+    long ts = START_TIME;
+    long v = 1;
+    for (DataPoint dp : results[0]) {
+      assertEquals(ts, dp.timestamp());
+      assertTrue(dp.isInteger());
+      assertEquals(v, dp.longValue());
+      ts += INTERVAL;
+      v += 1;
+    }
+    ts = START_TIME;
+    v = 10;
+    for (DataPoint dp : results[1]) {
+      assertEquals(ts, dp.timestamp());
+      assertTrue(dp.isInteger());
+      assertEquals(v, dp.longValue());
+      ts += INTERVAL;
+      v += 1;
+    }
+  }
+  
+  @Test
+  public void evaluatePositiveGroupByDouble() throws Exception {
+    SeekableView view2 = SeekableViewsForTest.generator(START_TIME, INTERVAL, 
+        NUM_POINTS, false, 10, 1);
+    DataPoints dps2 = PowerMockito.mock(DataPoints.class);
+    when(dps2.iterator()).thenReturn(view2);
+    when(dps2.metricNameAsync()).thenReturn(Deferred.fromResult("sys.mem"));
+    group_bys = new DataPoints[] { dps, dps2 };
+    query_results.clear();
+    query_results.add(group_bys);
+    
+    final DataPoints[] results = func.evaluate(data_query, query_results, params);
+    
+    assertEquals(2, results.length);
+    assertEquals(METRIC, results[0].metricName());
+    assertEquals("sys.mem", results[1].metricName());
+    
+    long ts = START_TIME;
+    double v = 1;
+    for (DataPoint dp : results[0]) {
+      assertEquals(ts, dp.timestamp());
+      assertTrue(dp.isInteger());
+      assertEquals((long)v, dp.longValue());
+      ts += INTERVAL;
+      v += 1;
+    }
+    ts = START_TIME;
+    v = 10;
+    for (DataPoint dp : results[1]) {
+      assertEquals(ts, dp.timestamp());
+      assertFalse(dp.isInteger());
+      assertEquals(v, dp.doubleValue(), 0.001);
+      ts += INTERVAL;
+      v += 1;
+    }
+  }
+  
+  @Test
+  public void evaluateFactorNegativeGroupByLong() throws Exception {
+    SeekableView view2 = SeekableViewsForTest.generator(START_TIME, INTERVAL, 
+        NUM_POINTS, true, -10, -1);
+    DataPoints dps2 = PowerMockito.mock(DataPoints.class);
+    when(dps2.iterator()).thenReturn(view2);
+    when(dps2.metricNameAsync()).thenReturn(Deferred.fromResult("sys.mem"));
+    group_bys = new DataPoints[] { dps, dps2 };
+    query_results.clear();
+    query_results.add(group_bys);
+    
+    final DataPoints[] results = func.evaluate(data_query, query_results, params);
+    
+    assertEquals(2, results.length);
+    assertEquals(METRIC, results[0].metricName());
+    assertEquals("sys.mem", results[1].metricName());
+    
+    long ts = START_TIME;
+    long v = 1;
+    for (DataPoint dp : results[0]) {
+      assertEquals(ts, dp.timestamp());
+      assertTrue(dp.isInteger());
+      assertEquals(v, dp.longValue());
+      ts += INTERVAL;
+      v += 1;
+    }
+    ts = START_TIME;
+    v = 10;
+    for (DataPoint dp : results[1]) {
+      assertEquals(ts, dp.timestamp());
+      assertTrue(dp.isInteger());
+      assertEquals(v, dp.longValue());
+      ts += INTERVAL;
+      v += 1;
+    }
+  }
+  
+  @Test
+  public void evaluateNegativeGroupByDouble() throws Exception {
+    SeekableView view2 = SeekableViewsForTest.generator(START_TIME, INTERVAL, 
+        NUM_POINTS, false, -10, -1);
+    DataPoints dps2 = PowerMockito.mock(DataPoints.class);
+    when(dps2.iterator()).thenReturn(view2);
+    when(dps2.metricNameAsync()).thenReturn(Deferred.fromResult("sys.mem"));
+    group_bys = new DataPoints[] { dps, dps2 };
+    query_results.clear();
+    query_results.add(group_bys);
+    
+    final DataPoints[] results = func.evaluate(data_query, query_results, params);
+    
+    assertEquals(2, results.length);
+    assertEquals(METRIC, results[0].metricName());
+    assertEquals("sys.mem", results[1].metricName());
+    
+    long ts = START_TIME;
+    double v = 1;
+    for (DataPoint dp : results[0]) {
+      assertEquals(ts, dp.timestamp());
+      assertTrue(dp.isInteger());
+      assertEquals((long)v, dp.longValue());
+      ts += INTERVAL;
+      v += 1;
+    }
+    ts = START_TIME;
+    v = 10;
+    for (DataPoint dp : results[1]) {
+      assertEquals(ts, dp.timestamp());
+      assertFalse(dp.isInteger());
+      assertEquals(v, dp.doubleValue(), 0.001);
+      ts += INTERVAL;
+      v += 1;
+    }
+  }
+  
+  @Test
+  public void evaluateNegativeSubQuerySeries() throws Exception {
+    params.add("1");
+    SeekableView view2 = SeekableViewsForTest.generator(START_TIME, INTERVAL, 
+        NUM_POINTS, true, -10, -1);
+    DataPoints dps2 = PowerMockito.mock(DataPoints.class);
+    when(dps2.iterator()).thenReturn(view2);
+    when(dps2.metricNameAsync()).thenReturn(Deferred.fromResult("sys.mem"));
+    group_bys = new DataPoints[] { dps, dps2 };
+    query_results.clear();
+    query_results.add(group_bys);
+    
+    final DataPoints[] results = func.evaluate(data_query, query_results, params);
+    
+    assertEquals(2, results.length);
+    assertEquals(METRIC, results[0].metricName());
+    assertEquals("sys.mem", results[1].metricName());
+    
+    long ts = START_TIME;
+    long v = 1;
+    for (DataPoint dp : results[0]) {
+      assertEquals(ts, dp.timestamp());
+      assertTrue(dp.isInteger());
+      assertEquals(v, dp.longValue());
+      ts += INTERVAL;
+      v += 1;
+    }
+    ts = START_TIME;
+    v = 10;
+    for (DataPoint dp : results[1]) {
+      assertEquals(ts, dp.timestamp());
+      assertTrue(dp.isInteger());
+      assertEquals(v, dp.longValue());
+      ts += INTERVAL;
+      v += 1;
+    }
+  }
+  
+  @Test (expected = IllegalArgumentException.class)
+  public void evaluateNullQuery() throws Exception {
+    params.add("1");
+    func.evaluate(null, query_results, params);
+  }
+  
+  @Test
+  public void evaluateNullResults() throws Exception {
+    params.add("1");
+    final DataPoints[] results = func.evaluate(data_query, null, params);
+    assertEquals(0, results.length);
+  }
+  
+  @Test
+  public void evaluateNullParams() throws Exception {
+    assertNotNull(func.evaluate(data_query, query_results, null));
+  }
+
+  @Test
+  public void evaluateEmptyResults() throws Exception {
+    final DataPoints[] results = func.evaluate(data_query, 
+        Collections.<DataPoints[]>emptyList(), params);
+    assertEquals(0, results.length);
+  }
+  
+  @Test
+  public void evaluateEmptyParams() throws Exception {
+    assertNotNull(func.evaluate(data_query, query_results, null));
+  }
+  
+  @Test
+  public void writeStringField() throws Exception {
+    params.add("1");
+    assertEquals("absolute(inner_expression)", 
+        func.writeStringField(params, "inner_expression"));
+    assertEquals("absolute(null)", func.writeStringField(params, null));
+    assertEquals("absolute()", func.writeStringField(params, ""));
+    assertEquals("absolute(inner_expression)", 
+        func.writeStringField(null, "inner_expression"));
+  }
+}
diff --git a/test/query/expression/TestAlias.java b/test/query/expression/TestAlias.java
new file mode 100644
index 0000000000..744287e50f
--- /dev/null
+++ b/test/query/expression/TestAlias.java
@@ -0,0 +1,321 @@
+// This file is part of OpenTSDB.
+// Copyright (C) 2015  The OpenTSDB Authors.
+//
+// This program is free software: you can redistribute it and/or modify it
+// under the terms of the GNU Lesser General Public License as published by
+// the Free Software Foundation, either version 2.1 of the License, or (at your
+// option) any later version.  This program is distributed in the hope that it
+// will be useful, but WITHOUT ANY WARRANTY; without even the implied warranty
+// of MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser
+// General Public License for more details.  You should have received a copy
+// of the GNU Lesser General Public License along with this program.  If not,
+// see <http://www.gnu.org/licenses/>.
+package net.opentsdb.query.expression;
+
+import static org.junit.Assert.assertEquals;
+import static org.junit.Assert.assertFalse;
+import static org.junit.Assert.assertTrue;
+import static org.mockito.Mockito.mock;
+import static org.mockito.Mockito.when;
+
+import java.util.ArrayList;
+import java.util.Collections;
+import java.util.HashMap;
+import java.util.List;
+import java.util.Map;
+
+import net.opentsdb.core.DataPoint;
+import net.opentsdb.core.DataPoints;
+import net.opentsdb.core.SeekableView;
+import net.opentsdb.core.SeekableViewsForTest;
+import net.opentsdb.core.TSQuery;
+
+import org.hbase.async.Bytes.ByteMap;
+import org.junit.Before;
+import org.junit.Test;
+import org.junit.runner.RunWith;
+import org.powermock.api.mockito.PowerMockito;
+import org.powermock.core.classloader.annotations.PowerMockIgnore;
+import org.powermock.core.classloader.annotations.PrepareForTest;
+import org.powermock.modules.junit4.PowerMockRunner;
+
+import com.stumbleupon.async.Deferred;
+
+@RunWith(PowerMockRunner.class)
+@PowerMockIgnore({"javax.management.*", "javax.xml.*",
+  "ch.qos.*", "org.slf4j.*",
+  "com.sum.*", "org.xml.*"})
+@PrepareForTest({ TSQuery.class })
+public class TestAlias {
+
+  private static long START_TIME = 1356998400000L;
+  private static int INTERVAL = 60000;
+  private static int NUM_POINTS = 5;
+  private static String METRIC = "sys.cpu";
+  
+  private TSQuery data_query;
+  private SeekableView view;
+  private DataPoints dps;
+  private DataPoints[] group_bys;
+  private List<DataPoints[]> query_results;
+  private List<String> params;
+  private Alias func;
+  private Map<String, String> tags;
+  private ByteMap<byte[]> tag_uids;
+  
+  @Before
+  public void before() throws Exception {
+    view = SeekableViewsForTest.generator(START_TIME, INTERVAL, 
+        NUM_POINTS, true, 1, 1);
+    data_query = mock(TSQuery.class);
+    when(data_query.startTime()).thenReturn(START_TIME);
+    when(data_query.endTime()).thenReturn(START_TIME + (INTERVAL * NUM_POINTS));
+    
+    tags = new HashMap<String, String>(2);
+    tags.put("host", "web01");
+    tags.put("dc", "lga");
+    tag_uids = new ByteMap<byte[]>();
+    tag_uids.put(new byte[] { 0, 0, 1 }, new byte[] { 0, 0, 1 });
+    tag_uids.put(new byte[] { 0, 0, 2 }, new byte[] { 0, 0, 2 });
+    
+    dps = PowerMockito.mock(DataPoints.class);
+    when(dps.iterator()).thenReturn(view);
+    when(dps.metricName()).thenReturn(METRIC);
+    when(dps.getTagsAsync()).thenReturn(Deferred.fromResult(tags));
+    when(dps.getTagUids()).thenReturn(tag_uids);
+    
+    group_bys = new DataPoints[] { dps };
+    
+    query_results = new ArrayList<DataPoints[]>(1);
+    query_results.add(group_bys);
+    
+    params = new ArrayList<String>(1);
+    func = new Alias();
+  }
+  
+  @Test
+  public void evaluateGroupByLong() throws Exception {
+    SeekableView view2 = SeekableViewsForTest.generator(START_TIME, INTERVAL, 
+        NUM_POINTS, true, 10, 1);
+    DataPoints dps2 = PowerMockito.mock(DataPoints.class);
+    when(dps2.iterator()).thenReturn(view2);
+    when(dps2.metricName()).thenReturn("sys.mem");
+    group_bys = new DataPoints[] { dps, dps2 };
+    query_results.clear();
+    query_results.add(group_bys);
+    params.add("My Alias");
+    
+    final DataPoints[] results = func.evaluate(data_query, query_results, params);
+    
+    assertEquals(2, results.length);
+    assertEquals("My Alias", results[0].metricName());
+    assertEquals("My Alias", results[1].metricName());
+    
+    long ts = START_TIME;
+    long v = 1;
+    for (DataPoint dp : results[0]) {
+      assertEquals(ts, dp.timestamp());
+      assertTrue(dp.isInteger());
+      assertEquals(v, dp.longValue());
+      ts += INTERVAL;
+      v += 1;
+    }
+    ts = START_TIME;
+    v = 10;
+    for (DataPoint dp : results[1]) {
+      assertEquals(ts, dp.timestamp());
+      assertTrue(dp.isInteger());
+      assertEquals(v, dp.longValue());
+      ts += INTERVAL;
+      v += 1;
+    }
+  }
+  
+  @Test
+  public void evaluateGroupByDouble() throws Exception {
+    SeekableView view2 = SeekableViewsForTest.generator(START_TIME, INTERVAL, 
+        NUM_POINTS, false, 10, 1);
+    DataPoints dps2 = PowerMockito.mock(DataPoints.class);
+    when(dps2.iterator()).thenReturn(view2);
+    when(dps2.metricName()).thenReturn("sys.mem");
+    group_bys = new DataPoints[] { dps, dps2 };
+    query_results.clear();
+    query_results.add(group_bys);
+    params.add("My Alias");
+    
+    final DataPoints[] results = func.evaluate(data_query, query_results, params);
+    
+    assertEquals(2, results.length);
+    assertEquals("My Alias", results[0].metricName());
+    assertEquals("My Alias", results[1].metricName());
+    
+    long ts = START_TIME;
+    double v = 1;
+    for (DataPoint dp : results[0]) {
+      assertEquals(ts, dp.timestamp());
+      assertTrue(dp.isInteger());
+      assertEquals((long)v, dp.longValue());
+      ts += INTERVAL;
+      v += 1;
+    }
+    ts = START_TIME;
+    v = 10;
+    for (DataPoint dp : results[1]) {
+      assertEquals(ts, dp.timestamp());
+      assertFalse(dp.isInteger());
+      assertEquals(v, dp.doubleValue(), 0.001);
+      ts += INTERVAL;
+      v += 1;
+    }
+  }
+  
+  @Test
+  public void evaluateSubQuerySeries() throws Exception {
+    SeekableView view2 = SeekableViewsForTest.generator(START_TIME, INTERVAL, 
+        NUM_POINTS, true, -10, -1);
+    DataPoints dps2 = PowerMockito.mock(DataPoints.class);
+    when(dps2.iterator()).thenReturn(view2);
+    when(dps2.metricName()).thenReturn("sys.mem");
+    group_bys = new DataPoints[] { dps, dps2 };
+    query_results.clear();
+    query_results.add(group_bys);
+    params.add("My Alias");
+    
+    final DataPoints[] results = func.evaluate(data_query, query_results, params);
+    
+    assertEquals(2, results.length);
+    assertEquals("My Alias", results[0].metricName());
+    assertEquals("My Alias", results[1].metricName());
+    
+    long ts = START_TIME;
+    long v = 1;
+    for (DataPoint dp : results[0]) {
+      assertEquals(ts, dp.timestamp());
+      assertTrue(dp.isInteger());
+      assertEquals(v, dp.longValue());
+      ts += INTERVAL;
+      v += 1;
+    }
+    ts = START_TIME;
+    v = 10;
+    for (DataPoint dp : results[1]) {
+      assertEquals(ts, dp.timestamp());
+      assertTrue(dp.isInteger());
+      assertEquals(v, dp.longValue());
+      ts += INTERVAL;
+      v += 1;
+    }
+  }
+  
+  @Test
+  public void evaluateWithTags() throws Exception {
+    SeekableView view2 = SeekableViewsForTest.generator(START_TIME, INTERVAL, 
+        NUM_POINTS, true, 10, 1);
+    DataPoints dps2 = PowerMockito.mock(DataPoints.class);
+    when(dps2.iterator()).thenReturn(view2);
+    when(dps2.metricName()).thenReturn("sys.mem");
+    when(dps2.getTagsAsync()).thenReturn(Deferred.fromResult(tags));
+    when(dps2.getTagUids()).thenReturn(tag_uids);
+    group_bys = new DataPoints[] { dps, dps2 };
+    query_results.clear();
+    query_results.add(group_bys);
+    params.add("My Alias.@host.@dc");
+    
+    final DataPoints[] results = func.evaluate(data_query, query_results, params);
+    
+    assertEquals(2, results.length);
+    assertEquals("My Alias.web01.lga", results[0].metricName());
+    assertEquals("My Alias.web01.lga", results[1].metricName());
+  }
+  
+  @Test
+  public void evaluateWithATag() throws Exception {
+    SeekableView view2 = SeekableViewsForTest.generator(START_TIME, INTERVAL, 
+        NUM_POINTS, true, 10, 1);
+    DataPoints dps2 = PowerMockito.mock(DataPoints.class);
+    when(dps2.iterator()).thenReturn(view2);
+    when(dps2.metricName()).thenReturn("sys.mem");
+    when(dps2.getTagsAsync()).thenReturn(Deferred.fromResult(tags));
+    when(dps2.getTagUids()).thenReturn(tag_uids);
+    group_bys = new DataPoints[] { dps, dps2 };
+    query_results.clear();
+    query_results.add(group_bys);
+    params.add("My Alias.@dc");
+    
+    final DataPoints[] results = func.evaluate(data_query, query_results, params);
+    
+    assertEquals(2, results.length);
+    assertEquals("My Alias.lga", results[0].metricName());
+    assertEquals("My Alias.lga", results[1].metricName());
+  }
+  
+  @Test
+  public void evaluateWithTagsJoined() throws Exception {
+    SeekableView view2 = SeekableViewsForTest.generator(START_TIME, INTERVAL, 
+        NUM_POINTS, true, 10, 1);
+    DataPoints dps2 = PowerMockito.mock(DataPoints.class);
+    when(dps2.iterator()).thenReturn(view2);
+    when(dps2.metricName()).thenReturn("sys.mem");
+    when(dps2.getTagsAsync()).thenReturn(Deferred.fromResult(tags));
+    when(dps2.getTagUids()).thenReturn(tag_uids);
+    group_bys = new DataPoints[] { dps, dps2 };
+    query_results.clear();
+    query_results.add(group_bys);
+    params.add("My Alias");
+    params.add("@host");
+    params.add("@dc");
+    params.add("@none");
+    
+    final DataPoints[] results = func.evaluate(data_query, query_results, params);
+    
+    assertEquals(2, results.length);
+    assertEquals("My Alias,web01,lga,@none", results[0].metricName());
+    assertEquals("My Alias,web01,lga,@none", results[1].metricName());
+  }
+  
+  @Test (expected = IllegalArgumentException.class)
+  public void evaluateNullQuery() throws Exception {
+    params.add("1");
+    func.evaluate(null, query_results, params);
+  }
+  
+  @Test
+  public void evaluateNullResults() throws Exception {
+    params.add("1");
+    final DataPoints[] results = func.evaluate(data_query, null, params);
+    assertEquals(0, results.length);
+  }
+  
+  @Test (expected = IllegalArgumentException.class)
+  public void evaluateNullParams() throws Exception {
+    func.evaluate(data_query, query_results, null);
+  }
+
+  @Test
+  public void evaluateEmptyResults() throws Exception {
+    final DataPoints[] results = func.evaluate(data_query, 
+        Collections.<DataPoints[]>emptyList(), params);
+    assertEquals(0, results.length);
+  }
+  
+  @Test (expected = IllegalArgumentException.class)
+  public void evaluateEmptyParams() throws Exception {
+    func.evaluate(data_query, query_results, null);
+  }
+  
+  @Test
+  public void writeStringField() throws Exception {
+    assertEquals("alias(m)", func.writeStringField(params, "m"));
+    params.add("MyAlias");
+    assertEquals("alias(m,MyAlias)", func.writeStringField(params, "m"));
+    params.clear();
+    params.add("Alias");
+    params.add("@host");
+    assertEquals("alias(m,Alias,@host)", func.writeStringField(params, "m"));
+    params.clear();
+    assertEquals("alias(null)", func.writeStringField(params, null));
+    assertEquals("alias()", func.writeStringField(params, ""));
+    assertEquals("alias(inner_expression)", 
+        func.writeStringField(null, "inner_expression"));
+  }
+}
diff --git a/test/query/expression/TestDiffSeries.java b/test/query/expression/TestDiffSeries.java
new file mode 100644
index 0000000000..3c36e234c1
--- /dev/null
+++ b/test/query/expression/TestDiffSeries.java
@@ -0,0 +1,192 @@
+// This file is part of OpenTSDB.
+// Copyright (C) 2015  The OpenTSDB Authors.
+//
+// This program is free software: you can redistribute it and/or modify it
+// under the terms of the GNU Lesser General Public License as published by
+// the Free Software Foundation, either version 2.1 of the License, or (at your
+// option) any later version.  This program is distributed in the hope that it
+// will be useful, but WITHOUT ANY WARRANTY; without even the implied warranty
+// of MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser
+// General Public License for more details.  You should have received a copy
+// of the GNU Lesser General Public License along with this program.  If not,
+// see <http://www.gnu.org/licenses/>.
+package net.opentsdb.query.expression;
+
+import static org.junit.Assert.assertEquals;
+import static org.mockito.Mockito.mock;
+import static org.mockito.Mockito.when;
+
+import java.util.ArrayList;
+import java.util.Collections;
+import java.util.List;
+
+import net.opentsdb.core.DataPoint;
+import net.opentsdb.core.DataPoints;
+import net.opentsdb.core.SeekableView;
+import net.opentsdb.core.SeekableViewsForTest;
+import net.opentsdb.core.TSQuery;
+
+import org.junit.Before;
+import org.junit.Test;
+import org.junit.runner.RunWith;
+import org.powermock.api.mockito.PowerMockito;
+import org.powermock.core.classloader.annotations.PowerMockIgnore;
+import org.powermock.core.classloader.annotations.PrepareForTest;
+import org.powermock.modules.junit4.PowerMockRunner;
+
+import com.sun.java_cup.internal.runtime.Scanner;
+
+@RunWith(PowerMockRunner.class)
+@PowerMockIgnore({"javax.management.*", "javax.xml.*",
+  "ch.qos.*", "org.slf4j.*",
+  "com.sum.*", "org.xml.*"})
+@PrepareForTest({ TSQuery.class, Scanner.class })
+public class TestDiffSeries extends BaseTimeSyncedIteratorTest {
+
+  private static long START_TIME = 1356998400000L;
+  private static int INTERVAL = 60000;
+  private static int NUM_POINTS = 5;
+  
+  private TSQuery data_query;
+  private SeekableView view;
+  private DataPoints dps;
+  private DataPoints[] group_bys;
+  private List<DataPoints[]> query_results;
+  private List<String> params;
+  private DiffSeries func;
+  
+  @Before
+  public void beforeLocal() throws Exception {
+    view = SeekableViewsForTest.generator(START_TIME, INTERVAL, 
+        NUM_POINTS, true, 1, 1);
+    data_query = mock(TSQuery.class);
+    when(data_query.startTime()).thenReturn(START_TIME);
+    when(data_query.endTime()).thenReturn(START_TIME + (INTERVAL * NUM_POINTS));
+    
+    dps = PowerMockito.mock(DataPoints.class);
+    when(dps.iterator()).thenReturn(view);
+    when(dps.metricName()).thenReturn(METRIC_STRING);
+    when(dps.metricUID()).thenReturn(new byte[] {0,0,1});
+    
+    group_bys = new DataPoints[] { dps };
+    
+    query_results = new ArrayList<DataPoints[]>(1);
+    query_results.add(group_bys);
+    
+    params = new ArrayList<String>(1);
+    func = new DiffSeries(tsdb);
+  }
+  
+  @Test
+  public void diffOneSeriesEach() throws Exception {
+    SeekableView view2 = SeekableViewsForTest.generator(START_TIME, INTERVAL, 
+        NUM_POINTS, true, 10, 1);
+    DataPoints dps2 = PowerMockito.mock(DataPoints.class);
+    when(dps2.iterator()).thenReturn(view2);
+    when(dps2.metricName()).thenReturn("sys.mem");
+    when(dps2.metricUID()).thenReturn(new byte[] {0,0,2});
+    group_bys = new DataPoints[] { dps2 };
+    query_results.add(group_bys);
+    
+    final DataPoints[] results = func.evaluate(data_query, query_results, params);
+
+    assertEquals(1, results.length);
+    assertEquals(METRIC_STRING, results[0].metricName());
+    
+    long ts = START_TIME;
+    for (DataPoint dp : results[0]) {
+      assertEquals(ts, dp.timestamp());
+      assertEquals(-9, dp.toDouble(), 0.001);
+      ts += INTERVAL;
+    }
+  }
+  
+  @Test
+  public void diffMultipleSeriesEach() throws Exception {
+    oneExtraSameE();
+    queryAB_Dstar();
+    
+    query_results.clear();
+    query_results.add(results.get("1").getValue());
+    query_results.add(results.get("0").getValue());
+    final DataPoints[] results = func.evaluate(data_query, 
+        query_results, params);
+
+    assertEquals(3, results.length);
+    
+    double val = 17;
+    for (int i = 0; i < results.length; i++) {
+      long ts = 1431561600000l;
+      final SeekableView it = results[i].iterator();
+      while (it.hasNext()) {
+        final DataPoint dp = it.next();
+        assertEquals(ts, dp.timestamp());
+        if (i < 2) {
+          assertEquals(10, dp.toDouble(), 0.0001);
+        } else {
+          assertEquals(val++, dp.toDouble(), 0.0001);
+        }
+        ts += INTERVAL;
+      }
+    }
+  }
+  
+  @Test (expected = IllegalArgumentException.class)
+  public void diffOneResultSet() throws Exception {    
+    func.evaluate(data_query, query_results, params);
+  }
+  
+  @Test (expected = IllegalArgumentException.class)
+  public void diffTooManyResultSets() throws Exception {
+    SeekableView view2 = SeekableViewsForTest.generator(START_TIME, INTERVAL, 
+        NUM_POINTS, true, 10, 1);
+    DataPoints dps2 = PowerMockito.mock(DataPoints.class);
+    when(dps2.iterator()).thenReturn(view2);
+    when(dps2.metricName()).thenReturn("sys.mem");
+    when(dps2.metricUID()).thenReturn(new byte[] {0,0,2});
+    group_bys = new DataPoints[] { dps2 };
+    // doesn't matter what they are
+    for (int i = 0; i < 100; i++) {
+      query_results.add(group_bys);
+    }
+    
+    func.evaluate(data_query, query_results, params);
+  }
+  
+  @Test (expected = IllegalArgumentException.class)
+  public void evaluateNullQuery() throws Exception {
+    params.add("1");
+    func.evaluate(null, query_results, params);
+  }
+  
+  @Test
+  public void evaluateNullResults() throws Exception {
+    params.add("1");
+    final DataPoints[] results = func.evaluate(data_query, null, params);
+    assertEquals(0, results.length);
+  }
+  
+  @Test (expected = IllegalArgumentException.class)
+  public void evaluateNullParams() throws Exception {
+    func.evaluate(data_query, query_results, null);
+  }
+
+  @Test
+  public void evaluateEmptyResults() throws Exception {
+    params.add("1");
+    final DataPoints[] results = func.evaluate(data_query, 
+        Collections.<DataPoints[]>emptyList(), params);
+    assertEquals(0, results.length);
+  }
+  
+  @Test
+  public void writeStringField() throws Exception {
+    params.add("1");
+    assertEquals("diffSeries(inner_expression)", 
+        func.writeStringField(params, "inner_expression"));
+    assertEquals("diffSeries(null)", func.writeStringField(params, null));
+    assertEquals("diffSeries()", func.writeStringField(params, ""));
+    assertEquals("diffSeries(inner_expression)", 
+        func.writeStringField(null, "inner_expression"));
+  }
+}
diff --git a/test/query/expression/TestDivideSeries.java b/test/query/expression/TestDivideSeries.java
new file mode 100644
index 0000000000..e880a6c31e
--- /dev/null
+++ b/test/query/expression/TestDivideSeries.java
@@ -0,0 +1,197 @@
+// This file is part of OpenTSDB.
+// Copyright (C) 2015  The OpenTSDB Authors.
+//
+// This program is free software: you can redistribute it and/or modify it
+// under the terms of the GNU Lesser General Public License as published by
+// the Free Software Foundation, either version 2.1 of the License, or (at your
+// option) any later version.  This program is distributed in the hope that it
+// will be useful, but WITHOUT ANY WARRANTY; without even the implied warranty
+// of MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser
+// General Public License for more details.  You should have received a copy
+// of the GNU Lesser General Public License along with this program.  If not,
+// see <http://www.gnu.org/licenses/>.
+package net.opentsdb.query.expression;
+
+import static org.junit.Assert.assertEquals;
+import static org.mockito.Mockito.mock;
+import static org.mockito.Mockito.when;
+
+import java.util.ArrayList;
+import java.util.Collections;
+import java.util.List;
+
+import net.opentsdb.core.DataPoint;
+import net.opentsdb.core.DataPoints;
+import net.opentsdb.core.SeekableView;
+import net.opentsdb.core.SeekableViewsForTest;
+import net.opentsdb.core.TSQuery;
+
+import org.junit.Before;
+import org.junit.Test;
+import org.junit.runner.RunWith;
+import org.powermock.api.mockito.PowerMockito;
+import org.powermock.core.classloader.annotations.PowerMockIgnore;
+import org.powermock.core.classloader.annotations.PrepareForTest;
+import org.powermock.modules.junit4.PowerMockRunner;
+
+@RunWith(PowerMockRunner.class)
+@PowerMockIgnore({"javax.management.*", "javax.xml.*",
+  "ch.qos.*", "org.slf4j.*",
+  "com.sum.*", "org.xml.*"})
+@PrepareForTest({ TSQuery.class })
+public class TestDivideSeries extends BaseTimeSyncedIteratorTest {
+
+  private static long START_TIME = 1356998400000L;
+  private static int INTERVAL = 60000;
+  private static int NUM_POINTS = 5;
+  
+  private TSQuery data_query;
+  private SeekableView view;
+  private DataPoints dps;
+  private DataPoints[] group_bys;
+  private List<DataPoints[]> query_results;
+  private List<String> params;
+  private DivideSeries func;
+  
+  @Before
+  public void beforeLocal() throws Exception {
+    view = SeekableViewsForTest.generator(START_TIME, INTERVAL, 
+        NUM_POINTS, true, 1, 1);
+    data_query = mock(TSQuery.class);
+    when(data_query.startTime()).thenReturn(START_TIME);
+    when(data_query.endTime()).thenReturn(START_TIME + (INTERVAL * NUM_POINTS));
+    
+    dps = PowerMockito.mock(DataPoints.class);
+    when(dps.iterator()).thenReturn(view);
+    when(dps.metricName()).thenReturn(METRIC_STRING);
+    when(dps.metricUID()).thenReturn(new byte[] {0,0,1});
+    
+    group_bys = new DataPoints[] { dps };
+    
+    query_results = new ArrayList<DataPoints[]>(1);
+    query_results.add(group_bys);
+    
+    params = new ArrayList<String>(1);
+    func = new DivideSeries(tsdb);
+  }
+  
+  @Test
+  public void divideOneSeriesEach() throws Exception {
+    SeekableView view2 = SeekableViewsForTest.generator(START_TIME, INTERVAL, 
+        NUM_POINTS, true, 10, 1);
+    DataPoints dps2 = PowerMockito.mock(DataPoints.class);
+    when(dps2.iterator()).thenReturn(view2);
+    when(dps2.metricName()).thenReturn("sys.mem");
+    when(dps2.metricUID()).thenReturn(new byte[] {0,0,2});
+    group_bys = new DataPoints[] { dps2 };
+    query_results.add(group_bys);
+    
+    final DataPoints[] results = func.evaluate(data_query, query_results, params);
+
+    assertEquals(1, results.length);
+    assertEquals(METRIC_STRING, results[0].metricName());
+    
+    double[] vals= new double[] { 0.1, 0.181, 0.25, 0.307, 0.357 };
+    
+    long ts = START_TIME;
+    int i = 0;
+    for (final DataPoint dp : results[0]) {
+      assertEquals(ts, dp.timestamp());
+      assertEquals(vals[i++], dp.toDouble(), 0.001);
+      ts += INTERVAL;
+    }
+  }
+  
+  @Test
+  public void divideMultipleSeriesEach() throws Exception {
+    oneExtraSameE();
+    queryAB_Dstar();
+    
+    query_results.clear();
+    query_results.add(results.get("1").getValue());
+    query_results.add(results.get("0").getValue());
+    final DataPoints[] results = func.evaluate(data_query, 
+        query_results, params);
+
+    assertEquals(3, results.length);
+    
+    final int vals[][] = new int[2][]; 
+    vals[0] = new int[] { 11, 1 };
+    vals[1] = new int[] { 14, 4 };
+    for (int i = 0; i < results.length; i++) {
+      long ts = 1431561600000l;
+      final SeekableView it = results[i].iterator();
+      while (it.hasNext()) {
+        final DataPoint dp = it.next();
+        assertEquals(ts, dp.timestamp());
+        if (i < 2) {
+          assertEquals(((double)vals[i][0]++ / (double)vals[i][1]++), 
+              dp.toDouble(), 0.001);
+        } else {
+          assertEquals(0, dp.toDouble(), 0.0001);
+        }
+        ts += INTERVAL;
+      }
+    }
+  }
+  
+  @Test (expected = IllegalArgumentException.class)
+  public void divideOneResultSet() throws Exception {    
+    func.evaluate(data_query, query_results, params);
+  }
+  
+  @Test (expected = IllegalArgumentException.class)
+  public void divideTooManyResultSets() throws Exception {
+    SeekableView view2 = SeekableViewsForTest.generator(START_TIME, INTERVAL, 
+        NUM_POINTS, true, 10, 1);
+    DataPoints dps2 = PowerMockito.mock(DataPoints.class);
+    when(dps2.iterator()).thenReturn(view2);
+    when(dps2.metricName()).thenReturn("sys.mem");
+    when(dps2.metricUID()).thenReturn(new byte[] {0,0,2});
+    group_bys = new DataPoints[] { dps2 };
+    query_results.add(group_bys);
+    // doesn't matter what they are
+    for (int i = 0; i < 100; i++) {
+      query_results.add(group_bys);
+    }
+    
+    func.evaluate(data_query, query_results, params);
+  }
+  
+  @Test (expected = IllegalArgumentException.class)
+  public void evaluateNullQuery() throws Exception {
+    params.add("1");
+    func.evaluate(null, query_results, params);
+  }
+  
+  @Test
+  public void evaluateNullResults() throws Exception {
+    params.add("1");
+    final DataPoints[] results = func.evaluate(data_query, null, params);
+    assertEquals(0, results.length);
+  }
+  
+  @Test (expected = IllegalArgumentException.class)
+  public void evaluateNullParams() throws Exception {
+    func.evaluate(data_query, query_results, null);
+  }
+
+  @Test
+  public void evaluateEmptyResults() throws Exception {
+    params.add("1");
+    final DataPoints[] results = func.evaluate(data_query, 
+        Collections.<DataPoints[]>emptyList(), params);
+    assertEquals(0, results.length);
+  }
+    
+  @Test
+  public void writeStringField() throws Exception {
+    params.add("1");
+    assertEquals("divideSeries(inner_expression)", 
+        func.writeStringField(params, "inner_expression"));
+    assertEquals("divideSeries(null)", func.writeStringField(params, null));
+    assertEquals("divideSeries()", func.writeStringField(params, ""));
+    assertEquals("divideSeries(inner_expression)", 
+        func.writeStringField(null, "inner_expression"));
+  }
+}
diff --git a/test/query/expression/TestExpressionFactory.java b/test/query/expression/TestExpressionFactory.java
new file mode 100644
index 0000000000..b0024fa44f
--- /dev/null
+++ b/test/query/expression/TestExpressionFactory.java
@@ -0,0 +1,93 @@
+// This file is part of OpenTSDB.
+// Copyright (C) 2015  The OpenTSDB Authors.
+//
+// This program is free software: you can redistribute it and/or modify it
+// under the terms of the GNU Lesser General Public License as published by
+// the Free Software Foundation, either version 2.1 of the License, or (at your
+// option) any later version.  This program is distributed in the hope that it
+// will be useful, but WITHOUT ANY WARRANTY; without even the implied warranty
+// of MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser
+// General Public License for more details.  You should have received a copy
+// of the GNU Lesser General Public License along with this program.  If not,
+// see <http://www.gnu.org/licenses/>.
+package net.opentsdb.query.expression;
+
+import static org.junit.Assert.assertTrue;
+
+import java.util.List;
+
+import net.opentsdb.core.DataPoints;
+import net.opentsdb.core.TSQuery;
+
+import org.junit.Test;
+import org.junit.runner.RunWith;
+import org.powermock.core.classloader.annotations.PowerMockIgnore;
+import org.powermock.modules.junit4.PowerMockRunner;
+
+@RunWith(PowerMockRunner.class)
+@PowerMockIgnore({"javax.management.*", "javax.xml.*",
+  "ch.qos.*", "org.slf4j.*",
+  "com.sum.*", "org.xml.*"})
+public class TestExpressionFactory {
+
+  @Test
+  public void getByName() throws Exception {
+    // pick a couple of implementations
+    Expression e = ExpressionFactory.getByName("scale");
+    assertTrue(e instanceof Scale);
+    
+    e = ExpressionFactory.getByName("highestMax");
+    assertTrue(e instanceof HighestMax);
+  }
+  
+  @Test (expected = UnsupportedOperationException.class)
+  public void getByNameNoSuchFunction() throws Exception {
+    ExpressionFactory.getByName("I don't exist");
+  }
+  
+  @Test (expected = UnsupportedOperationException.class)
+  public void getByNameNullName() throws Exception {
+    ExpressionFactory.getByName(null);
+  }
+  
+  @Test (expected = UnsupportedOperationException.class)
+  public void getByNameEmptyName() throws Exception {
+    ExpressionFactory.getByName("");
+  }
+  
+  @Test
+  public void addFunction() throws Exception {
+    ExpressionFactory.addFunction("testExpr", new TestExpr());
+    final Expression e = ExpressionFactory.getByName("testExpr");
+    assertTrue(e instanceof TestExpr);
+  }
+  
+  @Test (expected = IllegalArgumentException.class)
+  public void addFunctionNullName() throws Exception {
+    ExpressionFactory.addFunction(null, new TestExpr());
+  }
+  
+  @Test (expected = IllegalArgumentException.class)
+  public void addFunctionEmptyName() throws Exception {
+    ExpressionFactory.addFunction("", new TestExpr());
+  }
+  
+  @Test (expected = IllegalArgumentException.class)
+  public void addFunctionNullFunction() throws Exception {
+    ExpressionFactory.addFunction("testExpr", null);
+  }
+  
+  /** Dummy expression class used for testing */
+  private static class TestExpr implements Expression {
+    @Override
+    public DataPoints[] evaluate(TSQuery data_query,
+        List<DataPoints[]> results, List<String> params) {
+      return null;
+    }
+    @Override
+    public String writeStringField(List<String> params,
+        String inner_expression) {
+      return null;
+    }
+  }
+}
diff --git a/test/query/expression/TestExpressionIterator.java b/test/query/expression/TestExpressionIterator.java
new file mode 100644
index 0000000000..eaaf8ef05f
--- /dev/null
+++ b/test/query/expression/TestExpressionIterator.java
@@ -0,0 +1,1196 @@
+// This file is part of OpenTSDB.
+// Copyright (C) 2015  The OpenTSDB Authors.
+//
+// This program is free software: you can redistribute it and/or modify it
+// under the terms of the GNU Lesser General Public License as published by
+// the Free Software Foundation, either version 2.1 of the License, or (at your
+// option) any later version.  This program is distributed in the hope that it
+// will be useful, but WITHOUT ANY WARRANTY; without even the implied warranty
+// of MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser
+// General Public License for more details.  You should have received a copy
+// of the GNU Lesser General Public License along with this program.  If not,
+// see <http://www.gnu.org/licenses/>.
+package net.opentsdb.query.expression;
+
+import static org.junit.Assert.assertArrayEquals;
+import static org.junit.Assert.assertEquals;
+import static org.junit.Assert.assertFalse;
+import static org.junit.Assert.assertNull;
+import static org.junit.Assert.assertTrue;
+import static org.junit.Assert.fail;
+import net.opentsdb.core.FillPolicy;
+import net.opentsdb.core.IllegalDataException;
+import net.opentsdb.query.expression.VariableIterator.SetOperator;
+
+import org.apache.commons.jexl2.JexlException;
+import org.hbase.async.Bytes;
+import org.junit.Test;
+
+public class TestExpressionIterator extends BaseTimeSyncedIteratorTest {
+
+  @Test
+  public void ctor() throws Exception {
+    final ExpressionIterator exp = new ExpressionIterator("ei", "a + b", 
+        SetOperator.INTERSECTION, false, false);
+    assertEquals(2, exp.getVariableNames().size());
+    assertTrue(exp.getVariableNames().contains("a"));
+    assertTrue(exp.getVariableNames().contains("b"));
+    assertFalse(exp.getVariableNames().contains("+")); // I'm not a variable :(
+    assertNull(exp.values());
+  }
+  
+  @Test (expected = IllegalArgumentException.class)
+  public void ctorNoVariables() throws Exception {
+    new ExpressionIterator("ei", "1 + 1", SetOperator.INTERSECTION, false, false);
+  }
+  
+  @Test (expected = IllegalArgumentException.class)
+  public void ctorNullExpression() throws Exception {
+    new ExpressionIterator("ei", null, SetOperator.INTERSECTION, false, false);
+  }
+  
+  @Test (expected = JexlException.class)
+  public void ctorBadExpression() throws Exception {
+    new ExpressionIterator("ei", " a / ", SetOperator.INTERSECTION, false, false);
+  }
+  
+  @Test (expected = IllegalArgumentException.class)
+  public void ctorEmptyExpression() throws Exception {
+    new ExpressionIterator("ei", "", SetOperator.INTERSECTION, false, false);
+  }
+
+  @Test (expected = IllegalArgumentException.class)
+  public void ctorNullOperator() throws Exception {
+    new ExpressionIterator("ei", "a + b", null, false, false);
+  }
+  
+  @Test
+  public void aPlusBWithTwoSeries() throws Exception {
+    oneExtraSameE();
+    queryAB_Dstar();
+    remapResults();
+    
+    ExpressionIterator exp = new ExpressionIterator("ei", "a + b", 
+        SetOperator.INTERSECTION, false, false);
+    exp.addResults("a", iterators.get("a"));
+    exp.addResults("b", iterators.get("b"));
+    
+    exp.compile();
+    final ExpressionDataPoint[] dps = exp.values();
+    assertEquals(2, dps.length);
+    validateMeta(dps, true);
+    
+    long ts = 1431561600000L;
+    double[] values = new double[] { 12, 18 };
+    long its = exp.nextTimestamp();
+    while (exp.hasNext()) {
+      exp.next(its);
+      
+      assertEquals(ts, dps[0].timestamp());
+      assertEquals(ts, dps[1].timestamp());
+      assertEquals(values[0], dps[0].toDouble(), 0.0001);
+      assertEquals(values[1], dps[1].toDouble(), 0.0001);
+      
+      values[0] += 2;
+      values[1] += 2;
+      ts += 60000;
+      its = exp.nextTimestamp();
+    }
+    
+    for (int i = 0; i < dps.length; i++) {
+      assertEquals(2, dps[i].tags().size());
+      assertTrue(dps[i].aggregatedTags().isEmpty());
+    }
+    assertArrayEquals(TAGV_UIDS.get("D"), dps[0].tags().get(TAGV_UIDS.get("D")));
+    assertArrayEquals(TAGV_UIDS.get("F"), dps[1].tags().get(TAGV_UIDS.get("D")));
+  }
+  
+  @Test
+  public void aMinusBWithTwoSeries() throws Exception {
+    oneExtraSameE();
+    queryAB_Dstar();
+    remapResults();
+    
+    ExpressionIterator exp = new ExpressionIterator("ei", "a - b", 
+        SetOperator.INTERSECTION, false, false);
+    exp.addResults("a", iterators.get("a"));
+    exp.addResults("b", iterators.get("b"));
+    
+    exp.compile();
+    final ExpressionDataPoint[] dps = exp.values();
+    assertEquals(2, dps.length);
+    validateMeta(dps, true);
+    
+    long ts = 1431561600000L;
+    long its = exp.nextTimestamp();
+    while (exp.hasNext()) {
+      exp.next(its);
+      
+      assertEquals(ts, dps[0].timestamp());
+      assertEquals(ts, dps[1].timestamp());
+      assertEquals(-10, dps[0].toDouble(), 0.0001);
+      assertEquals(-10, dps[1].toDouble(), 0.0001);
+      ts += 60000;
+      its = exp.nextTimestamp();
+    }
+    
+    for (int i = 0; i < dps.length; i++) {
+      assertEquals(2, dps[i].tags().size());
+      assertTrue(dps[i].aggregatedTags().isEmpty());
+    }
+    assertArrayEquals(TAGV_UIDS.get("D"), dps[0].tags().get(TAGV_UIDS.get("D")));
+    assertArrayEquals(TAGV_UIDS.get("F"), dps[1].tags().get(TAGV_UIDS.get("D")));
+  }
+  
+  @Test
+  public void aTimesBWithTwoSeries() throws Exception {
+    oneExtraSameE();
+    queryAB_Dstar();
+    remapResults();
+    
+    ExpressionIterator exp = new ExpressionIterator("ei", "a * b", 
+        SetOperator.INTERSECTION, false, false);
+    exp.addResults("a", iterators.get("a"));
+    exp.addResults("b", iterators.get("b"));
+    
+    exp.compile();
+    final ExpressionDataPoint[] dps = exp.values();
+    assertEquals(2, dps.length);
+    validateMeta(dps, true);
+    
+    long ts = 1431561600000L;
+    long its = exp.nextTimestamp();
+    exp.next(its);
+    assertEquals(ts, dps[0].timestamp());
+    assertEquals(ts, dps[1].timestamp());
+    assertEquals(11, dps[0].toDouble(), 0.0001);
+    assertEquals(56, dps[1].toDouble(), 0.0001);
+    ts += 60000;
+    
+    its = exp.nextTimestamp();
+    exp.next(its);
+    assertEquals(ts, dps[0].timestamp());
+    assertEquals(ts, dps[1].timestamp());
+    assertEquals(24, dps[0].toDouble(), 0.0001);
+    assertEquals(75, dps[1].toDouble(), 0.0001);
+    ts += 60000;
+    
+    its = exp.nextTimestamp();
+    exp.next(its);
+    assertEquals(ts, dps[0].timestamp());
+    assertEquals(ts, dps[1].timestamp());
+    assertEquals(39, dps[0].toDouble(), 0.0001);
+    assertEquals(96, dps[1].toDouble(), 0.0001);
+    
+    assertFalse(exp.hasNext());
+    
+    for (int i = 0; i < dps.length; i++) {
+      assertEquals(2, dps[i].tags().size());
+      assertTrue(dps[i].aggregatedTags().isEmpty());
+    }
+    assertArrayEquals(TAGV_UIDS.get("D"), dps[0].tags().get(TAGV_UIDS.get("D")));
+    assertArrayEquals(TAGV_UIDS.get("F"), dps[1].tags().get(TAGV_UIDS.get("D")));
+  }
+  
+  @Test
+  public void aDivideBWithTwoSeries() throws Exception {
+    oneExtraSameE();
+    queryAB_Dstar();
+    remapResults();
+    
+    ExpressionIterator exp = new ExpressionIterator("ei", "a / b", 
+        SetOperator.INTERSECTION, false, false);
+    exp.addResults("a", iterators.get("a"));
+    exp.addResults("b", iterators.get("b"));
+    
+    exp.compile();
+    final ExpressionDataPoint[] dps = exp.values();
+    assertEquals(2, dps.length);
+    validateMeta(dps, true);
+    
+    long ts = 1431561600000L;
+    long its = exp.nextTimestamp();
+    exp.next(its);
+    assertEquals(ts, dps[0].timestamp());
+    assertEquals(ts, dps[1].timestamp());
+    assertEquals(0.0909, dps[0].toDouble(), 0.0001);
+    assertEquals(0.2857, dps[1].toDouble(), 0.0001);
+    ts += 60000;
+    
+    its = exp.nextTimestamp();
+    exp.next(its);
+    assertEquals(ts, dps[0].timestamp());
+    assertEquals(ts, dps[1].timestamp());
+    assertEquals(0.1666, dps[0].toDouble(), 0.0001);
+    assertEquals(0.3333, dps[1].toDouble(), 0.0001);
+    ts += 60000;
+    
+    its = exp.nextTimestamp();
+    exp.next(its);
+    assertEquals(ts, dps[0].timestamp());
+    assertEquals(ts, dps[1].timestamp());
+    assertEquals(0.2307, dps[0].toDouble(), 0.0001);
+    assertEquals(0.375, dps[1].toDouble(), 0.0001);
+    
+    assertFalse(exp.hasNext());
+    
+    for (int i = 0; i < dps.length; i++) {
+      assertEquals(2, dps[i].tags().size());
+      assertTrue(dps[i].aggregatedTags().isEmpty());
+    }
+    assertArrayEquals(TAGV_UIDS.get("D"), dps[0].tags().get(TAGV_UIDS.get("D")));
+    assertArrayEquals(TAGV_UIDS.get("F"), dps[1].tags().get(TAGV_UIDS.get("D")));
+  }
+  
+  @Test
+  public void aModBWithTwoSeries() throws Exception {
+    oneExtraSameE();
+    queryAB_Dstar();
+    remapResults();
+    
+    ExpressionIterator exp = new ExpressionIterator("ei", "a % b", 
+        SetOperator.INTERSECTION, false, false);
+    exp.addResults("a", iterators.get("a"));
+    exp.addResults("b", iterators.get("b"));
+    
+    exp.compile();
+    final ExpressionDataPoint[] dps = exp.values();
+    assertEquals(2, dps.length);
+    validateMeta(dps, true);
+    
+    long ts = 1431561600000L;
+    long its = exp.nextTimestamp();
+    double[] values = new double[] { 1, 4 };
+    while (exp.hasNext()) {
+      exp.next(its);
+      
+      assertEquals(ts, dps[0].timestamp());
+      assertEquals(ts, dps[1].timestamp());
+      assertEquals(values[0]++, dps[0].toDouble(), 0.0001);
+      assertEquals(values[1]++, dps[1].toDouble(), 0.0001);
+      ts += 60000;
+      its = exp.nextTimestamp();
+    }
+    
+    for (int i = 0; i < dps.length; i++) {
+      assertEquals(2, dps[i].tags().size());
+      assertTrue(dps[i].aggregatedTags().isEmpty());
+    }
+    assertArrayEquals(TAGV_UIDS.get("D"), dps[0].tags().get(TAGV_UIDS.get("D")));
+    assertArrayEquals(TAGV_UIDS.get("F"), dps[1].tags().get(TAGV_UIDS.get("D")));
+  }
+  
+  @Test
+  public void aDivideByZeroWithTwoSeries() throws Exception {
+    oneExtraSameE();
+    queryAB_Dstar();
+    remapResults();
+  
+    // Jexl apparently happily allows this, just emits a zero
+    ExpressionIterator exp = new ExpressionIterator("ei", "a / 0", 
+        SetOperator.INTERSECTION, false, false);
+    exp.addResults("a", iterators.get("a"));
+    exp.addResults("b", iterators.get("b"));
+    
+    exp.compile();
+    final ExpressionDataPoint[] dps = exp.values();
+    assertEquals(2, dps.length);
+    validateMeta(dps, true);
+    
+    long ts = 1431561600000L;
+    long its = exp.nextTimestamp();
+    while (exp.hasNext()) {
+      exp.next(its);
+      
+      assertEquals(ts, dps[0].timestamp());
+      assertEquals(ts, dps[1].timestamp());
+      assertEquals(0, dps[0].toDouble(), 0.0001);
+      assertEquals(0, dps[1].toDouble(), 0.0001);
+      ts += 60000;
+      its = exp.nextTimestamp();
+    }
+    
+    for (int i = 0; i < dps.length; i++) {
+      assertEquals(2, dps[i].tags().size());
+      assertTrue(dps[i].aggregatedTags().isEmpty());
+    }
+    assertArrayEquals(TAGV_UIDS.get("D"), dps[0].tags().get(TAGV_UIDS.get("D")));
+    assertArrayEquals(TAGV_UIDS.get("F"), dps[1].tags().get(TAGV_UIDS.get("D")));
+  }
+  
+  @Test
+  public void doubleVariableAndPrecedence() throws Exception {
+    oneExtraSameE();
+    queryAB_Dstar();
+    remapResults();
+    
+    ExpressionIterator exp = new ExpressionIterator("ei", "a + (b * b)", 
+        SetOperator.INTERSECTION, false, false);
+    exp.addResults("a", iterators.get("a"));
+    exp.addResults("b", iterators.get("b"));
+    
+    exp.compile();
+    final ExpressionDataPoint[] dps = exp.values();
+    assertEquals(2, dps.length);
+    validateMeta(dps, true);
+    
+    long ts = 1431561600000L;
+    long its = exp.nextTimestamp();
+    exp.next(its);
+    assertEquals(ts, dps[0].timestamp());
+    assertEquals(ts, dps[1].timestamp());
+    assertEquals(122, dps[0].toDouble(), 0.0001);
+    assertEquals(200, dps[1].toDouble(), 0.0001);
+    ts += 60000;
+    
+    its = exp.nextTimestamp();
+    exp.next(its);
+    assertEquals(ts, dps[0].timestamp());
+    assertEquals(ts, dps[1].timestamp());
+    assertEquals(146, dps[0].toDouble(), 0.0001);
+    assertEquals(230, dps[1].toDouble(), 0.0001);
+    ts += 60000;
+    
+    its = exp.nextTimestamp();
+    exp.next(its);
+    assertEquals(ts, dps[0].timestamp());
+    assertEquals(ts, dps[1].timestamp());
+    assertEquals(172, dps[0].toDouble(), 0.0001);
+    assertEquals(262, dps[1].toDouble(), 0.0001);
+    
+    assertFalse(exp.hasNext());
+    
+    for (int i = 0; i < dps.length; i++) {
+      assertEquals(2, dps[i].tags().size());
+      assertTrue(dps[i].aggregatedTags().isEmpty());
+    }
+    assertArrayEquals(TAGV_UIDS.get("D"), dps[0].tags().get(TAGV_UIDS.get("D")));
+    assertArrayEquals(TAGV_UIDS.get("F"), dps[1].tags().get(TAGV_UIDS.get("D")));
+  }
+  
+  @Test
+  public void doubleVariableAndPrecedenceChanged() throws Exception {
+    oneExtraSameE();
+    queryAB_Dstar();
+    remapResults();
+    
+    ExpressionIterator exp = new ExpressionIterator("ei", "(a + b) * b", 
+        SetOperator.INTERSECTION, false, false);
+    exp.addResults("a", iterators.get("a"));
+    exp.addResults("b", iterators.get("b"));
+    
+    exp.compile();
+    final ExpressionDataPoint[] dps = exp.values();
+    assertEquals(2, dps.length);
+    validateMeta(dps, true);
+    
+    long ts = 1431561600000L;
+    long its = exp.nextTimestamp();
+    exp.next(its);
+    assertEquals(ts, dps[0].timestamp());
+    assertEquals(ts, dps[1].timestamp());
+    assertEquals(132, dps[0].toDouble(), 0.0001);
+    assertEquals(252, dps[1].toDouble(), 0.0001);
+    ts += 60000;
+    
+    its = exp.nextTimestamp();
+    exp.next(its);
+    assertEquals(ts, dps[0].timestamp());
+    assertEquals(ts, dps[1].timestamp());
+    assertEquals(168, dps[0].toDouble(), 0.0001);
+    assertEquals(300, dps[1].toDouble(), 0.0001);
+    ts += 60000;
+    
+    its = exp.nextTimestamp();
+    exp.next(its);
+    assertEquals(ts, dps[0].timestamp());
+    assertEquals(ts, dps[1].timestamp());
+    assertEquals(208, dps[0].toDouble(), 0.0001);
+    assertEquals(352, dps[1].toDouble(), 0.0001);
+    
+    assertFalse(exp.hasNext());
+    
+    for (int i = 0; i < dps.length; i++) {
+      assertEquals(2, dps[i].tags().size());
+      assertTrue(dps[i].aggregatedTags().isEmpty());
+    }
+    assertArrayEquals(TAGV_UIDS.get("D"), dps[0].tags().get(TAGV_UIDS.get("D")));
+    assertArrayEquals(TAGV_UIDS.get("F"), dps[1].tags().get(TAGV_UIDS.get("D")));
+  }
+
+  @Test
+  public void aPlusScalarDropB() throws Exception {
+    oneExtraSameE();
+    queryAB_Dstar();
+    remapResults();
+    
+    ExpressionIterator exp = new ExpressionIterator("ei", "a + 1", 
+        SetOperator.INTERSECTION, false, false);
+    exp.addResults("a", iterators.get("a"));
+    exp.addResults("b", iterators.get("b"));
+    
+    exp.compile();
+    final ExpressionDataPoint[] dps = exp.values();
+    assertEquals(2, dps.length);
+    validateMeta(dps, true);
+    
+    long ts = 1431561600000L;
+    double[] values = new double[] { 2, 5 };
+    long its = exp.nextTimestamp();
+    while (exp.hasNext()) {
+      exp.next(its);
+      
+      assertEquals(ts, dps[0].timestamp());
+      assertEquals(ts, dps[1].timestamp());
+      assertEquals(values[0]++, dps[0].toDouble(), 0.0001);
+      assertEquals(values[1]++, dps[1].toDouble(), 0.0001);
+      ts += 60000;
+      its = exp.nextTimestamp();
+    }
+    
+    for (int i = 0; i < dps.length; i++) {
+      assertEquals(2, dps[i].tags().size());
+      assertTrue(dps[i].aggregatedTags().isEmpty());
+    }
+    assertArrayEquals(TAGV_UIDS.get("D"), dps[0].tags().get(TAGV_UIDS.get("D")));
+    assertArrayEquals(TAGV_UIDS.get("F"), dps[1].tags().get(TAGV_UIDS.get("D")));
+  }
+  
+  @Test (expected = IllegalArgumentException.class)
+  public void missingRequiredVariable() throws Exception {
+    oneExtraSameE();
+    queryAB_Dstar();
+    remapResults();
+    
+    ExpressionIterator exp = new ExpressionIterator("ei", "a + b + c", 
+        SetOperator.INTERSECTION, false, false);
+    exp.addResults("a", iterators.get("a"));
+    exp.addResults("b", iterators.get("b"));
+    
+    exp.compile();
+  }
+  
+  @Test
+  public void aPlusBMissingPointsDefaultFillZero() throws Exception {
+    threeSameEGaps();
+    queryAB_Dstar();
+    remapResults();
+    
+    ExpressionIterator exp = new ExpressionIterator("ei", "a + b", 
+        SetOperator.INTERSECTION, false, false);
+    exp.addResults("a", iterators.get("a"));
+    exp.addResults("b", iterators.get("b"));
+    
+    exp.compile();
+    final ExpressionDataPoint[] dps = exp.values();
+    assertEquals(3, dps.length);
+    validateMeta(dps, true);
+    
+    long ts = 1431561600000L;
+    long its = exp.nextTimestamp();
+    exp.next(its);
+    assertEquals(ts, dps[0].timestamp());
+    assertEquals(ts, dps[1].timestamp());
+    assertEquals(ts, dps[2].timestamp());
+    assertEquals(1, dps[0].toDouble(), 0.0001);
+    assertEquals(4, dps[1].toDouble(), 0.0001);
+    assertEquals(0, dps[2].toDouble(), 0.0001);
+    ts += 60000;
+    
+    its = exp.nextTimestamp();
+    exp.next(its);
+    assertEquals(ts, dps[0].timestamp());
+    assertEquals(ts, dps[1].timestamp());
+    assertEquals(ts, dps[2].timestamp());
+    assertEquals(0, dps[0].toDouble(), 0.0001);
+    assertEquals(20, dps[1].toDouble(), 0.0001);
+    assertEquals(8, dps[2].toDouble(), 0.0001);
+    ts += 60000;
+    
+    its = exp.nextTimestamp();
+    exp.next(its);
+    assertEquals(ts, dps[0].timestamp());
+    assertEquals(ts, dps[1].timestamp());
+    assertEquals(ts, dps[2].timestamp());
+    assertEquals(16, dps[0].toDouble(), 0.0001);
+    assertEquals(0, dps[1].toDouble(), 0.0001);
+    assertEquals(28, dps[2].toDouble(), 0.0001);
+    
+    assertFalse(exp.hasNext());
+    
+    for (int i = 0; i < dps.length; i++) {
+      assertEquals(2, dps[i].tags().size());
+      assertTrue(dps[i].aggregatedTags().isEmpty());
+    }
+    assertArrayEquals(TAGV_UIDS.get("D"), dps[0].tags().get(TAGV_UIDS.get("D")));
+    assertArrayEquals(TAGV_UIDS.get("F"), dps[1].tags().get(TAGV_UIDS.get("D")));
+    assertArrayEquals(TAGV_UIDS.get("G"), dps[2].tags().get(TAGV_UIDS.get("D")));
+  }
+  
+  @Test
+  public void aPlusBMissingPointsFillOne() throws Exception {
+    threeSameEGaps();
+    queryAB_Dstar();
+    remapResults();
+    
+    ExpressionIterator exp = new ExpressionIterator("ei", "a + b", 
+        SetOperator.INTERSECTION, false, false);
+    exp.addResults("a", iterators.get("a"));
+    exp.addResults("b", iterators.get("b"));
+    iterators.get("a").setFillPolicy(new NumericFillPolicy(FillPolicy.SCALAR, 1));
+    iterators.get("b").setFillPolicy(new NumericFillPolicy(FillPolicy.SCALAR, 1));
+    
+    exp.compile();
+    final ExpressionDataPoint[] dps = exp.values();
+    assertEquals(3, dps.length);
+    validateMeta(dps, true);
+    
+    long ts = 1431561600000L;
+    long its = exp.nextTimestamp();
+    exp.next(its);
+    assertEquals(ts, dps[0].timestamp());
+    assertEquals(ts, dps[1].timestamp());
+    assertEquals(ts, dps[2].timestamp());
+    assertEquals(2, dps[0].toDouble(), 0.0001);
+    assertEquals(5, dps[1].toDouble(), 0.0001);
+    assertEquals(2, dps[2].toDouble(), 0.0001);
+    ts += 60000;
+    
+    its = exp.nextTimestamp();
+    exp.next(its);
+    assertEquals(ts, dps[0].timestamp());
+    assertEquals(ts, dps[1].timestamp());
+    assertEquals(ts, dps[2].timestamp());
+    assertEquals(2, dps[0].toDouble(), 0.0001);
+    assertEquals(20, dps[1].toDouble(), 0.0001);
+    assertEquals(9, dps[2].toDouble(), 0.0001);
+    ts += 60000;
+    
+    its = exp.nextTimestamp();
+    exp.next(its);
+    assertEquals(ts, dps[0].timestamp());
+    assertEquals(ts, dps[1].timestamp());
+    assertEquals(ts, dps[2].timestamp());
+    assertEquals(16, dps[0].toDouble(), 0.0001);
+    assertEquals(2, dps[1].toDouble(), 0.0001);
+    assertEquals(28, dps[2].toDouble(), 0.0001);
+    
+    assertFalse(exp.hasNext());
+    
+    for (int i = 0; i < dps.length; i++) {
+      assertEquals(2, dps[i].tags().size());
+      assertTrue(dps[i].aggregatedTags().isEmpty());
+    }
+    assertArrayEquals(TAGV_UIDS.get("D"), dps[0].tags().get(TAGV_UIDS.get("D")));
+    assertArrayEquals(TAGV_UIDS.get("F"), dps[1].tags().get(TAGV_UIDS.get("D")));
+    assertArrayEquals(TAGV_UIDS.get("G"), dps[2].tags().get(TAGV_UIDS.get("D")));
+  }
+  
+  @Test
+  public void aPlusBMissingPointsFillInfectiousNaN() throws Exception {
+    threeSameEGaps();
+    queryAB_Dstar();
+    remapResults();
+    
+    ExpressionIterator exp = new ExpressionIterator("ei", "a + b", 
+        SetOperator.INTERSECTION, false, false);
+    exp.addResults("a", iterators.get("a"));
+    exp.addResults("b", iterators.get("b"));
+    iterators.get("a").setFillPolicy(
+        new NumericFillPolicy(FillPolicy.NOT_A_NUMBER, Double.NaN));
+    iterators.get("b").setFillPolicy(
+        new NumericFillPolicy(FillPolicy.NOT_A_NUMBER, Double.NaN));
+    
+    exp.compile();
+    final ExpressionDataPoint[] dps = exp.values();
+    assertEquals(3, dps.length);
+    validateMeta(dps, true);
+    
+    long ts = 1431561600000L;
+    long its = exp.nextTimestamp();
+    exp.next(its);
+    assertEquals(ts, dps[0].timestamp());
+    assertEquals(ts, dps[1].timestamp());
+    assertEquals(ts, dps[2].timestamp());
+    assertTrue(Double.isNaN(dps[0].toDouble()));
+    assertTrue(Double.isNaN(dps[1].toDouble()));
+    assertTrue(Double.isNaN(dps[2].toDouble()));
+    ts += 60000;
+    
+    its = exp.nextTimestamp();
+    exp.next(its);
+    assertEquals(ts, dps[0].timestamp());
+    assertEquals(ts, dps[1].timestamp());
+    assertEquals(ts, dps[2].timestamp());
+    assertTrue(Double.isNaN(dps[0].toDouble()));
+    assertEquals(20, dps[1].toDouble(), 0.0001);
+    assertTrue(Double.isNaN(dps[2].toDouble()));
+    ts += 60000;
+    
+    its = exp.nextTimestamp();
+    exp.next(its);
+    assertEquals(ts, dps[0].timestamp());
+    assertEquals(ts, dps[1].timestamp());
+    assertEquals(ts, dps[2].timestamp());
+    assertEquals(16, dps[0].toDouble(), 0.0001);
+    assertTrue(Double.isNaN(dps[1].toDouble()));
+    assertEquals(28, dps[2].toDouble(), 0.0001);
+    
+    assertFalse(exp.hasNext());
+    
+    for (int i = 0; i < dps.length; i++) {
+      assertEquals(2, dps[i].tags().size());
+      assertTrue(dps[i].aggregatedTags().isEmpty());
+    }
+    assertArrayEquals(TAGV_UIDS.get("D"), dps[0].tags().get(TAGV_UIDS.get("D")));
+    assertArrayEquals(TAGV_UIDS.get("F"), dps[1].tags().get(TAGV_UIDS.get("D")));
+    assertArrayEquals(TAGV_UIDS.get("G"), dps[2].tags().get(TAGV_UIDS.get("D")));
+  }
+  
+  @Test
+  public void aPlusBResultsOffsetDefaultFill() throws Exception {
+    timeOffset();
+    queryAB_Dstar();
+    remapResults();
+    
+    ExpressionIterator exp = new ExpressionIterator("ei", "a + b", 
+        SetOperator.INTERSECTION, false, false);
+    exp.addResults("a", iterators.get("a"));
+    exp.addResults("b", iterators.get("b"));
+    
+    exp.compile();
+    final ExpressionDataPoint[] dps = exp.values();
+    assertEquals(2, dps.length);
+    validateMeta(dps, true);
+    
+    long ts = 1431561600000L;
+    long its = exp.nextTimestamp();
+    exp.next(its);
+    assertEquals(ts, dps[0].timestamp());
+    assertEquals(ts, dps[1].timestamp());
+    assertEquals(1, dps[0].toDouble(), 0.0001);
+    assertEquals(4, dps[1].toDouble(), 0.0001);
+    ts += 60000;
+    
+    its = exp.nextTimestamp();
+    exp.next(its);
+    assertEquals(ts, dps[0].timestamp());
+    assertEquals(ts, dps[1].timestamp());
+    assertEquals(2, dps[0].toDouble(), 0.0001);
+    assertEquals(5, dps[1].toDouble(), 0.0001);
+    ts += 60000;
+    
+    its = exp.nextTimestamp();
+    exp.next(its);
+    assertEquals(ts, dps[0].timestamp());
+    assertEquals(ts, dps[1].timestamp());
+    assertEquals(13, dps[0].toDouble(), 0.0001);
+    assertEquals(16, dps[1].toDouble(), 0.0001);
+    ts += 60000;
+    
+    its = exp.nextTimestamp();
+    exp.next(its);
+    assertEquals(ts, dps[0].timestamp());
+    assertEquals(ts, dps[1].timestamp());
+    assertEquals(14, dps[0].toDouble(), 0.0001);
+    assertEquals(17, dps[1].toDouble(), 0.0001);
+    
+    assertFalse(exp.hasNext());
+    
+    for (int i = 0; i < dps.length; i++) {
+      assertEquals(2, dps[i].tags().size());
+      assertTrue(dps[i].aggregatedTags().isEmpty());
+    }
+    assertArrayEquals(TAGV_UIDS.get("D"), dps[0].tags().get(TAGV_UIDS.get("D")));
+    assertArrayEquals(TAGV_UIDS.get("F"), dps[1].tags().get(TAGV_UIDS.get("D")));
+  }
+  
+  @Test
+  public void aPlusBOneAggedOneTaggedUseQueryTagsWoutQueryTags() throws Exception {
+    oneAggedTheOtherTagged();
+    queryAB_AggAll();
+    remapResults();
+    
+    ExpressionIterator exp = new ExpressionIterator("ei", "a + b", 
+        SetOperator.INTERSECTION, true, false);
+    exp.addResults("a", iterators.get("a"));
+    exp.addResults("b", iterators.get("b"));
+    
+    exp.compile();
+    final ExpressionDataPoint[] dps = exp.values();
+    assertEquals(1, dps.length);
+    // TODO - fix the TODO in the set operators to join tags
+    //validateMeta(dps, true);
+    
+    long ts = 1431561600000L;
+    double value = 13;
+    long its = exp.nextTimestamp();
+    while (exp.hasNext()) {
+      exp.next(its);
+      
+      assertEquals(ts, dps[0].timestamp());
+      assertEquals(value, dps[0].toDouble(), 0.0001);
+      
+      value += 3;
+      ts += 60000;
+      its = exp.nextTimestamp();
+    }
+
+    // TODO - fix the TODO in the set operators to join tags
+    //assertEquals(0, dps[0].tags().size());
+    assertEquals(2, dps[0].aggregatedTags().size());
+    assertTrue(dps[0].aggregatedTags().contains(TAGV_UIDS.get("D")));
+    assertTrue(dps[0].aggregatedTags().contains(TAGV_UIDS.get("E")));
+    // TODO - make sure the tags are empty once the expression data does it's
+    // thing
+    //assertTrue(dps[0].tags().isEmpty());
+  }
+  
+  @Test
+  public void singleNestedExpression() throws Exception {
+    oneExtraSameE();
+    queryAB_Dstar();
+    remapResults();
+    
+    ExpressionIterator ei = new ExpressionIterator("ei", "a + b", 
+        SetOperator.INTERSECTION, false, false);
+    ei.addResults("a", iterators.get("a"));
+    ei.addResults("b", iterators.get("b"));
+    ei.compile();
+    
+    ExpressionIterator exp = new ExpressionIterator("ei", "x * 2", 
+        SetOperator.INTERSECTION, false, false);
+    exp.addResults("x", ei);
+    
+    exp.compile();
+    final ExpressionDataPoint[] dps = exp.values();
+    assertEquals(2, dps.length);
+    validateMeta(dps, true);
+    
+    long ts = 1431561600000L;
+    double[] values = new double[] { 24, 36 };
+    long its = exp.nextTimestamp();
+    while (exp.hasNext()) {
+      exp.next(its);
+      
+      assertEquals(ts, dps[0].timestamp());
+      assertEquals(ts, dps[1].timestamp());
+      assertEquals(values[0], dps[0].toDouble(), 0.0001);
+      assertEquals(values[1], dps[1].toDouble(), 0.0001);
+      
+      values[0] += 4;
+      values[1] += 4;
+      ts += 60000;
+      its = exp.nextTimestamp();
+    }
+    
+    for (int i = 0; i < dps.length; i++) {
+      assertEquals(2, dps[i].tags().size());
+      assertTrue(dps[i].aggregatedTags().isEmpty());
+    }
+    assertArrayEquals(TAGV_UIDS.get("D"), dps[0].tags().get(TAGV_UIDS.get("D")));
+    assertArrayEquals(TAGV_UIDS.get("F"), dps[1].tags().get(TAGV_UIDS.get("D")));
+  }
+  
+  @Test
+  public void doubleNestedExpression() throws Exception {
+    oneExtraSameE();
+    queryAB_Dstar();
+    remapResults();
+    
+    ExpressionIterator e1 = new ExpressionIterator("e1", "a + b", 
+        SetOperator.INTERSECTION, false, false);
+    e1.addResults("a", iterators.get("a"));
+    e1.addResults("b", iterators.get("b"));
+    e1.compile();
+    
+    ExpressionIterator e2 = new ExpressionIterator("e2", "e1 * 2", 
+        SetOperator.INTERSECTION, false, false);
+    e2.addResults("e1", e1);
+    e2.compile();
+    
+    ExpressionIterator e3 = new ExpressionIterator("e3", "e2 * 2", 
+        SetOperator.INTERSECTION, false, false);
+    e3.addResults("e2", e2);
+    
+    e3.compile();
+    final ExpressionDataPoint[] dps = e3.values();
+    assertEquals(2, dps.length);
+    validateMeta(dps, true);
+    
+    long ts = 1431561600000L;
+    double[] values = new double[] { 48, 72 };
+    long its = e3.nextTimestamp();
+    while (e3.hasNext()) {
+      e3.next(its);
+      
+      assertEquals(ts, dps[0].timestamp());
+      assertEquals(ts, dps[1].timestamp());
+      assertEquals(values[0], dps[0].toDouble(), 0.0001);
+      assertEquals(values[1], dps[1].toDouble(), 0.0001);
+      
+      values[0] += 8;
+      values[1] += 8;
+      ts += 60000;
+      its = e3.nextTimestamp();
+    }
+    
+    for (int i = 0; i < dps.length; i++) {
+      assertEquals(2, dps[i].tags().size());
+      assertTrue(dps[i].aggregatedTags().isEmpty());
+    }
+    assertArrayEquals(TAGV_UIDS.get("D"), dps[0].tags().get(TAGV_UIDS.get("D")));
+    assertArrayEquals(TAGV_UIDS.get("F"), dps[1].tags().get(TAGV_UIDS.get("D")));
+  }
+  
+  @Test (expected = IllegalDataException.class)
+  public void noIntersectionFound() throws Exception {
+    threeDifE();
+    queryAB_Dstar();
+    remapResults();
+    
+    ExpressionIterator exp = new ExpressionIterator("ei", "a + b", 
+        SetOperator.INTERSECTION, false, false);
+    exp.addResults("a", iterators.get("a"));
+    exp.addResults("b", iterators.get("b"));
+    
+    exp.compile();
+  }
+  
+  @Test (expected = IllegalArgumentException.class)
+  public void addResultsMissingId() throws Exception {
+    oneExtraSameE();
+    queryAB_Dstar();
+    
+    ExpressionIterator exp = new ExpressionIterator("ei", "a + b + c", 
+        SetOperator.INTERSECTION, false, false);
+    exp.addResults("a", iterators.get("a"));
+  }
+  
+  @Test (expected = IllegalArgumentException.class)
+  public void addResultsMissingSubQuery() throws Exception {
+    oneExtraSameE();
+    queryAB_Dstar();
+    
+    ExpressionIterator exp = new ExpressionIterator("ei", "a + b + c", 
+        SetOperator.INTERSECTION, false, false);
+    exp.addResults("a", iterators.get("a"));
+  }
+  
+  @Test (expected = IllegalArgumentException.class)
+  public void addResultsMissingResults() throws Exception {
+    oneExtraSameE();
+    queryAB_Dstar();
+    
+    ExpressionIterator exp = new ExpressionIterator("ei", "a + b + c", 
+        SetOperator.INTERSECTION, false, false);
+    exp.addResults("a", iterators.get("a"));
+  }
+
+  @Test
+  public void unionOneExtraSeries() throws Exception {
+    oneExtraSameE();
+    queryAB_Dstar();
+    remapResults();
+    
+    ExpressionIterator exp = new ExpressionIterator("ei", "a + b", 
+        SetOperator.UNION, false, false);
+    exp.addResults("a", iterators.get("a"));
+    exp.addResults("b", iterators.get("b"));
+    
+    exp.compile();
+    final ExpressionDataPoint[] dps = exp.values();
+    assertEquals(3, dps.length);
+    // TODO - fix the TODO in the set operators to join tags
+    //validateMeta(dps, true);
+    
+    long ts = 1431561600000L;
+    double[] values = new double[] { 12, 18, 17 };
+    long its = exp.nextTimestamp();
+    while (exp.hasNext()) {
+      exp.next(its);
+      assertEquals(ts, dps[0].timestamp());
+      assertEquals(ts, dps[1].timestamp());
+      assertEquals(ts, dps[2].timestamp());
+      assertEquals(values[0], dps[0].toDouble(), 0.0001);
+      assertEquals(values[1], dps[1].toDouble(), 0.0001);
+      assertEquals(values[2], dps[2].toDouble(), 0.0001);
+      
+      values[0] += 2;
+      values[1] += 2;
+      values[2] += 1;
+      ts += 60000;
+      its = exp.nextTimestamp();
+    }
+    
+    for (int i = 0; i < dps.length; i++) {
+      // TODO - fix the TODO in the set operators to join tags
+      //assertEquals(2, dps[i].tags().size());
+      assertTrue(dps[i].aggregatedTags().isEmpty());
+    }
+    assertArrayEquals(TAGV_UIDS.get("D"), dps[0].tags().get(TAGV_UIDS.get("D")));
+    assertArrayEquals(TAGV_UIDS.get("F"), dps[1].tags().get(TAGV_UIDS.get("D")));
+  }
+  
+  @Test
+  public void unionOffset() throws Exception {
+    timeOffset();
+    queryAB_Dstar();
+    remapResults();
+    
+    ExpressionIterator exp = new ExpressionIterator("ei", "a + b", 
+        SetOperator.UNION, false, false);
+    exp.addResults("a", iterators.get("a"));
+    exp.addResults("b", iterators.get("b"));
+    
+    exp.compile();
+    final ExpressionDataPoint[] dps = exp.values();
+    assertEquals(2, dps.length);
+    validateMeta(dps, true);
+ 
+    long ts = 1431561600000L;
+    long its = exp.nextTimestamp();
+    exp.next(its);
+    assertEquals(ts, dps[0].timestamp());
+    assertEquals(ts, dps[1].timestamp());
+    assertEquals(1, dps[0].toDouble(), 0.0001);
+    assertEquals(4, dps[1].toDouble(), 0.0001);
+    ts += 60000;
+    
+    its = exp.nextTimestamp();
+    exp.next(its);
+    assertEquals(ts, dps[0].timestamp());
+    assertEquals(ts, dps[1].timestamp());
+    assertEquals(2, dps[0].toDouble(), 0.0001);
+    assertEquals(5, dps[1].toDouble(), 0.0001);
+    ts += 60000;
+    
+    its = exp.nextTimestamp();
+    exp.next(its);
+    assertEquals(ts, dps[0].timestamp());
+    assertEquals(ts, dps[1].timestamp());
+    assertEquals(13, dps[0].toDouble(), 0.0001);
+    assertEquals(16, dps[1].toDouble(), 0.0001);
+    ts += 60000;
+    
+    its = exp.nextTimestamp();
+    exp.next(its);
+    assertEquals(ts, dps[0].timestamp());
+    assertEquals(ts, dps[1].timestamp());
+    assertEquals(14, dps[0].toDouble(), 0.0001);
+    assertEquals(17, dps[1].toDouble(), 0.0001);
+    
+    assertFalse(exp.hasNext());
+    
+    for (int i = 0; i < dps.length; i++) {
+      assertEquals(2, dps[i].tags().size());
+      assertTrue(dps[i].aggregatedTags().isEmpty());
+    }
+    assertArrayEquals(TAGV_UIDS.get("D"), dps[0].tags().get(TAGV_UIDS.get("D")));
+    assertArrayEquals(TAGV_UIDS.get("F"), dps[1].tags().get(TAGV_UIDS.get("D")));
+  }
+  
+  @Test
+  public void unionNoIntersection() throws Exception {
+    threeDifE();
+    queryAB_Dstar();
+    remapResults();
+    
+    ExpressionIterator exp = new ExpressionIterator("ei", "a + b", 
+        SetOperator.UNION, false, false);
+    exp.addResults("a", iterators.get("a"));
+    exp.addResults("b", iterators.get("b"));
+    
+    exp.compile();
+    final ExpressionDataPoint[] dps = exp.values();
+    assertEquals(6, dps.length);
+    validateMeta(dps, false);
+    
+    long ts = 1431561600000L;
+    double[] values = new double[] { 1, 11, 4, 14, 7, 17 };
+    long its = exp.nextTimestamp();
+    while (exp.hasNext()) {
+      exp.next(its);
+      for (int i = 0; i < values.length; i++) {
+        assertEquals(ts, dps[i].timestamp());
+        assertEquals(values[i], dps[i].toDouble(), 0.0001);
+        ++values[i];
+      }
+      
+      ts += 60000;
+      its = exp.nextTimestamp();
+    }
+  }
+  
+  @Test
+  public void unionSingleSeriesIteration() throws Exception {
+    oneExtraSameE();
+    queryAB_Dstar();
+    remapResults();
+    
+    ExpressionIterator exp = new ExpressionIterator("ei", "a + b", 
+        SetOperator.UNION, false, false);
+    exp.addResults("a", iterators.get("a"));
+    exp.addResults("b", iterators.get("b"));
+    
+    exp.compile();
+    final ExpressionDataPoint[] dps = exp.values();
+    double[] values = new double[] { 12, 18, 17 };
+    
+    for (int i = 0; i < dps.length; i++) {
+      long ts = 1431561600000L;
+      while (exp.hasNext(i)) {
+        exp.next(i);
+        assertEquals(ts, dps[i].timestamp());
+        assertEquals(values[i], dps[i].toDouble(), 0.001);
+
+        ts += 60000;
+        if (i < dps.length - 1) {
+          values[i] += 2;
+        } else {
+          values[i]++;
+        }
+      }
+    }
+  }
+  
+  @Test
+  public void intersectionSingleSeriesIteration() throws Exception {
+    oneExtraSameE();
+    queryAB_Dstar();
+    remapResults();
+    
+    ExpressionIterator exp = new ExpressionIterator("ei", "a + b", 
+        SetOperator.INTERSECTION, false, false);
+    exp.addResults("a", iterators.get("a"));
+    exp.addResults("b", iterators.get("b"));
+    
+    exp.compile();
+    final ExpressionDataPoint[] dps = exp.values();
+    double[] values = new double[] { 12, 18 };
+    
+    for (int i = 0; i < dps.length; i++) {
+      long ts = 1431561600000L;
+      while (exp.hasNext(i)) {
+        exp.next(i);
+        assertEquals(ts, dps[i].timestamp());
+        assertEquals(values[i], dps[i].toDouble(), 0.001);
+        ts += 60000;
+        values[i] += 2;
+      }
+    }
+    
+  }
+  
+  @Test
+  public void aGreaterThanb() throws Exception {
+    oneExtraSameE();
+    queryAB_Dstar();
+    remapResults();
+    
+    ExpressionIterator exp = new ExpressionIterator("ei", "a > b", 
+        SetOperator.INTERSECTION, false, false);
+    exp.addResults("a", iterators.get("a"));
+    exp.addResults("b", iterators.get("b"));
+    
+    exp.compile();
+    final ExpressionDataPoint[] dps = exp.values();
+    assertEquals(2, dps.length);
+    validateMeta(dps, true);
+    
+    long ts = 1431561600000L;
+    double[] values = new double[] { 0, 0 };
+    long its = exp.nextTimestamp();
+    while (exp.hasNext()) {
+      exp.next(its);
+      
+      assertEquals(ts, dps[0].timestamp());
+      assertEquals(ts, dps[1].timestamp());
+      assertEquals(values[0], dps[0].toDouble(), 0.0001);
+      assertEquals(values[1], dps[1].toDouble(), 0.0001);
+      
+      ts += 60000;
+      its = exp.nextTimestamp();
+    }
+    
+    for (int i = 0; i < dps.length; i++) {
+      assertEquals(2, dps[i].tags().size());
+      assertTrue(dps[i].aggregatedTags().isEmpty());
+    }
+  }
+  
+  @Test
+  public void aLessThanb() throws Exception {
+    oneExtraSameE();
+    queryAB_Dstar();
+    remapResults();
+    
+    ExpressionIterator exp = new ExpressionIterator("ei", "a < b", 
+        SetOperator.INTERSECTION, false, false);
+    exp.addResults("a", iterators.get("a"));
+    exp.addResults("b", iterators.get("b"));
+    
+    exp.compile();
+    final ExpressionDataPoint[] dps = exp.values();
+    assertEquals(2, dps.length);
+    validateMeta(dps, true);
+    
+    long ts = 1431561600000L;
+    double[] values = new double[] { 1, 1 };
+    long its = exp.nextTimestamp();
+    while (exp.hasNext()) {
+      exp.next(its);
+      
+      assertEquals(ts, dps[0].timestamp());
+      assertEquals(ts, dps[1].timestamp());
+      assertEquals(values[0], dps[0].toDouble(), 0.0001);
+      assertEquals(values[1], dps[1].toDouble(), 0.0001);
+      
+      ts += 60000;
+      its = exp.nextTimestamp();
+    }
+    
+    for (int i = 0; i < dps.length; i++) {
+      assertEquals(2, dps[i].tags().size());
+      assertTrue(dps[i].aggregatedTags().isEmpty());
+    }
+  }
+  
+  /**
+   * Makes sure the series contain both metrics
+   * @param dps The results to validate
+   * @param common_e The common e
+   */
+  private void validateMeta(final ExpressionDataPoint[] dps, 
+      final boolean common_e) {
+    for (int i = 0; i < dps.length; i++) {
+      // TODO - change this guy to a byteset :( Since it's a bloody list we
+      // can't do a "contains" because it checks for the address of the byte 
+      // arrays
+      boolean found = false;
+      for (final byte[] metric : dps[i].metricUIDs()) {
+        if (Bytes.memcmp(TAGV_UIDS.get("A"), metric) == 0) {
+          found = true;
+        } else if (Bytes.memcmp(TAGV_UIDS.get("B"), metric) == 0) {
+          found = true;
+          break;
+        }
+      }
+      if (!found) {
+        fail("Missing a metric");
+      }
+      
+      if (common_e) {
+        assertArrayEquals(TAGV_UIDS.get("E"), dps[i].tags().get(TAGV_UIDS.get("E")));
+      }
+    }
+  }
+
+  private void remapResults() {
+    iterators.clear();
+    iterators.put("a", new TimeSyncedIterator("a", 
+        query.getQueries().get(0).getFilterTagKs(), results.get("0").getValue()));
+    iterators.put("b", new TimeSyncedIterator("b", 
+        query.getQueries().get(1).getFilterTagKs(), results.get("1").getValue()));
+  }
+}
diff --git a/test/query/expression/TestExpressionReader.java b/test/query/expression/TestExpressionReader.java
new file mode 100644
index 0000000000..3e4e7bd653
--- /dev/null
+++ b/test/query/expression/TestExpressionReader.java
@@ -0,0 +1,205 @@
+// This file is part of OpenTSDB.
+// Copyright (C) 2015  The OpenTSDB Authors.
+//
+// This program is free software: you can redistribute it and/or modify it
+// under the terms of the GNU Lesser General Public License as published by
+// the Free Software Foundation, either version 2.1 of the License, or (at your
+// option) any later version.  This program is distributed in the hope that it
+// will be useful, but WITHOUT ANY WARRANTY; without even the implied warranty
+// of MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser
+// General Public License for more details.  You should have received a copy
+// of the GNU Lesser General Public License along with this program.  If not,
+// see <http://www.gnu.org/licenses/>.
+package net.opentsdb.query.expression;
+
+import static org.junit.Assert.assertEquals;
+import static org.junit.Assert.assertFalse;
+import static org.junit.Assert.assertTrue;
+import static org.junit.Assert.fail;
+
+import java.util.NoSuchElementException;
+
+import org.junit.Test;
+
+public class TestExpressionReader {
+  final static String EXP = "test(sys.cpu.user)";
+  
+  @Test
+  public void ctor() throws Exception {
+    final ExpressionReader reader = new ExpressionReader(EXP.toCharArray());
+    assertEquals(EXP, reader.toString());
+    assertEquals(0, reader.getMark());
+    assertEquals('t', reader.peek());
+  }
+  
+  @Test (expected = IllegalArgumentException.class)
+  public void ctorNull() throws Exception {
+    new ExpressionReader(null);
+  }
+  
+  @Test
+  public void ctorEmptyString() throws Exception {
+    final ExpressionReader reader = new ExpressionReader(new char[] { });
+    assertEquals(0, reader.getMark());
+    assertTrue(reader.isEOF());
+    try {
+      reader.peek();
+      fail("Expected a NoSuchElementException");
+    } catch (NoSuchElementException e) { }
+    try {
+      reader.next();
+      fail("Expected a NoSuchElementException");
+    } catch (NoSuchElementException e) { }
+    try {
+      reader.isNextChar('o');
+      fail("Expected a NoSuchElementException");
+    } catch (NoSuchElementException e) { }
+    try {
+      reader.readFuncName();
+      fail("Expected a NoSuchElementException");
+    } catch (NoSuchElementException e) { }
+    reader.readNextParameter();
+    // always false
+    assertFalse(reader.isNextSeq("laska"));
+    // no-op
+    reader.skipWhitespaces();
+    // doesn't hurt anything
+    reader.skip(52);
+  }
+
+  @Test
+  public void peek() throws Exception {
+    final ExpressionReader reader = new ExpressionReader(EXP.toCharArray());
+    assertEquals(0, reader.getMark());
+    assertEquals('t', reader.peek());
+    reader.next();
+    assertEquals(1, reader.getMark());
+    assertEquals('e', reader.peek());
+    assertEquals(1, reader.getMark());
+  }
+  
+  @Test
+  public void nextTillEOF() throws Exception {
+    final char[] chars = EXP.toCharArray();
+    final ExpressionReader reader = new ExpressionReader(EXP.toCharArray());
+    for (final char c : chars) {
+      assertEquals(c, reader.next());
+    }
+    assertTrue(reader.isEOF());
+  }
+  
+  @Test
+  public void skip() throws Exception {
+    final ExpressionReader reader = new ExpressionReader(EXP.toCharArray());
+    reader.skip(4);
+    assertEquals(4, reader.getMark());
+    assertEquals('(', reader.peek());
+  }
+  
+  @Test
+  public void skipOutOfBounds() throws Exception {
+    final ExpressionReader reader = new ExpressionReader(EXP.toCharArray());
+    reader.skip(EXP.length());
+    assertEquals(EXP.length(), reader.getMark());
+    assertTrue(reader.isEOF());
+  }
+  
+  @Test (expected = UnsupportedOperationException.class)
+  public void skipBackwards() throws Exception {
+    final ExpressionReader reader = new ExpressionReader(EXP.toCharArray());
+    reader.skip(-1);
+  }
+  
+  @Test
+  public void isNextChar() throws Exception {
+    final ExpressionReader reader = new ExpressionReader(EXP.toCharArray());
+    assertTrue(reader.isNextChar('t'));
+    reader.skip(4);
+    assertTrue(reader.isNextChar('('));
+    assertFalse(reader.isNextChar('t'));
+  }
+  
+  @Test
+  public void isNextSeq() throws Exception {
+    final ExpressionReader reader = new ExpressionReader(EXP.toCharArray());
+    assertTrue(reader.isNextSeq("test("));
+    assertFalse(reader.isNextSeq("est("));
+    assertTrue(reader.isNextSeq(EXP));
+    assertFalse(reader.isNextSeq(EXP + "morestuff"));
+  }
+  
+  @Test
+  public void readFuncName() {
+    ExpressionReader reader = new ExpressionReader(EXP.toCharArray());
+    assertEquals("test", reader.readFuncName());
+    assertEquals("", reader.readFuncName());
+    assertEquals("", reader.readFuncName());
+    assertFalse(reader.isEOF());
+    
+    // space between method and parens
+    reader = new ExpressionReader("test (foo)".toCharArray());
+    assertEquals("test", reader.readFuncName());
+    assertEquals("", reader.readFuncName());
+    
+    // consume initial whitespace
+    reader = new ExpressionReader("  test(foo)".toCharArray());
+    assertEquals("test", reader.readFuncName());
+    assertEquals("", reader.readFuncName());
+    
+    // whitespace everywhere!!
+    reader = new ExpressionReader("  test(foo)  ".toCharArray());
+    assertEquals("test", reader.readFuncName());
+    assertEquals("", reader.readFuncName());
+    
+    // nesting fails unless we consume the parens
+    reader = new ExpressionReader("test(foo(bar()))".toCharArray());
+    assertEquals("test", reader.readFuncName());
+    assertEquals("", reader.readFuncName());
+    assertEquals("", reader.readFuncName());
+    
+    reader = new ExpressionReader("test(foo(bar()))".toCharArray());
+    assertEquals("test", reader.readFuncName());
+    reader.next();
+    assertEquals("foo", reader.readFuncName());
+    reader.next();
+    assertEquals("bar", reader.readFuncName());
+    
+    // parens with space
+    reader = new ExpressionReader("test ( foo ( bar()))".toCharArray());
+    assertEquals("test", reader.readFuncName());
+    reader.next();
+    assertEquals("foo", reader.readFuncName());
+    reader.next();
+    assertEquals("bar", reader.readFuncName());
+    
+    // TODO - Watch out for the following gotchas
+    reader = new ExpressionReader("test ( foo  bar()))".toCharArray());
+    assertEquals("test", reader.readFuncName());
+    reader.next();
+    assertEquals("foo", reader.readFuncName());
+    reader.next();
+    assertEquals("ar", reader.readFuncName());
+    
+    reader = new ExpressionReader("test ".toCharArray());
+    assertEquals("test", reader.readFuncName());
+  }
+
+  // TODO - more UTs around this guy
+  @Test
+  public void readNextParameter() {
+    // will read the whole thing, so watch out!
+    ExpressionReader reader = new ExpressionReader(EXP.toCharArray());
+    assertEquals(EXP, reader.readNextParameter());
+    
+    // TODO - ok?
+    reader = new ExpressionReader(EXP.toCharArray());
+    reader.readFuncName();
+    assertEquals("(sys.cpu.user)", reader.readNextParameter());
+    
+    // TODO - ok?
+    reader = new ExpressionReader("test(foo,1,2)".toCharArray());
+    reader.readFuncName();
+    reader.next();
+    assertEquals("foo,1,2", reader.readNextParameter());
+  }
+}
diff --git a/test/query/expression/TestExpressionTree.java b/test/query/expression/TestExpressionTree.java
new file mode 100644
index 0000000000..ad1a5f37c7
--- /dev/null
+++ b/test/query/expression/TestExpressionTree.java
@@ -0,0 +1,319 @@
+// This file is part of OpenTSDB.
+// Copyright (C) 2015  The OpenTSDB Authors.
+//
+// This program is free software: you can redistribute it and/or modify it
+// under the terms of the GNU Lesser General Public License as published by
+// the Free Software Foundation, either version 2.1 of the License, or (at your
+// option) any later version.  This program is distributed in the hope that it
+// will be useful, but WITHOUT ANY WARRANTY; without even the implied warranty
+// of MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser
+// General Public License for more details.  You should have received a copy
+// of the GNU Lesser General Public License along with this program.  If not,
+// see <http://www.gnu.org/licenses/>.
+package net.opentsdb.query.expression;
+
+import static org.junit.Assert.assertEquals;
+import static org.junit.Assert.assertNull;
+import static org.junit.Assert.assertSame;
+import static org.junit.Assert.assertTrue;
+import static org.mockito.Mockito.mock;
+import static org.mockito.Mockito.spy;
+import static org.mockito.Mockito.times;
+import static org.mockito.Mockito.verify;
+import static org.mockito.Mockito.when;
+
+import java.util.ArrayList;
+import java.util.List;
+
+import net.opentsdb.core.DataPoints;
+import net.opentsdb.core.IllegalDataException;
+import net.opentsdb.core.SeekableView;
+import net.opentsdb.core.SeekableViewsForTest;
+import net.opentsdb.core.TSQuery;
+import net.opentsdb.query.expression.ExpressionTree.Parameter;
+
+import org.junit.Before;
+import org.junit.Test;
+import org.junit.runner.RunWith;
+import org.powermock.api.mockito.PowerMockito;
+import org.powermock.core.classloader.annotations.PowerMockIgnore;
+import org.powermock.core.classloader.annotations.PrepareForTest;
+import org.powermock.modules.junit4.PowerMockRunner;
+
+@RunWith(PowerMockRunner.class)
+@PowerMockIgnore({"javax.management.*", "javax.xml.*",
+  "ch.qos.*", "org.slf4j.*",
+  "com.sum.*", "org.xml.*"})
+@PrepareForTest({ TSQuery.class })
+public class TestExpressionTree {
+  private final static String EXPR_NAME = "treeTestExpr";
+  private static long START_TIME = 1356998400000L;
+  private static int INTERVAL = 60000;
+  private static int NUM_POINTS = 5;
+  private static String METRIC = "sys.cpu";
+  
+  private TSQuery data_query;
+  private SeekableView view;
+  private DataPoints dps;
+  private DataPoints[] group_bys;
+  private List<DataPoints[]> query_results;
+  private TreeTestExpr test_expression;
+  
+  @Before
+  public void before() throws Exception {
+    view = SeekableViewsForTest.generator(START_TIME, INTERVAL, 
+        NUM_POINTS, true, 1, 1);
+    data_query = mock(TSQuery.class);
+    when(data_query.startTime()).thenReturn(START_TIME);
+    when(data_query.endTime()).thenReturn(START_TIME + (INTERVAL * NUM_POINTS));
+    
+    dps = PowerMockito.mock(DataPoints.class);
+    when(dps.iterator()).thenReturn(view);
+    when(dps.metricName()).thenReturn(METRIC);
+    
+    group_bys = new DataPoints[] { dps };
+    
+    query_results = new ArrayList<DataPoints[]>(1);
+    query_results.add(group_bys);
+    
+    test_expression = new TreeTestExpr();
+    ExpressionFactory.addFunction(EXPR_NAME, test_expression);
+  }
+  
+  @Test
+  public void ctorString() throws Exception {
+    final ExpressionTree tree = new ExpressionTree(EXPR_NAME, data_query);
+    assertEquals(EXPR_NAME + "()", tree.toString());
+    assertNull(tree.subExpressions());
+    assertNull(tree.funcParams());
+    assertNull(tree.subMetricQueries());
+    assertTrue(tree.parameterIndex().isEmpty());
+  }
+  
+  @Test (expected = UnsupportedOperationException.class)
+  public void ctorStringNull() throws Exception {
+    new ExpressionTree((String)null, data_query);
+  }
+  
+  @Test (expected = UnsupportedOperationException.class)
+  public void ctorStringEmpty() throws Exception {
+    new ExpressionTree("", data_query);
+  }
+  
+  @Test (expected = UnsupportedOperationException.class)
+  public void ctorStringUnknown() throws Exception {
+    new ExpressionTree("No such method", data_query);
+  }
+  
+  @Test
+  public void ctorExpression() throws Exception {
+    final ExpressionTree tree = new ExpressionTree(test_expression, data_query);
+    assertEquals(EXPR_NAME + "()", tree.toString());
+    assertNull(tree.subExpressions());
+    assertNull(tree.funcParams());
+    assertNull(tree.subMetricQueries());
+    assertTrue(tree.parameterIndex().isEmpty());
+  }
+  
+  @Test
+  public void addSubExpression() throws Exception {
+    final ExpressionTree tree = new ExpressionTree(EXPR_NAME, data_query);
+    final ExpressionTree child = new ExpressionTree("scale", data_query);
+    tree.addSubExpression(child, 1);
+    assertEquals(1, tree.subExpressions().size());
+    assertSame(child, tree.subExpressions().get(0));
+    assertNull(tree.funcParams());
+    assertNull(tree.subMetricQueries());
+    assertEquals(1, tree.parameterIndex().size());
+    assertEquals(Parameter.SUB_EXPRESSION, tree.parameterIndex().get(1));
+  }
+  
+  @Test (expected = IllegalArgumentException.class)
+  public void addSubExpressionNullTree() throws Exception {
+    final ExpressionTree tree = new ExpressionTree(EXPR_NAME, data_query);
+    tree.addSubExpression(null, 1);
+  }
+  
+  @Test (expected = IllegalArgumentException.class)
+  public void addSubExpressionNegativeIndex() throws Exception {
+    final ExpressionTree tree = new ExpressionTree(EXPR_NAME, data_query);
+    tree.addSubExpression(null, 1);
+  }
+  
+  @Test (expected = IllegalDataException.class)
+  public void addSubExpressionRecursion() throws Exception {
+    final ExpressionTree tree = new ExpressionTree(EXPR_NAME, data_query);
+    tree.addSubExpression(tree, 1);
+  }
+  
+  @Test
+  public void addSubMetricQuery() throws Exception {
+    final ExpressionTree tree = new ExpressionTree(EXPR_NAME, data_query);
+    tree.addSubMetricQuery(METRIC, 1, 1);
+    assertEquals(EXPR_NAME + "(" + METRIC + ")", tree.toString());
+    assertNull(tree.subExpressions());
+    assertNull(tree.funcParams());
+    assertEquals(1, tree.subMetricQueries().size());
+    assertEquals(METRIC, tree.subMetricQueries().get(1));
+    assertEquals(1, tree.parameterIndex().size());
+    assertEquals(Parameter.METRIC_QUERY, tree.parameterIndex().get(1));
+  }
+  
+  @Test (expected = IllegalArgumentException.class)
+  public void addSubMetricQueryNullMetric() throws Exception {
+    final ExpressionTree tree = new ExpressionTree(EXPR_NAME, data_query);
+    tree.addSubMetricQuery(null, 1, 1);
+  }
+  
+  @Test (expected = IllegalArgumentException.class)
+  public void addSubMetricQueryEmptyMetric() throws Exception {
+    final ExpressionTree tree = new ExpressionTree(EXPR_NAME, data_query);
+    tree.addSubMetricQuery("", 1, 1);
+  }
+  
+  @Test (expected = IllegalArgumentException.class)
+  public void addSubMetricQueryNegativeQueryIndex() throws Exception {
+    final ExpressionTree tree = new ExpressionTree(EXPR_NAME, data_query);
+    tree.addSubMetricQuery(METRIC, -1, 1);
+  }
+  
+  @Test (expected = IllegalArgumentException.class)
+  public void addSubMetricQueryNegativeParamIndex() throws Exception {
+    final ExpressionTree tree = new ExpressionTree(EXPR_NAME, data_query);
+    tree.addSubMetricQuery(METRIC, 1, -1);
+  }
+  
+  @Test
+  public void addFunctionParameter() throws Exception {
+    final ExpressionTree tree = new ExpressionTree(EXPR_NAME, data_query);
+    tree.addFunctionParameter("vimes");
+    assertEquals(EXPR_NAME + "()", tree.toString());
+    assertNull(tree.subExpressions());
+    assertEquals(1, tree.funcParams().size());
+    assertEquals("vimes", tree.funcParams().get(0));
+    assertNull(tree.subMetricQueries());
+    assertTrue(tree.parameterIndex().isEmpty());
+  }
+  
+  @Test (expected = IllegalArgumentException.class)
+  public void addFunctionParameterNull() throws Exception {
+    final ExpressionTree tree = new ExpressionTree(EXPR_NAME, data_query);
+    tree.addFunctionParameter(null);
+  }
+  
+  @Test (expected = IllegalArgumentException.class)
+  public void addFunctionParameterEmpty() throws Exception {
+    final ExpressionTree tree = new ExpressionTree(EXPR_NAME, data_query);
+    tree.addFunctionParameter("");
+  }
+  
+  @Test
+  public void evaluateNothingSet() throws Exception {
+    final ExpressionTree tree = new ExpressionTree(EXPR_NAME, data_query);
+    assertEquals(EXPR_NAME + "()", tree.toString());
+    
+    final DataPoints[] response = tree.evaluate(query_results);
+    assertEquals(1, response.length);
+    assertSame(data_query, test_expression.data_query);
+    assertEquals(0, test_expression.results.size());
+    assertNull(test_expression.params);
+  }
+  
+  @Test
+  public void evaluateSubMetricQuerySet() throws Exception {
+    final ExpressionTree tree = new ExpressionTree(EXPR_NAME, data_query);
+    tree.addSubMetricQuery(METRIC, 0, 0);
+    assertEquals(EXPR_NAME + "(" + METRIC + ")", tree.toString());
+    
+    final DataPoints[] response = tree.evaluate(query_results);
+    assertEquals(1, response.length);
+    assertSame(data_query, test_expression.data_query);
+    assertEquals(1, test_expression.results.size());
+    assertNull(test_expression.params);
+  }
+  
+  @Test
+  public void evaluateSubMetricQuerySetWithParam() throws Exception {
+    final ExpressionTree tree = new ExpressionTree(EXPR_NAME, data_query);
+    tree.addSubMetricQuery(METRIC, 0, 0);
+    tree.addFunctionParameter("foo");
+    assertEquals(EXPR_NAME + "(" + METRIC + ")", tree.toString());
+    
+    final DataPoints[] response = tree.evaluate(query_results);
+    assertEquals(1, response.length);
+    assertSame(data_query, test_expression.data_query);
+    assertEquals(1, test_expression.results.size());
+    assertEquals(1, test_expression.params.size());
+    assertEquals("foo", test_expression.params.get(0));
+  }
+  
+  @Test
+  public void evaluateSubExpressionSet() throws Exception {
+    final ExpressionTree tree = new ExpressionTree(EXPR_NAME, data_query);
+    final ExpressionTree child = spy(new ExpressionTree("scale", data_query));
+    child.addSubMetricQuery(METRIC, 0, 0);
+    child.addFunctionParameter("1");
+    tree.addSubExpression(child, 0);
+    assertEquals(EXPR_NAME + "(scale(" + METRIC + "))", tree.toString());
+    
+    final DataPoints[] response = tree.evaluate(query_results);
+    assertEquals(1, response.length);
+    assertSame(data_query, test_expression.data_query);
+    assertEquals(1, test_expression.results.size());
+    assertNull(test_expression.params);
+    verify(child, times(1)).evaluate(query_results);
+  }
+
+// TODO - fix this up
+//  @Test
+//  public void evaluateSubExpressionAndSubMetricSet() throws Exception {
+//    final ExpressionTree tree = new ExpressionTree(EXPR_NAME, data_query);
+//    final ExpressionTree child = spy(new ExpressionTree("scale", data_query));
+//    child.addSubMetricQuery(METRIC, 0, 0);
+//    child.addFunctionParameter("1");
+//    tree.addSubExpression(child, 0);
+//    
+//    tree.addSubMetricQuery(METRIC, 1, 0);
+//    tree.addFunctionParameter("foo");
+//    
+//    assertEquals(EXPR_NAME + "(scale(" + METRIC + ")," + METRIC + ")", 
+//        tree.toString());
+//    
+//    final DataPoints[] response = tree.evaluate(query_results);
+//    assertEquals(1, response.length);
+//    assertSame(data_query, test_expression.data_query);
+//    assertEquals(1, test_expression.results.size());
+//    assertEquals(1, test_expression.params.size());
+//    assertEquals("foo", test_expression.params.get(0));
+//    verify(child, times(1)).evaluate(query_results);
+//  }
+  
+  // TODO - more tests around indexes, etc unless we cleanup the class
+  
+  private class TreeTestExpr implements Expression {
+    TSQuery data_query;
+    List<DataPoints[]> results;
+    List<String> params;
+    
+    @Override
+    public DataPoints[] evaluate(TSQuery data_query,
+        List<DataPoints[]> results, List<String> params) {
+      this.data_query = data_query;
+      this.results = results;
+      this.params = params;
+      
+      // Returns an array the size of the total incoming results array
+      int num_results = 0;
+      for (DataPoints[] r: query_results) {
+        num_results += r.length;
+      }
+      final DataPoints[] response = new DataPoints[num_results];
+      return response;
+    }
+    @Override
+    public String writeStringField(List<String> params,
+        String inner_expression) {
+      return EXPR_NAME + "(" + inner_expression + ")";
+    }
+  }
+}
diff --git a/test/query/expression/TestExpressions.java b/test/query/expression/TestExpressions.java
new file mode 100644
index 0000000000..60dd6ec7c1
--- /dev/null
+++ b/test/query/expression/TestExpressions.java
@@ -0,0 +1,147 @@
+// This file is part of OpenTSDB.
+// Copyright (C) 2015  The OpenTSDB Authors.
+//
+// This program is free software: you can redistribute it and/or modify it
+// under the terms of the GNU Lesser General Public License as published by
+// the Free Software Foundation, either version 2.1 of the License, or (at your
+// option) any later version.  This program is distributed in the hope that it
+// will be useful, but WITHOUT ANY WARRANTY; without even the implied warranty
+// of MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser
+// General Public License for more details.  You should have received a copy
+// of the GNU Lesser General Public License along with this program.  If not,
+// see <http://www.gnu.org/licenses/>.
+package net.opentsdb.query.expression;
+
+import static org.junit.Assert.assertEquals;
+import static org.junit.Assert.assertNull;
+import static org.mockito.Mockito.mock;
+
+import java.util.ArrayList;
+import java.util.List;
+
+import net.opentsdb.core.DataPoints;
+import net.opentsdb.core.TSQuery;
+
+import org.junit.Before;
+import org.junit.Test;
+import org.junit.runner.RunWith;
+import org.powermock.core.classloader.annotations.PowerMockIgnore;
+import org.powermock.core.classloader.annotations.PrepareForTest;
+import org.powermock.modules.junit4.PowerMockRunner;
+
+@RunWith(PowerMockRunner.class)
+@PowerMockIgnore({"javax.management.*", "javax.xml.*",
+  "ch.qos.*", "org.slf4j.*",
+  "com.sum.*", "org.xml.*"})
+@PrepareForTest({ TSQuery.class })
+public class TestExpressions {
+  private TSQuery data_query;
+  private List<String> metric_queries;
+  
+  @Before
+  public void before() throws Exception {
+    data_query = mock(TSQuery.class);
+    metric_queries = new ArrayList<String>();
+    ExpressionFactory.addFunction("foo", new FooExpression());
+  }
+  
+  @Test
+  public void parse() throws Exception {
+    final ExpressionTree tree = Expressions.parse(
+        "scale(sys.cpu)", metric_queries, data_query);
+    assertEquals("scale()", tree.toString());
+  }
+  
+  @Test
+  public void parseWithWhitespace() throws Exception {
+    final ExpressionTree tree = Expressions.parse(
+        "   scale(sys.cpu)", metric_queries, data_query);
+    assertEquals("scale()", tree.toString());
+  }
+
+  @Test
+  public void parseMultiParameter() {
+    final String expr = "foo(sum:proc.sys.cpu,, sum:proc.meminfo.memfree)";
+    final ExpressionTree tree = Expressions.parse(expr, metric_queries, null);
+    assertEquals("foo(proc.sys.cpu,proc.meminfo.memfree)", tree.toString());
+    assertEquals(2, metric_queries.size());
+    assertEquals("sum:proc.sys.cpu", metric_queries.get(0));
+    assertEquals("sum:proc.meminfo.memfree", metric_queries.get(1));
+    assertNull(tree.funcParams());
+  }
+  
+  @Test
+  public void parseNestedExpr() {
+    final String expr = "foo(sum:proc.sys.cpu,, foo(sum:proc.a.b))";
+    final ExpressionTree tree = Expressions.parse(expr, metric_queries, null);
+    assertEquals("foo(foo(proc.a.b),proc.sys.cpu)", tree.toString());
+    assertEquals(2, metric_queries.size());
+    assertEquals("sum:proc.sys.cpu", metric_queries.get(0));
+    assertEquals("sum:proc.a.b", metric_queries.get(1));
+    assertNull(tree.funcParams());
+  }
+  
+  @Test
+  public void parseExprWithParam() {
+    final String expr = "foo(sum:proc.sys.cpu,, 100,, 3.1415)";
+    final ExpressionTree tree = Expressions.parse(expr, metric_queries, null);
+    assertEquals("foo(proc.sys.cpu)", tree.toString());
+    assertEquals(1, metric_queries.size());
+    assertEquals("sum:proc.sys.cpu", metric_queries.get(0));
+    assertEquals(2, tree.funcParams().size());
+    assertEquals("100", tree.funcParams().get(0));
+    assertEquals("3.1415", tree.funcParams().get(1));
+  }
+  
+  @Test (expected = IllegalArgumentException.class)
+  public void parseNullExpression() throws Exception {
+    Expressions.parse(null, metric_queries, data_query);
+  }
+  
+  @Test (expected = IllegalArgumentException.class)
+  public void parseEmptyExpression() throws Exception {
+    Expressions.parse("", metric_queries, data_query);
+  }
+  
+  @Test (expected = IllegalArgumentException.class)
+  public void parseMissingOpenParens() throws Exception {
+    Expressions.parse("scalesys.cpu)", metric_queries, data_query);
+  }
+  
+  @Test (expected = IllegalArgumentException.class)
+  public void parseMissingClosingParens() throws Exception {
+    Expressions.parse("scale(sys.cpu", metric_queries, data_query);
+  }
+  
+  // TODO - These two may be problematic and need validation/fixing?
+  @Test
+  public void parseNullMetricQueries() throws Exception {
+    final ExpressionTree tree = Expressions.parse(
+        "scale(sys.cpu)", null, data_query);
+    assertEquals("scale()", tree.toString());
+  }
+  
+  @Test
+  public void parseNullTSQuery() throws Exception {
+    final ExpressionTree tree = Expressions.parse(
+        "scale(sys.cpu)", metric_queries, null);
+    assertEquals("scale()", tree.toString());
+  }
+
+  //TODO - Need to add more tests around parsing nested functions and params
+  
+  /** Dummy test expression implementation */
+  private static class FooExpression implements Expression {
+    @Override
+    public DataPoints[] evaluate(final TSQuery data_query, 
+        final List<DataPoints[]> query_results, final List<String> params) {
+      return new DataPoints[0];
+    }
+
+    @Override
+    public String writeStringField(final List<String> query_params, 
+        final String inner_expressions) {
+      return "foo(" + inner_expressions + ")";
+    }
+  }
+}
diff --git a/test/query/expression/TestHighestCurrent.java b/test/query/expression/TestHighestCurrent.java
new file mode 100644
index 0000000000..876ee6356d
--- /dev/null
+++ b/test/query/expression/TestHighestCurrent.java
@@ -0,0 +1,395 @@
+// This file is part of OpenTSDB.
+// Copyright (C) 2015  The OpenTSDB Authors.
+//
+// This program is free software: you can redistribute it and/or modify it
+// under the terms of the GNU Lesser General Public License as published by
+// the Free Software Foundation, either version 2.1 of the License, or (at your
+// option) any later version.  This program is distributed in the hope that it
+// will be useful, but WITHOUT ANY WARRANTY; without even the implied warranty
+// of MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser
+// General Public License for more details.  You should have received a copy
+// of the GNU Lesser General Public License along with this program.  If not,
+// see <http://www.gnu.org/licenses/>.
+package net.opentsdb.query.expression;
+
+import static org.junit.Assert.assertEquals;
+import static org.junit.Assert.assertFalse;
+import static org.junit.Assert.assertTrue;
+import static org.mockito.Mockito.mock;
+import static org.mockito.Mockito.when;
+
+import java.util.ArrayList;
+import java.util.Collections;
+import java.util.List;
+
+import net.opentsdb.core.DataPoint;
+import net.opentsdb.core.DataPoints;
+import net.opentsdb.core.SeekableView;
+import net.opentsdb.core.SeekableViewsForTest;
+import net.opentsdb.core.TSQuery;
+
+import org.junit.Before;
+import org.junit.Test;
+import org.junit.runner.RunWith;
+import org.powermock.api.mockito.PowerMockito;
+import org.powermock.core.classloader.annotations.PowerMockIgnore;
+import org.powermock.core.classloader.annotations.PrepareForTest;
+import org.powermock.modules.junit4.PowerMockRunner;
+
+import com.stumbleupon.async.Deferred;
+
+@RunWith(PowerMockRunner.class)
+@PowerMockIgnore({"javax.management.*", "javax.xml.*",
+  "ch.qos.*", "org.slf4j.*",
+  "com.sum.*", "org.xml.*"})
+@PrepareForTest({ TSQuery.class })
+public class TestHighestCurrent {
+
+  private static long START_TIME = 1356998400000L;
+  private static int INTERVAL = 60000;
+  private static int NUM_POINTS = 5;
+  private static String METRIC = "sys.cpu";
+  
+  private TSQuery data_query;
+  private SeekableView view;
+  private DataPoints dps;
+  private DataPoints[] group_bys;
+  private List<DataPoints[]> query_results;
+  private List<String> params;
+  private HighestCurrent func;
+  
+  @Before
+  public void before() throws Exception {
+    view = SeekableViewsForTest.generator(START_TIME, INTERVAL, 
+        NUM_POINTS, true, 1, 1);
+    data_query = mock(TSQuery.class);
+    when(data_query.startTime()).thenReturn(START_TIME);
+    when(data_query.endTime()).thenReturn(START_TIME + (INTERVAL * NUM_POINTS));
+    
+    dps = PowerMockito.mock(DataPoints.class);
+    when(dps.iterator()).thenReturn(view);
+    when(dps.metricNameAsync()).thenReturn(Deferred.fromResult(METRIC));
+    
+    group_bys = new DataPoints[] { dps };
+    
+    query_results = new ArrayList<DataPoints[]>(1);
+    query_results.add(group_bys);
+    
+    params = new ArrayList<String>(1);
+    func = new HighestCurrent();
+  }
+  
+  @Test
+  public void evaluateTopN1with2SeriesLong() throws Exception {
+    params.add("1");
+    SeekableView view2 = SeekableViewsForTest.generator(START_TIME, INTERVAL, 
+        NUM_POINTS, true, 10, 1);
+    DataPoints dps2 = PowerMockito.mock(DataPoints.class);
+    when(dps2.iterator()).thenReturn(view2);
+    when(dps2.metricNameAsync()).thenReturn(Deferred.fromResult("sys.mem"));
+    group_bys = new DataPoints[] { dps, dps2 };
+    query_results.clear();
+    query_results.add(group_bys);
+    
+    final DataPoints[] results = func.evaluate(data_query, query_results, params);
+    
+    assertEquals(1, results.length);
+    assertEquals("sys.mem", results[0].metricName());
+    
+    long ts = START_TIME;
+    long v = 10;
+    for (DataPoint dp : results[0]) {
+      assertEquals(ts, dp.timestamp());
+      assertTrue(dp.isInteger());
+      assertEquals(v, dp.longValue());
+      ts += INTERVAL;
+      v += 1;
+    }
+  }
+  
+  @Test
+  public void evaluateTopN2with2SeriesLong() throws Exception {
+    params.add("2");
+    SeekableView view2 = SeekableViewsForTest.generator(START_TIME, INTERVAL, 
+        NUM_POINTS, true, 10, 1);
+    DataPoints dps2 = PowerMockito.mock(DataPoints.class);
+    when(dps2.iterator()).thenReturn(view2);
+    when(dps2.metricNameAsync()).thenReturn(Deferred.fromResult("sys.mem"));
+    group_bys = new DataPoints[] { dps, dps2 };
+    query_results.clear();
+    query_results.add(group_bys);
+    
+    final DataPoints[] results = func.evaluate(data_query, query_results, params);
+    
+    assertEquals(2, results.length);
+    assertEquals("sys.mem", results[0].metricName());
+    assertEquals(METRIC, results[1].metricName());
+    
+    long ts = START_TIME;
+    long v = 10;
+    for (DataPoint dp : results[0]) {
+      assertEquals(ts, dp.timestamp());
+      assertTrue(dp.isInteger());
+      assertEquals(v, dp.longValue());
+      ts += INTERVAL;
+      v += 1;
+    }
+    
+    ts = START_TIME;
+    v = 1;
+    for (DataPoint dp : results[1]) {
+      assertEquals(ts, dp.timestamp());
+      assertTrue(dp.isInteger());
+      assertEquals(v, dp.longValue());
+      ts += INTERVAL;
+      v += 1;
+    }
+  }
+  
+  @Test
+  public void evaluateTopN100with2SeriesLong() throws Exception {
+    params.add("100");
+    SeekableView view2 = SeekableViewsForTest.generator(START_TIME, INTERVAL, 
+        NUM_POINTS, true, 10, 1);
+    DataPoints dps2 = PowerMockito.mock(DataPoints.class);
+    when(dps2.iterator()).thenReturn(view2);
+    when(dps2.metricNameAsync()).thenReturn(Deferred.fromResult("sys.mem"));
+    DataPoints[] group_bys2 = new DataPoints[] { dps2 };
+    query_results.add(group_bys2);
+    
+    final DataPoints[] results = func.evaluate(data_query, query_results, params);
+    
+    assertEquals(2, results.length);
+    assertEquals("sys.mem", results[0].metricName());
+    assertEquals(METRIC, results[1].metricName());
+    
+    long ts = START_TIME;
+    long v = 10;
+    for (DataPoint dp : results[0]) {
+      assertEquals(ts, dp.timestamp());
+      assertTrue(dp.isInteger());
+      assertEquals(v, dp.longValue());
+      ts += INTERVAL;
+      v += 1;
+    }
+    
+    ts = START_TIME;
+    v = 1;
+    for (DataPoint dp : results[1]) {
+      assertEquals(ts, dp.timestamp());
+      assertTrue(dp.isInteger());
+      assertEquals(v, dp.longValue());
+      ts += INTERVAL;
+      v += 1;
+    }
+  }
+  
+  @Test
+  public void evaluateTopN100with2SubQuerySeriesLong() throws Exception {
+    params.add("100");
+    SeekableView view2 = SeekableViewsForTest.generator(START_TIME, INTERVAL, 
+        NUM_POINTS, true, 10, 1);
+    DataPoints dps2 = PowerMockito.mock(DataPoints.class);
+    when(dps2.iterator()).thenReturn(view2);
+    when(dps2.metricNameAsync()).thenReturn(Deferred.fromResult("sys.mem"));
+    group_bys = new DataPoints[] { dps, dps2 };
+    query_results.clear();
+    query_results.add(group_bys);
+    
+    final DataPoints[] results = func.evaluate(data_query, query_results, params);
+    
+    assertEquals(2, results.length);
+    assertEquals("sys.mem", results[0].metricName());
+    assertEquals(METRIC, results[1].metricName());
+    
+    long ts = START_TIME;
+    long v = 10;
+    for (DataPoint dp : results[0]) {
+      assertEquals(ts, dp.timestamp());
+      assertTrue(dp.isInteger());
+      assertEquals(v, dp.longValue());
+      ts += INTERVAL;
+      v += 1;
+    }
+    
+    ts = START_TIME;
+    v = 1;
+    for (DataPoint dp : results[1]) {
+      assertEquals(ts, dp.timestamp());
+      assertTrue(dp.isInteger());
+      assertEquals(v, dp.longValue());
+      ts += INTERVAL;
+      v += 1;
+    }
+  }
+  
+  @Test
+  public void evaluateTopN2with2SeriesDouble() throws Exception {
+    params.add("2");
+    SeekableView view2 = SeekableViewsForTest.generator(START_TIME, INTERVAL, 
+        NUM_POINTS, false, 10, 1.5);
+    DataPoints dps2 = PowerMockito.mock(DataPoints.class);
+    when(dps2.iterator()).thenReturn(view2);
+    when(dps2.metricNameAsync()).thenReturn(Deferred.fromResult("sys.mem"));
+    group_bys = new DataPoints[] { dps, dps2 };
+    query_results.clear();
+    query_results.add(group_bys);
+    
+    final DataPoints[] results = func.evaluate(data_query, query_results, params);
+    
+    assertEquals(2, results.length);
+    assertEquals("sys.mem", results[0].metricName());
+    assertEquals(METRIC, results[1].metricName());
+    
+    long ts = START_TIME;
+    double v = 10;
+    for (DataPoint dp : results[0]) {
+      assertEquals(ts, dp.timestamp());
+      assertFalse(dp.isInteger());
+      assertEquals(v, dp.doubleValue(), 0.001);
+      ts += INTERVAL;
+      v += 1.5;
+    }
+    
+    ts = START_TIME;
+    v = 1;
+    for (DataPoint dp : results[1]) {
+      assertEquals(ts, dp.timestamp());
+      assertTrue(dp.isInteger());
+      assertEquals(v, dp.toDouble(), 0.001);
+      ts += INTERVAL;
+      v += 1;
+    }
+  }
+  
+  @Test
+  public void evaluateTopN1with2SeriesLongDoubleMixed() throws Exception {
+    params.add("1");
+    SeekableView view2 = SeekableViewsForTest.generator(START_TIME, INTERVAL, 
+        NUM_POINTS, false, 10, 1.5, true);
+    DataPoints dps2 = PowerMockito.mock(DataPoints.class);
+    when(dps2.iterator()).thenReturn(view2);
+    when(dps2.metricNameAsync()).thenReturn(Deferred.fromResult("sys.mem"));
+    group_bys = new DataPoints[] { dps, dps2 };
+    query_results.clear();
+    query_results.add(group_bys);
+    
+    final DataPoints[] results = func.evaluate(data_query, query_results, params);
+    
+    assertEquals(1, results.length);
+    assertEquals("sys.mem", results[0].metricName());
+    
+    long ts = START_TIME;
+    double v = 10;
+    boolean toggle = true;
+    for (DataPoint dp : results[0]) {
+      assertEquals(ts, dp.timestamp());
+      if (toggle) {
+        assertTrue(dp.isInteger());
+        assertEquals(v, dp.longValue(), 0.001);
+      } else {
+        assertFalse(dp.isInteger());
+        assertEquals(v, dp.doubleValue(), 0.001);
+      }
+      toggle = !toggle;
+      ts += INTERVAL;
+      v += 1.5;
+    }
+  }
+  
+  @Test
+  public void evaluateTopN1with2SeriesDiffSpan() throws Exception {
+    params.add("1");
+    // in this case one series ends earlier than the other so it's removed
+    // even though it's last value was greater than the winners.
+    SeekableView view2 = SeekableViewsForTest.generator(START_TIME, INTERVAL, 
+        3, true, 10, 1);
+    DataPoints dps2 = PowerMockito.mock(DataPoints.class);
+    when(dps2.iterator()).thenReturn(view2);
+    when(dps2.metricNameAsync()).thenReturn(Deferred.fromResult("sys.mem"));
+    group_bys = new DataPoints[] { dps, dps2 };
+    query_results.clear();
+    query_results.add(group_bys);
+    
+    final DataPoints[] results = func.evaluate(data_query, query_results, params);
+    
+    assertEquals(1, results.length);
+    assertEquals(METRIC, results[0].metricName());
+    
+    long ts = START_TIME;
+    long v = 1;
+    for (DataPoint dp : results[0]) {
+      assertEquals(ts, dp.timestamp());
+      assertTrue(dp.isInteger());
+      assertEquals(v, dp.longValue());
+      ts += INTERVAL;
+      v += 1;
+    }
+  }
+  
+  @Test (expected = IllegalArgumentException.class)
+  public void evaluateNullQuery() throws Exception {
+    params.add("1");
+    func.evaluate(null, query_results, params);
+  }
+  
+  @Test
+  public void evaluateNullResults() throws Exception {
+    params.add("1");
+    final DataPoints[] results = func.evaluate(data_query, null, params);
+    assertEquals(0, results.length);
+  }
+  
+  @Test (expected = IllegalArgumentException.class)
+  public void evaluateNullParams() throws Exception {
+    func.evaluate(data_query, query_results, null);
+  }
+
+  @Test
+  public void evaluateEmptyResults() throws Exception {
+    params.add("1");
+    final DataPoints[] results = func.evaluate(data_query, 
+        Collections.<DataPoints[]>emptyList(), params);
+    assertEquals(0, results.length);
+  }
+  
+  @Test (expected = IllegalArgumentException.class)
+  public void evaluateEmptyParams() throws Exception {
+    func.evaluate(data_query, query_results, params);
+  }
+  
+  @Test (expected = IllegalArgumentException.class)
+  public void evaluateTopnNull() throws Exception {
+    params.add(null);
+    func.evaluate(data_query, query_results, params);
+  }
+  
+  @Test (expected = IllegalArgumentException.class)
+  public void evaluateTopnEmpty() throws Exception {
+    params.add("");
+    func.evaluate(data_query, query_results, params);
+  }
+  
+  @Test (expected = IllegalArgumentException.class)
+  public void evaluateTopnZero() throws Exception {
+    params.add("0");
+    func.evaluate(data_query, query_results, params);
+  }
+  
+  @Test (expected = IllegalArgumentException.class)
+  public void evaluateTopnNotaNumber() throws Exception {
+    params.add("not a number");
+    func.evaluate(data_query, query_results, params);
+  }
+  
+  @Test
+  public void writeStringField() throws Exception {
+    params.add("1");
+    assertEquals("highestCurrent(inner_expression)", 
+        func.writeStringField(params, "inner_expression"));
+    assertEquals("highestCurrent(null)", func.writeStringField(params, null));
+    assertEquals("highestCurrent()", func.writeStringField(params, ""));
+    assertEquals("highestCurrent(inner_expression)", 
+        func.writeStringField(null, "inner_expression"));
+  }
+}
diff --git a/test/query/expression/TestHighestMax.java b/test/query/expression/TestHighestMax.java
new file mode 100644
index 0000000000..66e38689a7
--- /dev/null
+++ b/test/query/expression/TestHighestMax.java
@@ -0,0 +1,365 @@
+// This file is part of OpenTSDB.
+// Copyright (C) 2015  The OpenTSDB Authors.
+//
+// This program is free software: you can redistribute it and/or modify it
+// under the terms of the GNU Lesser General Public License as published by
+// the Free Software Foundation, either version 2.1 of the License, or (at your
+// option) any later version.  This program is distributed in the hope that it
+// will be useful, but WITHOUT ANY WARRANTY; without even the implied warranty
+// of MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser
+// General Public License for more details.  You should have received a copy
+// of the GNU Lesser General Public License along with this program.  If not,
+// see <http://www.gnu.org/licenses/>.
+package net.opentsdb.query.expression;
+
+import static org.junit.Assert.assertEquals;
+import static org.junit.Assert.assertFalse;
+import static org.junit.Assert.assertTrue;
+import static org.mockito.Mockito.mock;
+import static org.mockito.Mockito.when;
+
+import java.util.ArrayList;
+import java.util.Collections;
+import java.util.List;
+
+import net.opentsdb.core.DataPoint;
+import net.opentsdb.core.DataPoints;
+import net.opentsdb.core.SeekableView;
+import net.opentsdb.core.SeekableViewsForTest;
+import net.opentsdb.core.TSQuery;
+
+import org.junit.Before;
+import org.junit.Test;
+import org.junit.runner.RunWith;
+import org.powermock.api.mockito.PowerMockito;
+import org.powermock.core.classloader.annotations.PowerMockIgnore;
+import org.powermock.core.classloader.annotations.PrepareForTest;
+import org.powermock.modules.junit4.PowerMockRunner;
+
+import com.stumbleupon.async.Deferred;
+
+@RunWith(PowerMockRunner.class)
+@PowerMockIgnore({"javax.management.*", "javax.xml.*",
+  "ch.qos.*", "org.slf4j.*",
+  "com.sum.*", "org.xml.*"})
+@PrepareForTest({ TSQuery.class })
+public class TestHighestMax {
+
+  private static long START_TIME = 1356998400000L;
+  private static int INTERVAL = 60000;
+  private static int NUM_POINTS = 5;
+  private static String METRIC = "sys.cpu";
+  
+  private TSQuery data_query;
+  private SeekableView view;
+  private DataPoints dps;
+  private DataPoints[] group_bys;
+  private List<DataPoints[]> query_results;
+  private List<String> params;
+  private HighestMax func;
+  
+  @Before
+  public void before() throws Exception {
+    view = SeekableViewsForTest.generator(START_TIME, INTERVAL, 
+        NUM_POINTS, true, 1, 1);
+    data_query = mock(TSQuery.class);
+    when(data_query.startTime()).thenReturn(START_TIME);
+    when(data_query.endTime()).thenReturn(START_TIME + (INTERVAL * NUM_POINTS));
+    
+    dps = PowerMockito.mock(DataPoints.class);
+    when(dps.iterator()).thenReturn(view);
+    when(dps.metricNameAsync()).thenReturn(Deferred.fromResult(METRIC));
+    
+    group_bys = new DataPoints[] { dps };
+    
+    query_results = new ArrayList<DataPoints[]>(1);
+    query_results.add(group_bys);
+    
+    params = new ArrayList<String>(1);
+    func = new HighestMax();
+  }
+  
+  @Test
+  public void evaluateTopN1with2SeriesLong() throws Exception {
+    params.add("1");
+    SeekableView view2 = SeekableViewsForTest.generator(START_TIME, INTERVAL, 
+        NUM_POINTS, true, 10, 1);
+    DataPoints dps2 = PowerMockito.mock(DataPoints.class);
+    when(dps2.iterator()).thenReturn(view2);
+    when(dps2.metricNameAsync()).thenReturn(Deferred.fromResult("sys.mem"));
+    group_bys = new DataPoints[] { dps, dps2 };
+    query_results.clear();
+    query_results.add(group_bys);
+    
+    final DataPoints[] results = func.evaluate(data_query, query_results, params);
+    
+    assertEquals(1, results.length);
+    assertEquals("sys.mem", results[0].metricName());
+    
+    long ts = START_TIME;
+    long v = 10;
+    for (DataPoint dp : results[0]) {
+      assertEquals(ts, dp.timestamp());
+      assertTrue(dp.isInteger());
+      assertEquals(v, dp.longValue());
+      ts += INTERVAL;
+      v += 1;
+    }
+  }
+  
+  @Test
+  public void evaluateTopN2with2SeriesLong() throws Exception {
+    params.add("2");
+    SeekableView view2 = SeekableViewsForTest.generator(START_TIME, INTERVAL, 
+        NUM_POINTS, true, 10, 1);
+    DataPoints dps2 = PowerMockito.mock(DataPoints.class);
+    when(dps2.iterator()).thenReturn(view2);
+    when(dps2.metricNameAsync()).thenReturn(Deferred.fromResult("sys.mem"));
+    group_bys = new DataPoints[] { dps, dps2 };
+    query_results.clear();
+    query_results.add(group_bys);
+    
+    final DataPoints[] results = func.evaluate(data_query, query_results, params);
+    
+    assertEquals(2, results.length);
+    assertEquals("sys.mem", results[0].metricName());
+    assertEquals(METRIC, results[1].metricName());
+    
+    long ts = START_TIME;
+    long v = 10;
+    for (DataPoint dp : results[0]) {
+      assertEquals(ts, dp.timestamp());
+      assertTrue(dp.isInteger());
+      assertEquals(v, dp.longValue());
+      ts += INTERVAL;
+      v += 1;
+    }
+    
+    ts = START_TIME;
+    v = 1;
+    for (DataPoint dp : results[1]) {
+      assertEquals(ts, dp.timestamp());
+      assertTrue(dp.isInteger());
+      assertEquals(v, dp.longValue());
+      ts += INTERVAL;
+      v += 1;
+    }
+  }
+  
+  @Test
+  public void evaluateTopN100with2SeriesLong() throws Exception {
+    params.add("100");
+    SeekableView view2 = SeekableViewsForTest.generator(START_TIME, INTERVAL, 
+        NUM_POINTS, true, 10, 1);
+    DataPoints dps2 = PowerMockito.mock(DataPoints.class);
+    when(dps2.iterator()).thenReturn(view2);
+    when(dps2.metricNameAsync()).thenReturn(Deferred.fromResult("sys.mem"));
+    DataPoints[] group_bys2 = new DataPoints[] { dps2 };
+    query_results.add(group_bys2);
+    
+    final DataPoints[] results = func.evaluate(data_query, query_results, params);
+    
+    assertEquals(2, results.length);
+    assertEquals("sys.mem", results[0].metricName());
+    assertEquals(METRIC, results[1].metricName());
+    
+    long ts = START_TIME;
+    long v = 10;
+    for (DataPoint dp : results[0]) {
+      assertEquals(ts, dp.timestamp());
+      assertTrue(dp.isInteger());
+      assertEquals(v, dp.longValue());
+      ts += INTERVAL;
+      v += 1;
+    }
+    
+    ts = START_TIME;
+    v = 1;
+    for (DataPoint dp : results[1]) {
+      assertEquals(ts, dp.timestamp());
+      assertTrue(dp.isInteger());
+      assertEquals(v, dp.longValue());
+      ts += INTERVAL;
+      v += 1;
+    }
+  }
+  
+  @Test
+  public void evaluateTopN100with2SubQuerySeriesLong() throws Exception {
+    params.add("100");
+    SeekableView view2 = SeekableViewsForTest.generator(START_TIME, INTERVAL, 
+        NUM_POINTS, true, 10, 1);
+    DataPoints dps2 = PowerMockito.mock(DataPoints.class);
+    when(dps2.iterator()).thenReturn(view2);
+    when(dps2.metricNameAsync()).thenReturn(Deferred.fromResult("sys.mem"));
+    group_bys = new DataPoints[] { dps, dps2 };
+    query_results.clear();
+    query_results.add(group_bys);
+    
+    final DataPoints[] results = func.evaluate(data_query, query_results, params);
+    
+    assertEquals(2, results.length);
+    assertEquals("sys.mem", results[0].metricName());
+    assertEquals(METRIC, results[1].metricName());
+    
+    long ts = START_TIME;
+    long v = 10;
+    for (DataPoint dp : results[0]) {
+      assertEquals(ts, dp.timestamp());
+      assertTrue(dp.isInteger());
+      assertEquals(v, dp.longValue());
+      ts += INTERVAL;
+      v += 1;
+    }
+    
+    ts = START_TIME;
+    v = 1;
+    for (DataPoint dp : results[1]) {
+      assertEquals(ts, dp.timestamp());
+      assertTrue(dp.isInteger());
+      assertEquals(v, dp.longValue());
+      ts += INTERVAL;
+      v += 1;
+    }
+  }
+  
+  @Test
+  public void evaluateTopN2with2SeriesDouble() throws Exception {
+    params.add("2");
+    SeekableView view2 = SeekableViewsForTest.generator(START_TIME, INTERVAL, 
+        NUM_POINTS, false, 10, 1.5);
+    DataPoints dps2 = PowerMockito.mock(DataPoints.class);
+    when(dps2.iterator()).thenReturn(view2);
+    when(dps2.metricNameAsync()).thenReturn(Deferred.fromResult("sys.mem"));
+    group_bys = new DataPoints[] { dps, dps2 };
+    query_results.clear();
+    query_results.add(group_bys);
+    
+    final DataPoints[] results = func.evaluate(data_query, query_results, params);
+    
+    assertEquals(2, results.length);
+    assertEquals("sys.mem", results[0].metricName());
+    assertEquals(METRIC, results[1].metricName());
+    
+    long ts = START_TIME;
+    double v = 10;
+    for (DataPoint dp : results[0]) {
+      assertEquals(ts, dp.timestamp());
+      assertFalse(dp.isInteger());
+      assertEquals(v, dp.doubleValue(), 0.001);
+      ts += INTERVAL;
+      v += 1.5;
+    }
+    
+    ts = START_TIME;
+    v = 1;
+    for (DataPoint dp : results[1]) {
+      assertEquals(ts, dp.timestamp());
+      assertTrue(dp.isInteger());
+      assertEquals(v, dp.toDouble(), 0.001);
+      ts += INTERVAL;
+      v += 1;
+    }
+  }
+  
+  @Test
+  public void evaluateTopN1with2SeriesLongDoubleMixed() throws Exception {
+    params.add("1");
+    SeekableView view2 = SeekableViewsForTest.generator(START_TIME, INTERVAL, 
+        NUM_POINTS, false, 10, 1.5, true);
+    DataPoints dps2 = PowerMockito.mock(DataPoints.class);
+    when(dps2.iterator()).thenReturn(view2);
+    when(dps2.metricNameAsync()).thenReturn(Deferred.fromResult("sys.mem"));
+    group_bys = new DataPoints[] { dps, dps2 };
+    query_results.clear();
+    query_results.add(group_bys);
+    
+    final DataPoints[] results = func.evaluate(data_query, query_results, params);
+    
+    assertEquals(1, results.length);
+    assertEquals("sys.mem", results[0].metricName());
+    
+    long ts = START_TIME;
+    double v = 10;
+    boolean toggle = true;
+    for (DataPoint dp : results[0]) {
+      assertEquals(ts, dp.timestamp());
+      if (toggle) {
+        assertTrue(dp.isInteger());
+        assertEquals(v, dp.longValue(), 0.001);
+      } else {
+        assertFalse(dp.isInteger());
+        assertEquals(v, dp.doubleValue(), 0.001);
+      }
+      toggle = !toggle;
+      ts += INTERVAL;
+      v += 1.5;
+    }
+  }
+  
+  @Test (expected = IllegalArgumentException.class)
+  public void evaluateNullQuery() throws Exception {
+    params.add("1");
+    func.evaluate(null, query_results, params);
+  }
+  
+  @Test
+  public void evaluateNullResults() throws Exception {
+    params.add("1");
+    final DataPoints[] results = func.evaluate(data_query, null, params);
+    assertEquals(0, results.length);
+  }
+  
+  @Test (expected = IllegalArgumentException.class)
+  public void evaluateNullParams() throws Exception {
+    func.evaluate(data_query, query_results, null);
+  }
+
+  @Test
+  public void evaluateEmptyResults() throws Exception {
+    params.add("1");
+    final DataPoints[] results = func.evaluate(data_query, 
+        Collections.<DataPoints[]>emptyList(), params);
+    assertEquals(0, results.length);
+  }
+  
+  @Test (expected = IllegalArgumentException.class)
+  public void evaluateEmptyParams() throws Exception {
+    func.evaluate(data_query, query_results, params);
+  }
+  
+  @Test (expected = IllegalArgumentException.class)
+  public void evaluateTopnNull() throws Exception {
+    params.add(null);
+    func.evaluate(data_query, query_results, params);
+  }
+  
+  @Test (expected = IllegalArgumentException.class)
+  public void evaluateTopnEmpty() throws Exception {
+    params.add("");
+    func.evaluate(data_query, query_results, params);
+  }
+  
+  @Test (expected = IllegalArgumentException.class)
+  public void evaluateTopnZero() throws Exception {
+    params.add("0");
+    func.evaluate(data_query, query_results, params);
+  }
+  
+  @Test (expected = IllegalArgumentException.class)
+  public void evaluateTopnNotaNumber() throws Exception {
+    params.add("not a number");
+    func.evaluate(data_query, query_results, params);
+  }
+  
+  @Test
+  public void writeStringField() throws Exception {
+    params.add("1");
+    assertEquals("highestMax(inner_expression)", 
+        func.writeStringField(params, "inner_expression"));
+    assertEquals("highestMax(null)", func.writeStringField(params, null));
+    assertEquals("highestMax()", func.writeStringField(params, ""));
+    assertEquals("highestMax(inner_expression)", 
+        func.writeStringField(null, "inner_expression"));
+  }
+}
diff --git a/test/query/expression/TestIntersectionIterator.java b/test/query/expression/TestIntersectionIterator.java
new file mode 100644
index 0000000000..80adf6ca43
--- /dev/null
+++ b/test/query/expression/TestIntersectionIterator.java
@@ -0,0 +1,813 @@
+// This file is part of OpenTSDB.
+// Copyright (C) 2015  The OpenTSDB Authors.
+//
+// This program is free software: you can redistribute it and/or modify it
+// under the terms of the GNU Lesser General Public License as published by
+// the Free Software Foundation, either version 2.1 of the License, or (at your
+// option) any later version.  This program is distributed in the hope that it
+// will be useful, but WITHOUT ANY WARRANTY; without even the implied warranty
+// of MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser
+// General Public License for more details.  You should have received a copy
+// of the GNU Lesser General Public License along with this program.  If not,
+// see <http://www.gnu.org/licenses/>.
+package net.opentsdb.query.expression;
+
+import static org.junit.Assert.assertArrayEquals;
+import static org.junit.Assert.assertEquals;
+import static org.junit.Assert.assertFalse;
+import static org.junit.Assert.assertTrue;
+import static org.mockito.Mockito.mock;
+import static org.mockito.Mockito.when;
+
+import java.util.HashMap;
+import java.util.Map;
+
+import org.hbase.async.HBaseClient;
+import org.hbase.async.Bytes.ByteMap;
+import org.junit.Before;
+import org.junit.Test;
+import org.junit.runner.RunWith;
+import org.powermock.core.classloader.annotations.PowerMockIgnore;
+import org.powermock.core.classloader.annotations.PrepareForTest;
+import org.powermock.modules.junit4.PowerMockRunner;
+
+import net.opentsdb.core.DataPoint;
+import net.opentsdb.core.FillPolicy;
+import net.opentsdb.core.IllegalDataException;
+import net.opentsdb.storage.MockBase;
+import net.opentsdb.utils.ByteSet;
+
+@RunWith(PowerMockRunner.class)
+@PowerMockIgnore({"javax.management.*", "javax.xml.*",
+  "ch.qos.*", "org.slf4j.*",
+  "com.sum.*", "org.xml.*"})
+@PrepareForTest({ TimeSyncedIterator.class })
+public class TestIntersectionIterator extends BaseTimeSyncedIteratorTest  {
+
+  /** used for the flattenTags tests */
+  private static final byte[] UID1 = new byte[] { 0, 0, 1 };
+  private static final byte[] UID2 = new byte[] { 0, 0, 2 };
+  private static final byte[] UID3 = new byte[] { 0, 0, 3 };  
+  private ByteMap<byte[]> tags;
+  private ByteSet agg_tags;
+  private ITimeSyncedIterator sub;
+  private ByteSet query_tags;
+  
+  @Before
+  public void beforeLocal() throws Exception {
+    tags = new ByteMap<byte[]>();
+    tags.put(UID1, UID1);
+    tags.put(UID2, UID2);
+    
+    agg_tags = new ByteSet();
+    agg_tags.add(UID3);
+    
+    sub = mock(ITimeSyncedIterator.class);
+    query_tags = new ByteSet();
+    query_tags.add(UID1);
+    when(sub.getQueryTagKs()).thenReturn(query_tags);
+  }
+
+  @Test (expected = NullPointerException.class)
+  public void ctorNullResults() {
+    new IntersectionIterator("it", null, true, true);
+  }
+  
+  @Test
+  public void ctorEmptyResults() {
+    final IntersectionIterator it = new IntersectionIterator("it",
+        new HashMap<String, ITimeSyncedIterator>(), true, true);
+    assertEquals(0, it.getSeriesSize());
+    assertFalse(it.hasNext());
+  }
+  
+  @Test
+  public void twoAndThreeSeries() throws Exception {
+    oneExtraSameE();
+    queryAB_Dstar();
+    
+    final IntersectionIterator it = new IntersectionIterator("it", iterators, false, false);
+    final Map<String, ExpressionDataPoint[]> dps = it.getResults();
+    assertTrue(it.hasNext());
+    assertEquals(2, dps.size());
+    assertEquals(2, it.getSeriesSize());
+    
+    long ts = 1431561600000L;
+    double values[] = new double[] { 1, 4, 11, 14 };
+    while (it.hasNext()) {
+      it.next();
+      
+      DataPoint[] set_dps = dps.get("0");
+      assertEquals(2, set_dps.length);
+      assertEquals(ts, set_dps[0].timestamp());
+      assertEquals(ts, set_dps[1].timestamp());
+      assertEquals(values[0]++, set_dps[0].toDouble(), 0.0001);
+      assertEquals(values[1]++, set_dps[1].toDouble(), 0.0001);
+      
+      set_dps = dps.get("1");
+      assertEquals(2, set_dps.length);
+      assertEquals(ts, set_dps[0].timestamp());
+      assertEquals(ts, set_dps[1].timestamp());
+      assertEquals(values[2]++, set_dps[0].toDouble(), 0.0001);
+      assertEquals(values[3]++, set_dps[1].toDouble(), 0.0001);
+
+      ts += 60000;
+    }
+  }
+  
+  @Test
+  public void twoAndThreeSeriesExtraDPinKickedSeries() throws Exception {
+    // in this case we want to make sure the kicked series doesn't cause us
+    // to dump a bunch of nulls
+    oneExtraSameE();
+    queryAB_Dstar();
+    
+    final HashMap<String, String> tags = new HashMap<String, String>(2);
+    tags.put("D", "G");
+    tags.put("E", "E");
+    tsdb.addPoint("B", 1431561630, 14, tags).joinUninterruptibly();
+    
+    final IntersectionIterator it = new IntersectionIterator("it", iterators, false, false);
+    final Map<String, ExpressionDataPoint[]> dps = it.getResults();
+    assertTrue(it.hasNext());
+    assertEquals(2, dps.size());
+    assertEquals(2, it.getSeriesSize());
+    
+    long ts = 1431561600000L;
+    double values[] = new double[] { 1, 4, 11, 14 };
+    while (it.hasNext()) {
+      it.next();
+      
+      DataPoint[] set_dps = dps.get("0");
+      assertEquals(2, set_dps.length);
+      assertEquals(ts, set_dps[0].timestamp());
+      assertEquals(ts, set_dps[1].timestamp());
+      assertEquals(values[0]++, set_dps[0].toDouble(), 0.0001);
+      assertEquals(values[1]++, set_dps[1].toDouble(), 0.0001);
+      
+      set_dps = dps.get("1");
+      assertEquals(2, set_dps.length);
+      assertEquals(ts, set_dps[0].timestamp());
+      assertEquals(ts, set_dps[1].timestamp());
+      assertEquals(values[2]++, set_dps[0].toDouble(), 0.0001);
+      assertEquals(values[3]++, set_dps[1].toDouble(), 0.0001);
+
+      ts += 60000;
+    }
+  }
+  
+  @Test
+  public void threeSeriesIntersectToTwo() throws Exception {
+    threeDisjointSameE();
+    queryAB_Dstar();
+    
+    final IntersectionIterator it = new IntersectionIterator("it", iterators, false, false);
+    final Map<String, ExpressionDataPoint[]> dps = it.getResults();
+    assertTrue(it.hasNext());
+    assertEquals(2, dps.size());
+    assertEquals(2, it.getSeriesSize());
+    
+    long ts = 1431561600000L;
+    double values[] = new double[] { 1, 7, 11, 17 };
+    while (it.hasNext()) {
+      it.next();
+      
+      DataPoint[] set_dps = dps.get("0");
+      assertEquals(2, set_dps.length);
+      assertEquals(ts, set_dps[0].timestamp());
+      assertEquals(ts, set_dps[1].timestamp());
+      assertEquals(values[0]++, set_dps[0].toDouble(), 0.0001);
+      assertEquals(values[1]++, set_dps[1].toDouble(), 0.0001);
+      
+      set_dps = dps.get("1");
+      assertEquals(2, set_dps.length);
+      assertEquals(ts, set_dps[0].timestamp());
+      assertEquals(ts, set_dps[1].timestamp());
+      assertEquals(values[2]++, set_dps[0].toDouble(), 0.0001);
+      assertEquals(values[3]++, set_dps[1].toDouble(), 0.0001);
+
+      ts += 60000;
+    }
+  }
+  
+  @Test
+  public void threeSeriesIntersectToExtraDPsinKicked() throws Exception {
+    reduceToOne();
+    queryAB_Dstar();
+    
+    HashMap<String, String> tags = new HashMap<String, String>(2);
+    tags.put("D", "F");
+    tags.put("E", "E");
+    tsdb.addPoint("A", 1431561630, 1024, tags).joinUninterruptibly();
+    
+    tags = new HashMap<String, String>(2);
+    tags.put("D", "Q");
+    tags.put("E", "E");
+    tsdb.addPoint("B", 1431561630, 1024, tags).joinUninterruptibly();
+    
+    final IntersectionIterator it = new IntersectionIterator("it", iterators, false, false);
+    final Map<String, ExpressionDataPoint[]> dps = it.getResults();
+    assertTrue(it.hasNext());
+    assertEquals(2, dps.size());
+    assertEquals(1, it.getSeriesSize());
+    
+    long ts = 1431561600000L;
+    double values[] = new double[] { 7, 17 };
+    while (it.hasNext()) {
+      it.next();
+
+      DataPoint[] set_dps = dps.get("0");
+      assertEquals(1, set_dps.length);
+      assertEquals(ts, set_dps[0].timestamp());
+      assertEquals(values[0]++, set_dps[0].toDouble(), 0.0001);
+      
+      set_dps = dps.get("1");
+      assertEquals(1, set_dps.length);
+      assertEquals(ts, set_dps[0].timestamp());
+      assertEquals(values[1]++, set_dps[0].toDouble(), 0.0001);
+
+      ts += 60000;
+    }
+  }
+  
+  @Test
+  public void threeSeriesIntersectToOne() throws Exception {
+    reduceToOne();
+    queryAB_Dstar();
+    
+    final IntersectionIterator it = new IntersectionIterator("it", iterators, false, false);
+    final Map<String, ExpressionDataPoint[]> dps = it.getResults();
+    assertTrue(it.hasNext());
+    assertEquals(2, dps.size());
+    assertEquals(1, it.getSeriesSize());
+    
+    long ts = 1431561600000L;
+    double values[] = new double[] { 7, 17 };
+    while (it.hasNext()) {
+      it.next();
+      
+      DataPoint[] set_dps = dps.get("0");
+      assertEquals(1, set_dps.length);
+      assertEquals(ts, set_dps[0].timestamp());
+      assertEquals(values[0]++, set_dps[0].toDouble(), 0.0001);
+      
+      set_dps = dps.get("1");
+      assertEquals(1, set_dps.length);
+      assertEquals(ts, set_dps[0].timestamp());
+      assertEquals(values[1]++, set_dps[0].toDouble(), 0.0001);
+
+      ts += 60000;
+    }
+  }
+  
+  @Test
+  public void threeSeriesAggedIntoOne() throws Exception {
+    threeSameE();
+    queryAB_AggAll();
+    
+    final IntersectionIterator it = new IntersectionIterator("it", iterators, false, false);
+    final Map<String, ExpressionDataPoint[]> dps = it.getResults();
+    assertTrue(it.hasNext());
+    assertEquals(2, dps.size());
+    assertEquals(1, it.getSeriesSize());
+    
+    long ts = 1431561600000L;
+    double values[] = new double[] { 12, 42 };
+    while (it.hasNext()) {
+      it.next();
+      
+      DataPoint[] set_dps = dps.get("0");
+      assertEquals(1, set_dps.length);
+      assertEquals(ts, set_dps[0].timestamp());
+      assertEquals(values[0], set_dps[0].toDouble(), 0.0001);
+      
+      set_dps = dps.get("1");
+      assertEquals(1, set_dps.length);
+      assertEquals(ts, set_dps[0].timestamp());
+      assertEquals(values[1], set_dps[0].toDouble(), 0.0001);
+      
+      values[0] += 3;
+      values[1] += 3;
+
+      ts += 60000;
+    }
+  }
+  
+  @Test
+  public void threeSeriesFullIntersetWithNaNs() throws Exception {
+    threeSameEGaps();
+    queryAB_Dstar();
+    for (ITimeSyncedIterator iterator : iterators.values()) {
+      iterator.setFillPolicy(new NumericFillPolicy(FillPolicy.NOT_A_NUMBER));
+    }
+    
+    final IntersectionIterator it = new IntersectionIterator("it", iterators, false, false);
+    final Map<String, ExpressionDataPoint[]> dps = it.getResults();
+    assertTrue(it.hasNext());
+    assertEquals(2, dps.size());
+    assertEquals(3, it.getSeriesSize());
+    
+    long ts = 1431561600000L;
+    it.next();
+    
+    DataPoint[] set_dps = dps.get("0");
+    assertEquals(3, set_dps.length);
+    assertEquals(ts, set_dps[0].timestamp());
+    assertEquals(ts, set_dps[1].timestamp());
+    assertEquals(ts, set_dps[2].timestamp());
+    assertEquals(1, set_dps[0].toDouble(), 0.0001);
+    assertEquals(4, set_dps[1].toDouble(), 0.0001);
+    assertTrue(Double.isNaN(set_dps[2].toDouble()));
+    
+    // whole series is NaN'd
+    set_dps = dps.get("1");
+    assertEquals(3, set_dps.length);
+    assertEquals(ts, set_dps[0].timestamp());
+    assertEquals(ts, set_dps[1].timestamp());
+    assertEquals(ts, set_dps[2].timestamp());
+    assertTrue(Double.isNaN(set_dps[0].toDouble()));
+    assertTrue(Double.isNaN(set_dps[1].toDouble()));
+    assertTrue(Double.isNaN(set_dps[2].toDouble()));
+
+    ts += 60000;
+    it.next();
+    
+    set_dps = dps.get("0");
+    assertEquals(3, set_dps.length);
+    assertEquals(ts, set_dps[0].timestamp());
+    assertEquals(ts, set_dps[1].timestamp());
+    assertEquals(ts, set_dps[2].timestamp());
+    assertTrue(Double.isNaN(set_dps[0].toDouble()));
+    assertEquals(5, set_dps[1].toDouble(), 0.0001);
+    assertEquals(8, set_dps[2].toDouble(), 0.0001);
+    
+    set_dps = dps.get("1");
+    assertEquals(3, set_dps.length);
+    assertEquals(ts, set_dps[0].timestamp());
+    assertEquals(ts, set_dps[1].timestamp());
+    assertEquals(ts, set_dps[2].timestamp());
+    assertTrue(Double.isNaN(set_dps[0].toDouble()));
+    assertEquals(15, set_dps[1].toDouble(), 0.0001);
+    assertTrue(Double.isNaN(set_dps[2].toDouble()));
+
+    ts += 60000;
+    it.next();
+    
+    set_dps = dps.get("0");
+    assertEquals(3, set_dps.length);
+    assertEquals(ts, set_dps[0].timestamp());
+    assertEquals(ts, set_dps[1].timestamp());
+    assertEquals(ts, set_dps[2].timestamp());
+    assertEquals(3, set_dps[0].toDouble(), 0.0001);
+    assertTrue(Double.isNaN(set_dps[1].toDouble()));
+    assertEquals(9, set_dps[2].toDouble(), 0.0001);
+    
+    set_dps = dps.get("1");
+    assertEquals(3, set_dps.length);
+    assertEquals(ts, set_dps[0].timestamp());
+    assertEquals(ts, set_dps[1].timestamp());
+    assertEquals(ts, set_dps[2].timestamp());
+    assertEquals(13, set_dps[0].toDouble(), 0.0001);
+    assertTrue(Double.isNaN(set_dps[1].toDouble()));
+    assertEquals(19, set_dps[2].toDouble(), 0.0001);
+
+    assertFalse(it.hasNext());
+  }
+  
+  @Test
+  public void twoSeriesTimeOffset() throws Exception {
+    timeOffset();
+    queryAB_Dstar();
+    for (ITimeSyncedIterator iterator : iterators.values()) {
+      iterator.setFillPolicy(new NumericFillPolicy(FillPolicy.NOT_A_NUMBER));
+    }
+    
+    final IntersectionIterator it = new IntersectionIterator("it", iterators, false, false);
+    final Map<String, ExpressionDataPoint[]> dps = it.getResults();
+    assertTrue(it.hasNext());
+    assertEquals(2, dps.size());
+    assertEquals(2, it.getSeriesSize());
+    
+    long ts = 1431561600000L;
+    it.next();
+    
+    DataPoint[] set_dps = dps.get("0");
+    assertEquals(2, set_dps.length);
+    assertEquals(ts, set_dps[0].timestamp());
+    assertEquals(ts, set_dps[1].timestamp());
+    assertEquals(1, set_dps[0].toDouble(), 0.0001);
+    assertEquals(4, set_dps[1].toDouble(), 0.0001);
+    
+    set_dps = dps.get("1");
+    assertEquals(2, set_dps.length);
+    assertEquals(ts, set_dps[0].timestamp());
+    assertEquals(ts, set_dps[1].timestamp());
+    assertTrue(Double.isNaN(set_dps[0].toDouble()));
+    assertTrue(Double.isNaN(set_dps[1].toDouble()));
+
+    ts += 60000;
+    it.next();
+    
+    set_dps = dps.get("0");
+    assertEquals(2, set_dps.length);
+    assertEquals(ts, set_dps[0].timestamp());
+    assertEquals(ts, set_dps[1].timestamp());
+    assertEquals(2, set_dps[0].toDouble(), 0.0001);
+    assertEquals(5, set_dps[1].toDouble(), 0.0001);
+    
+    set_dps = dps.get("1");
+    assertEquals(2, set_dps.length);
+    assertEquals(ts, set_dps[0].timestamp());
+    assertEquals(ts, set_dps[1].timestamp());
+    assertTrue(Double.isNaN(set_dps[0].toDouble()));
+    assertTrue(Double.isNaN(set_dps[1].toDouble()));
+
+    ts += 60000;
+    it.next();
+    
+    set_dps = dps.get("0");
+    assertEquals(2, set_dps.length);
+    assertEquals(ts, set_dps[0].timestamp());
+    assertEquals(ts, set_dps[1].timestamp());
+    assertTrue(Double.isNaN(set_dps[0].toDouble()));
+    assertTrue(Double.isNaN(set_dps[1].toDouble()));
+    
+    set_dps = dps.get("1");
+    assertEquals(2, set_dps.length);
+    assertEquals(ts, set_dps[0].timestamp());
+    assertEquals(ts, set_dps[1].timestamp());
+    assertEquals(13, set_dps[0].toDouble(), 0.0001);
+    assertEquals(16, set_dps[1].toDouble(), 0.0001);
+
+    ts += 60000;
+    it.next();
+    
+    set_dps = dps.get("0");
+    assertEquals(2, set_dps.length);
+    assertEquals(ts, set_dps[0].timestamp());
+    assertEquals(ts, set_dps[1].timestamp());
+    assertTrue(Double.isNaN(set_dps[0].toDouble()));
+    assertTrue(Double.isNaN(set_dps[1].toDouble()));
+    
+    set_dps = dps.get("1");
+    assertEquals(2, set_dps.length);
+    assertEquals(ts, set_dps[0].timestamp());
+    assertEquals(ts, set_dps[1].timestamp());
+    assertEquals(14, set_dps[0].toDouble(), 0.0001);
+    assertEquals(17, set_dps[1].toDouble(), 0.0001);
+    
+    assertFalse(it.hasNext());
+  }
+  
+  @Test (expected = IllegalDataException.class)
+  public void noIntersectionUsingResultTags() throws Exception {
+    threeDifE();
+    queryAB_Dstar();
+    new IntersectionIterator("it", iterators, false, false);
+  }
+  
+  @Test
+  public void intersectUsingQueryTags() throws Exception {
+    threeDifE();
+    queryAB_Dstar();
+    
+    final IntersectionIterator it = new IntersectionIterator("it", iterators, true, false);
+    final Map<String, ExpressionDataPoint[]> dps = it.getResults();
+    assertTrue(it.hasNext());
+    assertEquals(2, dps.size());
+    assertEquals(3, it.getSeriesSize());
+    
+    long ts = 1431561600000L;
+    double values[] = new double[] { 1, 4, 7, 11, 14, 17 };
+    while (it.hasNext()) {
+      it.next();
+      
+      DataPoint[] set_dps = dps.get("0");
+      assertEquals(3, set_dps.length);
+      assertEquals(ts, set_dps[0].timestamp());
+      assertEquals(ts, set_dps[1].timestamp());
+      assertEquals(ts, set_dps[2].timestamp());
+      assertEquals(values[0]++, set_dps[0].toDouble(), 0.0001);
+      assertEquals(values[1]++, set_dps[1].toDouble(), 0.0001);
+      assertEquals(values[2]++, set_dps[2].toDouble(), 0.0001);
+      
+      set_dps = dps.get("1");
+      assertEquals(3, set_dps.length);
+      assertEquals(ts, set_dps[0].timestamp());
+      assertEquals(ts, set_dps[1].timestamp());
+      assertEquals(ts, set_dps[2].timestamp());
+      assertEquals(values[3]++, set_dps[0].toDouble(), 0.0001);
+      assertEquals(values[4]++, set_dps[1].toDouble(), 0.0001);
+      assertEquals(values[5]++, set_dps[2].toDouble(), 0.0001);
+
+      ts += 60000;
+    }
+  }
+  
+  @Test
+  public void commonAggregatedTag() throws Exception {
+    twoSeriesAggedE();
+    queryAB_Dstar();
+    
+    final IntersectionIterator it = new IntersectionIterator("it", iterators, false, false);
+    final Map<String, ExpressionDataPoint[]> dps = it.getResults();
+    assertTrue(it.hasNext());
+    assertEquals(2, dps.size());
+    assertEquals(1, it.getSeriesSize());
+    
+    long ts = 1431561600000L;
+    double values[] = new double[] { 2, 22 };
+    while (it.hasNext()) {
+      it.next();
+      
+      DataPoint[] set_dps = dps.get("0");
+      assertEquals(1, set_dps.length);
+      assertEquals(ts, set_dps[0].timestamp());
+      assertEquals(values[0], set_dps[0].toDouble(), 0.0001);
+      
+      set_dps = dps.get("1");
+      assertEquals(1, set_dps.length);
+      assertEquals(ts, set_dps[0].timestamp());
+      assertEquals(values[1], set_dps[0].toDouble(), 0.0001);
+
+      values[0] += 2;
+      values[1] += 2;
+      
+      ts += 60000;
+    }
+  }
+  
+  @Test
+  public void extraAggTagIgnored() throws Exception {
+    twoSeriesAggedEandExtraTagK();
+    queryAB_Dstar();
+    
+    final IntersectionIterator it = new IntersectionIterator("it", iterators, false, false);
+    final Map<String, ExpressionDataPoint[]> dps = it.getResults();
+    assertTrue(it.hasNext());
+    assertEquals(2, dps.size());
+    assertEquals(1, it.getSeriesSize());
+    
+    long ts = 1431561600000L;
+    double values[] = new double[] { 2, 22 };
+    while (it.hasNext()) {
+      it.next();
+      
+      DataPoint[] set_dps = dps.get("0");
+      assertEquals(1, set_dps.length);
+      assertEquals(ts, set_dps[0].timestamp());
+      assertEquals(values[0], set_dps[0].toDouble(), 0.0001);
+      
+      set_dps = dps.get("1");
+      assertEquals(1, set_dps.length);
+      assertEquals(ts, set_dps[0].timestamp());
+      assertEquals(values[1], set_dps[0].toDouble(), 0.0001);
+
+      values[0] += 2;
+      values[1] += 2;
+      
+      ts += 60000;
+    }
+  }
+  
+  @Test (expected = IllegalDataException.class)
+  public void extraAggTagNoIntersection() throws Exception {
+    twoSeriesAggedEandExtraTagK();
+    queryAB_Dstar();
+    new IntersectionIterator("it", iterators, false, true);
+  }
+  
+  @Test (expected = IllegalDataException.class)
+  public void onlyOneResultSet() throws Exception {
+    threeSameENoB();
+    queryAB_Dstar();
+    new IntersectionIterator("it", iterators, false, true);
+  }
+  
+  @Test (expected = IllegalDataException.class)
+  public void oneAggedOneTaggedNoIntersection() throws Exception {
+    oneAggedTheOtherTagged();
+    queryAB_AggAll();
+    new IntersectionIterator("it", iterators, false, true);
+  }
+  
+  @Test
+  public void oneAggedOneTaggedUseQueryTagsWoutQueryTags() throws Exception {
+    oneAggedTheOtherTagged();
+    queryAB_AggAll();
+    
+    final IntersectionIterator it = new IntersectionIterator("it", iterators, true, false);
+    final Map<String, ExpressionDataPoint[]> dps = it.getResults();
+    assertTrue(it.hasNext());
+    assertEquals(2, dps.size());
+    assertEquals(1, it.getSeriesSize());
+    
+    long ts = 1431561600000L;
+    double values[] = new double[] { 2, 11 };
+    while (it.hasNext()) {
+      it.next();
+      
+      DataPoint[] set_dps = dps.get("0");
+      assertEquals(1, set_dps.length);
+      assertEquals(ts, set_dps[0].timestamp());
+      assertEquals(values[0], set_dps[0].toDouble(), 0.0001);
+      
+      set_dps = dps.get("1");
+      assertEquals(1, set_dps.length);
+      assertEquals(ts, set_dps[0].timestamp());
+      assertEquals(values[1]++, set_dps[0].toDouble(), 0.0001);
+
+      // the first set is agged
+      values[0] += 2;
+      
+      ts += 60000;
+    }
+  }
+  
+  @Test
+  public void singleSeries() throws Exception {
+    oneExtraSameE();
+    queryA_DD();
+    
+    final IntersectionIterator it = new IntersectionIterator("it", iterators, false, false);
+    final Map<String, ExpressionDataPoint[]> dps = it.getResults();
+    assertTrue(it.hasNext());
+    assertEquals(1, dps.size());
+    assertEquals(1, it.getSeriesSize());
+    
+    long ts = 1431561600000L;
+    double value = 1;
+    while (it.hasNext()) {
+      it.next();
+      
+      DataPoint[] set_dps = dps.get("0");
+      assertEquals(1, set_dps.length);
+      assertEquals(ts, set_dps[0].timestamp());
+      assertEquals(value++, set_dps[0].toDouble(), 0.0001);
+
+      ts += 60000;
+    }
+  }
+  
+  @Test (expected = IllegalDataException.class)
+  public void setAMissingE() throws Exception {
+    threeAMissingE();
+    queryAB_Dstar();
+    new IntersectionIterator("it", iterators, false, false);
+  }
+  
+  @Test
+  public void setAMissingEQueryTags() throws Exception {
+    threeAMissingE();
+    queryAB_Dstar();
+    
+    final IntersectionIterator it = new IntersectionIterator("it", iterators, true, false);
+    final Map<String, ExpressionDataPoint[]> dps = it.getResults();
+    assertTrue(it.hasNext());
+    assertEquals(2, dps.size());
+    assertEquals(3, it.getSeriesSize());
+    
+    long ts = 1431561600000L;
+    double values[] = new double[] { 1, 4, 7, 11, 14, 17 };
+    while (it.hasNext()) {
+      it.next();
+      
+      DataPoint[] set_dps = dps.get("0");
+      assertEquals(3, set_dps.length);
+      assertEquals(ts, set_dps[0].timestamp());
+      assertEquals(ts, set_dps[1].timestamp());
+      assertEquals(ts, set_dps[2].timestamp());
+      assertEquals(values[0]++, set_dps[0].toDouble(), 0.0001);
+      assertEquals(values[1]++, set_dps[1].toDouble(), 0.0001);
+      assertEquals(values[2]++, set_dps[2].toDouble(), 0.0001);
+      
+      set_dps = dps.get("1");
+      assertEquals(3, set_dps.length);
+      assertEquals(ts, set_dps[0].timestamp());
+      assertEquals(ts, set_dps[1].timestamp());
+      assertEquals(ts, set_dps[2].timestamp());
+      assertEquals(values[3]++, set_dps[0].toDouble(), 0.0001);
+      assertEquals(values[4]++, set_dps[1].toDouble(), 0.0001);
+      assertEquals(values[5]++, set_dps[2].toDouble(), 0.0001);
+
+      ts += 60000;
+    }
+  }
+  
+  @Test
+  public void noData() throws Exception {
+    setDataPointStorage();
+    queryAB_Dstar();
+    
+    final IntersectionIterator it = new IntersectionIterator("it", iterators, false, false);
+    final Map<String, ExpressionDataPoint[]> dps = it.getResults();
+    assertEquals(0, dps.size());
+    assertFalse(it.hasNext());
+    assertEquals(0, it.getSeriesSize());
+  }
+  
+  @Test (expected = IllegalDataException.class)
+  public void nextException() throws Exception {
+    threeDisjointSameE();
+    queryAB_Dstar();
+    
+    final IntersectionIterator it = new IntersectionIterator("it", iterators, false, false);
+    it.next();
+    it.next();
+    it.next();
+    it.next();
+  }
+ 
+  @Test
+  public void flattenTags() throws Exception {
+    final byte[] flat = IntersectionIterator.flattenTags(
+        false, false, tags, agg_tags, sub);
+    assertArrayEquals(MockBase.concatByteArrays(UID1, UID1, UID2, UID2), flat);
+  }
+  
+  @Test
+  public void flattenTagsWithAgg() throws Exception {
+    final byte[] flat = IntersectionIterator.flattenTags(
+        false, true, tags, agg_tags, sub);
+    assertArrayEquals(
+        MockBase.concatByteArrays(UID1, UID1, UID2, UID2, UID3), flat);
+  }
+  
+  @Test
+  public void flattenTagsQueryTags() throws Exception {
+    final byte[] flat = IntersectionIterator.flattenTags(
+        true, false, tags, agg_tags, sub);
+    assertArrayEquals(MockBase.concatByteArrays(UID1, UID1), flat);
+  }
+  
+  @Test
+  public void flattenTagsQueryTagsWithAgg() throws Exception {
+    final byte[] flat = IntersectionIterator.flattenTags(
+        true, true, tags, agg_tags, sub);
+    assertArrayEquals(MockBase.concatByteArrays(UID1, UID1, UID3), flat);
+  }
+  
+  @Test
+  public void flattenEmptyTags() throws Exception {
+    tags.clear();
+    final byte[] flat = IntersectionIterator.flattenTags(
+        false, false, tags, agg_tags, sub);
+    assertArrayEquals(HBaseClient.EMPTY_ARRAY, flat);
+  }
+  
+  @Test
+  public void flattenEmptyTagsWithAggEmpty() throws Exception {
+    agg_tags.clear();
+    final byte[] flat = IntersectionIterator.flattenTags(
+        false, true, tags, agg_tags, sub);
+    assertArrayEquals(MockBase.concatByteArrays(UID1, UID1, UID2, UID2), flat);
+  }
+  
+  // TODO - how will this play out if we choose a default agg of "none" and the
+  // user hasn't asked for any filtering?
+  @Test
+  public void flattenTagsQueryTagsEmpty() throws Exception {
+    query_tags.clear();
+    final byte[] flat = IntersectionIterator.flattenTags(
+        true, false, tags, agg_tags, sub);
+    assertArrayEquals(HBaseClient.EMPTY_ARRAY, flat);
+  }
+  
+  @Test
+  public void flattenTagsQueryTagsEmptyWithAgg() throws Exception {
+    query_tags.clear();
+    final byte[] flat = IntersectionIterator.flattenTags(
+        true, true, tags, agg_tags, sub);
+    assertArrayEquals(UID3, flat);
+  }
+
+  @Test (expected = NullPointerException.class)
+  public void flattenTagsNullTags() throws Exception {
+    IntersectionIterator.flattenTags(false, false, null, agg_tags, sub);
+  }
+  
+  @Test
+  public void flattenTagsNullAggTagsNotRequested() throws Exception {
+    final byte[] flat = IntersectionIterator.flattenTags(
+        false, false, tags, null, sub);
+    assertArrayEquals(MockBase.concatByteArrays(UID1, UID1, UID2, UID2), flat);
+  }
+  
+  @Test (expected = NullPointerException.class)
+  public void flattenTagsNullAggTags() throws Exception {
+    IntersectionIterator.flattenTags(false, true, tags, null, sub);
+  }
+  
+  @Test
+  public void flattenTagsNullSubNotRequested() throws Exception {
+    final byte[] flat = IntersectionIterator.flattenTags(
+        false, false, tags, agg_tags, null);
+    assertArrayEquals(MockBase.concatByteArrays(UID1, UID1, UID2, UID2), flat);
+  }
+  
+  @Test (expected = NullPointerException.class)
+  public void flattenTagsNullSub() throws Exception {
+    IntersectionIterator.flattenTags(true, false, tags, agg_tags, null);
+  }
+
+}
diff --git a/test/query/expression/TestMovingAverage.java b/test/query/expression/TestMovingAverage.java
new file mode 100644
index 0000000000..3d2be90d99
--- /dev/null
+++ b/test/query/expression/TestMovingAverage.java
@@ -0,0 +1,518 @@
+// This file is part of OpenTSDB.
+// Copyright (C) 2015  The OpenTSDB Authors.
+//
+// This program is free software: you can redistribute it and/or modify it
+// under the terms of the GNU Lesser General Public License as published by
+// the Free Software Foundation, either version 2.1 of the License, or (at your
+// option) any later version.  This program is distributed in the hope that it
+// will be useful, but WITHOUT ANY WARRANTY; without even the implied warranty
+// of MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser
+// General Public License for more details.  You should have received a copy
+// of the GNU Lesser General Public License along with this program.  If not,
+// see <http://www.gnu.org/licenses/>.
+package net.opentsdb.query.expression;
+
+import static org.junit.Assert.assertEquals;
+import static org.junit.Assert.assertFalse;
+import static org.junit.Assert.fail;
+import static org.mockito.Mockito.mock;
+import static org.mockito.Mockito.when;
+
+import java.util.ArrayList;
+import java.util.Collections;
+import java.util.List;
+
+import net.opentsdb.core.DataPoint;
+import net.opentsdb.core.DataPoints;
+import net.opentsdb.core.SeekableView;
+import net.opentsdb.core.SeekableViewsForTest;
+import net.opentsdb.core.TSQuery;
+
+import org.junit.Before;
+import org.junit.Test;
+import org.junit.runner.RunWith;
+import org.powermock.api.mockito.PowerMockito;
+import org.powermock.core.classloader.annotations.PowerMockIgnore;
+import org.powermock.core.classloader.annotations.PrepareForTest;
+import org.powermock.modules.junit4.PowerMockRunner;
+
+import com.stumbleupon.async.Deferred;
+
+@RunWith(PowerMockRunner.class)
+@PowerMockIgnore({"javax.management.*", "javax.xml.*",
+  "ch.qos.*", "org.slf4j.*",
+  "com.sum.*", "org.xml.*"})
+@PrepareForTest({ TSQuery.class })
+public class TestMovingAverage {
+  private static long START_TIME = 1356998400000L;
+  private static int INTERVAL = 60000;
+  private static int NUM_POINTS = 5;
+  private static String METRIC = "sys.cpu";
+  
+  private TSQuery data_query;
+  private SeekableView view;
+  private DataPoints dps;
+  private DataPoints[] group_bys;
+  private List<DataPoints[]> query_results;
+  private List<String> params;
+  private MovingAverage func;
+  
+  @Before
+  public void before() throws Exception {
+    view = SeekableViewsForTest.generator(START_TIME, INTERVAL, 
+        NUM_POINTS, true, 1, 1);
+    data_query = mock(TSQuery.class);
+    when(data_query.startTime()).thenReturn(START_TIME);
+    when(data_query.endTime()).thenReturn(START_TIME + (INTERVAL * NUM_POINTS));
+    
+    dps = PowerMockito.mock(DataPoints.class);
+    when(dps.iterator()).thenReturn(view);
+    when(dps.metricNameAsync()).thenReturn(Deferred.fromResult(METRIC));
+    
+    group_bys = new DataPoints[] { dps };
+    
+    query_results = new ArrayList<DataPoints[]>(1);
+    query_results.add(group_bys);
+    
+    params = new ArrayList<String>(1);
+    func = new MovingAverage();
+  }
+  
+  @Test
+  public void evaluateWindow1dps() throws Exception {
+    params.add("1");
+    
+    final DataPoints[] results = func.evaluate(data_query, query_results, params);
+    
+    assertEquals(1, results.length);
+    assertEquals(METRIC, results[0].metricName());
+    
+    long ts = START_TIME;
+    double v = 1;
+    for (DataPoint dp : results[0]) {
+      assertEquals(ts, dp.timestamp());
+      assertFalse(dp.isInteger());
+      assertEquals(v, dp.doubleValue(), 0.001);
+      ts += INTERVAL;
+      v += 1;
+    }
+  }
+  
+  @Test
+  public void evaluateWindow2dps() throws Exception {
+    params.add("2");
+    
+    final DataPoints[] results = func.evaluate(data_query, query_results, params);
+    
+    assertEquals(1, results.length);
+    assertEquals(METRIC, results[0].metricName());
+    
+    long ts = START_TIME;
+    double v = 0;
+    for (DataPoint dp : results[0]) {
+      assertEquals(ts, dp.timestamp());
+      assertFalse(dp.isInteger());
+      assertEquals(v, dp.doubleValue(), 0.001);
+      ts += INTERVAL;
+      if (v < 1) {
+        v = 1.5;
+      } else {
+        v += 1;
+      }
+    }
+  }
+
+  @Test
+  public void evaluateWindow5dps() throws Exception {
+    params.add("5");
+    
+    final DataPoints[] results = func.evaluate(data_query, query_results, params);
+    
+    assertEquals(1, results.length);
+    assertEquals(METRIC, results[0].metricName());
+    
+    long ts = START_TIME;
+    double v = 0;
+    for (DataPoint dp : results[0]) {
+      assertEquals(ts, dp.timestamp());
+      assertFalse(dp.isInteger());
+      assertEquals(v, dp.doubleValue(), 0.001);
+      ts += INTERVAL;
+      if (ts == 1356998640000L) {
+        v = 3.0;
+      }
+    }
+  }
+  
+  @Test
+  public void evaluateWindow6dps() throws Exception {
+    params.add("6");
+    
+    final DataPoints[] results = func.evaluate(data_query, query_results, params);
+    
+    assertEquals(1, results.length);
+    assertEquals(METRIC, results[0].metricName());
+    
+    long ts = START_TIME;
+    double v = 0;
+    for (DataPoint dp : results[0]) {
+      assertEquals(ts, dp.timestamp());
+      assertFalse(dp.isInteger());
+      assertEquals(v, dp.doubleValue(), 0.001);
+      ts += INTERVAL;
+    }
+  }
+
+  @Test
+  public void evaluateWindow1min() throws Exception {
+    params.add("'1min'");
+    
+    final DataPoints[] results = func.evaluate(data_query, query_results, params);
+    
+    assertEquals(1, results.length);
+    assertEquals(METRIC, results[0].metricName());
+    
+    long ts = START_TIME;
+    double v = 0;
+    for (DataPoint dp : results[0]) {
+      assertEquals(ts, dp.timestamp());
+      assertFalse(dp.isInteger());
+      assertEquals(v, dp.doubleValue(), 0.001);
+      ts += INTERVAL;
+      if (v < 1) {
+        v = 2;
+      } else {
+        v += 1;
+      }
+    }
+  }
+  
+  @Test
+  public void evaluateWindow2min() throws Exception {
+    params.add("'2min'");
+    
+    final DataPoints[] results = func.evaluate(data_query, query_results, params);
+    
+    assertEquals(1, results.length);
+    assertEquals(METRIC, results[0].metricName());
+    
+    long ts = START_TIME;
+    double v = 0;
+    for (DataPoint dp : results[0]) {
+      assertEquals(ts, dp.timestamp());
+      assertFalse(dp.isInteger());
+      assertEquals(v, dp.doubleValue(), 0.001);
+      ts += INTERVAL;
+      if (ts == 1356998520000L) {
+        v = 2.5;
+      } else if (v > 0) {
+        v += 1;
+      }
+    }
+  }
+  
+  @Test
+  public void evaluateWindow3min() throws Exception {
+    params.add("'3min'");
+    
+    final DataPoints[] results = func.evaluate(data_query, query_results, params);
+    
+    assertEquals(1, results.length);
+    assertEquals(METRIC, results[0].metricName());
+    
+    long ts = START_TIME;
+    double v = 0;
+    for (DataPoint dp : results[0]) {
+      System.out.println(dp.timestamp() + " : " + dp.doubleValue());
+      assertEquals(ts, dp.timestamp());
+      assertFalse(dp.isInteger());
+      assertEquals(v, dp.doubleValue(), 0.001);
+      ts += INTERVAL;
+      if (ts == 1356998580000L) {
+        v = 3;
+      } else if (v > 0) {
+        v += 1;
+      }
+    }
+  }
+  
+  @Test
+  public void evaluateWindow4min() throws Exception {
+    params.add("'4min'");
+    
+    final DataPoints[] results = func.evaluate(data_query, query_results, params);
+    
+    assertEquals(1, results.length);
+    assertEquals(METRIC, results[0].metricName());
+    
+    long ts = START_TIME;
+    double v = 0;
+    for (DataPoint dp : results[0]) {
+      assertEquals(ts, dp.timestamp());
+      assertFalse(dp.isInteger());
+      assertEquals(v, dp.doubleValue(), 0.001);
+      ts += INTERVAL;
+      if (ts == 1356998640000L) {
+        v = 3.5;
+      }
+    }
+  }
+  
+  @Test
+  public void evaluateWindow5min() throws Exception {
+    params.add("'5min'");
+    
+    final DataPoints[] results = func.evaluate(data_query, query_results, params);
+    
+    assertEquals(1, results.length);
+    assertEquals(METRIC, results[0].metricName());
+    
+    long ts = START_TIME;
+    double v = 0;
+    for (DataPoint dp : results[0]) {
+      assertEquals(ts, dp.timestamp());
+      assertFalse(dp.isInteger());
+      assertEquals(v, dp.doubleValue(), 0.001);
+      ts += INTERVAL;
+    }
+  }
+
+  @Test
+  public void evaluateGroupBy() throws Exception {
+    params.add("1");
+    SeekableView view2 = SeekableViewsForTest.generator(START_TIME, INTERVAL, 
+        NUM_POINTS, true, 10, 1);
+    DataPoints dps2 = PowerMockito.mock(DataPoints.class);
+    when(dps2.iterator()).thenReturn(view2);
+    when(dps2.metricNameAsync()).thenReturn(Deferred.fromResult("sys.mem"));
+    group_bys = new DataPoints[] { dps, dps2 };
+    query_results.clear();
+    query_results.add(group_bys);
+    
+    final DataPoints[] results = func.evaluate(data_query, query_results, params);
+    
+    assertEquals(2, results.length);
+    assertEquals(METRIC, results[0].metricName());
+    assertEquals("sys.mem", results[1].metricName());
+    
+    long ts = START_TIME;
+    double v = 1;
+    for (DataPoint dp : results[0]) {
+      assertEquals(ts, dp.timestamp());
+      assertFalse(dp.isInteger());
+      assertEquals(v, dp.doubleValue(), 0.001);
+      ts += INTERVAL;
+      v += 1;
+    }
+    
+    ts = START_TIME;
+    v = 10;
+    for (DataPoint dp : results[1]) {
+      assertEquals(ts, dp.timestamp());
+      assertFalse(dp.isInteger());
+      assertEquals(v, dp.doubleValue(), 0.001);
+      ts += INTERVAL;
+      v += 1;
+    }
+  }
+  
+  @Test
+  public void evaluateSubQuery() throws Exception {
+    params.add("1");
+    
+    SeekableView view2 = SeekableViewsForTest.generator(START_TIME, INTERVAL, 
+        NUM_POINTS, true, 10, 1);
+    DataPoints dps2 = PowerMockito.mock(DataPoints.class);
+    when(dps2.iterator()).thenReturn(view2);
+    when(dps2.metricNameAsync()).thenReturn(Deferred.fromResult("sys.mem"));
+    DataPoints[] group_bys2 = new DataPoints[] { dps2 };
+    query_results.add(group_bys2);
+    
+    final DataPoints[] results = func.evaluate(data_query, query_results, params);
+    
+    assertEquals(2, results.length);
+    assertEquals(METRIC, results[0].metricName());
+    assertEquals("sys.mem", results[1].metricName());
+    
+    long ts = START_TIME;
+    double v = 1;
+    for (DataPoint dp : results[0]) {
+      assertEquals(ts, dp.timestamp());
+      assertFalse(dp.isInteger());
+      assertEquals(v, dp.doubleValue(), 0.001);
+      ts += INTERVAL;
+      v += 1;
+    }
+    
+    ts = START_TIME;
+    v = 10;
+    for (DataPoint dp : results[1]) {
+      assertEquals(ts, dp.timestamp());
+      assertFalse(dp.isInteger());
+      assertEquals(v, dp.doubleValue(), 0.001);
+      ts += INTERVAL;
+      v += 1;
+    }
+  }
+  
+  @Test (expected = IllegalArgumentException.class)
+  public void evaluateNullQuery() throws Exception {
+    params.add("1");
+    func.evaluate(null, query_results, params);
+  }
+  
+  @Test
+  public void evaluateNullResults() throws Exception {
+    params.add("1");
+    final DataPoints[] results = func.evaluate(data_query, null, params);
+    assertEquals(0, results.length);
+  }
+  
+  @Test (expected = IllegalArgumentException.class)
+  public void evaluateNullParams() throws Exception {
+    func.evaluate(data_query, query_results, null);
+  }
+
+  @Test
+  public void evaluateEmptyResults() throws Exception {
+    params.add("1");
+    final DataPoints[] results = func.evaluate(data_query, 
+        Collections.<DataPoints[]>emptyList(), params);
+    assertEquals(0, results.length);
+  }
+  
+  @Test (expected = IllegalArgumentException.class)
+  public void evaluateEmptyParams() throws Exception {
+    func.evaluate(data_query, query_results, params);
+  }
+  
+  @Test (expected = IllegalArgumentException.class)
+  public void evaluateWindowIsZeroDataPoints() throws Exception {
+    params.add("0");
+    func.evaluate(data_query, query_results, params);
+  }
+  
+  @Test (expected = IllegalArgumentException.class)
+  public void evaluateWindowIsZeroTime() throws Exception {
+    params.add("'0sec'");
+    func.evaluate(data_query, query_results, params);
+  }
+
+  @Test (expected = IllegalArgumentException.class)
+  public void evaluateWindowTimedMissingQuotes() throws Exception {
+    params.add("60sec");
+    func.evaluate(data_query, query_results, params);
+  }
+  
+  @Test (expected = IllegalArgumentException.class)
+  public void evaluateWindowNull() throws Exception {
+    params.add(null);
+    func.evaluate(data_query, query_results, params);
+  }
+  
+  @Test (expected = IllegalArgumentException.class)
+  public void evaluateWindowEmpty() throws Exception {
+    params.add("");
+    func.evaluate(data_query, query_results, params);
+  }
+  
+  @Test (expected = IllegalArgumentException.class)
+  public void evaluateWindowUnknown() throws Exception {
+    params.add("somethingelse");
+    func.evaluate(data_query, query_results, params);
+  }
+  
+  @Test (expected = IllegalArgumentException.class)
+  public void evaluateWindowNotFirstParam() throws Exception {
+    params.add("somethingelse");
+    params.add("60");
+    func.evaluate(data_query, query_results, params);
+  }
+  
+  @Test
+  public void writeStringField() throws Exception {
+    params.add("1");
+    assertEquals("movingAverage(inner_expression)", 
+        func.writeStringField(params, "inner_expression"));
+    assertEquals("movingAverage(null)", func.writeStringField(params, null));
+    assertEquals("movingAverage()", func.writeStringField(params, ""));
+    assertEquals("movingAverage(inner_expression)", 
+        func.writeStringField(null, "inner_expression"));
+  }
+
+  @Test
+  public void parseParam() throws Exception {
+    // second
+    assertEquals(1000, func.parseParam("'1sec'"));
+    assertEquals(1000, func.parseParam("'1s'"));
+    assertEquals(5000, func.parseParam("'5sec'"));
+    assertEquals(5000, func.parseParam("'5s'"));
+    
+    // minute
+    assertEquals(60000, func.parseParam("'1min'"));
+    assertEquals(60000, func.parseParam("'1m'"));
+    assertEquals(300000, func.parseParam("'5min'"));
+    assertEquals(300000, func.parseParam("'5m'"));
+    
+    // hour
+    assertEquals(3600000, func.parseParam("'1hr"));
+    assertEquals(3600000, func.parseParam("'1h'"));
+    assertEquals(3600000, func.parseParam("'1hour'"));
+    assertEquals(18000000, func.parseParam("'5hr'"));
+    assertEquals(18000000, func.parseParam("'5h'"));
+    assertEquals(18000000, func.parseParam("'5hour'"));
+    
+    // day
+    assertEquals(86400000, func.parseParam("'1day'"));
+    assertEquals(86400000, func.parseParam("'1d'"));
+    assertEquals(432000000, func.parseParam("'5day'"));
+    assertEquals(432000000, func.parseParam("'5d'"));
+    
+    // TODO - fix it, closing with a 1 seems to work instead of a '
+    assertEquals(1000, func.parseParam("'1sec1"));
+    
+    // missing quotes
+    try {
+      func.parseParam("'1sec");
+      fail("Expected an IllegalArgumentException");
+    } catch (IllegalArgumentException e) { }
+    try {
+      func.parseParam("1sec'");
+      fail("Expected an IllegalArgumentException");
+    } catch (IllegalArgumentException e) { }
+    try {
+      func.parseParam("1sec");
+      fail("Expected an IllegalArgumentException");
+    } catch (IllegalArgumentException e) { }
+    
+    // no numbers or units
+    try {
+      func.parseParam("'sec'");
+      fail("Expected an IllegalArgumentException");
+    } catch (IllegalArgumentException e) { }
+    try {
+      func.parseParam("'60'");
+      fail("Expected an IllegalArgumentException");
+    } catch (IllegalArgumentException e) { }
+    
+    // null or empty or short
+    try {
+      func.parseParam(null);
+      fail("Expected an IllegalArgumentException");
+    } catch (IllegalArgumentException e) { }
+    try {
+      func.parseParam("");
+      fail("Expected an IllegalArgumentException");
+    } catch (IllegalArgumentException e) { }
+    try {
+      func.parseParam("'");
+      fail("Expected an IllegalArgumentException");
+    } catch (IllegalArgumentException e) { }
+    
+    // floating point
+    try {
+      func.parseParam("'1.5sec'");
+      fail("Expected an IllegalArgumentException");
+    } catch (IllegalArgumentException e) { }
+  }
+}
diff --git a/test/query/expression/TestMultiplySeries.java b/test/query/expression/TestMultiplySeries.java
new file mode 100644
index 0000000000..292f975f47
--- /dev/null
+++ b/test/query/expression/TestMultiplySeries.java
@@ -0,0 +1,196 @@
+// This file is part of OpenTSDB.
+// Copyright (C) 2015  The OpenTSDB Authors.
+//
+// This program is free software: you can redistribute it and/or modify it
+// under the terms of the GNU Lesser General Public License as published by
+// the Free Software Foundation, either version 2.1 of the License, or (at your
+// option) any later version.  This program is distributed in the hope that it
+// will be useful, but WITHOUT ANY WARRANTY; without even the implied warranty
+// of MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser
+// General Public License for more details.  You should have received a copy
+// of the GNU Lesser General Public License along with this program.  If not,
+// see <http://www.gnu.org/licenses/>.
+package net.opentsdb.query.expression;
+
+import static org.junit.Assert.assertEquals;
+import static org.mockito.Mockito.mock;
+import static org.mockito.Mockito.when;
+
+import java.util.ArrayList;
+import java.util.Collections;
+import java.util.List;
+
+import net.opentsdb.core.DataPoint;
+import net.opentsdb.core.DataPoints;
+import net.opentsdb.core.SeekableView;
+import net.opentsdb.core.SeekableViewsForTest;
+import net.opentsdb.core.TSQuery;
+
+import org.junit.Before;
+import org.junit.Test;
+import org.junit.runner.RunWith;
+import org.powermock.api.mockito.PowerMockito;
+import org.powermock.core.classloader.annotations.PowerMockIgnore;
+import org.powermock.core.classloader.annotations.PrepareForTest;
+import org.powermock.modules.junit4.PowerMockRunner;
+
+import com.sun.java_cup.internal.runtime.Scanner;
+
+@RunWith(PowerMockRunner.class)
+@PowerMockIgnore({"javax.management.*", "javax.xml.*",
+  "ch.qos.*", "org.slf4j.*",
+  "com.sum.*", "org.xml.*"})
+@PrepareForTest({ TSQuery.class, Scanner.class })
+public class TestMultiplySeries extends BaseTimeSyncedIteratorTest {
+
+  private static long START_TIME = 1356998400000L;
+  private static int INTERVAL = 60000;
+  private static int NUM_POINTS = 5;
+  
+  private TSQuery data_query;
+  private SeekableView view;
+  private DataPoints dps;
+  private DataPoints[] group_bys;
+  private List<DataPoints[]> query_results;
+  private List<String> params;
+  private MultiplySeries func;
+  
+  @Before
+  public void beforeLocal() throws Exception {
+    view = SeekableViewsForTest.generator(START_TIME, INTERVAL, 
+        NUM_POINTS, true, 1, 1);
+    data_query = mock(TSQuery.class);
+    when(data_query.startTime()).thenReturn(START_TIME);
+    when(data_query.endTime()).thenReturn(START_TIME + (INTERVAL * NUM_POINTS));
+    
+    dps = PowerMockito.mock(DataPoints.class);
+    when(dps.iterator()).thenReturn(view);
+    when(dps.metricName()).thenReturn(METRIC_STRING);
+    when(dps.metricUID()).thenReturn(new byte[] {0,0,1});
+    
+    group_bys = new DataPoints[] { dps };
+    
+    query_results = new ArrayList<DataPoints[]>(1);
+    query_results.add(group_bys);
+    
+    params = new ArrayList<String>(1);
+    func = new MultiplySeries(tsdb);
+  }
+  
+  @Test
+  public void multiplyOneSeriesEach() throws Exception {
+    SeekableView view2 = SeekableViewsForTest.generator(START_TIME, INTERVAL, 
+        NUM_POINTS, true, 10, 1);
+    DataPoints dps2 = PowerMockito.mock(DataPoints.class);
+    when(dps2.iterator()).thenReturn(view2);
+    when(dps2.metricName()).thenReturn("sys.mem");
+    when(dps2.metricUID()).thenReturn(new byte[] {0,0,2});
+    group_bys = new DataPoints[] { dps2 };
+    query_results.add(group_bys);
+    
+    final DataPoints[] results = func.evaluate(data_query, query_results, params);
+
+    assertEquals(1, results.length);
+    assertEquals(METRIC_STRING, results[0].metricName());
+    final int[] vals = new int[] { 10, 22, 36, 52, 70 };
+    int i = 0;
+    long ts = START_TIME;
+    for (DataPoint dp : results[0]) {
+      assertEquals(ts, dp.timestamp());
+      assertEquals(vals[i++], dp.toDouble(), 0.001);
+      ts += INTERVAL;
+    }
+  }
+  
+  @Test
+  public void multiplyMultipleSeriesEach() throws Exception {
+    oneExtraSameE();
+    queryAB_Dstar();
+    
+    query_results.clear();
+    query_results.add(results.get("1").getValue());
+    query_results.add(results.get("0").getValue());
+    final DataPoints[] results = func.evaluate(data_query, 
+        query_results, params);
+
+    assertEquals(3, results.length);
+    
+    double[][] vals = new double[2][];
+    vals[0] = new double[] { 11, 24, 39 };
+    vals[1] = new double[] { 56, 75, 96 };
+    for (int i = 0; i < results.length; i++) {
+      long ts = 1431561600000l;
+      final SeekableView it = results[i].iterator();
+      int x = 0;
+      while (it.hasNext()) {
+        final DataPoint dp = it.next();
+        assertEquals(ts, dp.timestamp());
+        if (i < 2) {
+          assertEquals(vals[i][x++], dp.toDouble(), 0.0001);
+        } else {
+          assertEquals(0, dp.toDouble(), 0.0001);
+        }
+        ts += INTERVAL;
+      }
+    }
+  }
+  
+  @Test (expected = IllegalArgumentException.class)
+  public void multiplyOneResultSet() throws Exception {    
+    func.evaluate(data_query, query_results, params);
+  }
+  
+  @Test (expected = IllegalArgumentException.class)
+  public void multiplyTooManyResultSets() throws Exception {
+    SeekableView view2 = SeekableViewsForTest.generator(START_TIME, INTERVAL, 
+        NUM_POINTS, true, 10, 1);
+    DataPoints dps2 = PowerMockito.mock(DataPoints.class);
+    when(dps2.iterator()).thenReturn(view2);
+    when(dps2.metricName()).thenReturn("sys.mem");
+    when(dps2.metricUID()).thenReturn(new byte[] {0,0,2});
+    group_bys = new DataPoints[] { dps2 };
+    // doesn't matter what they are
+    for (int i = 0; i < 100; i++) {
+      query_results.add(group_bys);
+    }
+    
+    func.evaluate(data_query, query_results, params);
+  }
+  
+  @Test (expected = IllegalArgumentException.class)
+  public void evaluateNullQuery() throws Exception {
+    params.add("1");
+    func.evaluate(null, query_results, params);
+  }
+  
+  @Test
+  public void evaluateNullResults() throws Exception {
+    params.add("1");
+    final DataPoints[] results = func.evaluate(data_query, null, params);
+    assertEquals(0, results.length);
+  }
+  
+  @Test (expected = IllegalArgumentException.class)
+  public void evaluateNullParams() throws Exception {
+    func.evaluate(data_query, query_results, null);
+  }
+
+  @Test
+  public void evaluateEmptyResults() throws Exception {
+    params.add("1");
+    final DataPoints[] results = func.evaluate(data_query, 
+        Collections.<DataPoints[]>emptyList(), params);
+    assertEquals(0, results.length);
+  }
+  
+  @Test
+  public void writeStringField() throws Exception {
+    params.add("1");
+    assertEquals("multiplySeries(inner_expression)", 
+        func.writeStringField(params, "inner_expression"));
+    assertEquals("multiplySeries(null)", func.writeStringField(params, null));
+    assertEquals("multiplySeries()", func.writeStringField(params, ""));
+    assertEquals("multiplySeries(inner_expression)", 
+        func.writeStringField(null, "inner_expression"));
+  }
+}
diff --git a/test/query/expression/TestNumericFillPolicy.java b/test/query/expression/TestNumericFillPolicy.java
new file mode 100644
index 0000000000..2b83d68b5c
--- /dev/null
+++ b/test/query/expression/TestNumericFillPolicy.java
@@ -0,0 +1,304 @@
+// This file is part of OpenTSDB.
+// Copyright (C) 2015  The OpenTSDB Authors.
+//
+// This program is free software: you can redistribute it and/or modify it
+// under the terms of the GNU Lesser General Public License as published by
+// the Free Software Foundation, either version 2.1 of the License, or (at your
+// option) any later version.  This program is distributed in the hope that it
+// will be useful, but WITHOUT ANY WARRANTY; without even the implied warranty
+// of MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser
+// General Public License for more details.  You should have received a copy
+// of the GNU Lesser General Public License along with this program.  If not,
+// see <http://www.gnu.org/licenses/>.
+package net.opentsdb.query.expression;
+
+import static org.junit.Assert.assertEquals;
+import static org.junit.Assert.assertTrue;
+import static org.junit.Assert.fail;
+import net.opentsdb.core.FillPolicy;
+import net.opentsdb.utils.JSON;
+
+import org.junit.Test;
+
+public class TestNumericFillPolicy {
+
+  @Test
+  public void builder() throws Exception {
+    NumericFillPolicy nfp = NumericFillPolicy.Builder()
+        .setPolicy(FillPolicy.NOT_A_NUMBER).build();
+    assertEquals(FillPolicy.NOT_A_NUMBER, nfp.getPolicy());
+    assertTrue(Double.isNaN((Double)nfp.getValue()));
+    
+    nfp = NumericFillPolicy.Builder()
+        .setPolicy(null).build();
+    assertEquals(FillPolicy.ZERO, nfp.getPolicy());
+    assertEquals(0, nfp.getValue(), 0.0001);
+  }
+  
+  @Test
+  public void policyCtor() throws Exception {
+    NumericFillPolicy nfp = new NumericFillPolicy(FillPolicy.NONE);
+    assertTrue(Double.isNaN((Double)nfp.getValue()));
+    assertEquals(FillPolicy.NONE, nfp.getPolicy());
+    
+    nfp = new NumericFillPolicy(FillPolicy.NOT_A_NUMBER);
+    assertTrue(Double.isNaN((Double)nfp.getValue()));
+    assertEquals(FillPolicy.NOT_A_NUMBER, nfp.getPolicy());
+    
+    nfp = new NumericFillPolicy(FillPolicy.NULL);
+    assertTrue(Double.isNaN((Double)nfp.getValue()));
+    assertEquals(FillPolicy.NULL, nfp.getPolicy());
+    
+    nfp = new NumericFillPolicy(FillPolicy.ZERO);
+    assertEquals(0, nfp.getValue(), 0.0001);
+    assertEquals(FillPolicy.ZERO, nfp.getPolicy());
+    
+    nfp = new NumericFillPolicy(null);
+    assertEquals(0, nfp.getValue(), 0.0001);
+    assertEquals(FillPolicy.ZERO, nfp.getPolicy());
+    
+    nfp = new NumericFillPolicy(FillPolicy.SCALAR);
+    assertEquals(0, nfp.getValue(), 0.0001);
+    assertEquals(FillPolicy.SCALAR, nfp.getPolicy());
+
+  }
+  
+  @Test
+  public void policyAndValueCtor() throws Exception {
+    NumericFillPolicy nfp = new NumericFillPolicy(FillPolicy.NONE, Double.NaN);
+    assertTrue(Double.isNaN((Double)nfp.getValue()));
+    assertEquals(FillPolicy.NONE, nfp.getPolicy());
+    
+    nfp = new NumericFillPolicy(FillPolicy.NOT_A_NUMBER, Double.NaN);
+    assertTrue(Double.isNaN((Double)nfp.getValue()));
+    assertEquals(FillPolicy.NOT_A_NUMBER, nfp.getPolicy());
+    
+    nfp = new NumericFillPolicy(FillPolicy.NULL, 0);
+    assertTrue(Double.isNaN((Double)nfp.getValue()));
+    assertEquals(FillPolicy.NULL, nfp.getPolicy());
+    
+    nfp = new NumericFillPolicy(FillPolicy.ZERO, 0);
+    assertEquals(0, nfp.getValue(), 0.0001);
+    assertEquals(FillPolicy.ZERO, nfp.getPolicy());
+    
+    nfp = new NumericFillPolicy(null, 0);
+    assertEquals(0, nfp.getValue(), 0.0001);
+    assertEquals(FillPolicy.ZERO, nfp.getPolicy());
+    
+    nfp = new NumericFillPolicy(FillPolicy.SCALAR, 42);
+    assertEquals(42, nfp.getValue(), 0.0001);
+    assertEquals(FillPolicy.SCALAR, nfp.getPolicy());
+    
+    nfp = new NumericFillPolicy(FillPolicy.SCALAR, 0);
+    assertEquals(0, nfp.getValue(), 0.0001);
+    assertEquals(FillPolicy.SCALAR, nfp.getPolicy());
+    
+    nfp = new NumericFillPolicy(FillPolicy.SCALAR, Double.NaN);
+    assertTrue(Double.isNaN((Double)nfp.getValue()));
+    assertEquals(FillPolicy.SCALAR, nfp.getPolicy());
+    
+    nfp = new NumericFillPolicy(FillPolicy.SCALAR, 42.5);
+    assertEquals(42.5, (Double)nfp.getValue(), 0.0001);
+    assertEquals(FillPolicy.SCALAR, nfp.getPolicy());
+    
+    // defaults from value
+    nfp = new NumericFillPolicy(null, Double.NaN);
+    assertTrue(Double.isNaN((Double)nfp.getValue()));
+    assertEquals(FillPolicy.NOT_A_NUMBER, nfp.getPolicy());
+    
+    nfp = new NumericFillPolicy(null, 42);
+    assertEquals(42, nfp.getValue(), 0.0001);
+    assertEquals(FillPolicy.SCALAR, nfp.getPolicy());
+    
+    nfp = new NumericFillPolicy(null, 42.5);
+    assertEquals(42.5, (Double)nfp.getValue(), 0.0001);
+    assertEquals(FillPolicy.SCALAR, nfp.getPolicy());
+    
+    nfp = new NumericFillPolicy(null, -42.5);
+    assertEquals(-42.5, (Double)nfp.getValue(), 0.0001);
+    assertEquals(FillPolicy.SCALAR, nfp.getPolicy());
+    
+    nfp = new NumericFillPolicy(null, Double.NaN);
+    assertTrue(Double.isNaN((Double)nfp.getValue()));
+    assertEquals(FillPolicy.NOT_A_NUMBER, nfp.getPolicy());
+    
+    nfp = new NumericFillPolicy(null, 0);
+    assertEquals(0, nfp.getValue(), 0.0001);
+    assertEquals(FillPolicy.ZERO, nfp.getPolicy());
+    
+    nfp = new NumericFillPolicy(null, 0.0);
+    assertEquals(0.0, (Double)nfp.getValue(), 0.0001);
+    assertEquals(FillPolicy.ZERO, nfp.getPolicy());
+     
+    nfp = new NumericFillPolicy(null, -0.0);
+    assertEquals(-0.0, (Double)nfp.getValue(), 0.0001);
+    assertEquals(FillPolicy.ZERO, nfp.getPolicy());
+    
+    nfp = new NumericFillPolicy(null, -0);
+    assertEquals(-0, nfp.getValue(), 0.0001);
+    assertEquals(FillPolicy.ZERO, nfp.getPolicy());
+    
+    nfp = new NumericFillPolicy(FillPolicy.NOT_A_NUMBER, 0);
+    assertTrue(Double.isNaN((Double)nfp.getValue()));
+    assertEquals(FillPolicy.NOT_A_NUMBER, nfp.getPolicy());
+    
+    nfp = new NumericFillPolicy(FillPolicy.NULL, Double.NaN);
+    assertTrue(Double.isNaN((Double)nfp.getValue()));
+    assertEquals(FillPolicy.NULL, nfp.getPolicy());
+    
+    // inappropriate combos
+    try {
+      nfp = new NumericFillPolicy(FillPolicy.ZERO, 42);
+      fail("expected an IllegalArgumentException");
+    } catch (IllegalArgumentException iae) { }
+    
+    try {
+      nfp = new NumericFillPolicy(FillPolicy.NONE, 42);
+      fail("expected an IllegalArgumentException");
+    } catch (IllegalArgumentException iae) { }
+    
+    try {
+      nfp = new NumericFillPolicy(FillPolicy.NULL, 42);
+      fail("expected an IllegalArgumentException");
+    } catch (IllegalArgumentException iae) { }
+    
+    try {
+      nfp = new NumericFillPolicy(FillPolicy.NOT_A_NUMBER, 42);
+      fail("expected an IllegalArgumentException");
+    } catch (IllegalArgumentException iae) { }
+
+  }
+
+  @Test
+  public void serdes() throws Exception {
+    
+    NumericFillPolicy ser_nfp = new NumericFillPolicy(FillPolicy.NONE);
+    String json = JSON.serializeToString(ser_nfp);
+    assertTrue(json.contains("\"policy\":\"none\""));
+    assertTrue(json.contains("\"value\":\"NaN\""));
+    NumericFillPolicy des_nfp = JSON.parseToObject(json, NumericFillPolicy.class);
+    assertTrue(des_nfp != ser_nfp);
+    assertTrue(des_nfp.equals(ser_nfp));
+    
+    ser_nfp = new NumericFillPolicy(FillPolicy.ZERO);
+    json = JSON.serializeToString(ser_nfp);
+    assertTrue(json.contains("\"policy\":\"zero\""));
+    assertTrue(json.contains("\"value\":0"));
+    des_nfp = JSON.parseToObject(json, NumericFillPolicy.class);
+    assertTrue(des_nfp != ser_nfp);
+    assertTrue(des_nfp.equals(ser_nfp));
+    
+    ser_nfp = new NumericFillPolicy(FillPolicy.NOT_A_NUMBER);
+    json = JSON.serializeToString(ser_nfp);
+    assertTrue(json.contains("\"policy\":\"nan\""));
+    assertTrue(json.contains("\"value\":\"NaN\""));
+    des_nfp = JSON.parseToObject(json, NumericFillPolicy.class);
+    assertTrue(des_nfp != ser_nfp);
+    assertTrue(des_nfp.equals(ser_nfp));
+    
+    ser_nfp = new NumericFillPolicy(FillPolicy.NULL);
+    json = JSON.serializeToString(ser_nfp);
+    assertTrue(json.contains("\"policy\":\"null\""));
+    assertTrue(json.contains("\"value\":\"NaN\""));
+    des_nfp = JSON.parseToObject(json, NumericFillPolicy.class);
+    assertTrue(des_nfp != ser_nfp);
+    assertTrue(des_nfp.equals(ser_nfp));
+    
+    ser_nfp = new NumericFillPolicy(FillPolicy.SCALAR, 42);
+    json = JSON.serializeToString(ser_nfp);
+    assertTrue(json.contains("\"policy\":\"scalar\""));
+    assertTrue(json.contains("\"value\":42"));
+    des_nfp = JSON.parseToObject(json, NumericFillPolicy.class);
+    assertTrue(des_nfp != ser_nfp);
+    assertTrue(des_nfp.equals(ser_nfp));
+    
+    ser_nfp = new NumericFillPolicy(FillPolicy.SCALAR, 42.5);
+    json = JSON.serializeToString(ser_nfp);
+    assertTrue(json.contains("\"policy\":\"scalar\""));
+    assertTrue(json.contains("\"value\":42.5"));
+    des_nfp = JSON.parseToObject(json, NumericFillPolicy.class);
+    assertTrue(des_nfp != ser_nfp);
+    assertTrue(des_nfp.equals(ser_nfp));
+    
+    ser_nfp = new NumericFillPolicy(FillPolicy.SCALAR, -42.5);
+    json = JSON.serializeToString(ser_nfp);
+    assertTrue(json.contains("\"policy\":\"scalar\""));
+    assertTrue(json.contains("\"value\":-42.5"));
+    des_nfp = JSON.parseToObject(json, NumericFillPolicy.class);
+    assertTrue(des_nfp != ser_nfp);
+    assertTrue(des_nfp.equals(ser_nfp));
+    
+    json = "{\"policy\":\"zero\"}";
+    des_nfp = JSON.parseToObject(json, NumericFillPolicy.class);
+    assertEquals(FillPolicy.ZERO, des_nfp.getPolicy());
+    assertEquals(0, des_nfp.getValue(), 0.0001);
+    
+    json = "{\"policy\":\"nan\"}";
+    des_nfp = JSON.parseToObject(json, NumericFillPolicy.class);
+    assertEquals(FillPolicy.NOT_A_NUMBER, des_nfp.getPolicy());
+    assertTrue(Double.isNaN((Double)des_nfp.getValue()));
+    
+    json = "{\"policy\":\"scalar\"}";
+    des_nfp = JSON.parseToObject(json, NumericFillPolicy.class);
+    assertEquals(FillPolicy.SCALAR, des_nfp.getPolicy());
+    assertEquals(0, des_nfp.getValue(), 0.0001);
+    
+    json = "{\"policy\":\"none\"}";
+    des_nfp = JSON.parseToObject(json, NumericFillPolicy.class);
+    assertEquals(FillPolicy.NONE, des_nfp.getPolicy());
+    assertTrue(Double.isNaN((Double)des_nfp.getValue()));
+    
+    json = "{\"policy\":\"null\"}";
+    des_nfp = JSON.parseToObject(json, NumericFillPolicy.class);
+    assertEquals(FillPolicy.NULL, des_nfp.getPolicy());
+    assertTrue(Double.isNaN((Double)des_nfp.getValue()));
+    
+    json = "{\"policy\":\"scalar\",\"value\":42}";
+    des_nfp = JSON.parseToObject(json, NumericFillPolicy.class);
+    assertEquals(FillPolicy.SCALAR, des_nfp.getPolicy());
+    assertEquals(42, des_nfp.getValue(), 0.0001);
+    
+    json = "{\"policy\":\"scalar\",\"value\":\"42\"}";
+    des_nfp = JSON.parseToObject(json, NumericFillPolicy.class);
+    assertEquals(FillPolicy.SCALAR, des_nfp.getPolicy());
+    assertEquals(42, des_nfp.getValue(), 0.0001);
+    
+    json = "{\"policy\":\"scalar\",\"value\":42.5}";
+    des_nfp = JSON.parseToObject(json, NumericFillPolicy.class);
+    assertEquals(FillPolicy.SCALAR, des_nfp.getPolicy());
+    assertEquals(42.5, (Double)des_nfp.getValue(), 0.0001);
+    
+    json = "{\"policy\":\"nan\",\"value\":NaN}";
+    des_nfp = JSON.parseToObject(json, NumericFillPolicy.class);
+    assertEquals(FillPolicy.NOT_A_NUMBER, des_nfp.getPolicy());
+    assertTrue(Double.isNaN((Double)des_nfp.getValue()));
+    
+    json = "{\"policy\":\"scalar\",\"value\":0}";
+    des_nfp = JSON.parseToObject(json, NumericFillPolicy.class);
+    assertEquals(FillPolicy.SCALAR, des_nfp.getPolicy());
+    assertEquals(0, des_nfp.getValue(), 0.0001);
+    
+    json = "{\"policy\":\"scalar\",\"value\":0.0}";
+    des_nfp = JSON.parseToObject(json, NumericFillPolicy.class);
+    assertEquals(FillPolicy.SCALAR, des_nfp.getPolicy());
+    assertEquals(0.0, (Double)des_nfp.getValue(), 0.0001);
+    
+    try {
+      json = "{\"policy\":\"unknown\"}";
+      des_nfp = JSON.parseToObject(json, NumericFillPolicy.class);
+      fail("Expected a IllegalArgumentException");
+    } catch (IllegalArgumentException e) { }
+    
+    try {
+      json = "{\"policy\":\"scalar\",value\":\"foo\"}";
+      des_nfp = JSON.parseToObject(json, NumericFillPolicy.class);
+      fail("Expected a IllegalArgumentException");
+    } catch (IllegalArgumentException e) { }
+    
+    try {
+      json = "{\"policy\":\"badjson";
+      des_nfp = JSON.parseToObject(json, NumericFillPolicy.class);
+      fail("Expected a IllegalArgumentException");
+    } catch (IllegalArgumentException e) { }
+  }
+}
diff --git a/test/query/expression/TestPostAggregatedDataPoints.java b/test/query/expression/TestPostAggregatedDataPoints.java
new file mode 100644
index 0000000000..aa940d9072
--- /dev/null
+++ b/test/query/expression/TestPostAggregatedDataPoints.java
@@ -0,0 +1,220 @@
+// This file is part of OpenTSDB.
+// Copyright (C) 2015  The OpenTSDB Authors.
+//
+// This program is free software: you can redistribute it and/or modify it
+// under the terms of the GNU Lesser General Public License as published by
+// the Free Software Foundation, either version 2.1 of the License, or (at your
+// option) any later version.  This program is distributed in the hope that it
+// will be useful, but WITHOUT ANY WARRANTY; without even the implied warranty
+// of MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser
+// General Public License for more details.  You should have received a copy
+// of the GNU Lesser General Public License along with this program.  If not,
+// see <http://www.gnu.org/licenses/>.
+package net.opentsdb.query.expression;
+
+import static org.junit.Assert.assertEquals;
+import static org.junit.Assert.assertFalse;
+import static org.junit.Assert.assertSame;
+import static org.junit.Assert.assertTrue;
+import static org.junit.Assert.fail;
+import static org.mockito.Mockito.when;
+
+import java.util.ArrayList;
+import java.util.HashMap;
+import java.util.List;
+import java.util.Map;
+import java.util.NoSuchElementException;
+
+import net.opentsdb.core.DataPoint;
+import net.opentsdb.core.DataPoints;
+import net.opentsdb.core.MutableDataPoint;
+import net.opentsdb.core.SeekableView;
+import net.opentsdb.meta.Annotation;
+
+import org.hbase.async.Bytes.ByteMap;
+import org.junit.Before;
+import org.junit.Test;
+import org.junit.runner.RunWith;
+import org.powermock.api.mockito.PowerMockito;
+import org.powermock.core.classloader.annotations.PowerMockIgnore;
+import org.powermock.core.classloader.annotations.PrepareForTest;
+import org.powermock.modules.junit4.PowerMockRunner;
+
+import com.stumbleupon.async.Deferred;
+
+@RunWith(PowerMockRunner.class)
+@PowerMockIgnore({"javax.management.*", "javax.xml.*",
+  "ch.qos.*", "org.slf4j.*",
+  "com.sum.*", "org.xml.*"})
+@PrepareForTest({ Annotation.class })
+public class TestPostAggregatedDataPoints {
+  private static int NUM_POINTS = 5;
+  private static String METRIC_NAME = "sys.cpu";
+  private static long BASE_TIME = 1356998400000L;
+  private static int TIME_INTERVAL = 60000;
+  
+  private DataPoints base_data_points;
+  private DataPoint[] points;
+  private Map<String, String> tags;
+  private List<String> agg_tags;
+  private List<String> tsuids;
+  private List<Annotation> annotations;
+  private ByteMap<byte[]> tag_uids;
+  
+  @Before
+  public void before() throws Exception {
+    base_data_points = PowerMockito.mock(DataPoints.class);
+    points = new MutableDataPoint[NUM_POINTS];
+    
+    long ts = BASE_TIME;
+    for (int i = 0; i < NUM_POINTS; i++) {
+      MutableDataPoint mdp = new MutableDataPoint();
+      mdp.reset(ts, i);
+      points[i] = mdp;
+      ts += TIME_INTERVAL;
+    }
+    
+    tags = new HashMap<String, String>(1);
+    tags.put("colo", "lga");
+    agg_tags = new ArrayList<String>(1);
+    agg_tags.add("host");
+    tsuids = new ArrayList<String>(1);
+    tsuids.add("0101010202"); // just 1 byte UIDs for kicks
+    annotations = new ArrayList<Annotation>(1);
+    annotations.add(PowerMockito.mock(Annotation.class));
+    tag_uids = new ByteMap<byte[]>();
+    tag_uids.put(new byte[] { 1 }, new byte[] { 1 });
+    
+    when(base_data_points.metricName()).thenReturn(METRIC_NAME);
+    when(base_data_points.metricNameAsync()).thenReturn(
+        Deferred.fromResult(METRIC_NAME));
+    when(base_data_points.getTags()).thenReturn(tags);
+    when(base_data_points.getTagsAsync()).thenReturn(Deferred.fromResult(tags));
+    when(base_data_points.getAggregatedTags()).thenReturn(agg_tags);
+    when(base_data_points.getAggregatedTagsAsync()).thenReturn(
+        Deferred.fromResult(agg_tags));
+    when(base_data_points.getTSUIDs()).thenReturn(tsuids);
+    when(base_data_points.getAnnotations()).thenReturn(annotations);
+    when(base_data_points.getTagUids()).thenReturn(tag_uids);
+    when(base_data_points.getQueryIndex()).thenReturn(42);
+  }
+  
+  @Test
+  public void ctorDefaults() throws Exception {
+    final PostAggregatedDataPoints dps = new PostAggregatedDataPoints(
+        base_data_points, points);
+    assertEquals(METRIC_NAME, dps.metricName());
+    assertEquals(METRIC_NAME, dps.metricNameAsync().join());
+    assertSame(tags, dps.getTags());
+    assertSame(tags, dps.getTagsAsync().join());
+    assertSame(agg_tags, dps.getAggregatedTags());
+    assertSame(agg_tags, dps.getAggregatedTagsAsync().join());
+    assertSame(tsuids, dps.getTSUIDs());
+    assertSame(annotations, dps.getAnnotations());
+    assertSame(tag_uids, dps.getTagUids());
+    assertEquals(42, dps.getQueryIndex());
+    assertEquals(5, dps.size());
+    assertEquals(5, dps.aggregatedSize());
+    
+    // values
+    final SeekableView iterator = dps.iterator();
+    int values = 0;
+    long value = 0;
+    long ts = BASE_TIME;
+    while(iterator.hasNext()) {
+      final DataPoint dp = iterator.next();
+      assertEquals(value++, dp.longValue());
+      assertEquals(ts, dp.timestamp());
+      ts += TIME_INTERVAL;
+      values++;
+    }
+    assertEquals(5, values);
+    assertFalse(iterator.hasNext());
+    try {
+      iterator.next();
+      fail("Expected a NoSuchElementException");
+    } catch (NoSuchElementException e) { }
+    
+    assertEquals(BASE_TIME + (4 * TIME_INTERVAL), dps.timestamp(4));
+    assertEquals(4, dps.longValue(4));
+    assertTrue(dps.isInteger(4));
+    try {
+      assertEquals(4, dps.doubleValue(4), 0.00);
+      fail("Expected a ClassCastException");
+    } catch (ClassCastException e) { }
+    
+    try {
+      dps.timestamp(5);
+      fail("Expected a ArrayIndexOutOfBoundsException");
+    } catch (ArrayIndexOutOfBoundsException e) { }
+    try {
+      dps.isInteger(5);
+      fail("Expected a ArrayIndexOutOfBoundsException");
+    } catch (ArrayIndexOutOfBoundsException e) { }
+    try {
+      dps.longValue(5);
+      fail("Expected a ArrayIndexOutOfBoundsException");
+    } catch (ArrayIndexOutOfBoundsException e) { }
+    try {
+      dps.doubleValue(5);
+      fail("Expected a ArrayIndexOutOfBoundsException");
+    } catch (ArrayIndexOutOfBoundsException e) { }
+  }
+  
+  @Test (expected = IllegalArgumentException.class)
+  public void ctorNullBase() throws Exception {
+    new PostAggregatedDataPoints(null, points);
+  }
+  
+  @Test (expected = IllegalArgumentException.class)
+  public void ctorNullPoints() throws Exception {
+    new PostAggregatedDataPoints(base_data_points, null);
+  }
+  
+  @Test
+  public void alias() throws Exception {
+    final PostAggregatedDataPoints dps = new PostAggregatedDataPoints(
+        base_data_points, points);
+    final String alias = "ein";
+    dps.setAlias(alias);
+    assertEquals(alias, dps.metricName());
+    assertEquals(alias, dps.metricNameAsync().join());
+    assertTrue(dps.getTags().isEmpty());
+    assertTrue(dps.getTagsAsync().join().isEmpty());
+    assertTrue(dps.getAggregatedTags().isEmpty());
+    assertTrue(dps.getAggregatedTagsAsync().join().isEmpty());
+    assertSame(tsuids, dps.getTSUIDs());
+    assertSame(annotations, dps.getAnnotations());
+    assertSame(tag_uids, dps.getTagUids());
+    assertEquals(42, dps.getQueryIndex());
+    assertEquals(5, dps.size());
+    assertEquals(5, dps.aggregatedSize());
+  }
+  
+  @Test
+  public void emptyPoints() throws Exception {
+    points = new MutableDataPoint[0];
+    final PostAggregatedDataPoints dps = new PostAggregatedDataPoints(
+        base_data_points, points);
+    assertEquals(METRIC_NAME, dps.metricName());
+    assertEquals(METRIC_NAME, dps.metricNameAsync().join());
+    assertSame(tags, dps.getTags());
+    assertSame(tags, dps.getTagsAsync().join());
+    assertSame(agg_tags, dps.getAggregatedTags());
+    assertSame(agg_tags, dps.getAggregatedTagsAsync().join());
+    assertSame(tsuids, dps.getTSUIDs());
+    assertSame(annotations, dps.getAnnotations());
+    assertSame(tag_uids, dps.getTagUids());
+    assertEquals(42, dps.getQueryIndex());
+    assertEquals(0, dps.size());
+    assertEquals(0, dps.aggregatedSize());
+    
+    // values
+    final SeekableView iterator = dps.iterator();
+    assertFalse(iterator.hasNext());
+    try {
+      iterator.next();
+      fail("Expected a NoSuchElementException");
+    } catch (NoSuchElementException e) { }
+  }
+}
diff --git a/test/query/expression/TestScale.java b/test/query/expression/TestScale.java
new file mode 100644
index 0000000000..d34469d7c0
--- /dev/null
+++ b/test/query/expression/TestScale.java
@@ -0,0 +1,404 @@
+// This file is part of OpenTSDB.
+// Copyright (C) 2015  The OpenTSDB Authors.
+//
+// This program is free software: you can redistribute it and/or modify it
+// under the terms of the GNU Lesser General Public License as published by
+// the Free Software Foundation, either version 2.1 of the License, or (at your
+// option) any later version.  This program is distributed in the hope that it
+// will be useful, but WITHOUT ANY WARRANTY; without even the implied warranty
+// of MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser
+// General Public License for more details.  You should have received a copy
+// of the GNU Lesser General Public License along with this program.  If not,
+// see <http://www.gnu.org/licenses/>.
+package net.opentsdb.query.expression;
+
+import static org.junit.Assert.assertEquals;
+import static org.junit.Assert.assertFalse;
+import static org.junit.Assert.assertTrue;
+import static org.mockito.Mockito.mock;
+import static org.mockito.Mockito.when;
+
+import java.util.ArrayList;
+import java.util.Collections;
+import java.util.List;
+
+import net.opentsdb.core.DataPoint;
+import net.opentsdb.core.DataPoints;
+import net.opentsdb.core.SeekableView;
+import net.opentsdb.core.SeekableViewsForTest;
+import net.opentsdb.core.TSQuery;
+
+import org.junit.Before;
+import org.junit.Test;
+import org.junit.runner.RunWith;
+import org.powermock.api.mockito.PowerMockito;
+import org.powermock.core.classloader.annotations.PowerMockIgnore;
+import org.powermock.core.classloader.annotations.PrepareForTest;
+import org.powermock.modules.junit4.PowerMockRunner;
+
+import com.stumbleupon.async.Deferred;
+
+@RunWith(PowerMockRunner.class)
+@PowerMockIgnore({"javax.management.*", "javax.xml.*",
+  "ch.qos.*", "org.slf4j.*",
+  "com.sum.*", "org.xml.*"})
+@PrepareForTest({ TSQuery.class })
+public class TestScale {
+
+  private static long START_TIME = 1356998400000L;
+  private static int INTERVAL = 60000;
+  private static int NUM_POINTS = 5;
+  private static String METRIC = "sys.cpu";
+  
+  private TSQuery data_query;
+  private SeekableView view;
+  private DataPoints dps;
+  private DataPoints[] group_bys;
+  private List<DataPoints[]> query_results;
+  private List<String> params;
+  private Scale func;
+  
+  @Before
+  public void before() throws Exception {
+    view = SeekableViewsForTest.generator(START_TIME, INTERVAL, 
+        NUM_POINTS, true, 1, 1);
+    data_query = mock(TSQuery.class);
+    when(data_query.startTime()).thenReturn(START_TIME);
+    when(data_query.endTime()).thenReturn(START_TIME + (INTERVAL * NUM_POINTS));
+    
+    dps = PowerMockito.mock(DataPoints.class);
+    when(dps.iterator()).thenReturn(view);
+    when(dps.metricNameAsync()).thenReturn(Deferred.fromResult(METRIC));
+    
+    group_bys = new DataPoints[] { dps };
+    
+    query_results = new ArrayList<DataPoints[]>(1);
+    query_results.add(group_bys);
+    
+    params = new ArrayList<String>(1);
+    func = new Scale();
+  }
+  
+  @Test
+  public void evaluateFactor1GroupByLong() throws Exception {
+    params.add("1");
+    SeekableView view2 = SeekableViewsForTest.generator(START_TIME, INTERVAL, 
+        NUM_POINTS, true, 10, 1);
+    DataPoints dps2 = PowerMockito.mock(DataPoints.class);
+    when(dps2.iterator()).thenReturn(view2);
+    when(dps2.metricNameAsync()).thenReturn(Deferred.fromResult("sys.mem"));
+    group_bys = new DataPoints[] { dps, dps2 };
+    query_results.clear();
+    query_results.add(group_bys);
+    
+    final DataPoints[] results = func.evaluate(data_query, query_results, params);
+    
+    assertEquals(2, results.length);
+    assertEquals(METRIC, results[0].metricName());
+    assertEquals("sys.mem", results[1].metricName());
+    
+    long ts = START_TIME;
+    long v = 1;
+    for (DataPoint dp : results[0]) {
+      assertEquals(ts, dp.timestamp());
+      assertTrue(dp.isInteger());
+      assertEquals(v, dp.longValue());
+      ts += INTERVAL;
+      v += 1;
+    }
+    ts = START_TIME;
+    v = 10;
+    for (DataPoint dp : results[1]) {
+      assertEquals(ts, dp.timestamp());
+      assertTrue(dp.isInteger());
+      assertEquals(v, dp.longValue());
+      ts += INTERVAL;
+      v += 1;
+    }
+  }
+  
+  @Test
+  public void evaluateFactor1GroupByDouble() throws Exception {
+    params.add("1");
+    SeekableView view2 = SeekableViewsForTest.generator(START_TIME, INTERVAL, 
+        NUM_POINTS, false, 10, 1.5);
+    DataPoints dps2 = PowerMockito.mock(DataPoints.class);
+    when(dps2.iterator()).thenReturn(view2);
+    when(dps2.metricNameAsync()).thenReturn(Deferred.fromResult("sys.mem"));
+    group_bys = new DataPoints[] { dps, dps2 };
+    query_results.clear();
+    query_results.add(group_bys);
+    
+    final DataPoints[] results = func.evaluate(data_query, query_results, params);
+    
+    assertEquals(2, results.length);
+    assertEquals(METRIC, results[0].metricName());
+    assertEquals("sys.mem", results[1].metricName());
+    
+    long ts = START_TIME;
+    double v = 1;
+    for (DataPoint dp : results[0]) {
+      assertEquals(ts, dp.timestamp());
+      assertTrue(dp.isInteger());
+      assertEquals((long)v, dp.longValue());
+      ts += INTERVAL;
+      v += 1;
+    }
+    ts = START_TIME;
+    v = 10;
+    for (DataPoint dp : results[1]) {
+      assertEquals(ts, dp.timestamp());
+      assertFalse(dp.isInteger());
+      assertEquals(v, dp.doubleValue(), 0.001);
+      ts += INTERVAL;
+      v += 1.5;
+    }
+  }
+  
+  @Test
+  public void evaluateFactor1point5GroupBy() throws Exception {
+    params.add("1.5");
+    SeekableView view2 = SeekableViewsForTest.generator(START_TIME, INTERVAL, 
+        NUM_POINTS, true, 10, 1);
+    DataPoints dps2 = PowerMockito.mock(DataPoints.class);
+    when(dps2.iterator()).thenReturn(view2);
+    when(dps2.metricNameAsync()).thenReturn(Deferred.fromResult("sys.mem"));
+    group_bys = new DataPoints[] { dps, dps2 };
+    query_results.clear();
+    query_results.add(group_bys);
+    
+    final DataPoints[] results = func.evaluate(data_query, query_results, params);
+    
+    assertEquals(2, results.length);
+    assertEquals(METRIC, results[0].metricName());
+    assertEquals("sys.mem", results[1].metricName());
+    
+    long ts = START_TIME;
+    double v = 1.5;
+    for (DataPoint dp : results[0]) {
+      System.out.println(dp.timestamp() + " : " + dp.toDouble());
+      assertEquals(ts, dp.timestamp());
+      assertFalse(dp.isInteger());
+      assertEquals(v, dp.doubleValue(), 0.001);
+      ts += INTERVAL;
+      v += 1.5;
+    }
+    ts = START_TIME;
+    v = 15;
+    for (DataPoint dp : results[1]) {
+      assertEquals(ts, dp.timestamp());
+      assertFalse(dp.isInteger());
+      assertEquals(v, dp.doubleValue(), 0.001);
+      ts += INTERVAL;
+      v += 1.5;
+    }
+  }
+  
+  @Test
+  public void evaluateFactor1024GroupBy() throws Exception {
+    params.add("1024");
+    SeekableView view2 = SeekableViewsForTest.generator(START_TIME, INTERVAL, 
+        NUM_POINTS, true, 10, 1);
+    DataPoints dps2 = PowerMockito.mock(DataPoints.class);
+    when(dps2.iterator()).thenReturn(view2);
+    when(dps2.metricNameAsync()).thenReturn(Deferred.fromResult("sys.mem"));
+    group_bys = new DataPoints[] { dps, dps2 };
+    query_results.clear();
+    query_results.add(group_bys);
+    
+    final DataPoints[] results = func.evaluate(data_query, query_results, params);
+    
+    assertEquals(2, results.length);
+    assertEquals(METRIC, results[0].metricName());
+    assertEquals("sys.mem", results[1].metricName());
+    
+    long ts = START_TIME;
+    long v = 1024;
+    for (DataPoint dp : results[0]) {
+      assertEquals(ts, dp.timestamp());
+      assertTrue(dp.isInteger());
+      assertEquals(v, dp.longValue());
+      ts += INTERVAL;
+      v += 1024;
+    }
+    ts = START_TIME;
+    v = 10240;
+    for (DataPoint dp : results[1]) {
+      assertEquals(ts, dp.timestamp());
+      assertTrue(dp.isInteger());
+      assertEquals(v, dp.longValue());
+      ts += INTERVAL;
+      v += 1024;
+    }
+  }
+  
+  @Test
+  public void evaluateFactor1SubQuerySeries() throws Exception {
+    params.add("1");
+    SeekableView view2 = SeekableViewsForTest.generator(START_TIME, INTERVAL, 
+        NUM_POINTS, true, 10, 1);
+    DataPoints dps2 = PowerMockito.mock(DataPoints.class);
+    when(dps2.iterator()).thenReturn(view2);
+    when(dps2.metricNameAsync()).thenReturn(Deferred.fromResult("sys.mem"));
+    group_bys = new DataPoints[] { dps, dps2 };
+    query_results.clear();
+    query_results.add(group_bys);
+    
+    final DataPoints[] results = func.evaluate(data_query, query_results, params);
+    
+    assertEquals(2, results.length);
+    assertEquals(METRIC, results[0].metricName());
+    assertEquals("sys.mem", results[1].metricName());
+    
+    long ts = START_TIME;
+    long v = 1;
+    for (DataPoint dp : results[0]) {
+      assertEquals(ts, dp.timestamp());
+      assertTrue(dp.isInteger());
+      assertEquals(v, dp.longValue());
+      ts += INTERVAL;
+      v += 1;
+    }
+    ts = START_TIME;
+    v = 10;
+    for (DataPoint dp : results[1]) {
+      assertEquals(ts, dp.timestamp());
+      assertTrue(dp.isInteger());
+      assertEquals(v, dp.longValue());
+      ts += INTERVAL;
+      v += 1;
+    }
+  }
+  
+  @Test
+  public void evaluateFactor0GroupByLong() throws Exception {
+    params.add("0");
+    SeekableView view2 = SeekableViewsForTest.generator(START_TIME, INTERVAL, 
+        NUM_POINTS, true, 10, 1);
+    DataPoints dps2 = PowerMockito.mock(DataPoints.class);
+    when(dps2.iterator()).thenReturn(view2);
+    when(dps2.metricNameAsync()).thenReturn(Deferred.fromResult("sys.mem"));
+    group_bys = new DataPoints[] { dps, dps2 };
+    query_results.clear();
+    query_results.add(group_bys);
+    
+    final DataPoints[] results = func.evaluate(data_query, query_results, params);
+    
+    assertEquals(2, results.length);
+    assertEquals(METRIC, results[0].metricName());
+    assertEquals("sys.mem", results[1].metricName());
+    
+    long ts = START_TIME;
+    for (DataPoint dp : results[0]) {
+      assertEquals(ts, dp.timestamp());
+      assertTrue(dp.isInteger());
+      assertEquals(0, dp.longValue());
+      ts += INTERVAL;
+    }
+    ts = START_TIME;
+    for (DataPoint dp : results[1]) {
+      assertEquals(ts, dp.timestamp());
+      assertTrue(dp.isInteger());
+      assertEquals(0, dp.longValue());
+      ts += INTERVAL;
+    }
+  }
+  
+  @Test
+  public void evaluateFactorNegative1GroupByLong() throws Exception {
+    params.add("-1");
+    SeekableView view2 = SeekableViewsForTest.generator(START_TIME, INTERVAL, 
+        NUM_POINTS, true, 10, 1);
+    DataPoints dps2 = PowerMockito.mock(DataPoints.class);
+    when(dps2.iterator()).thenReturn(view2);
+    when(dps2.metricNameAsync()).thenReturn(Deferred.fromResult("sys.mem"));
+    group_bys = new DataPoints[] { dps, dps2 };
+    query_results.clear();
+    query_results.add(group_bys);
+    
+    final DataPoints[] results = func.evaluate(data_query, query_results, params);
+    
+    assertEquals(2, results.length);
+    assertEquals(METRIC, results[0].metricName());
+    assertEquals("sys.mem", results[1].metricName());
+    
+    long ts = START_TIME;
+    long v = -1;
+    for (DataPoint dp : results[0]) {
+      assertEquals(ts, dp.timestamp());
+      assertTrue(dp.isInteger());
+      assertEquals(v, dp.longValue());
+      ts += INTERVAL;
+      v -= 1;
+    }
+    ts = START_TIME;
+    v = -10;
+    for (DataPoint dp : results[1]) {
+      assertEquals(ts, dp.timestamp());
+      assertTrue(dp.isInteger());
+      assertEquals(v, dp.longValue());
+      ts += INTERVAL;
+      v -= 1;
+    }
+  }
+  
+  @Test (expected = IllegalArgumentException.class)
+  public void evaluateNullQuery() throws Exception {
+    params.add("1");
+    func.evaluate(null, query_results, params);
+  }
+  
+  @Test
+  public void evaluateNullResults() throws Exception {
+    params.add("1");
+    final DataPoints[] results = func.evaluate(data_query, null, params);
+    assertEquals(0, results.length);
+  }
+  
+  @Test (expected = IllegalArgumentException.class)
+  public void evaluateNullParams() throws Exception {
+    func.evaluate(data_query, query_results, null);
+  }
+
+  @Test
+  public void evaluateEmptyResults() throws Exception {
+    params.add("1");
+    final DataPoints[] results = func.evaluate(data_query, 
+        Collections.<DataPoints[]>emptyList(), params);
+    assertEquals(0, results.length);
+  }
+  
+  @Test (expected = IllegalArgumentException.class)
+  public void evaluateEmptyParams() throws Exception {
+    func.evaluate(data_query, query_results, params);
+  }
+  
+  @Test (expected = IllegalArgumentException.class)
+  public void evaluateScaleNull() throws Exception {
+    params.add(null);
+    func.evaluate(data_query, query_results, params);
+  }
+  
+  @Test (expected = IllegalArgumentException.class)
+  public void evaluateScaleEmpty() throws Exception {
+    params.add("");
+    func.evaluate(data_query, query_results, params);
+  }
+  
+  @Test (expected = IllegalArgumentException.class)
+  public void evaluateScaleNotaNumber() throws Exception {
+    params.add("not a number");
+    func.evaluate(data_query, query_results, params);
+  }
+  
+  @Test
+  public void writeStringField() throws Exception {
+    params.add("1");
+    assertEquals("scale(inner_expression)", 
+        func.writeStringField(params, "inner_expression"));
+    assertEquals("scale(null)", func.writeStringField(params, null));
+    assertEquals("scale()", func.writeStringField(params, ""));
+    assertEquals("scale(inner_expression)", 
+        func.writeStringField(null, "inner_expression"));
+  }
+}
diff --git a/test/query/expression/TestSumSeries.java b/test/query/expression/TestSumSeries.java
new file mode 100644
index 0000000000..77a22b56a3
--- /dev/null
+++ b/test/query/expression/TestSumSeries.java
@@ -0,0 +1,195 @@
+// This file is part of OpenTSDB.
+// Copyright (C) 2015  The OpenTSDB Authors.
+//
+// This program is free software: you can redistribute it and/or modify it
+// under the terms of the GNU Lesser General Public License as published by
+// the Free Software Foundation, either version 2.1 of the License, or (at your
+// option) any later version.  This program is distributed in the hope that it
+// will be useful, but WITHOUT ANY WARRANTY; without even the implied warranty
+// of MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser
+// General Public License for more details.  You should have received a copy
+// of the GNU Lesser General Public License along with this program.  If not,
+// see <http://www.gnu.org/licenses/>.
+package net.opentsdb.query.expression;
+
+import static org.junit.Assert.assertEquals;
+import static org.mockito.Mockito.mock;
+import static org.mockito.Mockito.when;
+
+import java.util.ArrayList;
+import java.util.Collections;
+import java.util.List;
+
+import net.opentsdb.core.DataPoint;
+import net.opentsdb.core.DataPoints;
+import net.opentsdb.core.SeekableView;
+import net.opentsdb.core.SeekableViewsForTest;
+import net.opentsdb.core.TSQuery;
+
+import org.junit.Before;
+import org.junit.Test;
+import org.junit.runner.RunWith;
+import org.powermock.api.mockito.PowerMockito;
+import org.powermock.core.classloader.annotations.PowerMockIgnore;
+import org.powermock.core.classloader.annotations.PrepareForTest;
+import org.powermock.modules.junit4.PowerMockRunner;
+
+import com.sun.java_cup.internal.runtime.Scanner;
+
+@RunWith(PowerMockRunner.class)
+@PowerMockIgnore({"javax.management.*", "javax.xml.*",
+  "ch.qos.*", "org.slf4j.*",
+  "com.sum.*", "org.xml.*"})
+@PrepareForTest({ TSQuery.class, Scanner.class })
+public class TestSumSeries extends BaseTimeSyncedIteratorTest {
+
+  private static long START_TIME = 1356998400000L;
+  private static int INTERVAL = 60000;
+  private static int NUM_POINTS = 5;
+  
+  private TSQuery data_query;
+  private SeekableView view;
+  private DataPoints dps;
+  private DataPoints[] group_bys;
+  private List<DataPoints[]> query_results;
+  private List<String> params;
+  private SumSeries func;
+  
+  @Before
+  public void beforeLocal() throws Exception {
+    view = SeekableViewsForTest.generator(START_TIME, INTERVAL, 
+        NUM_POINTS, true, 1, 1);
+    data_query = mock(TSQuery.class);
+    when(data_query.startTime()).thenReturn(START_TIME);
+    when(data_query.endTime()).thenReturn(START_TIME + (INTERVAL * NUM_POINTS));
+    
+    dps = PowerMockito.mock(DataPoints.class);
+    when(dps.iterator()).thenReturn(view);
+    when(dps.metricName()).thenReturn(METRIC_STRING);
+    when(dps.metricUID()).thenReturn(new byte[] {0,0,1});
+    
+    group_bys = new DataPoints[] { dps };
+    
+    query_results = new ArrayList<DataPoints[]>(1);
+    query_results.add(group_bys);
+    
+    params = new ArrayList<String>(1);
+    func = new SumSeries(tsdb);
+  }
+  
+  @Test
+  public void sumOneSeriesEach() throws Exception {
+    SeekableView view2 = SeekableViewsForTest.generator(START_TIME, INTERVAL, 
+        NUM_POINTS, true, 10, 1);
+    DataPoints dps2 = PowerMockito.mock(DataPoints.class);
+    when(dps2.iterator()).thenReturn(view2);
+    when(dps2.metricName()).thenReturn("sys.mem");
+    when(dps2.metricUID()).thenReturn(new byte[] {0,0,2});
+    group_bys = new DataPoints[] { dps2 };
+    query_results.add(group_bys);
+    
+    final DataPoints[] results = func.evaluate(data_query, query_results, params);
+
+    assertEquals(1, results.length);
+    assertEquals(METRIC_STRING, results[0].metricName());
+    
+    long ts = START_TIME;
+    double v = 11;
+    for (DataPoint dp : results[0]) {
+      assertEquals(ts, dp.timestamp());
+      assertEquals(v, dp.toDouble(), 0.001);
+      v += 2;
+      ts += INTERVAL;
+    }
+  }
+  
+  @Test
+  public void sumMultipleSeriesEach() throws Exception {
+    oneExtraSameE();
+    queryAB_Dstar();
+    
+    query_results.clear();
+    query_results.add(results.get("1").getValue());
+    query_results.add(results.get("0").getValue());
+    final DataPoints[] results = func.evaluate(data_query, 
+        query_results, params);
+
+    assertEquals(3, results.length);
+    
+    final int vals[] = new int[] { 12, 18, 17 };
+    for (int i = 0; i < results.length; i++) {
+      long ts = 1431561600000l;
+      final SeekableView it = results[i].iterator();
+      while (it.hasNext()) {
+        final DataPoint dp = it.next();
+        assertEquals(ts, dp.timestamp());
+        assertEquals(vals[i], dp.toDouble(), 0.0001);
+        if (i < 2) {
+          vals[i] += 2;
+        } else {
+          vals[i]++;
+        }
+        ts += INTERVAL;
+      }
+    }
+  }
+  
+  @Test (expected = IllegalArgumentException.class)
+  public void sumOneResultSet() throws Exception {    
+    func.evaluate(data_query, query_results, params);
+  }
+  
+  @Test (expected = IllegalArgumentException.class)
+  public void sumTooManyResultSets() throws Exception {
+    SeekableView view2 = SeekableViewsForTest.generator(START_TIME, INTERVAL, 
+        NUM_POINTS, true, 10, 1);
+    DataPoints dps2 = PowerMockito.mock(DataPoints.class);
+    when(dps2.iterator()).thenReturn(view2);
+    when(dps2.metricName()).thenReturn("sys.mem");
+    when(dps2.metricUID()).thenReturn(new byte[] {0,0,2});
+    group_bys = new DataPoints[] { dps2 };
+    // doesn't matter what they are
+    for (int i = 0; i < 100; i++) {
+      query_results.add(group_bys);
+    }
+    
+    func.evaluate(data_query, query_results, params);
+  }
+  
+  @Test (expected = IllegalArgumentException.class)
+  public void evaluateNullQuery() throws Exception {
+    params.add("1");
+    func.evaluate(null, query_results, params);
+  }
+  
+  @Test
+  public void evaluateNullResults() throws Exception {
+    params.add("1");
+    final DataPoints[] results = func.evaluate(data_query, null, params);
+    assertEquals(0, results.length);
+  }
+  
+  @Test (expected = IllegalArgumentException.class)
+  public void evaluateNullParams() throws Exception {
+    func.evaluate(data_query, query_results, null);
+  }
+
+  @Test
+  public void evaluateEmptyResults() throws Exception {
+    params.add("1");
+    final DataPoints[] results = func.evaluate(data_query, 
+        Collections.<DataPoints[]>emptyList(), params);
+    assertEquals(0, results.length);
+  }
+    
+  @Test
+  public void writeStringField() throws Exception {
+    params.add("1");
+    assertEquals("sumSeries(inner_expression)", 
+        func.writeStringField(params, "inner_expression"));
+    assertEquals("sumSeries(null)", func.writeStringField(params, null));
+    assertEquals("sumSeries()", func.writeStringField(params, ""));
+    assertEquals("sumSeries(inner_expression)", 
+        func.writeStringField(null, "inner_expression"));
+  }
+}
diff --git a/test/query/expression/TestTimeSyncedIterator.java b/test/query/expression/TestTimeSyncedIterator.java
new file mode 100644
index 0000000000..70491001f1
--- /dev/null
+++ b/test/query/expression/TestTimeSyncedIterator.java
@@ -0,0 +1,504 @@
+// This file is part of OpenTSDB.
+// Copyright (C) 2015  The OpenTSDB Authors.
+//
+// This program is free software: you can redistribute it and/or modify it
+// under the terms of the GNU Lesser General Public License as published by
+// the Free Software Foundation, either version 2.1 of the License, or (at your
+// option) any later version.  This program is distributed in the hope that it
+// will be useful, but WITHOUT ANY WARRANTY; without even the implied warranty
+// of MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser
+// General Public License for more details.  You should have received a copy
+// of the GNU Lesser General Public License along with this program.  If not,
+// see <http://www.gnu.org/licenses/>.
+package net.opentsdb.query.expression;
+
+import static org.junit.Assert.assertEquals;
+import static org.junit.Assert.assertFalse;
+import static org.junit.Assert.assertNull;
+import static org.junit.Assert.assertTrue;
+import static org.junit.Assert.fail;
+
+import org.junit.Test;
+import org.junit.runner.RunWith;
+import org.powermock.core.classloader.annotations.PowerMockIgnore;
+import org.powermock.modules.junit4.PowerMockRunner;
+
+import net.opentsdb.core.DataPoint;
+import net.opentsdb.core.FillPolicy;
+
+@RunWith(PowerMockRunner.class)
+@PowerMockIgnore({"javax.management.*", "javax.xml.*",
+  "ch.qos.*", "org.slf4j.*",
+  "com.sum.*", "org.xml.*"})
+public class TestTimeSyncedIterator extends BaseTimeSyncedIteratorTest {
+
+  @Test
+  public void ctor() throws Exception {
+    threeDisjointSameE();
+    queryAB_Dstar();
+    final TimeSyncedIterator it = new TimeSyncedIterator("0", 
+        results.get("0").getKey().getFilterTagKs(), 
+        results.get("0").getValue());
+    
+    assertEquals(3, it.size());
+    assertTrue(it.hasNext());
+    assertEquals(0, it.getIndex());
+    assertEquals("0", it.getId());
+    assertEquals(results.get("0").getKey().getFilterTagKs(), it.getQueryTagKs());
+    assertTrue(results.get("0").getValue() == it.getDataPoints());
+    assertEquals(3, it.values().length);
+    assertEquals(1, it.getQueryTagKs().size());
+    assertEquals(FillPolicy.ZERO, it.getFillPolicy().getPolicy());
+  }
+  
+  @Test (expected = IllegalArgumentException.class)
+  public void ctorNullId() throws Exception {
+    threeDisjointSameE();
+    queryAB_Dstar();
+    new TimeSyncedIterator(null, 
+        results.get("0").getKey().getFilterTagKs(), 
+        results.get("0").getValue());
+  }
+  
+  @Test (expected = IllegalArgumentException.class)
+  public void ctorEmptyId() throws Exception {
+    threeDisjointSameE();
+    queryAB_Dstar();
+    new TimeSyncedIterator("", 
+        results.get("0").getKey().getFilterTagKs(), 
+        results.get("0").getValue());
+  }
+  
+  @Test
+  public void ctorNullQueryTags() throws Exception {
+    threeDisjointSameE();
+    queryAB_Dstar();
+    final TimeSyncedIterator it = new TimeSyncedIterator("0", null, 
+        results.get("0").getValue());
+    
+    assertEquals(3, it.size());
+    assertTrue(it.hasNext());
+    assertEquals(0, it.getIndex());
+    assertEquals("0", it.getId());
+    assertNull(it.getQueryTagKs());
+    assertTrue(results.get("0").getValue() == it.getDataPoints());
+    assertEquals(3, it.values().length);
+  }
+  
+  @Test (expected = IllegalArgumentException.class)
+  public void ctorNullDPs() throws Exception {
+    threeDisjointSameE();
+    queryAB_Dstar();
+    new TimeSyncedIterator("0", results.get("0").getKey().getFilterTagKs(), 
+        null);
+  }
+  
+  @Test
+  public void threeSeries() throws Exception {
+    threeDisjointSameE();
+    queryAB_Dstar();
+    final TimeSyncedIterator it = new TimeSyncedIterator("0", 
+        results.get("0").getKey().getFilterTagKs(), 
+        results.get("0").getValue());
+    
+    long ts = it.nextTimestamp();
+    assertEquals(1431561600000L, ts);
+    
+    double[] values = new double[] { 1, 4, 7 };
+    while (it.hasNext()) {
+      final DataPoint[] dps = it.next(ts);
+      assertEquals(3, dps.length);
+      assertEquals(ts, dps[0].timestamp());
+      assertEquals(ts, dps[1].timestamp());
+      assertEquals(ts, dps[2].timestamp());
+      assertEquals(values[0]++, dps[0].toDouble(), 0.0001);
+      assertEquals(values[1]++, dps[1].toDouble(), 0.0001);
+      assertEquals(values[2]++, dps[2].toDouble(), 0.0001);
+      ts = it.nextTimestamp();
+    }
+    assertEquals(Long.MAX_VALUE, ts);
+  }
+  
+  @Test
+  public void threeSeriesEmitter() throws Exception {
+    threeDisjointSameE();
+    queryAB_Dstar();
+    final TimeSyncedIterator it = new TimeSyncedIterator("0", 
+        results.get("0").getKey().getFilterTagKs(), 
+        results.get("0").getValue());
+    
+    long ts = it.nextTimestamp();
+    assertEquals(1431561600000L, ts);
+    final DataPoint[] dps = it.values();
+    double[] values = new double[] { 1, 4, 7 };
+    while (it.hasNext()) {
+      it.next(ts);
+      assertEquals(3, dps.length);
+      assertEquals(ts, dps[0].timestamp());
+      assertEquals(ts, dps[1].timestamp());
+      assertEquals(ts, dps[2].timestamp());
+      assertEquals(values[0]++, dps[0].toDouble(), 0.0001);
+      assertEquals(values[1]++, dps[1].toDouble(), 0.0001);
+      assertEquals(values[2]++, dps[2].toDouble(), 0.0001);
+      ts = it.nextTimestamp();
+    }
+    assertEquals(Long.MAX_VALUE, ts);
+  }
+  
+  @Test
+  public void nullASeries() throws Exception {
+    threeDisjointSameE();
+    queryAB_Dstar();
+    final TimeSyncedIterator it = new TimeSyncedIterator("0", 
+        results.get("0").getKey().getFilterTagKs(), 
+        results.get("0").getValue());
+    // mimic the intersector kicking out a series
+    it.nullIterator(0);
+    
+    long ts = it.nextTimestamp();
+    assertEquals(1431561600000L, ts);
+    
+    final DataPoint[] dps = it.values();
+    double[] values = new double[] { 1, 4, 7 };
+    while (it.hasNext()) {
+      it.next(ts);
+      assertEquals(3, dps.length);
+      assertEquals(ts, dps[0].timestamp());
+      assertEquals(ts, dps[1].timestamp());
+      assertEquals(ts, dps[2].timestamp());
+      assertEquals(0, dps[0].toDouble(), 0.0001);
+      assertEquals(values[1]++, dps[1].toDouble(), 0.0001);
+      assertEquals(values[2]++, dps[2].toDouble(), 0.0001);
+      ts = it.nextTimestamp();
+    }
+    assertEquals(Long.MAX_VALUE, ts);
+  }
+  
+  @Test
+  public void nullAll() throws Exception {
+    threeDisjointSameE();
+    queryAB_Dstar();
+    final TimeSyncedIterator it = new TimeSyncedIterator("0", 
+        results.get("0").getKey().getFilterTagKs(), 
+        results.get("0").getValue());
+    // mimic the intersector kicking out all series.
+    it.nullIterator(0);
+    it.nullIterator(1);
+    it.nullIterator(2);
+
+    assertEquals(Long.MAX_VALUE, it.nextTimestamp());
+    assertFalse(it.hasNext());
+  }
+  
+  @Test
+  public void singleSeries() throws Exception {
+    threeDisjointSameE();
+    queryA_DD();
+    final TimeSyncedIterator it = new TimeSyncedIterator("0", 
+        results.get("0").getKey().getFilterTagKs(), 
+        results.get("0").getValue());
+    
+    long ts = it.nextTimestamp();
+    assertEquals(1431561600000L, ts);
+    
+    double value = 1;
+    while (it.hasNext()) {
+      final DataPoint[] dps = it.next(ts);
+      assertEquals(1, dps.length);
+      assertEquals(ts, dps[0].timestamp());
+      assertEquals(value++, dps[0].toDouble(), 0.0001);
+      ts = it.nextTimestamp();
+    }
+    assertEquals(Long.MAX_VALUE, ts);
+  }
+  
+  @Test
+  public void noData() throws Exception {
+    setDataPointStorage();
+    queryA_DD();
+    final TimeSyncedIterator it = new TimeSyncedIterator("0", 
+        results.get("0").getKey().getFilterTagKs(), 
+        results.get("0").getValue());
+    
+    assertEquals(0, it.values().length);
+    assertEquals(Long.MAX_VALUE, it.nextTimestamp());
+    assertFalse(it.hasNext());
+  }
+  
+  @Test
+  public void threeSeriesMissing() throws Exception {
+    threeSameEGaps();
+    queryAB_Dstar();
+    final TimeSyncedIterator it = new TimeSyncedIterator("0", 
+        results.get("0").getKey().getFilterTagKs(), 
+        results.get("0").getValue());
+    it.setFillPolicy(new NumericFillPolicy(FillPolicy.NOT_A_NUMBER));
+    
+    long ts = it.nextTimestamp();
+    assertEquals(1431561600000L, ts);
+    
+    DataPoint[] dps = it.next(ts);
+    assertEquals(ts, dps[0].timestamp());
+    assertEquals(ts, dps[1].timestamp());
+    assertEquals(ts, dps[2].timestamp());
+    
+    assertEquals(1, dps[0].toDouble(), 0.0001);
+    assertEquals(4, dps[1].toDouble(), 0.0001);
+    assertTrue(Double.isNaN(dps[2].toDouble()));
+    ts = it.nextTimestamp();
+    
+    dps = it.next(ts);
+    assertEquals(ts, dps[0].timestamp());
+    assertEquals(ts, dps[1].timestamp());
+    assertEquals(ts, dps[2].timestamp());
+    
+    assertTrue(Double.isNaN(dps[0].toDouble()));
+    assertEquals(5, dps[1].toDouble(), 0.0001);
+    assertEquals(8, dps[2].toDouble(), 0.0001);
+    ts = it.nextTimestamp();
+    
+    dps = it.next(ts);
+    assertEquals(ts, dps[0].timestamp());
+    assertEquals(ts, dps[1].timestamp());
+    assertEquals(ts, dps[2].timestamp());
+    
+    assertEquals(3, dps[0].toDouble(), 0.0001);
+    assertTrue(Double.isNaN(dps[1].toDouble()));
+    assertEquals(9, dps[2].toDouble(), 0.0001);
+    ts = it.nextTimestamp();
+  }
+  
+  @Test
+  public void threeSeriesMissingFillZero() throws Exception {
+    threeSameEGaps();
+    queryAB_Dstar();
+    final TimeSyncedIterator it = new TimeSyncedIterator("0", 
+        results.get("0").getKey().getFilterTagKs(), 
+        results.get("0").getValue());
+    it.setFillPolicy(new NumericFillPolicy(FillPolicy.ZERO));
+    
+    long ts = it.nextTimestamp();
+    assertEquals(1431561600000L, ts);
+    
+    DataPoint[] dps = it.next(ts);
+    assertEquals(ts, dps[0].timestamp());
+    assertEquals(ts, dps[1].timestamp());
+    assertEquals(ts, dps[2].timestamp());
+    
+    assertEquals(1, dps[0].toDouble(), 0.0001);
+    assertEquals(4, dps[1].toDouble(), 0.0001);
+    assertEquals(0, dps[2].toDouble(), 0.0001);
+    ts = it.nextTimestamp();
+    
+    dps = it.next(ts);
+    assertEquals(ts, dps[0].timestamp());
+    assertEquals(ts, dps[1].timestamp());
+    assertEquals(ts, dps[2].timestamp());
+    
+    assertEquals(0, dps[0].toDouble(), 0.0001);
+    assertEquals(5, dps[1].toDouble(), 0.0001);
+    assertEquals(8, dps[2].toDouble(), 0.0001);
+    ts = it.nextTimestamp();
+    
+    dps = it.next(ts);
+    assertEquals(ts, dps[0].timestamp());
+    assertEquals(ts, dps[1].timestamp());
+    assertEquals(ts, dps[2].timestamp());
+    
+    assertEquals(3, dps[0].toDouble(), 0.0001);
+    assertEquals(0, dps[1].toDouble(), 0.0001);
+    assertEquals(9, dps[2].toDouble(), 0.0001);
+    ts = it.nextTimestamp();
+  }
+  
+  @Test
+  public void threeSeriesMissingNull() throws Exception {
+    threeSameEGaps();
+    queryAB_Dstar();
+    final TimeSyncedIterator it = new TimeSyncedIterator("0", 
+        results.get("0").getKey().getFilterTagKs(), 
+        results.get("0").getValue());
+    it.setFillPolicy(new NumericFillPolicy(FillPolicy.NULL));
+    
+    long ts = it.nextTimestamp();
+    assertEquals(1431561600000L, ts);
+    
+    DataPoint[] dps = it.next(ts);
+    assertEquals(ts, dps[0].timestamp());
+    assertEquals(ts, dps[1].timestamp());
+    assertEquals(ts, dps[2].timestamp());
+    
+    assertEquals(1, dps[0].toDouble(), 0.0001);
+    assertEquals(4, dps[1].toDouble(), 0.0001);
+    assertTrue(Double.isNaN(dps[2].toDouble()));
+    ts = it.nextTimestamp();
+    
+    dps = it.next(ts);
+    assertEquals(ts, dps[0].timestamp());
+    assertEquals(ts, dps[1].timestamp());
+    assertEquals(ts, dps[2].timestamp());
+    
+    assertTrue(Double.isNaN(dps[0].toDouble()));
+    assertEquals(5, dps[1].toDouble(), 0.0001);
+    assertEquals(8, dps[2].toDouble(), 0.0001);
+    ts = it.nextTimestamp();
+    
+    dps = it.next(ts);
+    assertEquals(ts, dps[0].timestamp());
+    assertEquals(ts, dps[1].timestamp());
+    assertEquals(ts, dps[2].timestamp());
+    
+    assertEquals(3, dps[0].toDouble(), 0.0001);
+    assertTrue(Double.isNaN(dps[1].toDouble()));
+    assertEquals(9, dps[2].toDouble(), 0.0001);
+    ts = it.nextTimestamp();
+  }
+  
+  @Test
+  public void threeSeriesMissingScalar() throws Exception {
+    threeSameEGaps();
+    queryAB_Dstar();
+    final TimeSyncedIterator it = new TimeSyncedIterator("0", 
+        results.get("0").getKey().getFilterTagKs(), 
+        results.get("0").getValue());
+    it.setFillPolicy(new NumericFillPolicy(FillPolicy.SCALAR, 42));
+    
+    long ts = it.nextTimestamp();
+    assertEquals(1431561600000L, ts);
+    
+    DataPoint[] dps = it.next(ts);
+    assertEquals(ts, dps[0].timestamp());
+    assertEquals(ts, dps[1].timestamp());
+    assertEquals(ts, dps[2].timestamp());
+    
+    assertEquals(1, dps[0].toDouble(), 0.0001);
+    assertEquals(4, dps[1].toDouble(), 0.0001);
+    assertEquals(42, dps[2].toDouble(), 0.0001);
+    ts = it.nextTimestamp();
+    
+    dps = it.next(ts);
+    assertEquals(ts, dps[0].timestamp());
+    assertEquals(ts, dps[1].timestamp());
+    assertEquals(ts, dps[2].timestamp());
+    
+    assertEquals(42, dps[0].toDouble(), 0.0001);
+    assertEquals(5, dps[1].toDouble(), 0.0001);
+    assertEquals(8, dps[2].toDouble(), 0.0001);
+    ts = it.nextTimestamp();
+    
+    dps = it.next(ts);
+    assertEquals(ts, dps[0].timestamp());
+    assertEquals(ts, dps[1].timestamp());
+    assertEquals(ts, dps[2].timestamp());
+    
+    assertEquals(3, dps[0].toDouble(), 0.0001);
+    assertEquals(42, dps[1].toDouble(), 0.0001);
+    assertEquals(9, dps[2].toDouble(), 0.0001);
+    ts = it.nextTimestamp();
+  }
+  
+  @Test
+  public void failToNextTS() throws Exception {
+    threeDisjointSameE();
+    queryAB_Dstar();
+    final TimeSyncedIterator it = new TimeSyncedIterator("0", 
+        results.get("0").getKey().getFilterTagKs(), 
+        results.get("0").getValue());
+    
+    long ts = it.nextTimestamp();
+    assertEquals(1431561600000L, ts);
+    
+    int i = 0;
+    boolean broke = false;
+    while (it.hasNext()) {
+      // in this case the caller fails to advance the TS so we keep getting the
+      // same data points over and over again.
+      it.next(ts);
+      ++i;
+      if (i > 100) {
+        broke = true;
+        break;
+      }
+    }
+    if (!broke) {
+      fail("Expected to iterate over 100 times");
+    }
+  }
+
+  @Test
+  public void nextTimestampDoesntAdvance() throws Exception {
+    threeDisjointSameE();
+    queryAB_Dstar();
+    final TimeSyncedIterator it = new TimeSyncedIterator("0", 
+        results.get("0").getKey().getFilterTagKs(), 
+        results.get("0").getValue());
+    
+    assertEquals(1431561600000L, it.nextTimestamp());
+    assertEquals(1431561600000L, it.nextTimestamp());
+    assertEquals(1431561600000L, it.nextTimestamp());
+    assertEquals(1431561600000L, it.nextTimestamp());
+    assertEquals(1431561600000L, it.nextTimestamp());
+    assertEquals(1431561600000L, it.nextTimestamp());
+    assertEquals(1431561600000L, it.nextTimestamp());
+  }
+  
+  @Test
+  public void nextExceptionNoException() throws Exception {
+    threeDisjointSameE();
+    queryAB_Dstar();
+    final TimeSyncedIterator it = new TimeSyncedIterator("0", 
+        results.get("0").getKey().getFilterTagKs(), 
+        results.get("0").getValue());
+    it.next(it.nextTimestamp());
+    it.next(it.nextTimestamp());
+    it.next(it.nextTimestamp());
+    it.next(it.nextTimestamp());
+    assertEquals(Long.MAX_VALUE, it.nextTimestamp());
+  }
+  
+  @Test
+  public void getCopy() throws Exception {
+    threeDisjointSameE();
+    queryAB_Dstar();
+    final TimeSyncedIterator it = new TimeSyncedIterator("0", 
+        results.get("0").getKey().getFilterTagKs(), 
+        results.get("0").getValue());
+    
+    final ITimeSyncedIterator copy = it.getCopy();
+    assertTrue(copy != it);
+    
+    long ts = it.nextTimestamp();
+    assertEquals(1431561600000L, ts);
+    
+    double[] values = new double[] { 1, 4, 7 };
+    while (it.hasNext()) {
+      final DataPoint[] dps = it.next(ts);
+      assertEquals(3, dps.length);
+      assertEquals(ts, dps[0].timestamp());
+      assertEquals(ts, dps[1].timestamp());
+      assertEquals(ts, dps[2].timestamp());
+      assertEquals(values[0]++, dps[0].toDouble(), 0.0001);
+      assertEquals(values[1]++, dps[1].toDouble(), 0.0001);
+      assertEquals(values[2]++, dps[2].toDouble(), 0.0001);
+      ts = it.nextTimestamp();
+    }
+    assertEquals(Long.MAX_VALUE, ts);
+    
+    ts = copy.nextTimestamp();
+    assertEquals(1431561600000L, ts);
+    
+    values = new double[] { 1, 4, 7 };
+    while (copy.hasNext()) {
+      final DataPoint[] dps = copy.next(ts);
+      assertEquals(3, dps.length);
+      assertEquals(ts, dps[0].timestamp());
+      assertEquals(ts, dps[1].timestamp());
+      assertEquals(ts, dps[2].timestamp());
+      assertEquals(values[0]++, dps[0].toDouble(), 0.0001);
+      assertEquals(values[1]++, dps[1].toDouble(), 0.0001);
+      assertEquals(values[2]++, dps[2].toDouble(), 0.0001);
+      ts = copy.nextTimestamp();
+    }
+    assertEquals(Long.MAX_VALUE, ts);
+  }
+}
diff --git a/test/query/expression/TestUnionIterator.java b/test/query/expression/TestUnionIterator.java
new file mode 100644
index 0000000000..77a191e7bb
--- /dev/null
+++ b/test/query/expression/TestUnionIterator.java
@@ -0,0 +1,1075 @@
+// This file is part of OpenTSDB.
+// Copyright (C) 2015  The OpenTSDB Authors.
+//
+// This program is free software: you can redistribute it and/or modify it
+// under the terms of the GNU Lesser General Public License as published by
+// the Free Software Foundation, either version 2.1 of the License, or (at your
+// option) any later version.  This program is distributed in the hope that it
+// will be useful, but WITHOUT ANY WARRANTY; without even the implied warranty
+// of MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser
+// General Public License for more details.  You should have received a copy
+// of the GNU Lesser General Public License along with this program.  If not,
+// see <http://www.gnu.org/licenses/>.
+package net.opentsdb.query.expression;
+
+import static org.junit.Assert.assertArrayEquals;
+import static org.junit.Assert.assertEquals;
+import static org.junit.Assert.assertFalse;
+import static org.junit.Assert.assertTrue;
+import static org.mockito.Mockito.mock;
+import static org.mockito.Mockito.when;
+
+import java.util.HashMap;
+import java.util.Map;
+
+import org.hbase.async.HBaseClient;
+import org.hbase.async.Bytes.ByteMap;
+import org.junit.Before;
+import org.junit.Test;
+import org.junit.runner.RunWith;
+import org.powermock.core.classloader.annotations.PowerMockIgnore;
+import org.powermock.core.classloader.annotations.PrepareForTest;
+import org.powermock.modules.junit4.PowerMockRunner;
+
+import net.opentsdb.core.DataPoint;
+import net.opentsdb.core.FillPolicy;
+import net.opentsdb.core.IllegalDataException;
+import net.opentsdb.storage.MockBase;
+import net.opentsdb.utils.ByteSet;
+
+@RunWith(PowerMockRunner.class)
+@PowerMockIgnore({"javax.management.*", "javax.xml.*",
+  "ch.qos.*", "org.slf4j.*",
+  "com.sum.*", "org.xml.*"})
+@PrepareForTest({ TimeSyncedIterator.class })
+public class TestUnionIterator extends BaseTimeSyncedIteratorTest  {
+
+  /** used for the flattenTags tests */
+  private static final byte[] UID1 = new byte[] { 0, 0, 1 };
+  private static final byte[] UID2 = new byte[] { 0, 0, 2 };
+  private static final byte[] UID3 = new byte[] { 0, 0, 3 };  
+  private ByteMap<byte[]> tags;
+  private ByteSet agg_tags;
+  private ITimeSyncedIterator sub;
+  private ByteSet query_tags;
+  private NumericFillPolicy fill_policy;
+  
+  @Before
+  public void beforeLocal() throws Exception {
+    tags = new ByteMap<byte[]>();
+    tags.put(UID1, UID1);
+    tags.put(UID2, UID2);
+    
+    agg_tags = new ByteSet();
+    agg_tags.add(UID3);
+    
+    fill_policy = new NumericFillPolicy(FillPolicy.NOT_A_NUMBER);
+    sub = mock(ITimeSyncedIterator.class);
+    query_tags = new ByteSet();
+    query_tags.add(UID1);
+    when(sub.getQueryTagKs()).thenReturn(query_tags);
+    when(sub.getFillPolicy()).thenReturn(fill_policy);
+  }
+
+  @Test (expected = NullPointerException.class)
+  public void ctorNullResults() {
+    new UnionIterator("it", null, true, true);
+  }
+  
+  @Test
+  public void ctorEmptyResults() {
+    final UnionIterator it = new UnionIterator("it",
+        new HashMap<String, ITimeSyncedIterator>(), true, true);
+    assertEquals(0, it.getSeriesSize());
+    assertFalse(it.hasNext());
+  }
+  
+  @Test
+  public void twoAndThreeSeries() throws Exception {
+    oneExtraSameE();
+    queryAB_Dstar();
+    
+    final UnionIterator it = new UnionIterator("it", iterators, false, false);
+    final Map<String, ExpressionDataPoint[]> dps = it.getResults();
+    assertTrue(it.hasNext());
+    assertEquals(2, dps.size());
+    assertEquals(3, it.getSeriesSize());
+    
+    long ts = 1431561600000L;
+    double values[] = new double[] { 1, 4, 11, 14, 17 };
+    while (it.hasNext()) {
+      it.next();
+      
+      DataPoint[] set_dps = dps.get("0");
+      assertEquals(3, set_dps.length);
+      assertEquals(ts, set_dps[0].timestamp());
+      assertEquals(ts, set_dps[1].timestamp());
+      assertEquals(ts, set_dps[2].timestamp());
+      assertEquals(values[0]++, set_dps[0].toDouble(), 0.0001);
+      assertEquals(values[1]++, set_dps[1].toDouble(), 0.0001);
+      assertEquals(0, set_dps[2].toDouble(), 0.0001);
+      
+      set_dps = dps.get("1");
+      assertEquals(3, set_dps.length);
+      assertEquals(ts, set_dps[0].timestamp());
+      assertEquals(ts, set_dps[1].timestamp());
+      assertEquals(ts, set_dps[2].timestamp());
+      assertEquals(values[2]++, set_dps[0].toDouble(), 0.0001);
+      assertEquals(values[3]++, set_dps[1].toDouble(), 0.0001);
+      assertEquals(values[4]++, set_dps[2].toDouble(), 0.0001);
+      ts += 60000;
+    }
+  }
+  
+  @Test
+  public void twoAndThreeSeriesExtraDP() throws Exception {
+    oneExtraSameE();
+    queryAB_Dstar();
+    
+    final HashMap<String, String> tags = new HashMap<String, String>(2);
+    tags.put("D", "G");
+    tags.put("E", "E");
+    tsdb.addPoint("B", 1431561630, 14, tags).joinUninterruptibly();
+    
+    final UnionIterator it = new UnionIterator("it", iterators, false, false);
+    final Map<String, ExpressionDataPoint[]> dps = it.getResults();
+    assertTrue(it.hasNext());
+    assertEquals(2, dps.size());
+    assertEquals(3, it.getSeriesSize());
+    
+    long ts = 1431561600000L;
+    double values[] = new double[] { 1, 4, 11, 14, 17 };
+    while (it.hasNext()) {
+      it.next();
+      
+      DataPoint[] set_dps = dps.get("0");
+      assertEquals(3, set_dps.length);
+      assertEquals(ts, set_dps[0].timestamp());
+      assertEquals(ts, set_dps[1].timestamp());
+      assertEquals(ts, set_dps[2].timestamp());
+      assertEquals(values[0]++, set_dps[0].toDouble(), 0.0001);
+      assertEquals(values[1]++, set_dps[1].toDouble(), 0.0001);
+      assertEquals(0, set_dps[2].toDouble(), 0.0001);
+      
+      set_dps = dps.get("1");
+      assertEquals(ts, set_dps[0].timestamp());
+      assertEquals(ts, set_dps[1].timestamp());
+      assertEquals(ts, set_dps[2].timestamp());
+      assertEquals(values[2]++, set_dps[0].toDouble(), 0.0001);
+      assertEquals(values[3]++, set_dps[1].toDouble(), 0.0001);
+      assertEquals(values[4]++, set_dps[2].toDouble(), 0.0001);
+
+      ts += 60000;
+    }
+  }
+  
+  @Test
+  public void threeSeriesUnionToFour() throws Exception {
+    threeDisjointSameE();
+    queryAB_Dstar();
+    
+    final UnionIterator it = new UnionIterator("it", iterators, false, false);
+    final Map<String, ExpressionDataPoint[]> dps = it.getResults();
+    assertTrue(it.hasNext());
+    assertEquals(2, dps.size());
+    assertEquals(4, it.getSeriesSize());
+    
+    long ts = 1431561600000L;
+    double values[] = new double[] { 1, 4, 7, 11, 17, 14 };
+    while (it.hasNext()) {
+      it.next();
+      
+      DataPoint[] set_dps = dps.get("0");
+      assertEquals(4, set_dps.length);
+      assertEquals(ts, set_dps[0].timestamp());
+      assertEquals(ts, set_dps[1].timestamp());
+      assertEquals(ts, set_dps[2].timestamp());
+      assertEquals(ts, set_dps[3].timestamp());
+      assertEquals(values[0]++, set_dps[0].toDouble(), 0.0001);
+      assertEquals(values[1]++, set_dps[1].toDouble(), 0.0001);
+      assertEquals(values[2]++, set_dps[2].toDouble(), 0.0001);
+      assertEquals(0, set_dps[3].toDouble(), 0.0001);
+      
+      set_dps = dps.get("1");
+      assertEquals(4, set_dps.length);
+      assertEquals(ts, set_dps[0].timestamp());
+      assertEquals(ts, set_dps[1].timestamp());
+      assertEquals(ts, set_dps[2].timestamp());
+      assertEquals(ts, set_dps[3].timestamp());
+      assertEquals(values[3]++, set_dps[0].toDouble(), 0.0001);
+      assertEquals(0, set_dps[1].toDouble(), 0.0001);
+      assertEquals(values[4]++, set_dps[2].toDouble(), 0.0001);
+      assertEquals(values[5]++, set_dps[3].toDouble(), 0.0001);
+
+      ts += 60000;
+    }
+  }
+  
+  @Test
+  public void threeSeriesUnionToExtraDPs() throws Exception {
+    reduceToOne(); // though we won't :)
+    queryAB_Dstar();
+    
+    HashMap<String, String> tags = new HashMap<String, String>(2);
+    tags.put("D", "F");
+    tags.put("E", "E");
+    tsdb.addPoint("A", 1431561630, 1024, tags).joinUninterruptibly();
+    
+    tags = new HashMap<String, String>(2);
+    tags.put("D", "Q");
+    tags.put("E", "E");
+    tsdb.addPoint("B", 1431561630, 1024, tags).joinUninterruptibly();
+    
+    final UnionIterator it = new UnionIterator("it", iterators, false, false);
+    final Map<String, ExpressionDataPoint[]> dps = it.getResults();
+    assertTrue(it.hasNext());
+    assertEquals(2, dps.size());
+    assertEquals(5, it.getSeriesSize());
+    
+    long ts = 1431561600000L;
+    double values[] = new double[] { 1, 4, 7, 17, 11, 14 };
+    while (it.hasNext()) {
+      it.next();
+
+      DataPoint[] set_dps = dps.get("0");
+      assertEquals(5, set_dps.length);
+      assertEquals(ts, set_dps[0].timestamp());
+      assertEquals(ts, set_dps[1].timestamp());
+      assertEquals(ts, set_dps[2].timestamp());
+      assertEquals(ts, set_dps[3].timestamp());
+      assertEquals(ts, set_dps[4].timestamp());
+      assertEquals(values[0]++, set_dps[0].toDouble(), 0.0001);
+      assertEquals(values[1]++, set_dps[1].toDouble(), 0.0001);
+      assertEquals(values[2]++, set_dps[2].toDouble(), 0.0001);
+      assertEquals(0, set_dps[3].toDouble(), 0.0001);
+      assertEquals(0, set_dps[4].toDouble(), 0.0001);
+      
+      set_dps = dps.get("1");
+      assertEquals(5, set_dps.length);
+      assertEquals(ts, set_dps[1].timestamp());
+      assertEquals(ts, set_dps[2].timestamp());
+      assertEquals(ts, set_dps[3].timestamp());
+      assertEquals(ts, set_dps[4].timestamp());
+      assertEquals(ts, set_dps[0].timestamp());
+      assertEquals(0, set_dps[0].toDouble(), 0.0001);
+      assertEquals(0, set_dps[1].toDouble(), 0.0001);
+      assertEquals(values[3]++, set_dps[2].toDouble(), 0.0001);
+      assertEquals(values[4]++, set_dps[3].toDouble(), 0.0001);
+      assertEquals(values[5]++, set_dps[4].toDouble(), 0.0001);
+
+      ts += 60000;
+    }
+  }
+  
+  @Test
+  public void threeSeriesAgged() throws Exception {
+    threeSameE();
+    queryAB_AggAll();
+    
+    final UnionIterator it = new UnionIterator("it", iterators, false, false);
+    final Map<String, ExpressionDataPoint[]> dps = it.getResults();
+    assertTrue(it.hasNext());
+    assertEquals(2, dps.size());
+    assertEquals(1, it.getSeriesSize());
+    
+    long ts = 1431561600000L;
+    double values[] = new double[] { 12, 42 };
+    while (it.hasNext()) {
+      it.next();
+      
+      DataPoint[] set_dps = dps.get("0");
+      assertEquals(1, set_dps.length);
+      assertEquals(ts, set_dps[0].timestamp());
+      assertEquals(values[0], set_dps[0].toDouble(), 0.0001);
+      
+      set_dps = dps.get("1");
+      assertEquals(1, set_dps.length);
+      assertEquals(ts, set_dps[0].timestamp());
+      assertEquals(values[1], set_dps[0].toDouble(), 0.0001);
+      
+      values[0] += 3;
+      values[1] += 3;
+
+      ts += 60000;
+    }
+  }
+  
+  @Test
+  public void threeSeriesWithNaNs() throws Exception {
+    threeSameEGaps();
+    queryAB_Dstar();
+    for (ITimeSyncedIterator iterator : iterators.values()) {
+      iterator.setFillPolicy(new NumericFillPolicy(FillPolicy.NOT_A_NUMBER));
+    }
+    
+    final UnionIterator it = new UnionIterator("it", iterators, false, false);
+    final Map<String, ExpressionDataPoint[]> dps = it.getResults();
+    assertTrue(it.hasNext());
+    assertEquals(2, dps.size());
+    assertEquals(3, it.getSeriesSize());
+    
+    long ts = 1431561600000L;
+    it.next();
+    
+    DataPoint[] set_dps = dps.get("0");
+    assertEquals(3, set_dps.length);
+    assertEquals(ts, set_dps[0].timestamp());
+    assertEquals(ts, set_dps[1].timestamp());
+    assertEquals(ts, set_dps[2].timestamp());
+    assertEquals(1, set_dps[0].toDouble(), 0.0001);
+    assertEquals(4, set_dps[1].toDouble(), 0.0001);
+    assertTrue(Double.isNaN(set_dps[2].toDouble()));
+    
+    // whole series is NaN'd
+    set_dps = dps.get("1");
+    assertEquals(3, set_dps.length);
+    assertEquals(ts, set_dps[0].timestamp());
+    assertEquals(ts, set_dps[1].timestamp());
+    assertEquals(ts, set_dps[2].timestamp());
+    assertTrue(Double.isNaN(set_dps[0].toDouble()));
+    assertTrue(Double.isNaN(set_dps[1].toDouble()));
+    assertTrue(Double.isNaN(set_dps[2].toDouble()));
+
+    ts += 60000;
+    it.next();
+    
+    set_dps = dps.get("0");
+    assertEquals(3, set_dps.length);
+    assertEquals(ts, set_dps[0].timestamp());
+    assertEquals(ts, set_dps[1].timestamp());
+    assertEquals(ts, set_dps[2].timestamp());
+    assertTrue(Double.isNaN(set_dps[0].toDouble()));
+    assertEquals(5, set_dps[1].toDouble(), 0.0001);
+    assertEquals(8, set_dps[2].toDouble(), 0.0001);
+    
+    set_dps = dps.get("1");
+    assertEquals(3, set_dps.length);
+    assertEquals(ts, set_dps[0].timestamp());
+    assertEquals(ts, set_dps[1].timestamp());
+    assertEquals(ts, set_dps[2].timestamp());
+    assertTrue(Double.isNaN(set_dps[0].toDouble()));
+    assertEquals(15, set_dps[1].toDouble(), 0.0001);
+    assertTrue(Double.isNaN(set_dps[2].toDouble()));
+
+    ts += 60000;
+    it.next();
+    
+    set_dps = dps.get("0");
+    assertEquals(3, set_dps.length);
+    assertEquals(ts, set_dps[0].timestamp());
+    assertEquals(ts, set_dps[1].timestamp());
+    assertEquals(ts, set_dps[2].timestamp());
+    assertEquals(3, set_dps[0].toDouble(), 0.0001);
+    assertTrue(Double.isNaN(set_dps[1].toDouble()));
+    assertEquals(9, set_dps[2].toDouble(), 0.0001);
+    
+    set_dps = dps.get("1");
+    assertEquals(3, set_dps.length);
+    assertEquals(ts, set_dps[0].timestamp());
+    assertEquals(ts, set_dps[1].timestamp());
+    assertEquals(ts, set_dps[2].timestamp());
+    assertEquals(13, set_dps[0].toDouble(), 0.0001);
+    assertTrue(Double.isNaN(set_dps[1].toDouble()));
+    assertEquals(19, set_dps[2].toDouble(), 0.0001);
+
+    assertFalse(it.hasNext());
+  }
+  
+  @Test
+  public void twoSeriesTimeOffset() throws Exception {
+    timeOffset();
+    queryAB_Dstar();
+    for (ITimeSyncedIterator iterator : iterators.values()) {
+      iterator.setFillPolicy(new NumericFillPolicy(FillPolicy.NOT_A_NUMBER));
+    }
+    
+    final UnionIterator it = new UnionIterator("it", iterators, false, false);
+    final Map<String, ExpressionDataPoint[]> dps = it.getResults();
+    assertTrue(it.hasNext());
+    assertEquals(2, dps.size());
+    assertEquals(2, it.getSeriesSize());
+    
+    long ts = 1431561600000L;
+    it.next();
+    
+    DataPoint[] set_dps = dps.get("0");
+    assertEquals(2, set_dps.length);
+    assertEquals(ts, set_dps[0].timestamp());
+    assertEquals(ts, set_dps[1].timestamp());
+    assertEquals(1, set_dps[0].toDouble(), 0.0001);
+    assertEquals(4, set_dps[1].toDouble(), 0.0001);
+    
+    set_dps = dps.get("1");
+    assertEquals(2, set_dps.length);
+    assertEquals(ts, set_dps[0].timestamp());
+    assertEquals(ts, set_dps[1].timestamp());
+    assertTrue(Double.isNaN(set_dps[0].toDouble()));
+    assertTrue(Double.isNaN(set_dps[1].toDouble()));
+
+    ts += 60000;
+    it.next();
+    
+    set_dps = dps.get("0");
+    assertEquals(2, set_dps.length);
+    assertEquals(ts, set_dps[0].timestamp());
+    assertEquals(ts, set_dps[1].timestamp());
+    assertEquals(2, set_dps[0].toDouble(), 0.0001);
+    assertEquals(5, set_dps[1].toDouble(), 0.0001);
+    
+    set_dps = dps.get("1");
+    assertEquals(2, set_dps.length);
+    assertEquals(ts, set_dps[0].timestamp());
+    assertEquals(ts, set_dps[1].timestamp());
+    assertTrue(Double.isNaN(set_dps[0].toDouble()));
+    assertTrue(Double.isNaN(set_dps[1].toDouble()));
+
+    ts += 60000;
+    it.next();
+    
+    set_dps = dps.get("0");
+    assertEquals(2, set_dps.length);
+    assertEquals(ts, set_dps[0].timestamp());
+    assertEquals(ts, set_dps[1].timestamp());
+    assertTrue(Double.isNaN(set_dps[0].toDouble()));
+    assertTrue(Double.isNaN(set_dps[1].toDouble()));
+    
+    set_dps = dps.get("1");
+    assertEquals(2, set_dps.length);
+    assertEquals(ts, set_dps[0].timestamp());
+    assertEquals(ts, set_dps[1].timestamp());
+    assertEquals(13, set_dps[0].toDouble(), 0.0001);
+    assertEquals(16, set_dps[1].toDouble(), 0.0001);
+
+    ts += 60000;
+    it.next();
+    
+    set_dps = dps.get("0");
+    assertEquals(2, set_dps.length);
+    assertEquals(ts, set_dps[0].timestamp());
+    assertEquals(ts, set_dps[1].timestamp());
+    assertTrue(Double.isNaN(set_dps[0].toDouble()));
+    assertTrue(Double.isNaN(set_dps[1].toDouble()));
+    
+    set_dps = dps.get("1");
+    assertEquals(2, set_dps.length);
+    assertEquals(ts, set_dps[0].timestamp());
+    assertEquals(ts, set_dps[1].timestamp());
+    assertEquals(14, set_dps[0].toDouble(), 0.0001);
+    assertEquals(17, set_dps[1].toDouble(), 0.0001);
+    
+    assertFalse(it.hasNext());
+  }
+  
+  @Test
+  public void threeSeriesUsingResultTags() throws Exception {
+    threeDifE();
+    queryAB_Dstar();
+    final UnionIterator it = new UnionIterator("it", iterators, false, false);
+    final Map<String, ExpressionDataPoint[]> dps = it.getResults();
+    assertTrue(it.hasNext());
+    assertEquals(2, dps.size());
+    assertEquals(6, it.getSeriesSize());
+    
+    long ts = 1431561600000L;
+    double values[] = new double[] { 1, 4, 7, 11, 14, 17 };
+    while (it.hasNext()) {
+      it.next();
+      
+      DataPoint[] set_dps = dps.get("0");
+      assertEquals(6, set_dps.length);
+      assertEquals(ts, set_dps[0].timestamp());
+      assertEquals(ts, set_dps[1].timestamp());
+      assertEquals(ts, set_dps[2].timestamp());
+      assertEquals(ts, set_dps[3].timestamp());
+      assertEquals(ts, set_dps[4].timestamp());
+      assertEquals(ts, set_dps[5].timestamp());
+      assertEquals(values[0]++, set_dps[0].toDouble(), 0.0001);
+      assertEquals(0, set_dps[1].toDouble(), 0.0001);
+      assertEquals(values[1]++, set_dps[2].toDouble(), 0.0001);
+      assertEquals(0, set_dps[3].toDouble(), 0.0001);
+      assertEquals(values[2]++, set_dps[4].toDouble(), 0.0001);
+      assertEquals(0, set_dps[5].toDouble(), 0.0001);
+      
+      set_dps = dps.get("1");
+      assertEquals(6, set_dps.length);
+      assertEquals(ts, set_dps[0].timestamp());
+      assertEquals(ts, set_dps[1].timestamp());
+      assertEquals(ts, set_dps[2].timestamp());
+      assertEquals(ts, set_dps[3].timestamp());
+      assertEquals(ts, set_dps[4].timestamp());
+      assertEquals(ts, set_dps[5].timestamp());
+      assertEquals(0, set_dps[0].toDouble(), 0.0001);
+      assertEquals(values[3]++, set_dps[1].toDouble(), 0.0001);
+      assertEquals(0, set_dps[2].toDouble(), 0.0001);
+      assertEquals(values[4]++, set_dps[3].toDouble(), 0.0001);
+      assertEquals(0, set_dps[4].toDouble(), 0.0001);
+      assertEquals(values[5]++, set_dps[5].toDouble(), 0.0001);
+
+      ts += 60000;
+    }
+  }
+  
+  @Test
+  public void threeSeriesUsingQueryTags() throws Exception {
+    threeDifE();
+    queryAB_Dstar();
+    final UnionIterator it = new UnionIterator("it", iterators, true, false);
+    final Map<String, ExpressionDataPoint[]> dps = it.getResults();
+    assertTrue(it.hasNext());
+    assertEquals(2, dps.size());
+    assertEquals(3, it.getSeriesSize());
+    
+    long ts = 1431561600000L;
+    double values[] = new double[] { 1, 4, 7, 11, 14, 17 };
+    while (it.hasNext()) {
+      it.next();
+      
+      DataPoint[] set_dps = dps.get("0");
+      assertEquals(3, set_dps.length);
+      assertEquals(ts, set_dps[0].timestamp());
+      assertEquals(ts, set_dps[1].timestamp());
+      assertEquals(ts, set_dps[2].timestamp());
+      assertEquals(values[0]++, set_dps[0].toDouble(), 0.0001);
+      assertEquals(values[1]++, set_dps[1].toDouble(), 0.0001);
+      assertEquals(values[2]++, set_dps[2].toDouble(), 0.0001);
+      //assertEquals(0, set_dps[3].toDouble(), 0.0001);
+      
+      set_dps = dps.get("1");
+      assertEquals(3, set_dps.length);
+      assertEquals(ts, set_dps[0].timestamp());
+      assertEquals(ts, set_dps[1].timestamp());
+      assertEquals(ts, set_dps[2].timestamp());
+      assertEquals(values[3]++, set_dps[0].toDouble(), 0.0001);
+      assertEquals(values[4]++, set_dps[1].toDouble(), 0.0001);
+      assertEquals(values[5]++, set_dps[2].toDouble(), 0.0001);
+
+      ts += 60000;
+    }
+  }
+  
+  @Test
+  public void commonAggregatedTag() throws Exception {
+    twoSeriesAggedE();
+    queryAB_Dstar();
+    
+    final UnionIterator it = new UnionIterator("it", iterators, false, false);
+    final Map<String, ExpressionDataPoint[]> dps = it.getResults();
+    assertTrue(it.hasNext());
+    assertEquals(2, dps.size());
+    assertEquals(1, it.getSeriesSize());
+    
+    long ts = 1431561600000L;
+    double values[] = new double[] { 2, 22 };
+    while (it.hasNext()) {
+      it.next();
+      
+      DataPoint[] set_dps = dps.get("0");
+      assertEquals(1, set_dps.length);
+      assertEquals(ts, set_dps[0].timestamp());
+      assertEquals(values[0], set_dps[0].toDouble(), 0.0001);
+      
+      set_dps = dps.get("1");
+      assertEquals(1, set_dps.length);
+      assertEquals(ts, set_dps[0].timestamp());
+      assertEquals(values[1], set_dps[0].toDouble(), 0.0001);
+
+      values[0] += 2;
+      values[1] += 2;
+      
+      ts += 60000;
+    }
+  }
+  
+  @Test
+  public void extraAggTagIgnored() throws Exception {
+    twoSeriesAggedEandExtraTagK();
+    queryAB_Dstar();
+    
+    final UnionIterator it = new UnionIterator("it", iterators, false, false);
+    final Map<String, ExpressionDataPoint[]> dps = it.getResults();
+    assertTrue(it.hasNext());
+    assertEquals(2, dps.size());
+    assertEquals(1, it.getSeriesSize());
+    
+    long ts = 1431561600000L;
+    double values[] = new double[] { 2, 22 };
+    while (it.hasNext()) {
+      it.next();
+      
+      DataPoint[] set_dps = dps.get("0");
+      assertEquals(1, set_dps.length);
+      assertEquals(ts, set_dps[0].timestamp());
+      assertEquals(values[0], set_dps[0].toDouble(), 0.0001);
+      
+      set_dps = dps.get("1");
+      assertEquals(1, set_dps.length);
+      assertEquals(ts, set_dps[0].timestamp());
+      assertEquals(values[1], set_dps[0].toDouble(), 0.0001);
+
+      values[0] += 2;
+      values[1] += 2;
+      
+      ts += 60000;
+    }
+  }
+  
+  @Test
+  public void extraAggTag() throws Exception {
+    twoSeriesAggedEandExtraTagK();
+    queryAB_Dstar();
+    
+    final UnionIterator it = new UnionIterator("it", iterators, false, true);
+    final Map<String, ExpressionDataPoint[]> dps = it.getResults();
+    assertTrue(it.hasNext());
+    assertEquals(2, dps.size());
+    assertEquals(2, it.getSeriesSize());
+    
+    long ts = 1431561600000L;
+    double values[] = new double[] { 2, 22 };
+    while (it.hasNext()) {
+      it.next();
+      
+      DataPoint[] set_dps = dps.get("0");
+      assertEquals(2, set_dps.length);
+      assertEquals(ts, set_dps[0].timestamp());
+      assertEquals(ts, set_dps[1].timestamp());
+      assertEquals(values[0], set_dps[0].toDouble(), 0.0001);
+      assertEquals(0, set_dps[1].toDouble(), 0.0001);
+      values[0] += 2;
+      
+      set_dps = dps.get("1");
+      assertEquals(2, set_dps.length);
+      assertEquals(ts, set_dps[0].timestamp());
+      assertEquals(ts, set_dps[1].timestamp());
+      assertEquals(0, set_dps[0].toDouble(), 0.0001);
+      assertEquals(values[1], set_dps[1].toDouble(), 0.0001);
+      values[1] += 2;
+
+      ts += 60000;
+    }
+  }
+  
+  @Test
+  public void onlyOneResultSet() throws Exception {
+    threeSameENoB();
+    queryAB_Dstar();
+    
+    final UnionIterator it = new UnionIterator("it", iterators, false, false);
+    final Map<String, ExpressionDataPoint[]> dps = it.getResults();
+    assertTrue(it.hasNext());
+    assertEquals(2, dps.size());
+    assertEquals(3, it.getSeriesSize());
+    
+    long ts = 1431561600000L;
+    double values[] = new double[] { 1, 4, 7 };
+    while (it.hasNext()) {
+      it.next();
+      
+      DataPoint[] set_dps = dps.get("0");
+      assertEquals(3, set_dps.length);
+      assertEquals(ts, set_dps[0].timestamp());
+      assertEquals(ts, set_dps[1].timestamp());
+      assertEquals(ts, set_dps[2].timestamp());
+      assertEquals(values[0]++, set_dps[0].toDouble(), 0.0001);
+      assertEquals(values[1]++, set_dps[1].toDouble(), 0.0001);
+      assertEquals(values[2]++, set_dps[2].toDouble(), 0.0001);
+      
+      set_dps = dps.get("1");
+      assertEquals(3, set_dps.length);
+      assertEquals(ts, set_dps[0].timestamp());
+      assertEquals(ts, set_dps[1].timestamp());
+      assertEquals(ts, set_dps[2].timestamp());
+      assertEquals(0, set_dps[0].toDouble(), 0.0001);
+      assertEquals(0, set_dps[1].toDouble(), 0.0001);
+      assertEquals(0, set_dps[2].toDouble(), 0.0001);
+
+      ts += 60000;
+    }
+  }
+  
+  @Test
+  public void onlyOneResultSetQueryTags() throws Exception {
+    threeSameENoB();
+    queryAB_Dstar();
+    
+    final UnionIterator it = new UnionIterator("it", iterators, true, false);
+    final Map<String, ExpressionDataPoint[]> dps = it.getResults();
+    assertTrue(it.hasNext());
+    assertEquals(2, dps.size());
+    assertEquals(3, it.getSeriesSize());
+    
+    long ts = 1431561600000L;
+    double values[] = new double[] { 1, 4, 7 };
+    while (it.hasNext()) {
+      it.next();
+      
+      DataPoint[] set_dps = dps.get("0");
+      assertEquals(3, set_dps.length);
+      assertEquals(ts, set_dps[0].timestamp());
+      assertEquals(ts, set_dps[1].timestamp());
+      assertEquals(ts, set_dps[2].timestamp());
+      assertEquals(values[0]++, set_dps[0].toDouble(), 0.0001);
+      assertEquals(values[1]++, set_dps[1].toDouble(), 0.0001);
+      assertEquals(values[2]++, set_dps[2].toDouble(), 0.0001);
+      
+      set_dps = dps.get("1");
+      assertEquals(3, set_dps.length);
+      assertEquals(ts, set_dps[0].timestamp());
+      assertEquals(ts, set_dps[1].timestamp());
+      assertEquals(ts, set_dps[2].timestamp());
+      assertEquals(0, set_dps[0].toDouble(), 0.0001);
+      assertEquals(0, set_dps[1].toDouble(), 0.0001);
+      assertEquals(0, set_dps[2].toDouble(), 0.0001);
+
+      ts += 60000;
+    }
+  }
+  
+  @Test
+  public void onlyOneResultSetAggTags() throws Exception {
+    threeSameENoB();
+    queryAB_Dstar();
+    
+    final UnionIterator it = new UnionIterator("it", iterators, false, true);
+    final Map<String, ExpressionDataPoint[]> dps = it.getResults();
+    assertTrue(it.hasNext());
+    assertEquals(2, dps.size());
+    assertEquals(3, it.getSeriesSize());
+    
+    long ts = 1431561600000L;
+    double values[] = new double[] { 1, 4, 7 };
+    while (it.hasNext()) {
+      it.next();
+      
+      DataPoint[] set_dps = dps.get("0");
+      assertEquals(3, set_dps.length);
+      assertEquals(ts, set_dps[0].timestamp());
+      assertEquals(ts, set_dps[1].timestamp());
+      assertEquals(ts, set_dps[2].timestamp());
+      assertEquals(values[0]++, set_dps[0].toDouble(), 0.0001);
+      assertEquals(values[1]++, set_dps[1].toDouble(), 0.0001);
+      assertEquals(values[2]++, set_dps[2].toDouble(), 0.0001);
+      
+      set_dps = dps.get("1");
+      assertEquals(3, set_dps.length);
+      assertEquals(ts, set_dps[0].timestamp());
+      assertEquals(ts, set_dps[1].timestamp());
+      assertEquals(ts, set_dps[2].timestamp());
+      assertEquals(0, set_dps[0].toDouble(), 0.0001);
+      assertEquals(0, set_dps[1].toDouble(), 0.0001);
+      assertEquals(0, set_dps[2].toDouble(), 0.0001);
+
+      ts += 60000;
+    }
+  }
+  
+  @Test
+  public void oneAggedOneTagged() throws Exception {
+    oneAggedTheOtherTagged();
+    queryAB_AggAll();
+    final UnionIterator it = new UnionIterator("it", iterators, false, true);
+    final Map<String, ExpressionDataPoint[]> dps = it.getResults();
+    assertTrue(it.hasNext());
+    assertEquals(2, dps.size());
+    assertEquals(2, it.getSeriesSize());
+    
+    long ts = 1431561600000L;
+    double values[] = new double[] { 2, 11 };
+    while (it.hasNext()) {
+      it.next();
+      
+      DataPoint[] set_dps = dps.get("0");
+      assertEquals(2, set_dps.length);
+      assertEquals(ts, set_dps[0].timestamp());
+      assertEquals(ts, set_dps[1].timestamp());
+      assertEquals(values[0], set_dps[0].toDouble(), 0.0001);
+      assertEquals(0, set_dps[1].toDouble(), 0.0001);
+      values[0] += 2;
+      
+      set_dps = dps.get("1");
+      assertEquals(2, set_dps.length);
+      assertEquals(ts, set_dps[0].timestamp());
+      assertEquals(ts, set_dps[1].timestamp());
+      System.out.println(set_dps[0].toDouble());
+      System.out.println(set_dps[1].toDouble());
+      assertEquals(0, set_dps[0].toDouble(), 0.0001);
+      assertEquals(values[1]++, set_dps[1].toDouble(), 0.0001);
+
+      ts += 60000;
+    }
+  }
+  
+  @Test
+  public void oneAggedOneTaggedUseQueryTagsWoutQueryTags() throws Exception {
+    oneAggedTheOtherTagged();
+    queryAB_AggAll();
+    
+    final UnionIterator it = new UnionIterator("it", iterators, true, false);
+    final Map<String, ExpressionDataPoint[]> dps = it.getResults();
+    assertTrue(it.hasNext());
+    assertEquals(2, dps.size());
+    assertEquals(1, it.getSeriesSize());
+    
+    long ts = 1431561600000L;
+    double values[] = new double[] { 2, 11 };
+    while (it.hasNext()) {
+      it.next();
+      
+      DataPoint[] set_dps = dps.get("0");
+      assertEquals(1, set_dps.length);
+      assertEquals(ts, set_dps[0].timestamp());
+      assertEquals(values[0], set_dps[0].toDouble(), 0.0001);
+      
+      set_dps = dps.get("1");
+      assertEquals(1, set_dps.length);
+      assertEquals(ts, set_dps[0].timestamp());
+      assertEquals(values[1]++, set_dps[0].toDouble(), 0.0001);
+
+      // the first set is agged
+      values[0] += 2;
+      
+      ts += 60000;
+    }
+  }
+  
+  @Test
+  public void singleSeries() throws Exception {
+    oneExtraSameE();
+    queryA_DD();
+    
+    final UnionIterator it = new UnionIterator("it", iterators, false, false);
+    final Map<String, ExpressionDataPoint[]> dps = it.getResults();
+    assertTrue(it.hasNext());
+    assertEquals(1, dps.size());
+    assertEquals(1, it.getSeriesSize());
+    
+    long ts = 1431561600000L;
+    double value = 1;
+    while (it.hasNext()) {
+      it.next();
+      
+      DataPoint[] set_dps = dps.get("0");
+      assertEquals(1, set_dps.length);
+      assertEquals(ts, set_dps[0].timestamp());
+      assertEquals(value++, set_dps[0].toDouble(), 0.0001);
+
+      ts += 60000;
+    }
+  }
+  
+  @Test
+  public void setAMissingE() throws Exception {
+    threeAMissingE();
+    queryAB_Dstar();
+    
+    final UnionIterator it = new UnionIterator("it", iterators, false, false);
+    final Map<String, ExpressionDataPoint[]> dps = it.getResults();
+    assertTrue(it.hasNext());
+    assertEquals(2, dps.size());
+    assertEquals(6, it.getSeriesSize());
+    
+    long ts = 1431561600000L;
+    double values[] = new double[] { 1, 4, 7, 11, 14, 17 };
+    while (it.hasNext()) {
+      it.next();
+      
+      DataPoint[] set_dps = dps.get("0");
+      assertEquals(6, set_dps.length);
+      for (int i = 0; i < set_dps.length; i++) {
+        assertEquals(ts, set_dps[i].timestamp());  
+      }
+      assertEquals(values[0]++, set_dps[0].toDouble(), 0.0001);
+      assertEquals(0, set_dps[1].toDouble(), 0.0001);
+      assertEquals(values[1]++, set_dps[2].toDouble(), 0.0001);
+      assertEquals(0, set_dps[3].toDouble(), 0.0001);
+      assertEquals(values[2]++, set_dps[4].toDouble(), 0.0001);
+      assertEquals(0, set_dps[5].toDouble(), 0.0001);
+      
+      set_dps = dps.get("1");
+      assertEquals(6, set_dps.length);
+      for (int i = 0; i < set_dps.length; i++) {
+        assertEquals(ts, set_dps[i].timestamp());  
+      }
+      assertEquals(0, set_dps[0].toDouble(), 0.0001);
+      assertEquals(values[3]++, set_dps[1].toDouble(), 0.0001);
+      assertEquals(0, set_dps[2].toDouble(), 0.0001);
+      assertEquals(values[4]++, set_dps[3].toDouble(), 0.0001);
+      assertEquals(0, set_dps[4].toDouble(), 0.0001);
+      assertEquals(values[5]++, set_dps[5].toDouble(), 0.0001);
+      
+      ts += 60000;
+    }
+  }
+  
+  @Test
+  public void setAMissingEQueryTags() throws Exception {
+    threeAMissingE();
+    queryAB_Dstar();
+    
+    final UnionIterator it = new UnionIterator("it", iterators, true, false);
+    final Map<String, ExpressionDataPoint[]> dps = it.getResults();
+    assertTrue(it.hasNext());
+    assertEquals(2, dps.size());
+    assertEquals(3, it.getSeriesSize());
+    
+    long ts = 1431561600000L;
+    double values[] = new double[] { 1, 4, 7, 11, 14, 17 };
+    while (it.hasNext()) {
+      it.next();
+      
+      DataPoint[] set_dps = dps.get("0");
+      assertEquals(3, set_dps.length);
+      assertEquals(ts, set_dps[0].timestamp());
+      assertEquals(ts, set_dps[1].timestamp());
+      assertEquals(ts, set_dps[2].timestamp());
+      assertEquals(values[0]++, set_dps[0].toDouble(), 0.0001);
+      assertEquals(values[1]++, set_dps[1].toDouble(), 0.0001);
+      assertEquals(values[2]++, set_dps[2].toDouble(), 0.0001);
+      
+      set_dps = dps.get("1");
+      assertEquals(3, set_dps.length);
+      assertEquals(ts, set_dps[0].timestamp());
+      assertEquals(ts, set_dps[1].timestamp());
+      assertEquals(ts, set_dps[2].timestamp());
+      assertEquals(values[3]++, set_dps[0].toDouble(), 0.0001);
+      assertEquals(values[4]++, set_dps[1].toDouble(), 0.0001);
+      assertEquals(values[5]++, set_dps[2].toDouble(), 0.0001);
+
+      ts += 60000;
+    }
+  }
+  
+  @Test 
+  public void noData() throws Exception {
+    setDataPointStorage();
+    queryAB_Dstar();
+    
+    final UnionIterator it = new UnionIterator("it", iterators, false, false);
+    final Map<String, ExpressionDataPoint[]> dps = it.getResults();
+    assertEquals(0, dps.size());
+    assertFalse(it.hasNext());
+    assertEquals(0, it.getSeriesSize());
+  }
+  
+  @Test (expected = IllegalDataException.class)
+  public void nextException() throws Exception {
+    threeDisjointSameE();
+    queryAB_Dstar();
+    
+    final UnionIterator it = new UnionIterator("it", iterators, false, false);
+    it.next();
+    it.next();
+    it.next();
+    it.next();
+  }
+ 
+  @Test
+  public void flattenTags() throws Exception {
+    final ExpressionDataPoint dp = getMockDB(tags, agg_tags);
+    final byte[] flat = UnionIterator.flattenTags(false, false, dp, sub);
+    assertArrayEquals(MockBase.concatByteArrays(UID1, UID1, UID2, UID2), flat);
+  }
+  
+  @Test
+  public void flattenTagsWithAgg() throws Exception {
+    final ExpressionDataPoint dp = getMockDB(tags, agg_tags);
+    final byte[] flat = UnionIterator.flattenTags(false, true, dp, sub);
+    assertArrayEquals(
+        MockBase.concatByteArrays(UID1, UID1, UID2, UID2, UID3), flat);
+  }
+  
+  @Test
+  public void flattenTagsQueryTags() throws Exception {
+    final ExpressionDataPoint dp = getMockDB(tags, agg_tags);
+    final byte[] flat = UnionIterator.flattenTags(true, false, dp, sub);
+    assertArrayEquals(MockBase.concatByteArrays(UID1, UID1), flat);
+  }
+  
+  @Test
+  public void flattenTagsQueryTagsWithAgg() throws Exception {
+    final ExpressionDataPoint dp = getMockDB(tags, agg_tags);
+    final byte[] flat = UnionIterator.flattenTags(true, true, dp, sub);
+    assertArrayEquals(MockBase.concatByteArrays(UID1, UID1, UID3), flat);
+  }
+  
+  @Test
+  public void flattenEmptyTags() throws Exception {
+    tags.clear();
+    final ExpressionDataPoint dp = getMockDB(tags, agg_tags);
+    final byte[] flat = UnionIterator.flattenTags(false, false, dp, sub);
+    assertArrayEquals(HBaseClient.EMPTY_ARRAY, flat);
+  }
+  
+  @Test
+  public void flattenEmptyTagsWithAggEmpty() throws Exception {
+    agg_tags.clear();
+    final ExpressionDataPoint dp = getMockDB(tags, agg_tags);
+    final byte[] flat = UnionIterator.flattenTags(false, true, dp, sub);
+    assertArrayEquals(MockBase.concatByteArrays(UID1, UID1, UID2, UID2), flat);
+  }
+  
+  // TODO - how will this play out if we choose a default agg of "none" and the
+  // user hasn't asked for any filtering?
+  @Test
+  public void flattenTagsQueryTagsEmpty() throws Exception {
+    query_tags.clear();
+    final ExpressionDataPoint dp = getMockDB(tags, agg_tags);
+    final byte[] flat = UnionIterator.flattenTags(true, false, dp, sub);
+    assertArrayEquals(HBaseClient.EMPTY_ARRAY, flat);
+  }
+  
+  @Test
+  public void flattenTagsQueryTagsEmptyWithAgg() throws Exception {
+    query_tags.clear();
+    final ExpressionDataPoint dp = getMockDB(tags, agg_tags);
+    final byte[] flat = UnionIterator.flattenTags(true, true, dp, sub);
+    assertArrayEquals(UID3, flat);
+  }
+
+  @Test
+  public void flattenTagsNullTags() throws Exception {
+    final ExpressionDataPoint dp = getMockDB(null, agg_tags);
+    final byte[] flat = UnionIterator.flattenTags(true, false, dp, sub);
+    assertArrayEquals(HBaseClient.EMPTY_ARRAY, flat);
+  }
+  
+  @Test
+  public void flattenTagsNullAggTagsNotRequested() throws Exception {
+    final ExpressionDataPoint dp = getMockDB(tags, null);
+    final byte[] flat = UnionIterator.flattenTags(false, false, dp, sub);
+    assertArrayEquals(MockBase.concatByteArrays(UID1, UID1, UID2, UID2), flat);
+  }
+  
+  @Test (expected = NullPointerException.class)
+  public void flattenTagsNullAggTags() throws Exception {
+    final ExpressionDataPoint dp = getMockDB(tags, null);
+    UnionIterator.flattenTags(false, true, dp, sub);
+  }
+  
+  @Test
+  public void flattenTagsNullSubNotRequested() throws Exception {
+    final ExpressionDataPoint dp = getMockDB(tags, agg_tags);
+    final byte[] flat = UnionIterator.flattenTags(false, false, dp, null);
+    assertArrayEquals(MockBase.concatByteArrays(UID1, UID1, UID2, UID2), flat);
+  }
+  
+  @Test (expected = NullPointerException.class)
+  public void flattenTagsNullSub() throws Exception {
+    final ExpressionDataPoint dp = getMockDB(tags, agg_tags);
+    UnionIterator.flattenTags(true, false, dp, null);
+  }
+
+  /**
+   * A helper to mock out the calls for flatten tags
+   * @param tags The tags to return 
+   * @param agg_tags The aggregated tags to return
+   * @return A mocked data point
+   */
+  private ExpressionDataPoint getMockDB(final ByteMap<byte[]> tags, 
+      final ByteSet agg_tags) {
+    final ExpressionDataPoint dp = mock(ExpressionDataPoint.class);
+    when(dp.tags()).thenReturn(tags);
+    when(dp.aggregatedTags()).thenReturn(agg_tags);
+    return dp;
+  }
+}
diff --git a/test/query/pojo/TestDownsampler.java b/test/query/pojo/TestDownsampler.java
new file mode 100644
index 0000000000..9613999238
--- /dev/null
+++ b/test/query/pojo/TestDownsampler.java
@@ -0,0 +1,104 @@
+// This file is part of OpenTSDB.
+// Copyright (C) 2015  The OpenTSDB Authors.
+//
+// This program is free software: you can redistribute it and/or modify it
+// under the terms of the GNU Lesser General Public License as published by
+// the Free Software Foundation, either version 2.1 of the License, or (at your
+// option) any later version.  This program is distributed in the hope that it
+// will be useful, but WITHOUT ANY WARRANTY; without even the implied warranty
+// of MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser
+// General Public License for more details.  You should have received a copy
+// of the GNU Lesser General Public License along with this program.  If not,
+// see <http://www.gnu.org/licenses/>.
+package net.opentsdb.query.pojo;
+
+import static org.junit.Assert.assertEquals;
+import static org.junit.Assert.assertTrue;
+import net.opentsdb.core.FillPolicy;
+import net.opentsdb.query.expression.NumericFillPolicy;
+import net.opentsdb.utils.JSON;
+
+import org.junit.Test;
+
+public class TestDownsampler {
+  
+  @Test(expected = IllegalArgumentException.class)
+  public void validationErrorWhenIntervalIsNull() throws Exception {
+    String json = "{\"aggregator\":\"sum\"}";
+    Downsampler downsampler = JSON.parseToObject(json, Downsampler.class);
+    downsampler.validate();
+  }
+  
+  @Test(expected = IllegalArgumentException.class)
+  public void validationErrorWhenIntervalIsEmpty() throws Exception {
+    String json = "{\"interval\":\"\",\"aggregator\":\"sum\"}";
+    Downsampler downsampler = JSON.parseToObject(json, Downsampler.class);
+    downsampler.validate();
+  }
+  
+  @Test(expected = IllegalArgumentException.class)
+  public void validationErrorWhenIntervalIsInvalid() throws Exception {
+    String json = "{\"interval\":\"45foo\",\"aggregator\":\"sum\"}";
+    Downsampler downsampler = JSON.parseToObject(json, Downsampler.class);
+    downsampler.validate();
+  }
+  
+  @Test(expected = IllegalArgumentException.class)
+  public void validationErrorWhenAggregatorIsNull() throws Exception {
+    String json = "{\"interval\":\"1h\"}";
+    Downsampler downsampler = JSON.parseToObject(json, Downsampler.class);
+    downsampler.validate();
+  }
+  
+  @Test(expected = IllegalArgumentException.class)
+  public void validationErrorWhenAggregatorIsEmpty() throws Exception {
+    String json = "{\"interval\":\"1h\",\"aggregator\":\"\"}";
+    Downsampler downsampler = JSON.parseToObject(json, Downsampler.class);
+    downsampler.validate();
+  }
+  
+  @Test(expected = IllegalArgumentException.class)
+  public void validationErrorWhenAggregatorIsInvalid() throws Exception {
+    String json = "{\"interval\":\"1h\",\"aggregator\":\"no such agg\"}";
+    Downsampler downsampler = JSON.parseToObject(json, Downsampler.class);
+    downsampler.validate();
+  }
+  
+  @Test
+  public void deserialize() throws Exception {
+    String json = "{\"interval\":\"1h\",\"aggregator\":\"zimsum\"}";
+    Downsampler downsampler = JSON.parseToObject(json, Downsampler.class);
+    downsampler.validate();
+    Downsampler expected = Downsampler.Builder()
+        .setInterval("1h").setAggregator("zimsum").build();
+    assertEquals(expected, downsampler);
+    
+    json = "{\"interval\":\"1h\",\"aggregator\":\"zimsum\","
+        + "\"fillPolicy\":{\"policy\":\"nan\"},\"junkfield\":true}";
+    downsampler = JSON.parseToObject(json, Downsampler.class);
+    downsampler.validate();
+    expected = Downsampler.Builder()
+        .setInterval("1h").setAggregator("zimsum")
+        .setFillPolicy(new NumericFillPolicy(FillPolicy.NOT_A_NUMBER)).build();
+    assertEquals(expected, downsampler);
+  }
+  
+  @Test
+  public void serialize() throws Exception {
+    Downsampler downsampler = Downsampler.Builder()
+        .setInterval("1h").setAggregator("zimsum").build();
+    String json = JSON.serializeToString(downsampler);
+    assertTrue(json.contains("\"interval\":\"1h\""));
+    assertTrue(json.contains("\"aggregator\":\"zimsum\""));
+    assertTrue(json.contains("\"fillPolicy\":null"));
+    
+    downsampler = Downsampler.Builder()
+        .setInterval("15m").setAggregator("max")
+        .setFillPolicy(new NumericFillPolicy(FillPolicy.NOT_A_NUMBER)).build();
+    json = JSON.serializeToString(downsampler);
+    assertTrue(json.contains("\"interval\":\"15m\""));
+    assertTrue(json.contains("\"aggregator\":\"max\""));
+    assertTrue(json.contains("\"fillPolicy\":{"));
+    assertTrue(json.contains("\"policy\":\"nan\""));
+  }
+}
diff --git a/test/query/pojo/TestExpression.java b/test/query/pojo/TestExpression.java
new file mode 100644
index 0000000000..6d1f5afd4e
--- /dev/null
+++ b/test/query/pojo/TestExpression.java
@@ -0,0 +1,96 @@
+// This file is part of OpenTSDB.
+// Copyright (C) 2015  The OpenTSDB Authors.
+//
+// This program is free software: you can redistribute it and/or modify it
+// under the terms of the GNU Lesser General Public License as published by
+// the Free Software Foundation, either version 2.1 of the License, or (at your
+// option) any later version.  This program is distributed in the hope that it
+// will be useful, but WITHOUT ANY WARRANTY; without even the implied warranty
+// of MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser
+// General Public License for more details.  You should have received a copy
+// of the GNU Lesser General Public License along with this program.  If not,
+// see <http://www.gnu.org/licenses/>.
+package net.opentsdb.query.pojo;
+
+import net.opentsdb.query.expression.VariableIterator.SetOperator;
+import net.opentsdb.utils.JSON;
+
+import org.junit.Test;
+
+import static org.junit.Assert.assertEquals;
+import static org.junit.Assert.assertTrue;
+
+public class TestExpression {
+  @Test(expected = IllegalArgumentException.class)
+  public void validationErrorWhenIdIsNull() throws Exception {
+    String json = "{\"expr\":\"a + b + c\"}";
+    Expression expression = JSON.parseToObject(json, Expression.class);
+    expression.validate();
+  }
+
+  @Test(expected = IllegalArgumentException.class)
+  public void validationErrorWhenIdIsEmpty() throws Exception {
+    String json = "{\"expr\":\"a + b + c\",\"id\":\"\"}";
+    Expression expression = JSON.parseToObject(json, Expression.class);
+    expression.validate();
+  }
+  
+  @Test(expected = IllegalArgumentException.class)
+  public void validationErrorWhenIdIsInvalid() throws Exception {
+    String json = "{\"expr\":\"a + b + c\",\"id\":\"system.busy\"}";
+    Expression expression = JSON.parseToObject(json, Expression.class);
+    expression.validate();
+  }
+
+  @Test(expected = IllegalArgumentException.class)
+  public void validationErrorWhenExprIsNull() throws Exception {
+    String json = "{\"id\":\"1\"}";
+    Expression expression = JSON.parseToObject(json, Expression.class);
+    expression.validate();
+  }
+
+  @Test(expected = IllegalArgumentException.class)
+  public void validationErrorWhenExprIsEmpty() throws Exception {
+    String json = "{\"id\":\"1\",\"expr\":\"\"}";
+    Expression expression = JSON.parseToObject(json, Expression.class);
+    expression.validate();
+  }
+
+  @Test(expected = IllegalArgumentException.class)
+  public void validationErrorWhenJoinIsInvalid() throws Exception {
+    String json = "{\"expr\":\"a + b + c\",\"id\":\"system.busy\","
+        + "\"join\":{\"operator\":\"nosuchjoin\"}}";
+    Expression expression = JSON.parseToObject(json, Expression.class);
+    expression.validate();
+  }
+  
+  @Test
+  public void deserialize() throws Exception {
+    String json = "{\"id\":\"e\",\"expr\":\"a + b + c\"}";
+    Expression expression = JSON.parseToObject(json, Expression.class);
+    expression.validate();
+    Expression expected = Expression.Builder().setId("e")
+        .setExpression("a + b + c").setJoin(
+            Join.Builder().setOperator(SetOperator.UNION).build()).build();
+    assertEquals(expected, expression);
+  }
+
+  @Test
+  public void serialize() throws Exception {
+    Expression expression = Expression.Builder().setId("e1")
+        .setJoin(Join.Builder().setOperator(SetOperator.UNION).build())
+        .setExpression("a + b + c").build();
+    String actual = JSON.serializeToString(expression);
+    assertTrue(actual.contains("\"id\":\"e1\""));
+    assertTrue(actual.contains("\"expr\":\"a + b + c\""));
+    assertTrue(actual.contains("\"join\":{\"operator\":\"union\""));
+    
+  }
+
+  @Test
+  public void unknownShouldBeIgnored() throws Exception {
+    String json = "{\"id\":\"1\",\"expr\":\"a + b + c\",\"unknown\":\"yo\"}";
+    JSON.parseToObject(json, Expression.class);
+    // pass if no unexpected exception
+  }
+}
diff --git a/test/query/pojo/TestFilter.java b/test/query/pojo/TestFilter.java
new file mode 100644
index 0000000000..1d1f9ea0a5
--- /dev/null
+++ b/test/query/pojo/TestFilter.java
@@ -0,0 +1,99 @@
+// This file is part of OpenTSDB.
+// Copyright (C) 2015  The OpenTSDB Authors.
+//
+// This program is free software: you can redistribute it and/or modify it
+// under the terms of the GNU Lesser General Public License as published by
+// the Free Software Foundation, either version 2.1 of the License, or (at your
+// option) any later version.  This program is distributed in the hope that it
+// will be useful, but WITHOUT ANY WARRANTY; without even the implied warranty
+// of MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser
+// General Public License for more details.  You should have received a copy
+// of the GNU Lesser General Public License along with this program.  If not,
+// see <http://www.gnu.org/licenses/>.
+package net.opentsdb.query.pojo;
+
+import net.opentsdb.query.filter.TagVFilter;
+import net.opentsdb.utils.JSON;
+
+import org.junit.Test;
+
+import java.util.Arrays;
+
+import static org.junit.Assert.assertEquals;
+import static org.junit.Assert.assertTrue;
+
+public class TestFilter {
+
+  @Test(expected = IllegalArgumentException.class)
+  public void validationErrorWhenIdIsNull() throws Exception {
+    String json = "{\"id\":null}";
+    Filter filter = JSON.parseToObject(json, Filter.class);
+    filter.validate();
+  }
+
+  @Test(expected = IllegalArgumentException.class)
+  public void validationBadId() throws Exception {
+    String json = "{\"id\":\"bad.Id\",\"tags\":[]}";
+    Filter filter = JSON.parseToObject(json, Filter.class);
+    filter.validate();
+  }
+  
+  @Test
+  public void deserialize() throws Exception {
+    String json = "{\"id\":\"f1\",\"tags\":[{\"tagk\":\"host\","
+        + "\"filter\":\"*\",\"type\":\"iwildcard\",\"groupBy\":false}],"
+        + "\"explicitTags\":\"true\"}";
+
+    TagVFilter tag = new TagVFilter.Builder().setFilter("*").setGroupBy(
+        false)
+        .setTagk("host").setType("iwildcard").build();
+
+    Filter expectedFilter = Filter.Builder().setId("f1")
+        .setTags(Arrays.asList(tag)).setExplicitTags(true).build();
+
+    Filter filter = JSON.parseToObject(json, Filter.class);
+    filter.validate();
+    assertEquals(expectedFilter, filter);
+  }
+
+  @Test
+  public void serialize() throws Exception {
+    TagVFilter tag = new TagVFilter.Builder().setFilter("*").setGroupBy(false)
+        .setTagk("host").setType("iwildcard").build();
+
+    Filter filter = Filter.Builder().setId("f1")
+        .setTags(Arrays.asList(tag)).setExplicitTags(true).build();
+
+    String actual = JSON.serializeToString(filter);
+    assertTrue(actual.contains("\"id\":\"f1\""));
+    assertTrue(actual.contains("\"tags\":["));
+    assertTrue(actual.contains("\"tagk\":\"host\""));
+    assertTrue(actual.contains("\"explicitTags\":true"));
+  }
+
+  @Test
+  public void unknownShouldBeIgnored() throws Exception {
+    String json = "{\"id\":\"1\",\"unknown\":\"yo\"}";
+    JSON.parseToObject(json, Filter.class);
+    // pass if no unexpected exception
+  }
+
+  @Test(expected = IllegalArgumentException.class)
+  public void invalidTags() throws Exception {
+    String json = "{\"id\":\"1\",\"tags\":[{\"tagk\":\"\","
+        + "\"filter\":\"*\",\"type\":\"iwildcard\",\"group_by\":false}],"
+        + "\"aggregation\":{\"tags\":[\"appid\"],\"aggregator\":\"sum\"}}";
+
+    Filter filter = JSON.parseToObject(json, Filter.class);
+    filter.validate();
+  }
+
+  @Test(expected = IllegalArgumentException.class)
+  public void invalidAggregation() throws Exception {
+    String json = "{\"id\":\"1\",\"tags\":[{\"tagk\":\"\","
+        + "\"filter\":\"*\",\"type\":\"iwildcard\",\"group_by\":false}],"
+        + "\"aggregator\":\"what\"}";
+    Filter filter = JSON.parseToObject(json, Filter.class);
+    filter.validate();
+  }
+}
diff --git a/test/query/pojo/TestJoin.java b/test/query/pojo/TestJoin.java
new file mode 100644
index 0000000000..8b27a5d3ec
--- /dev/null
+++ b/test/query/pojo/TestJoin.java
@@ -0,0 +1,66 @@
+// This file is part of OpenTSDB.
+// Copyright (C) 2015  The OpenTSDB Authors.
+//
+// This program is free software: you can redistribute it and/or modify it
+// under the terms of the GNU Lesser General Public License as published by
+// the Free Software Foundation, either version 2.1 of the License, or (at your
+// option) any later version.  This program is distributed in the hope that it
+// will be useful, but WITHOUT ANY WARRANTY; without even the implied warranty
+// of MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser
+// General Public License for more details.  You should have received a copy
+// of the GNU Lesser General Public License along with this program.  If not,
+// see <http://www.gnu.org/licenses/>.
+package net.opentsdb.query.pojo;
+
+import static org.junit.Assert.assertEquals;
+import static org.junit.Assert.assertTrue;
+import net.opentsdb.query.expression.VariableIterator.SetOperator;
+import net.opentsdb.utils.JSON;
+
+import org.junit.Test;
+
+public class TestJoin {
+
+  @Test
+  public void deserialize() throws Exception {
+    final String json = "{\"operator\":\"union\"}";
+    final Join join = Join.Builder().setOperator(SetOperator.UNION).build();
+    final Join deserialized = JSON.parseToObject(json, Join.class);
+    assertEquals(join, deserialized);
+  }
+  
+  @Test
+  public void serialize() throws Exception {
+    final Join join = Join.Builder().setOperator(SetOperator.UNION).build();
+    final String json = JSON.serializeToString(join);
+    assertTrue(json.contains("\"operator\":\"union\""));
+  }
+  
+  @Test(expected = IllegalArgumentException.class)
+  public void validationErrorWhenOperatorIsNull() throws Exception {
+    final String json = "{\"operator\":null}";
+    final Join join = JSON.parseToObject(json, Join.class);
+    join.validate();
+  }
+  
+  @Test(expected = IllegalArgumentException.class)
+  public void validationErrorWhenOperatorIsEmpty() throws Exception {
+    final String json = "{\"operator\":\"\"}";
+    final Join join = JSON.parseToObject(json, Join.class);
+    join.validate();
+  }
+  
+  @Test(expected = IllegalArgumentException.class)
+  public void validationErrorWhenOperatorIsInvalid() throws Exception {
+    final String json = "{\"operator\":\"nosuchop\"}";
+    final Join join = JSON.parseToObject(json, Join.class);
+    join.validate();
+  }
+  
+  @Test
+  public void unknownShouldBeIgnored() throws Exception {
+    String json = "{\"operator\":\"intersection\",\"unknown\":\"yo\"}";
+    JSON.parseToObject(json, Filter.class);
+    // pass if no unexpected exception
+  }
+}
diff --git a/test/query/pojo/TestMetric.java b/test/query/pojo/TestMetric.java
new file mode 100644
index 0000000000..c312fc1b97
--- /dev/null
+++ b/test/query/pojo/TestMetric.java
@@ -0,0 +1,123 @@
+// This file is part of OpenTSDB.
+// Copyright (C) 2015  The OpenTSDB Authors.
+//
+// This program is free software: you can redistribute it and/or modify it
+// under the terms of the GNU Lesser General Public License as published by
+// the Free Software Foundation, either version 2.1 of the License, or (at your
+// option) any later version.  This program is distributed in the hope that it
+// will be useful, but WITHOUT ANY WARRANTY; without even the implied warranty
+// of MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser
+// General Public License for more details.  You should have received a copy
+// of the GNU Lesser General Public License along with this program.  If not,
+// see <http://www.gnu.org/licenses/>.
+package net.opentsdb.query.pojo;
+
+import net.opentsdb.core.FillPolicy;
+import net.opentsdb.query.expression.NumericFillPolicy;
+import net.opentsdb.utils.JSON;
+
+import org.junit.Test;
+
+import static org.junit.Assert.assertEquals;
+import static org.junit.Assert.assertTrue;
+
+public class TestMetric {
+  @Test(expected = IllegalArgumentException.class)
+  public void validationErrorWhenMetricIsNull() throws Exception {
+    String json = "{\"id\":\"1\",\"filter\":\"2\","
+        + "\"timeOffset\":\"1h-ago\",\"aggregator\":\"sum\","
+        + "\"fillPolicy\":{\"policy\":\"nan\"}}";
+    Metric metric = JSON.parseToObject(json, Metric.class);
+    metric.validate();
+  }
+
+  @Test(expected = IllegalArgumentException.class)
+  public void validationErrorWhenMetricIsEmpty() throws Exception {
+    String json = "{\"metric\":\"\",\"id\":\"1\",\"filter\":\"2\","
+        + "\"timeOffset\":\"1h-ago\",\"aggregator\":\"sum\","
+        + "\"fillPolicy\":{\"policy\":\"nan\"}}";
+    Metric metric = JSON.parseToObject(json, Metric.class);
+    metric.validate();
+  }
+
+  @Test(expected = IllegalArgumentException.class)
+  public void validationErrorWhenIDIsNull() throws Exception {
+    String json = "{\"metric\":\"system.cpu\",\"id\":null,\"filter\":\"2\","
+        + "\"timeOffset\":\"1h-ago\",\"aggregator\":\"sum\","
+        + "\"fillPolicy\":{\"policy\":\"nan\"}}";
+    Metric metric = JSON.parseToObject(json, Metric.class);
+    metric.validate();
+  }
+  
+  @Test(expected = IllegalArgumentException.class)
+  public void validationErrorWhenIDIsEmpty() throws Exception {
+    String json = "{\"metric\":\"system.cpu\",\"id\":\"\",\"filter\":\"2\","
+        + "\"timeOffset\":\"1h-ago\",\"aggregator\":\"sum\","
+        + "\"fillPolicy\":{\"policy\":\"nan\"}}";
+    Metric metric = JSON.parseToObject(json, Metric.class);
+    metric.validate();
+  }
+  
+  @Test(expected = IllegalArgumentException.class)
+  public void validationErrorWhenIDIsInvalid() throws Exception {
+    String json = "{\"metric\":\"system.cpu\",\"id\":\"system.cpu\",\"filter\":\"2\","
+        + "\"timeOffset\":\"1h-ago\",\"aggregator\":\"sum\","
+        + "\"fillPolicy\":{\"policy\":\"nan\"}}";
+    Metric metric = JSON.parseToObject(json, Metric.class);
+    metric.validate();
+  }
+  
+  @Test
+  public void deserializeAllFields() throws Exception {
+    String json = "{\"metric\":\"YAMAS.cpu.idle\",\"id\":\"e1\",\"filter\":\"f2\","
+        + "\"timeOffset\":\"1h-ago\",\"aggregator\":\"sum\","
+        + "\"fillPolicy\":{\"policy\":\"nan\"}}";
+    Metric metric = JSON.parseToObject(json, Metric.class);
+    metric.validate();
+    Metric expectedMetric = Metric.Builder().setMetric("YAMAS.cpu.idle")
+        .setId("e1").setFilter("f2").setTimeOffset("1h-ago")
+        .setAggregator("sum")
+        .setFillPolicy(new NumericFillPolicy(FillPolicy.NOT_A_NUMBER))
+        .build();
+    
+    assertEquals(expectedMetric, metric);
+  }
+
+  @Test
+  public void serialize() throws Exception {
+    Metric metric = Metric.Builder().setMetric("YAMAS.cpu.idle")
+        .setId("e1").setFilter("f2").setTimeOffset("1h-ago")
+        .setFillPolicy(new NumericFillPolicy(FillPolicy.NOT_A_NUMBER))
+        .build();
+
+    String actual = JSON.serializeToString(metric);
+    assertTrue(actual.contains("\"metric\":\"YAMAS.cpu.idle\""));
+    assertTrue(actual.contains("\"id\":\"e1\""));
+    assertTrue(actual.contains("\"filter\":\"f2\""));
+    assertTrue(actual.contains("\"timeOffset\":\"1h-ago\""));
+    assertTrue(actual.contains("\"fillPolicy\":{"));
+  }
+
+  @Test
+  public void unknownShouldBeIgnored() throws Exception {
+    String json = "{\"aggregator\":\"sum\",\"tags\":[\"foo\",\"bar\"],\"unknown\":\"garbage\"}";
+    JSON.parseToObject(json, Metric.class);
+    // pass if no unexpected exception
+  }
+
+  @Test(expected = IllegalArgumentException.class)
+  public void validationtErrorWhenTimeOffsetIsInvalid() throws Exception {
+    String json = "{\"metric\":\"YAMAS.cpu.idle\",\"id\":\"1\",\"filter\":\"2\","
+        + "\"timeOffset\":\"what?\"}";
+    Metric metric = JSON.parseToObject(json, Metric.class);
+    metric.validate();
+  }
+  
+  @Test(expected = IllegalArgumentException.class)
+  public void validationtErrorBadFill() throws Exception {
+    String json = "{\"metric\":\"YAMAS.cpu.idle\",\"id\":\"1\",\"filter\":\"2\","
+        + "\"fillPolicy\":{\"policy\":\"zero\",\"value\":42}}";
+    Metric metric = JSON.parseToObject(json, Metric.class);
+    metric.validate();
+  }
+}
diff --git a/test/query/pojo/TestOutput.java b/test/query/pojo/TestOutput.java
new file mode 100644
index 0000000000..b4084e4b3e
--- /dev/null
+++ b/test/query/pojo/TestOutput.java
@@ -0,0 +1,45 @@
+// This file is part of OpenTSDB.
+// Copyright (C) 2015  The OpenTSDB Authors.
+//
+// This program is free software: you can redistribute it and/or modify it
+// under the terms of the GNU Lesser General Public License as published by
+// the Free Software Foundation, either version 2.1 of the License, or (at your
+// option) any later version.  This program is distributed in the hope that it
+// will be useful, but WITHOUT ANY WARRANTY; without even the implied warranty
+// of MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser
+// General Public License for more details.  You should have received a copy
+// of the GNU Lesser General Public License along with this program.  If not,
+// see <http://www.gnu.org/licenses/>.
+package net.opentsdb.query.pojo;
+
+import net.opentsdb.utils.JSON;
+import org.junit.Test;
+
+import static org.junit.Assert.assertEquals;
+
+public class TestOutput {
+  @Test
+  public void deserializeAllFields() throws Exception {
+    String json = "{\"id\":\"m1\",\"alias\":\"CPU OK\"}";
+    Output output = JSON.parseToObject(json, Output.class);
+    Output expectedOutput = Output.Builder().setId("m1").setAlias("CPU OK")
+        .build();
+    assertEquals(expectedOutput, output);
+  }
+
+  @Test
+  public void serialize() throws Exception {
+    Output output = Output.Builder().setId("m1").setAlias("CPU OK")
+        .build();
+    String actual = JSON.serializeToString(output);
+    String expected = "{\"id\":\"m1\",\"alias\":\"CPU OK\"}";
+    assertEquals(expected, actual);
+  }
+
+  @Test
+  public void unknownFieldShouldBeIgnored() throws Exception {
+    String json = "{\"id\":\"m1\",\"unknown\":\"yo\"}";
+    JSON.parseToObject(json, Filter.class);
+    // pass if no unexpected exception
+  }
+}
diff --git a/test/query/pojo/TestQuery.java b/test/query/pojo/TestQuery.java
new file mode 100644
index 0000000000..613ff787a8
--- /dev/null
+++ b/test/query/pojo/TestQuery.java
@@ -0,0 +1,223 @@
+// This file is part of OpenTSDB.
+// Copyright (C) 2015  The OpenTSDB Authors.
+//
+// This program is free software: you can redistribute it and/or modify it
+// under the terms of the GNU Lesser General Public License as published by
+// the Free Software Foundation, either version 2.1 of the License, or (at your
+// option) any later version.  This program is distributed in the hope that it
+// will be useful, but WITHOUT ANY WARRANTY; without even the implied warranty
+// of MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser
+// General Public License for more details.  You should have received a copy
+// of the GNU Lesser General Public License along with this program.  If not,
+// see <http://www.gnu.org/licenses/>.
+package net.opentsdb.query.pojo;
+
+import net.opentsdb.core.FillPolicy;
+import net.opentsdb.query.expression.NumericFillPolicy;
+import net.opentsdb.query.expression.VariableIterator.SetOperator;
+import net.opentsdb.query.filter.TagVFilter;
+import net.opentsdb.utils.JSON;
+
+import org.junit.Before;
+import org.junit.Test;
+
+import java.util.Arrays;
+import java.util.Collections;
+
+import static org.junit.Assert.assertEquals;
+import static org.junit.Assert.assertTrue;
+
+public class TestQuery {
+  Timespan time;
+  TagVFilter tag;
+  Filter filter;
+  Metric metric;
+  Expression expression;
+  Output output;
+
+  String json = "{"
+      + "  \"time\":{"
+      + "    \"start\":\"3h-ago\","
+      + "    \"end\":\"1h-ago\","
+      + "    \"timezone\":\"UTC\","
+      + "    \"aggregator\":\"avg\","
+      + "    \"downsampler\":{\"interval\":\"15m\","
+      + "      \"aggregator\":\"avg\","
+      + "      \"fillPolicy\":{\"policy\":\"nan\"}}"
+      + "  },"
+      + "  \"filters\":["
+      + "    {"
+      + "      \"id\":\"f1\","
+      + "      \"tags\":["
+      + "        {"
+      + "          \"tagk\":\"host\","
+      + "          \"filter\":\"*\","
+      + "          \"type\":\"iwildcard\","
+      + "          \"groupBy\":false"
+      + "        }"
+      + "      ]"
+      + "    }"
+      + "  ],"
+      + "  \"metrics\":["
+      + "    {"
+      + "      \"metric\":\"YAMAS.cpu.idle\","
+      + "      \"id\":\"m1\","
+      + "      \"filter\":\"f1\","
+      + "      \"aggregator\":\"sum\","
+      + "      \"timeOffset\":\"0\""
+      + "    }"
+      + "  ],"
+      + "  \"expressions\":["
+      + "    {"
+      + "      \"id\":\"e1\","
+      + "      \"expr\":\"m1 * 1024\""
+      + "    }"
+      + "  ],"
+      + "  \"outputs\":["
+      + "    {"
+      + "      \"id\":\"m1\","
+      + "      \"alias\":\"CPU Idle EAST DC\""
+      + "    }"
+      + "  ]"
+      + "}";
+
+  @Before
+  public void setup() {
+    time = Timespan.Builder().setStart("3h-ago").setAggregator("avg")
+        .setEnd("1h-ago").setTimezone("UTC").setDownsampler(
+            Downsampler.Builder().setInterval("15m").setAggregator("avg")
+            .setFillPolicy(new NumericFillPolicy(FillPolicy.NOT_A_NUMBER)).build())
+        .build();
+    TagVFilter tag = new TagVFilter.Builder().setFilter("*").setGroupBy(
+        false)
+        .setTagk("host").setType("iwildcard").build();
+    filter = Filter.Builder().setId("f1").setTags(Arrays.asList(tag)).build();
+    metric = Metric.Builder().setMetric("YAMAS.cpu.idle")
+        .setId("m1").setFilter("f1").setTimeOffset("0")
+        .setAggregator("sum").build();
+    expression = Expression.Builder().setId("e1")
+        .setExpression("m1 * 1024").setJoin(
+            Join.Builder().setOperator(SetOperator.UNION).build()).build();
+    output = Output.Builder().setId("m1").setAlias("CPU Idle EAST DC")
+        .build();
+  }
+
+  @Test(expected = IllegalArgumentException.class)
+  public void validationErrorWhenTimeIsNull() throws Exception {
+    Query query = getDefaultQueryBuilder().setTime(null).build();
+    query.validate();
+  }
+
+  @Test(expected = IllegalArgumentException.class)
+  public void invalidTime() throws Exception {
+    Timespan invalidTime = Timespan.Builder().build();
+    Query query = getDefaultQueryBuilder().setTime(invalidTime).build();
+    query.validate();
+  }
+
+  @Test(expected = IllegalArgumentException.class)
+  public void metricsIsNull() throws Exception {
+    Query query = getDefaultQueryBuilder().setMetrics(null).build();
+    query.validate();
+  }
+
+  @Test(expected = IllegalArgumentException.class)
+  public void metricsIsEmpty() throws Exception {
+    Query query = getDefaultQueryBuilder().setMetrics(
+        Collections.<Metric>emptyList()).build();
+    query.validate();
+  }
+
+  @Test(expected = IllegalArgumentException.class)
+  public void invalidMetric() throws Exception {
+    Metric invalidMetric = Metric.Builder().build();
+    Query query = getDefaultQueryBuilder()
+        .setMetrics(Arrays.asList(invalidMetric)).build();
+    query.validate();
+  }
+
+  @Test(expected = IllegalArgumentException.class)
+  public void invalidFilter() throws Exception {
+    Filter invalidFilter = Filter.Builder().build();
+    Query query = getDefaultQueryBuilder()
+        .setFilters(Arrays.asList(invalidFilter)).build();
+    query.validate();
+  }
+
+  @Test(expected = IllegalArgumentException.class)
+  public void invalidExpression() throws Exception {
+    Expression invalidExpression = Expression.Builder().build();
+    Query query = getDefaultQueryBuilder()
+        .setExpressions(Arrays.asList(invalidExpression)).build();
+    query.validate();
+  }
+
+  @Test(expected = IllegalArgumentException.class)
+  public void noSuchFilterIdInMetric() throws Exception {
+    Metric invalid_metric = Metric.Builder().setMetric("YAMAS.cpu.idle")
+        .setId("m2").setFilter("f2").setTimeOffset("0").build();
+    Query query = getDefaultQueryBuilder().setMetrics(
+        Arrays.asList(invalid_metric, metric)).build();
+    query.validate();
+  }
+
+  @Test
+  public void deserialize() throws Exception {
+    Query query = JSON.parseToObject(json, Query.class);
+    query.validate();
+    Query expected = Query.Builder().setExpressions(Arrays.asList(expression))
+        .setFilters(Arrays.asList(filter)).setMetrics(Arrays.asList(metric))
+        .setTime(time).setOutputs(Arrays.asList(output)).build();
+    assertEquals(expected, query);
+  }
+
+  @Test(expected = IllegalArgumentException.class)
+  public void duplicatedFilterId() throws Exception {
+    Query query = getDefaultQueryBuilder().setFilters(
+        Arrays.asList(filter, filter)).build();
+    query.validate();
+  }
+
+  @Test(expected = IllegalArgumentException.class)
+  public void duplicatedExpressionId() throws Exception {
+    Query query = getDefaultQueryBuilder().setExpressions(
+        Arrays.asList(expression, expression)).build();
+    query.validate();
+  }
+
+  @Test(expected = IllegalArgumentException.class)
+  public void duplicatedMetricId() throws Exception {
+    Query query = getDefaultQueryBuilder().setMetrics(
+        Arrays.asList(metric, metric)).build();
+    query.validate();
+  }
+
+  @Test
+  public void serialize() throws Exception {
+    Query query = Query.Builder().setExpressions(Arrays.asList(expression))
+        .setFilters(Arrays.asList(filter)).setMetrics(Arrays.asList(metric))
+        .setName("q1").setTime(time).setOutputs(Arrays.asList(output)).build();
+
+    String actual = JSON.serializeToString(query);
+//    String expected = "{\"name\":\"q1\",\"time\":{\"start\":\"3h-ago\"," 
+//        + "\"end\":\"1h-ago\",\"timezone\":\"UTC\",\"downsample\":\"15m-avg-nan\"," 
+//        + "\"interpolation\":\"LERP\"},\"filters\":[{\"id\":\"f1\"," 
+//        + "\"tags\":[{\"tagk\":\"host\",\"filter\":\"*\",\"group_by\":false," 
+//        + "\"type\":\"iwildcard\"}],\"aggregator\":\"sum\"}],"
+//        + "\"metrics\":[{\"metric\":\"YAMAS.cpu.idle\"," 
+//        + "\"id\":\"m1\",\"filter\":\"f1\",\"time_offset\":\"0\"}],"
+//        + "\"expressions\":[{\"id\":\"e1\",\"expr\":\"a + b + c\"}],"
+//        + "\"outputs\":[{\"var\":\"q1.m1\",\"alias\":\"CPU Idle EAST DC\"}]}";
+    assertTrue(actual.contains("\"name\":\"q1\""));
+    assertTrue(actual.contains("\"start\":\"3h-ago\""));
+    assertTrue(actual.contains("\"end\":\"1h-ago\""));
+    assertTrue(actual.contains("\"timezone\":\"UTC\""));
+    // TODO - finish the assertions
+  }
+
+  private Query.Builder getDefaultQueryBuilder() {
+    return Query.Builder().setExpressions(Arrays.asList(expression))
+          .setFilters(Arrays.asList(filter)).setMetrics(Arrays.asList(metric))
+          .setName("q1").setTime(time).setOutputs(Arrays.asList(output));
+  }
+}
diff --git a/test/query/pojo/TestTimeSpan.java b/test/query/pojo/TestTimeSpan.java
new file mode 100644
index 0000000000..ecd1450d72
--- /dev/null
+++ b/test/query/pojo/TestTimeSpan.java
@@ -0,0 +1,137 @@
+// This file is part of OpenTSDB.
+// Copyright (C) 2015  The OpenTSDB Authors.
+//
+// This program is free software: you can redistribute it and/or modify it
+// under the terms of the GNU Lesser General Public License as published by
+// the Free Software Foundation, either version 2.1 of the License, or (at your
+// option) any later version.  This program is distributed in the hope that it
+// will be useful, but WITHOUT ANY WARRANTY; without even the implied warranty
+// of MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser
+// General Public License for more details.  You should have received a copy
+// of the GNU Lesser General Public License along with this program.  If not,
+// see <http://www.gnu.org/licenses/>.
+package net.opentsdb.query.pojo;
+
+import net.opentsdb.core.FillPolicy;
+import net.opentsdb.query.expression.NumericFillPolicy;
+import net.opentsdb.utils.JSON;
+
+import org.junit.Test;
+
+import static org.junit.Assert.assertEquals;
+import static org.junit.Assert.assertTrue;
+
+public class TestTimeSpan {
+  @Test(expected = IllegalArgumentException.class)
+  public void startIsNull() {
+    String json = "{\"start\":null,\"end\":\"2015/05/05\","
+        + "\"timezone\":\"UTC\",\"downsample\":\"15m-avg-nan\","
+        + ",\"aggregator\":\"sum\"}";
+    Timespan timespan = JSON.parseToObject(json, Timespan.class);
+    timespan.validate();
+  }
+
+  @Test(expected = IllegalArgumentException.class)
+  public void startIsEmpty() {
+    String json = "{\"start\":\"\",\"end\":\"2015/05/05\","
+        + "\"timezone\":\"UTC\",\"downsample\":\"15m-avg-nan\""
+        + ",\"aggregator\":\"sum\"}";
+    Timespan timespan = JSON.parseToObject(json, Timespan.class);
+    timespan.validate();
+  }
+
+  @Test 
+  public void endIsNull() {
+    String json = "{\"start\":\"2015/05/05\",\"end\":null,"
+        + "\"timezone\":\"UTC\",\"downsample\":\"15m-avg-nan\""
+        + ",\"aggregator\":\"sum\"}";
+    Timespan timespan = JSON.parseToObject(json, Timespan.class);
+    timespan.validate();
+  }
+
+  @Test
+  public void endIsEmpty() {
+    String json = "{\"start\":\"1h-ago\",\"end\":\"\","
+        + "\"timezone\":\"UTC\",\"downsample\":\"15m-avg-nan\""
+        + ",\"aggregator\":\"sum\"}";
+    Timespan timespan = JSON.parseToObject(json, Timespan.class);
+    timespan.validate();
+  }
+
+  @Test(expected = IllegalArgumentException.class)
+  public void aggregatorIsNull() {
+    String json = "{\"start\":\"1h-ago\",\"end\":\"2015/05/05\","
+        + "\"timezone\":\"UTC\",\"downsample\":\"15m-avg-nan\","
+        + "}";
+    Timespan timespan = JSON.parseToObject(json, Timespan.class);
+    timespan.validate();
+  }
+
+  @Test(expected = IllegalArgumentException.class)
+  public void aggregatorIsEmpty() {
+    String json = "{\"start\":\"1h-ago\",\"end\":\"2015/05/05\","
+        + "\"timezone\":\"UTC\",\"downsample\":\"15m-avg-nan\""
+        + ",\"aggregator\":\"\"}";
+    Timespan timespan = JSON.parseToObject(json, Timespan.class);
+    timespan.validate();
+  }
+
+  @Test(expected = IllegalArgumentException.class)
+  public void idIsNull() {
+    String json = "{\"start\":\"-1h\",\"end\":\"2015/05/05\","
+        + "\"timezone\":\"UTC\",\"downsample\":\"15m-avg-nan\""
+        + ",\"interpolation\":\"LERP\"}";
+    Timespan timespan = JSON.parseToObject(json, Timespan.class);
+    timespan.validate();
+  }
+
+  @Test(expected = IllegalArgumentException.class)
+  public void idIsEmpty() {
+    String json = "{\"start\":\"-1h\",\"end\":\"2015/05/05\","
+        + "\"timezone\":\"UTC\",\"downsample\":\"15m-avg-nan\""
+        + ",\"interpolation\":\"LERP\"}";
+    Timespan timespan = JSON.parseToObject(json, Timespan.class);
+    timespan.validate();
+  }
+
+  @Test(expected = IllegalArgumentException.class)
+  public void invalidDownsample() {
+    String json = "{\"start\":\"1h-ago\",\"end\":\"2015/05/05\",\"timezone\":\"UTC\","
+        + "\"downsampler\":\"xxx\"}";
+    Timespan timespan = JSON.parseToObject(json, Timespan.class);
+    timespan.validate();
+  }
+
+  @Test
+  public void deserialize() {
+    String json = "{\"start\":\"1h-ago\",\"end\":\"2015/05/05\",\"timezone\":\"UTC\","
+        + "\"downsampler\":{\"interval\":\"15m\",\"aggregator\":\"avg\","
+        + "\"fillPolicy\":{\"policy\":\"nan\"}},\"aggregator\":\"sum\","
+        + "\"unknownfield\":\"boo\"}";
+    Timespan timespan = JSON.parseToObject(json, Timespan.class);
+    Timespan expected = Timespan.Builder().setStart("1h-ago")
+        .setEnd("2015/05/05").setTimezone("UTC").setAggregator("sum")
+        .setDownsampler(
+            Downsampler.Builder().setInterval("15m").setAggregator("avg")
+            .setFillPolicy(new NumericFillPolicy(FillPolicy.NOT_A_NUMBER)).build())
+        .build();
+    timespan.validate();
+    assertEquals(expected, timespan);
+  }
+
+  @Test
+  public void serialize() {
+    Timespan timespan = Timespan.Builder().setStart("1h-ago")
+        .setEnd("2015/05/05").setTimezone("UTC").setAggregator("sum").setDownsampler(
+            Downsampler.Builder().setInterval("15m").setAggregator("avg")
+            .setFillPolicy(new NumericFillPolicy(FillPolicy.NOT_A_NUMBER)).build())
+        .build();
+    String actual = JSON.serializeToString(timespan);
+    assertTrue(actual.contains("\"start\":\"1h-ago\""));
+    assertTrue(actual.contains("\"end\":\"2015/05/05\""));
+    assertTrue(actual.contains("\"aggregator\":\"sum\""));
+    assertTrue(actual.contains("\"timezone\":\"UTC\""));
+    assertTrue(actual.contains("\"downsampler\":{"));
+    assertTrue(actual.contains("\"interval\":\"15m\""));
+  }
+}
diff --git a/test/storage/MockBase.java b/test/storage/MockBase.java
index 73099e38b5..0a99c24197 100644
--- a/test/storage/MockBase.java
+++ b/test/storage/MockBase.java
@@ -33,6 +33,7 @@
 
 import javax.xml.bind.DatatypeConverter;
 
+import net.opentsdb.core.Const;
 import net.opentsdb.core.TSDB;
 import net.opentsdb.utils.Pair;
 
@@ -41,10 +42,13 @@
 import org.hbase.async.Bytes.ByteMap;
 import org.hbase.async.AppendRequest;
 import org.hbase.async.DeleteRequest;
+import org.hbase.async.FilterList;
 import org.hbase.async.GetRequest;
 import org.hbase.async.HBaseClient;
+import org.hbase.async.KeyRegexpFilter;
 import org.hbase.async.KeyValue;
 import org.hbase.async.PutRequest;
+import org.hbase.async.ScanFilter;
 import org.hbase.async.Scanner;
 import org.junit.Ignore;
 import org.mockito.invocation.InvocationOnMock;
@@ -632,6 +636,11 @@ public Set<byte[]> getKeys(final byte[] table) {
     return unique_rows.keySet();
   }
   
+  /** @return The set of scanners configured by the caller */
+  public HashSet<MockScanner> getScanners() {
+    return scanners;
+  }
+  
   /**
    * Return the mocked TSDB object to use for HBaseClient access
    * @return
@@ -1332,20 +1341,22 @@ public Deferred<Object> answer(InvocationOnMock invocation)
    * The KeyRegexp can be set and it will run against the hex value of the 
    * row key. In testing it seems to work nicely even with byte patterns.
    */
-  private class MockScanner implements 
+  public class MockScanner implements 
     Answer<Deferred<ArrayList<ArrayList<KeyValue>>>> {
 
+    private final Scanner mock_scanner;
     private final byte[] table;
     private byte[] start = null;
     private byte[] stop = null;
     private HashSet<String> scnr_qualifiers = null;
     private byte[] family = null;
-    private String regex = null;
+    private ScanFilter filter = null;
     private int max_num_rows = Scanner.DEFAULT_MAX_NUM_ROWS;
     private ByteMap<Iterator<Entry<byte[], ByteMap<TreeMap<Long, byte[]>>>>> 
       cursors;
     private ByteMap<Entry<byte[], ByteMap<TreeMap<Long, byte[]>>>> cf_rows;
     private byte[] last_row;
+    private String rex; // TEMP
     
     /**
      * Default ctor
@@ -1353,6 +1364,7 @@ private class MockScanner implements
      * @param table The table (confirmed to exist)
      */
     public MockScanner(final Scanner mock_scanner, final byte[] table) {
+      this.mock_scanner = mock_scanner;
       this.table = table;
 
       // capture the scanner fields when set
@@ -1360,7 +1372,8 @@ public MockScanner(final Scanner mock_scanner, final byte[] table) {
         @Override
         public Object answer(InvocationOnMock invocation) throws Throwable {
           final Object[] args = invocation.getArguments();
-          regex = (String)args[0];
+          filter = new KeyRegexpFilter((String)args[0], Const.ASCII_CHARSET);
+          rex = (String)args[0];
           return null;
         }
       }).when(mock_scanner).setKeyRegexp(anyString());
@@ -1369,11 +1382,21 @@ public Object answer(InvocationOnMock invocation) throws Throwable {
         @Override
         public Object answer(InvocationOnMock invocation) throws Throwable {
           final Object[] args = invocation.getArguments();
-          regex = (String)args[0];
+          filter = new KeyRegexpFilter((String)args[0], (Charset)args[1]);
+          rex = (String)args[0];
           return null;
         }
       }).when(mock_scanner).setKeyRegexp(anyString(), (Charset)any());
       
+      doAnswer(new Answer<Object>() {
+        @Override
+        public Object answer(InvocationOnMock invocation) throws Throwable {
+          final Object[] args = invocation.getArguments();
+          filter = (ScanFilter)args[0];
+          return null;
+        }
+      }).when(mock_scanner).setFilter(any(ScanFilter.class));
+
       doAnswer(new Answer<Object>() {
         @Override
         public Object answer(InvocationOnMock invocation) throws Throwable {
@@ -1424,6 +1447,13 @@ public Object answer(InvocationOnMock invocation) throws Throwable {
         }      
       }).when(mock_scanner).setQualifiers((byte[][])any());
       
+      doAnswer(new Answer<byte[]>() {
+        @Override
+        public byte[] answer(InvocationOnMock invocation) throws Throwable {
+          return start;
+        }
+      }).when(mock_scanner).getCurrentKey();
+      
       when(mock_scanner.nextRows()).thenAnswer(this);
       
     }
@@ -1470,12 +1500,41 @@ public Deferred<ArrayList<ArrayList<KeyValue>>> answer(
         return Deferred.fromResult(null);
       }
       
+      // TODO - fuzzy filter support
+      // TODO - fix the regex comparator 
       Pattern pattern = null;
-      if (regex != null && !regex.isEmpty()) {
-        try {
-          pattern = Pattern.compile(regex);
-        } catch (PatternSyntaxException e) {
-          e.printStackTrace();
+      if (rex != null) {
+        if (!rex.isEmpty()) {
+          pattern = Pattern.compile(rex);
+        }
+      } else if (filter != null) {
+        KeyRegexpFilter regex_filter = null;
+        
+        if (filter instanceof KeyRegexpFilter) {
+          regex_filter = (KeyRegexpFilter)filter;
+        } else if (filter instanceof FilterList) {
+          final List<ScanFilter> filters = 
+              Whitebox.getInternalState(filter, "filters");
+          for (final ScanFilter f : filters) {
+            if (f instanceof KeyRegexpFilter) {
+              regex_filter = (KeyRegexpFilter)f;
+            }
+          }
+        }
+        
+        if (regex_filter != null) {
+          try {
+            final String regexp = new String(
+                (byte[])Whitebox.getInternalState(regex_filter, "regexp"), 
+                Charset.forName(new String(
+                    (byte[])Whitebox.getInternalState(regex_filter, "charset"))));
+            if (!regexp.isEmpty()) {
+              pattern = Pattern.compile(regexp);
+            }
+          } catch (PatternSyntaxException e) {
+            e.printStackTrace();
+            return Deferred.fromError(e);
+          }
         }
       }
       
@@ -1624,6 +1683,16 @@ private void advance() {
         }
       }
     }
+    
+    /** @return The scanner for this mock */
+    public Scanner getScanner() {
+      return mock_scanner;
+    }
+  
+    /** @return The filter for this mock */
+    public ScanFilter getFilter() {
+      return filter;
+    }
   }
   
   /**
diff --git a/test/tools/TestDumpSeries.java b/test/tools/TestDumpSeries.java
index 375f3c4710..a589b34068 100644
--- a/test/tools/TestDumpSeries.java
+++ b/test/tools/TestDumpSeries.java
@@ -23,6 +23,7 @@
 import java.lang.reflect.Method;
 import java.util.HashMap;
 
+import net.opentsdb.core.AppendDataPoints;
 import net.opentsdb.core.TSDB;
 import net.opentsdb.meta.Annotation;
 import net.opentsdb.storage.MockBase;
@@ -312,7 +313,18 @@ public void dumpImportCompacted() throws Exception {
     assertEquals("sys.cpu.user 1356998400004 6 host=web01", log_lines[1]);
     assertEquals("sys.cpu.user 1356998400008 5 host=web01", log_lines[2]);
   }
-  
+
+  @Test
+  public void dumpImportAppendDataPoints() throws Exception {
+    writeAppendDataPoints();
+    doDump.invoke(null, tsdb, client, "tsdb".getBytes(MockBase.ASCII()), false,
+        true, new String[] { "1356998400", "1357002000", "sum", "sys.cpu.user" });
+    final String[] log_lines = buffer.toString("ISO-8859-1").split("\n");
+    assertNotNull(log_lines);
+    assertEquals("sys.cpu.user 1356998402 42 host=web01", log_lines[0]);
+    assertEquals("sys.cpu.user 1356998404 6 host=web01", log_lines[1]);
+  }
+
   @Test
   public void dumpRawCompactedAndDelete() throws Exception {
     writeCompactedData();
@@ -397,4 +409,11 @@ private void writeCompactedData() throws Exception {
 //    kvs.add(makekv(qual12, MockBase.concatByteArrays(val1, val2, ZERO)));
 
   }
+
+  private void writeAppendDataPoints() throws Exception {
+    storage.addColumn(MockBase.stringToBytes("00000150E22700000001000001"),
+        "t".getBytes(MockBase.ASCII()),
+        AppendDataPoints.APPEND_COLUMN_QUALIFIER,
+        new byte[] { 0, 0x20, 42, 0, 0x40, 6 });
+  }
 }
diff --git a/test/tsd/TestHttpJsonSerializer.java b/test/tsd/TestHttpJsonSerializer.java
index 1c746f55a2..fc8acad09d 100644
--- a/test/tsd/TestHttpJsonSerializer.java
+++ b/test/tsd/TestHttpJsonSerializer.java
@@ -163,6 +163,37 @@ public void parseSuggestV1NotJSON() throws Exception {
     serdes.parseSuggestV1();
   }
   
+  @Test
+  public void parseUidRenameV1() throws Exception {
+    HttpQuery query = NettyMocks.postQuery(tsdb, "",
+        "{\"metric\":\"sys.cpu.1\",\"name\":\"sys.cpu.2\"}", "");
+    HttpJsonSerializer serdes = new HttpJsonSerializer(query);
+    HashMap<String, String> map = serdes.parseUidRenameV1();
+    assertNotNull(map);
+    assertEquals("sys.cpu.1", map.get("metric"));
+  }
+
+  @Test (expected = BadRequestException.class)
+  public void parseUidRenameV1NoContent() throws Exception {
+    HttpQuery query = NettyMocks.postQuery(tsdb, "", null, "");
+    HttpJsonSerializer serdes = new HttpJsonSerializer(query);
+    serdes.parseUidRenameV1();
+  }
+
+  @Test (expected = BadRequestException.class)
+  public void parseUidRenameV1EmptyContent() throws Exception {
+    HttpQuery query = NettyMocks.postQuery(tsdb, "", "", "");
+    HttpJsonSerializer serdes = new HttpJsonSerializer(query);
+    serdes.parseUidRenameV1();
+  }
+
+  @Test (expected = BadRequestException.class)
+  public void parseUidRenameV1NotJSON() throws Exception {
+    HttpQuery query = NettyMocks.postQuery(tsdb, "", "NOT JSON", "");
+    HttpJsonSerializer serdes = new HttpJsonSerializer(query);
+    serdes.parseUidRenameV1();
+  }
+
   @Test
   public void formatSuggestV1() throws Exception {
     HttpQuery query = NettyMocks.getQuery(tsdb, "");
@@ -194,14 +225,53 @@ public void formatSuggestV1Null() throws Exception {
     serdes.formatSuggestV1(null);
   }
   
+  @Test
+  public void formatUidRenameV1Success() throws Exception {
+    HttpQuery query = NettyMocks.getQuery(tsdb, "");
+    HttpJsonSerializer serdes = new HttpJsonSerializer(query);
+    final HashMap<String, String> map = new HashMap<String, String>(2);
+    map.put("result", "true");
+    ChannelBuffer cb = serdes.formatUidRenameV1(map);
+    assertNotNull(cb);
+    assertEquals("{\"result\":\"true\"}",
+        cb.toString(Charset.forName("UTF-8")));
+  }
+
+  @Test
+  public void formatUidRenameV1Failed() throws Exception {
+    HttpQuery query = NettyMocks.getQuery(tsdb, "");
+    HttpJsonSerializer serdes = new HttpJsonSerializer(query);
+    final HashMap<String, String> map = new HashMap<String, String>(2);
+    map.put("result", "false");
+    map.put("error", "known");
+    ChannelBuffer cb = serdes.formatUidRenameV1(map);
+    assertNotNull(cb);
+    final String json = cb.toString(Charset.forName("UTF-8"));
+    assertTrue(json.contains("\"error\":\"known\""));
+    assertTrue(json.contains("\"result\":\"false\""));
+  }
+
+  @Test (expected = IllegalArgumentException.class)
+  public void formatUidRenameV1Null() throws Exception {
+    HttpQuery query = NettyMocks.getQuery(tsdb, "");
+    HttpJsonSerializer serdes = new HttpJsonSerializer(query);
+    serdes.formatUidRenameV1(null);
+  }
+
   @Test
   public void formatSerializersV1() throws Exception {
     HttpQuery.initializeSerializerMaps(tsdb);
     HttpQuery query = NettyMocks.getQuery(tsdb, "");
     HttpJsonSerializer serdes = new HttpJsonSerializer(query);
-    assertEquals("[{\"formatters\":",
-        serdes.formatSerializersV1().toString(Charset.forName("UTF-8"))
-        .substring(0, 15));
+    
+    String json = serdes.formatSerializersV1().toString(Charset.forName("UTF-8"));
+    assertTrue(json.contains("\"request_content_type\":\"application/json\""));
+    assertTrue(json.contains("\"formatters\":["));
+    assertTrue(json.contains("\"response_content_type\":\"application/json; "
+        + "charset=UTF-8\""));
+    assertTrue(json.contains("\"parsers\":["));
+    assertTrue(json.contains("\"serializer\":\"json\""));
+    assertTrue(json.contains("\"class\":\"net.opentsdb.tsd.HttpJsonSerializer\""));
   }
 
   @Test
diff --git a/test/tsd/TestQueryExecutor.java b/test/tsd/TestQueryExecutor.java
new file mode 100644
index 0000000000..b5c1f5c903
--- /dev/null
+++ b/test/tsd/TestQueryExecutor.java
@@ -0,0 +1,720 @@
+// This file is part of OpenTSDB.
+// Copyright (C) 2010-2016  The OpenTSDB Authors.
+//
+// This program is free software: you can redistribute it and/or modify it
+// under the terms of the GNU Lesser General Public License as published by
+// the Free Software Foundation, either version 2.1 of the License, or (at your
+// option) any later version.  This program is distributed in the hope that it
+// will be useful, but WITHOUT ANY WARRANTY; without even the implied warranty
+// of MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser
+// General Public License for more details.  You should have received a copy
+// of the GNU Lesser General Public License along with this program.  If not,
+// see <http://www.gnu.org/licenses/>.
+package net.opentsdb.tsd;
+
+import static org.junit.Assert.assertTrue;
+
+import java.nio.charset.Charset;
+import java.util.ArrayList;
+import java.util.Arrays;
+import java.util.List;
+
+import net.opentsdb.core.FillPolicy;
+import net.opentsdb.core.TSDB;
+import net.opentsdb.core.TSQuery;
+import net.opentsdb.query.expression.NumericFillPolicy;
+import net.opentsdb.query.expression.BaseTimeSyncedIteratorTest;
+import net.opentsdb.query.expression.VariableIterator.SetOperator;
+import net.opentsdb.query.filter.TagVFilter;
+import net.opentsdb.query.pojo.Downsampler;
+import net.opentsdb.query.pojo.Expression;
+import net.opentsdb.query.pojo.Filter;
+import net.opentsdb.query.pojo.Join;
+import net.opentsdb.query.pojo.Metric;
+import net.opentsdb.query.pojo.Output;
+import net.opentsdb.query.pojo.Query;
+import net.opentsdb.query.pojo.Timespan;
+import net.opentsdb.storage.MockBase;
+import net.opentsdb.utils.Config;
+import net.opentsdb.utils.DateTime;
+import net.opentsdb.utils.JSON;
+
+import org.junit.Before;
+import org.junit.Test;
+import org.junit.runner.RunWith;
+import org.powermock.core.classloader.annotations.PrepareForTest;
+import org.powermock.modules.junit4.PowerMockRunner;
+
+import com.stumbleupon.async.Deferred;
+import com.stumbleupon.async.DeferredGroupException;
+
+@RunWith(PowerMockRunner.class)
+@PrepareForTest({TSDB.class, Config.class, HttpQuery.class, 
+  Deferred.class, TSQuery.class, DateTime.class, DeferredGroupException.class })
+public class TestQueryExecutor extends BaseTimeSyncedIteratorTest {
+
+  private Timespan time;
+  private List<TagVFilter> tags;
+  private List<Filter> filters;
+  private List<Metric> metrics;
+  private List<Expression> expressions;
+  private List<Output> outputs;
+  private Join intersection;
+  
+  @Before
+  public void setup() {
+    intersection = Join.Builder().setOperator(SetOperator.INTERSECTION).build();
+    time = Timespan.Builder().setStart("1431561600")
+        .setAggregator("sum").build();
+
+    tags = Arrays.asList(new TagVFilter.Builder().setFilter("*").setGroupBy(true)
+        .setTagk("D").setType("wildcard").build());
+    
+    filters = Arrays.asList(Filter.Builder().setId("f1")
+        .setTags(tags).build());
+    final Metric metric1 = Metric.Builder().setMetric("A").setId("a")
+        .setFilter("f1").build();
+    final Metric metric2 = Metric.Builder().setMetric("B").setId("b")
+        .setFilter("f1").build();
+    metrics = Arrays.asList(metric1, metric2);
+    expressions = Arrays.asList(Expression.Builder().setId("e")
+        .setExpression("a + b").setJoin(intersection).build());
+    outputs = Arrays.asList(Output.Builder().setId("e").setAlias("A plus B")
+        .build());
+  }
+
+  @Test
+  public void oneExpressionWithOutputAlias() throws Exception {
+    oneExtraSameE();
+    final String json = JSON.serializeToString(getDefaultQueryBuilder().build());
+    final QueryRpc rpc = new QueryRpc();
+    final HttpQuery query = NettyMocks.postQuery(tsdb, 
+        "/api/query/exp", json);
+    NettyMocks.mockChannelFuture(query);
+    rpc.execute(tsdb, query);
+    
+    final String response = 
+        query.response().getContent().toString(Charset.forName("UTF-8"));
+    assertTrue(response.contains("\"alias\":\"A plus B\""));
+    assertTrue(response.contains("\"dps\":[[1431561600000,12.0,18.0]"));
+    assertTrue(response.contains("[1431561660000,14.0,20.0]"));
+    assertTrue(response.contains("[1431561720000,16.0,22.0]"));
+    assertTrue(response.contains("\"firstTimestamp\":1431561600000"));
+    assertTrue(response.contains("\"index\":1"));
+    assertTrue(response.contains("\"metrics\":[\"A\",\"B\"]"));
+    assertTrue(response.contains("\"index\":2"));
+  }
+  
+  @Test
+  public void oneExpressionDefaultOutput() throws Exception {
+    oneExtraSameE();
+    final Query q = Query.Builder().setExpressions(expressions)
+        .setFilters(filters).setMetrics(metrics).setName("q1")
+        .setTime(time).build();
+    final String json = JSON.serializeToString(q);
+    final QueryRpc rpc = new QueryRpc();
+    final HttpQuery query = NettyMocks.postQuery(tsdb, 
+        "/api/query/exp", json);
+    NettyMocks.mockChannelFuture(query);
+    
+    rpc.execute(tsdb, query);
+    final String response = 
+        query.response().getContent().toString(Charset.forName("UTF-8"));
+    assertTrue(response.contains("\"id\":\"e\""));
+    assertTrue(response.contains("\"dps\":[[1431561600000,12.0,18.0]"));
+    assertTrue(response.contains("[1431561660000,14.0,20.0]"));
+    assertTrue(response.contains("[1431561720000,16.0,22.0]"));
+    assertTrue(response.contains("\"firstTimestamp\":1431561600000"));
+    assertTrue(response.contains("\"index\":1"));
+    assertTrue(response.contains("\"metrics\":[\"A\",\"B\"]"));
+    assertTrue(response.contains("\"index\":2"));
+    // TODO - more asserts once we settle on names
+  }
+  
+  @Test
+  public void oneExpressionOutputAndBAlso() throws Exception {
+    oneExtraSameE();
+    
+    outputs = new ArrayList<Output>(3);
+    outputs.add(Output.Builder().setId("e").setAlias("A plus B").build());
+    outputs.add(Output.Builder().setId("a").build());
+    outputs.add(Output.Builder().setId("b").build());
+    
+    final String json = JSON.serializeToString(getDefaultQueryBuilder().build());
+    
+    final QueryRpc rpc = new QueryRpc();
+    final HttpQuery query = NettyMocks.postQuery(tsdb, 
+        "/api/query/exp", json);
+    NettyMocks.mockChannelFuture(query);
+    
+    rpc.execute(tsdb, query);
+    final String response = 
+        query.response().getContent().toString(Charset.forName("UTF-8"));
+    assertTrue(response.contains("\"alias\":\"A plus B\""));
+    assertTrue(response.contains("\"dps\":[[1431561600000,12.0,18.0]"));
+    assertTrue(response.contains("[1431561660000,14.0,20.0]"));
+    assertTrue(response.contains("[1431561720000,16.0,22.0]"));
+    assertTrue(response.contains("\"firstTimestamp\":1431561600000"));
+    assertTrue(response.contains("\"index\":1"));
+    assertTrue(response.contains("\"metrics\":[\"A\",\"B\"]"));
+    assertTrue(response.contains("\"index\":2"));
+    
+    assertTrue(response.contains("\"id\":\"a\""));
+    assertTrue(response.contains("\"dps\":[[1431561600000,1.0,4.0]"));
+    assertTrue(response.contains("\"metrics\":[\"A\"]"));
+    assertTrue(response.contains("\"id\":\"b\""));
+    assertTrue(response.contains("\"dps\":[[1431561600000,11.0,14.0,17.0]"));
+    assertTrue(response.contains("\"metrics\":[\"B\"]"));
+  }
+
+  @Test
+  public void oneExpressionDefaultFill() throws Exception {
+    threeSameEGaps();
+    String json = JSON.serializeToString(getDefaultQueryBuilder());
+    final QueryRpc rpc = new QueryRpc();
+    final HttpQuery query = NettyMocks.postQuery(tsdb, 
+        "/api/query/exp", json);
+    query.getQueryBaseRoute(); // to the correct serializer
+    NettyMocks.mockChannelFuture(query);
+    
+    rpc.execute(tsdb, query);
+    final String response = 
+        query.response().getContent().toString(Charset.forName("UTF-8"));
+    assertTrue(response.contains("\"alias\":\"A plus B\""));
+    assertTrue(response.contains("\"dps\":[[1431561600000,1.0,4.0,0.0]"));
+    assertTrue(response.contains("[1431561660000,0.0,20.0,8.0]"));
+    assertTrue(response.contains("[1431561720000,16.0,0.0,28.0]"));
+    assertTrue(response.contains("\"firstTimestamp\":1431561600000"));
+    assertTrue(response.contains("\"index\":1"));
+    assertTrue(response.contains("\"metrics\":[\"A\",\"B\"]"));
+    assertTrue(response.contains("\"index\":2"));
+    assertTrue(response.contains("\"index\":3"));
+  }
+  
+  @Test
+  public void oneExpressionDownsamplingMissingTimestampNoFill() throws Exception {
+    threeSameEGaps();
+    final Downsampler downsampler = Downsampler.Builder()
+        .setAggregator("sum")
+        .setInterval("1m")
+        .build();
+    time = Timespan.Builder().setStart("1431561600")
+        .setAggregator("sum")
+        .setDownsampler(downsampler).build();
+    String json = JSON.serializeToString(getDefaultQueryBuilder());
+    final QueryRpc rpc = new QueryRpc();
+    final HttpQuery query = NettyMocks.postQuery(tsdb, 
+        "/api/query/exp", json);
+    query.getQueryBaseRoute(); // to the correct serializer
+    NettyMocks.mockChannelFuture(query);
+    
+    rpc.execute(tsdb, query);
+    final String response = 
+        query.response().getContent().toString(Charset.forName("UTF-8"));
+    assertTrue(response.contains("\"alias\":\"A plus B\""));
+    assertTrue(response.contains("\"dps\":[[1431561600000,1.0,4.0,0.0]"));
+    assertTrue(response.contains("[1431561660000,0.0,20.0,8.0]"));
+    assertTrue(response.contains("[1431561720000,16.0,0.0,28.0]"));
+    assertTrue(response.contains("\"firstTimestamp\":1431561600000"));
+    assertTrue(response.contains("\"index\":1"));
+    assertTrue(response.contains("\"metrics\":[\"A\",\"B\"]"));
+    assertTrue(response.contains("\"index\":2"));
+    assertTrue(response.contains("\"index\":3"));
+  }
+  
+//  @Test
+//  public void oneExpressionDownsamplingMissingTimestampZeroFill() throws Exception {
+//    threeSameEGaps();
+//    final Downsampler downsampler = Downsampler.Builder()
+//        .setAggregator("sum")
+//        .setInterval("1m")
+//        .setFillPolicy(new NumericFillPolicy(FillPolicy.ZERO))
+//        .build();
+//    time = Timespan.Builder().setStart("1431561540")
+//        .setEnd("1431561780")
+//        .setAggregator("sum")
+//        .setDownsampler(downsampler).build();
+//    String json = JSON.serializeToString(getDefaultQueryBuilder());
+//    final QueryRpc rpc = new QueryRpc();
+//    final HttpQuery query = NettyMocks.postQuery(tsdb, 
+//        "/api/query/exp", json);
+//    query.getQueryBaseRoute(); // to the correct serializer
+//    NettyMocks.mockChannelFuture(query);
+//    
+//    rpc.execute(tsdb, query);
+//    final String response = 
+//        query.response().getContent().toString(Charset.forName("UTF-8"));
+//    assertTrue(response.contains("\"alias\":\"A plus B\""));
+//    assertTrue(response.contains("\"dps\":[[1431561540000,0.0,0.0,0.0]"));
+//    assertTrue(response.contains("[1431561600000,1.0,4.0,0.0]"));
+//    assertTrue(response.contains("[1431561660000,0.0,20.0,8.0]"));
+//    assertTrue(response.contains("[1431561720000,16.0,0.0,28.0]"));
+//    assertTrue(response.contains("[1431561780000,0.0,0.0,0.0]"));
+//    assertTrue(response.contains("\"firstTimestamp\":1431561540000"));
+//    assertTrue(response.contains("\"index\":1"));
+//    assertTrue(response.contains("\"metrics\":[\"A\",\"B\"]"));
+//    assertTrue(response.contains("\"index\":2"));
+//    assertTrue(response.contains("\"index\":3"));
+//  }
+  
+  @Test
+  public void oneExpressionNoFilter() throws Exception {
+    oneExtraSameE();
+    final Metric metric1 = Metric.Builder().setMetric("A").setId("a")
+        .build();
+    final Metric metric2 = Metric.Builder().setMetric("B").setId("b")
+        .build();
+    metrics = Arrays.asList(metric1, metric2);
+    
+    final String json = JSON.serializeToString(getDefaultQueryBuilder().build());
+    final QueryRpc rpc = new QueryRpc();
+    final HttpQuery query = NettyMocks.postQuery(tsdb, 
+        "/api/query/exp", json);
+    NettyMocks.mockChannelFuture(query);
+    
+    rpc.execute(tsdb, query);
+    final String response = 
+        query.response().getContent().toString(Charset.forName("UTF-8"));
+System.out.println(response);
+    assertTrue(response.contains("\"alias\":\"A plus B\""));
+    assertTrue(response.contains("\"dps\":[[1431561600000,47.0]"));
+    assertTrue(response.contains("[1431561660000,52.0]"));
+    assertTrue(response.contains("[1431561720000,57.0]"));
+    assertTrue(response.contains("\"firstTimestamp\":1431561600000"));
+    assertTrue(response.contains("\"index\":1"));
+    assertTrue(response.contains("\"metrics\":[\"A\",\"B\"]"));
+    assertTrue(response.contains("\"index\":1"));
+  }
+  
+  @Test
+  public void twoExpressionsDefaultOutput() throws Exception {
+    oneExtraSameE();
+    expressions = Arrays.asList(
+        Expression.Builder().setId("e").setExpression("a + b")
+          .setJoin(intersection).build(),
+        Expression.Builder().setId("e2").setExpression("a * b")
+          .setJoin(intersection).build());
+    
+    final Query q = Query.Builder().setExpressions(expressions)
+        .setFilters(filters).setMetrics(metrics).setName("q1")
+        .setTime(time).build();
+    final String json = JSON.serializeToString(q);
+    final QueryRpc rpc = new QueryRpc();
+    final HttpQuery query = NettyMocks.postQuery(tsdb, 
+        "/api/query/exp", json);
+    NettyMocks.mockChannelFuture(query);
+    
+    rpc.execute(tsdb, query);
+    final String response = 
+        query.response().getContent().toString(Charset.forName("UTF-8"));
+    assertTrue(response.contains("\"id\":\"e\""));
+    assertTrue(response.contains("\"dps\":[[1431561600000,12.0,18.0]"));
+    assertTrue(response.contains("[1431561660000,14.0,20.0]"));
+    assertTrue(response.contains("[1431561720000,16.0,22.0]"));
+    assertTrue(response.contains("\"firstTimestamp\":1431561600000"));
+    assertTrue(response.contains("\"index\":1"));
+    assertTrue(response.contains("\"metrics\":[\"A\",\"B\"]"));
+    assertTrue(response.contains("\"index\":2"));
+    assertTrue(response.contains("\"id\":\"e2\""));
+    assertTrue(response.contains("\"dps\":[[1431561600000,11.0,56.0]"));
+    assertTrue(response.contains("[1431561660000,24.0,75.0]"));
+    assertTrue(response.contains("[1431561720000,39.0,96.0]"));
+  }
+  
+  @Test
+  public void twoExpressionsOneWithoutResultsDefaultOutput() throws Exception {
+    oneExtraSameE();
+    final Metric metric1 = Metric.Builder().setMetric("A").setId("a")
+        .setFilter("f1").setAggregator("sum").build();
+    final Metric metric2 = Metric.Builder().setMetric("B").setId("b")
+        .setFilter("f1").setAggregator("sum").build();
+    final Metric metric3 = Metric.Builder().setMetric("D").setId("d")
+        .setFilter("f1").setAggregator("sum").build();
+    final Metric metric4 = Metric.Builder().setMetric("F").setId("f")
+        .setFilter("f1").setAggregator("sum").build();
+    metrics = Arrays.asList(metric1, metric2, metric3, metric4);
+    
+    expressions = Arrays.asList(
+        Expression.Builder().setId("e").setExpression("a + b")
+          .setJoin(intersection).build(),
+        Expression.Builder().setId("x").setExpression("d + f")
+          .setJoin(intersection).build());
+    
+    final Query q = Query.Builder().setExpressions(expressions)
+        .setFilters(filters).setMetrics(metrics).setName("q1")
+        .setTime(time).build();
+    String json = JSON.serializeToString(q);
+    final QueryRpc rpc = new QueryRpc();
+    final HttpQuery query = NettyMocks.postQuery(tsdb, 
+        "/api/query/exp", json);
+    query.getQueryBaseRoute(); // to the correct serializer
+    NettyMocks.mockChannelFuture(query);
+    
+    rpc.execute(tsdb, query);
+    final String response = 
+        query.response().getContent().toString(Charset.forName("UTF-8"));
+    assertTrue(response.contains("\"id\":\"e\""));
+    assertTrue(response.contains("\"dps\":[[1431561600000,12.0,18.0]"));
+    assertTrue(response.contains("[1431561660000,14.0,20.0]"));
+    assertTrue(response.contains("[1431561720000,16.0,22.0]"));
+    assertTrue(response.contains("\"firstTimestamp\":1431561600000"));
+    assertTrue(response.contains("\"index\":1"));
+    assertTrue(response.contains("\"metrics\":[\"A\",\"B\"]"));
+    assertTrue(response.contains("\"index\":2"));
+    assertTrue(response.contains("\"id\":\"x\""));
+    assertTrue(response.contains("\"dps\":[]"));
+    assertTrue(response.contains("\"firstTimestamp\":0"));
+    assertTrue(response.contains("\"series\":0"));
+  }
+  
+  @Test
+  public void multiExpressionsOneOutput() throws Exception {
+    oneExtraSameE();
+    expressions = Arrays.asList(
+        Expression.Builder().setId("e").setExpression("a + b").setJoin(intersection).build(),
+        Expression.Builder().setId("e2").setExpression("e * 2").setJoin(intersection).build(),
+        Expression.Builder().setId("e3").setExpression("e * 2").setJoin(intersection).build(),
+        Expression.Builder().setId("e4").setExpression("e2 + e3").setJoin(intersection).build());
+
+    final String json = JSON.serializeToString(getDefaultQueryBuilder());
+    final QueryRpc rpc = new QueryRpc();
+    final HttpQuery query = NettyMocks.postQuery(tsdb, 
+        "/api/query/exp", json);
+    query.getQueryBaseRoute(); // to the correct serializer
+    NettyMocks.mockChannelFuture(query);
+    
+    rpc.execute(tsdb, query);
+    final String response = 
+        query.response().getContent().toString(Charset.forName("UTF-8"));
+    assertTrue(response.contains("[1431561660000,14.0,20.0]"));
+    assertTrue(response.contains("[1431561720000,16.0,22.0]"));
+    assertTrue(response.contains("\"firstTimestamp\":1431561600000"));
+    assertTrue(response.contains("\"index\":1"));
+    assertTrue(response.contains("\"metrics\":[\"A\",\"B\"]"));
+    assertTrue(response.contains("\"index\":2"));
+  }
+  
+  @Test
+  public void nestedExpressionsOneLevelDefaultOutput() throws Exception {
+    oneExtraSameE();
+    expressions = Arrays.asList(
+        Expression.Builder().setId("e").setExpression("a + b")
+          .setJoin(intersection).build(),
+        Expression.Builder().setId("e2").setExpression("e * 2")
+          .setJoin(intersection).build());
+    
+    final Query q = Query.Builder().setExpressions(expressions)
+        .setFilters(filters).setMetrics(metrics).setName("q1")
+        .setTime(time).build();
+    final String json = JSON.serializeToString(q);
+    final QueryRpc rpc = new QueryRpc();
+    final HttpQuery query = NettyMocks.postQuery(tsdb, 
+        "/api/query/exp", json);
+    NettyMocks.mockChannelFuture(query);
+    
+    rpc.execute(tsdb, query);
+    final String response = 
+        query.response().getContent().toString(Charset.forName("UTF-8"));
+    assertTrue(response.contains("\"id\":\"e\""));
+    assertTrue(response.contains("\"dps\":[[1431561600000,12.0,18.0]"));
+    assertTrue(response.contains("[1431561660000,14.0,20.0]"));
+    assertTrue(response.contains("[1431561720000,16.0,22.0]"));
+    assertTrue(response.contains("\"firstTimestamp\":1431561600000"));
+    assertTrue(response.contains("\"index\":1"));
+    assertTrue(response.contains("\"metrics\":[\"A\",\"B\"]"));
+    assertTrue(response.contains("\"index\":2"));
+    assertTrue(response.contains("\"id\":\"e2\""));
+    assertTrue(response.contains("\"dps\":[[1431561600000,24.0,36.0]"));
+    assertTrue(response.contains("[1431561660000,28.0,40.0]"));
+    assertTrue(response.contains("[1431561720000,32.0,44.0]"));
+  }
+  
+  @Test
+  public void nestedExpressionsTwoLevelsDefaultOutput() throws Exception {
+    oneExtraSameE();
+    expressions = Arrays.asList(
+        Expression.Builder().setId("e").setExpression("a + b").setJoin(intersection).build(),
+        Expression.Builder().setId("e2").setExpression("e * 2").setJoin(intersection).build(),
+        Expression.Builder().setId("e3").setExpression("e * 2").setJoin(intersection).build(),
+        Expression.Builder().setId("e4").setExpression("e2 + e3").setJoin(intersection).build());
+    
+    final Query q = Query.Builder().setExpressions(expressions)
+        .setFilters(filters).setMetrics(metrics).setName("q1")
+        .setTime(time).build();
+    final String json = JSON.serializeToString(q);
+    final QueryRpc rpc = new QueryRpc();
+    final HttpQuery query = NettyMocks.postQuery(tsdb, 
+        "/api/query/exp", json);
+    NettyMocks.mockChannelFuture(query);
+    
+    rpc.execute(tsdb, query);
+    final String response = 
+        query.response().getContent().toString(Charset.forName("UTF-8"));
+    assertTrue(response.contains("\"id\":\"e\""));
+    assertTrue(response.contains("\"dps\":[[1431561600000,12.0,18.0]"));
+    assertTrue(response.contains("[1431561660000,14.0,20.0]"));
+    assertTrue(response.contains("[1431561720000,16.0,22.0]"));
+    assertTrue(response.contains("\"firstTimestamp\":1431561600000"));
+    assertTrue(response.contains("\"index\":1"));
+    assertTrue(response.contains("\"metrics\":[\"A\",\"B\"]"));
+    assertTrue(response.contains("\"index\":2"));
+    assertTrue(response.contains("\"id\":\"e2\""));
+    assertTrue(response.contains("\"dps\":[[1431561600000,24.0,36.0]"));
+    assertTrue(response.contains("[1431561660000,28.0,40.0]"));
+    assertTrue(response.contains("[1431561720000,32.0,44.0]"));
+    assertTrue(response.contains("\"id\":\"e3\""));
+    assertTrue(response.contains("\"id\":\"e4\""));
+    assertTrue(response.contains("\"dps\":[[1431561600000,48.0,72.0]"));
+    assertTrue(response.contains("[1431561660000,56.0,80.0]"));
+    assertTrue(response.contains("[1431561720000,64.0,88.0]"));
+  }
+  
+  @Test
+  public void nestedExpressionsTwoLevelsDefaultOutputOrdering() throws Exception {
+    oneExtraSameE();
+    expressions = Arrays.asList(
+        Expression.Builder().setId("e2").setExpression("e * 2").setJoin(intersection).build(),
+        Expression.Builder().setId("e4").setExpression("e2 + e3").setJoin(intersection).build(),
+        Expression.Builder().setId("e3").setExpression("e * 2").setJoin(intersection).build(),
+        Expression.Builder().setId("e").setExpression("a + b").setJoin(intersection).build()
+        );
+    
+    final Query q = Query.Builder().setExpressions(expressions)
+        .setFilters(filters).setMetrics(metrics).setName("q1")
+        .setTime(time).build();
+    final String json = JSON.serializeToString(q);
+    final QueryRpc rpc = new QueryRpc();
+    final HttpQuery query = NettyMocks.postQuery(tsdb, 
+        "/api/query/exp", json);
+    NettyMocks.mockChannelFuture(query);
+    
+    rpc.execute(tsdb, query);
+    final String response = 
+        query.response().getContent().toString(Charset.forName("UTF-8"));
+    assertTrue(response.contains("\"id\":\"e\""));
+    assertTrue(response.contains("\"dps\":[[1431561600000,12.0,18.0]"));
+    assertTrue(response.contains("[1431561660000,14.0,20.0]"));
+    assertTrue(response.contains("[1431561720000,16.0,22.0]"));
+    assertTrue(response.contains("\"firstTimestamp\":1431561600000"));
+    assertTrue(response.contains("\"index\":1"));
+    assertTrue(response.contains("\"metrics\":[\"A\",\"B\"]"));
+    assertTrue(response.contains("\"index\":2"));
+    assertTrue(response.contains("\"id\":\"e2\""));
+    assertTrue(response.contains("\"dps\":[[1431561600000,24.0,36.0]"));
+    assertTrue(response.contains("[1431561660000,28.0,40.0]"));
+    assertTrue(response.contains("[1431561720000,32.0,44.0]"));
+    assertTrue(response.contains("\"id\":\"e3\""));
+    assertTrue(response.contains("\"id\":\"e4\""));
+    assertTrue(response.contains("\"dps\":[[1431561600000,48.0,72.0]"));
+    assertTrue(response.contains("[1431561660000,56.0,80.0]"));
+    assertTrue(response.contains("[1431561720000,64.0,88.0]"));
+  }
+  
+  @Test
+  public void emptyResultSet() throws Exception {
+    setDataPointStorage();
+    String json = JSON.serializeToString(getDefaultQueryBuilder());
+    final QueryRpc rpc = new QueryRpc();
+    final HttpQuery query = NettyMocks.postQuery(tsdb, 
+        "/api/query/exp", json);
+    query.getQueryBaseRoute(); // to the correct serializer
+    NettyMocks.mockChannelFuture(query);
+    
+    rpc.execute(tsdb, query);
+    final String response = 
+        query.response().getContent().toString(Charset.forName("UTF-8"));
+    assertTrue(response.contains("\"dps\":[]"));
+    assertTrue(response.contains("\"firstTimestamp\":0"));
+    assertTrue(response.contains("\"series\":0"));
+  }
+  
+  @Test
+  public void scannerException() throws Exception {
+    oneExtraSameE();
+    storage.throwException(MockBase.stringToBytes(
+        "00000B5553E58000000D00000F00000E00000E"), 
+        new RuntimeException("Boo!"), true);
+    final String json = JSON.serializeToString(getDefaultQueryBuilder().build());
+    
+    final QueryRpc rpc = new QueryRpc();
+    final HttpQuery query = NettyMocks.postQuery(tsdb, 
+        "/api/query/exp", json);
+    query.getQueryBaseRoute(); // to the correct serializer
+    NettyMocks.mockChannelFuture(query);
+    
+    rpc.execute(tsdb, query);
+    final String response = 
+        query.response().getContent().toString(Charset.forName("UTF-8"));
+    assertTrue(response.contains("\"code\":400"));
+    assertTrue(response.contains("\"message\":\"Boo!\""));
+  }
+  
+  @Test
+  public void nsunMetric() throws Exception {
+    oneExtraSameE();
+    final Metric metric1 = Metric.Builder().setMetric("A").setId("a")
+        .setFilter("f1").setAggregator("sum").build();
+    final Metric metric2 = Metric.Builder().setMetric(NSUN_METRIC).setId("b")
+        .setFilter("f1").setAggregator("sum").build();
+    metrics = Arrays.asList(metric1, metric2);
+    final String json = JSON.serializeToString(getDefaultQueryBuilder().build());
+    
+    final QueryRpc rpc = new QueryRpc();
+    final HttpQuery query = NettyMocks.postQuery(tsdb, 
+        "/api/query/exp", json);
+    query.getQueryBaseRoute(); // to the correct serializer
+    NettyMocks.mockChannelFuture(query);
+    
+    rpc.execute(tsdb, query);
+    final String response = 
+        query.response().getContent().toString(Charset.forName("UTF-8"));
+    assertTrue(response.contains("\"code\":400"));
+    assertTrue(response.contains("\"message\":\"No such name for '" + 
+        NSUN_METRIC + "'"));
+  }
+
+  @Test
+  public void selfReferencingExpression() throws Exception {
+    oneExtraSameE();
+    expressions = Arrays.asList(
+        Expression.Builder().setId("e").setExpression("a + b").build(),
+        Expression.Builder().setId("e2").setExpression("e * 2").build(),
+        Expression.Builder().setId("e3").setExpression("e * 2").build(),
+        Expression.Builder().setId("e4").setExpression("e2 + e4").build());
+    
+    final Query q = Query.Builder().setExpressions(expressions)
+        .setFilters(filters).setMetrics(metrics).setName("q1")
+        .setTime(time).build();
+    final String json = JSON.serializeToString(q);
+    final QueryRpc rpc = new QueryRpc();
+    final HttpQuery query = NettyMocks.postQuery(tsdb, 
+        "/api/query/exp", json);
+    query.getQueryBaseRoute(); // to the correct serializer
+    NettyMocks.mockChannelFuture(query);
+    
+    rpc.execute(tsdb, query);
+    final String response = 
+        query.response().getContent().toString(Charset.forName("UTF-8"));
+    assertTrue(response.contains("\"code\":400"));
+    assertTrue(response.contains("\"message\":\"Self referencing"));
+  }
+  
+  @Test
+  public void circularReferenceExpression() throws Exception {
+    oneExtraSameE();
+    expressions = Arrays.asList(
+        Expression.Builder().setId("e").setExpression("a + e4").build(),
+        Expression.Builder().setId("e2").setExpression("e * 2").build(),
+        Expression.Builder().setId("e3").setExpression("e * 2").build(),
+        Expression.Builder().setId("e4").setExpression("e2 + e3").build());
+    
+    final Query q = Query.Builder().setExpressions(expressions)
+        .setFilters(filters).setMetrics(metrics).setName("q1")
+        .setTime(time).build();
+    final String json = JSON.serializeToString(q);
+    final QueryRpc rpc = new QueryRpc();
+    final HttpQuery query = NettyMocks.postQuery(tsdb, 
+        "/api/query/exp", json);
+    query.getQueryBaseRoute(); // to the correct serializer
+    NettyMocks.mockChannelFuture(query);
+    
+    rpc.execute(tsdb, query);
+    final String response = 
+        query.response().getContent().toString(Charset.forName("UTF-8"));
+    assertTrue(response.contains("\"code\":400"));
+    assertTrue(response.contains("\"message\":\"Circular reference found:"));
+  }
+  
+  @Test
+  public void noIntersectionsFound() throws Exception {
+    threeDifE();
+    
+    String json = JSON.serializeToString(getDefaultQueryBuilder());
+    final QueryRpc rpc = new QueryRpc();
+    final HttpQuery query = NettyMocks.postQuery(tsdb, 
+        "/api/query/exp", json);
+    query.getQueryBaseRoute(); // to the correct serializer
+    NettyMocks.mockChannelFuture(query);
+    
+    rpc.execute(tsdb, query);
+    final String response = 
+        query.response().getContent().toString(Charset.forName("UTF-8"));
+    assertTrue(response.contains("\"code\":400"));
+    assertTrue(response.contains("\"message\":\"No intersections found"));
+  }
+  
+  @Test
+  public void noIntersectionsFoundNestedExpression() throws Exception {
+    oneExtraSameE();
+    
+    final Metric metric1 = Metric.Builder().setMetric("A").setId("a")
+        .setFilter("f1").setAggregator("sum").build();
+    final Metric metric2 = Metric.Builder().setMetric("B").setId("b")
+        .setFilter("f1").setAggregator("sum").build();
+    final Metric metric3 = Metric.Builder().setMetric("D").setId("d")
+        .setFilter("f1").setAggregator("sum").build();
+    metrics = Arrays.asList(metric1, metric2, metric3);
+    
+    expressions = Arrays.asList(
+        Expression.Builder().setId("e").setExpression("a + b").setJoin(intersection).build(),
+        Expression.Builder().setId("x").setExpression("d + e").setJoin(intersection).build());
+    
+    final Query q = Query.Builder().setExpressions(expressions)
+        .setFilters(filters).setMetrics(metrics).setName("q1")
+        .setTime(time).build();
+    String json = JSON.serializeToString(q);
+    final QueryRpc rpc = new QueryRpc();
+    final HttpQuery query = NettyMocks.postQuery(tsdb, 
+        "/api/query/exp", json);
+    query.getQueryBaseRoute(); // to the correct serializer
+    NettyMocks.mockChannelFuture(query);
+    
+    rpc.execute(tsdb, query);
+    final String response = 
+        query.response().getContent().toString(Charset.forName("UTF-8"));
+    assertTrue(response.contains("\"code\":400"));
+    assertTrue(response.contains("\"message\":\"No intersections found"));
+  }
+  
+  @Test
+  public void noIntersectionsFoundOneMetricEmpty() throws Exception {
+    oneExtraSameE();
+    final Metric metric1 = Metric.Builder().setMetric("A").setId("a")
+        .setFilter("f1").setAggregator("sum").build();
+    final Metric metric2 = Metric.Builder().setMetric("D").setId("b")
+        .setFilter("f1").setAggregator("sum").build();
+    metrics = Arrays.asList(metric1, metric2);
+    String json = JSON.serializeToString(getDefaultQueryBuilder());
+    final QueryRpc rpc = new QueryRpc();
+    final HttpQuery query = NettyMocks.postQuery(tsdb, 
+        "/api/query/exp", json);
+    query.getQueryBaseRoute(); // to the correct serializer
+    NettyMocks.mockChannelFuture(query);
+    
+    rpc.execute(tsdb, query);
+    final String response = 
+        query.response().getContent().toString(Charset.forName("UTF-8"));
+    assertTrue(response.contains("\"code\":400"));
+    assertTrue(response.contains("\"message\":\"No intersections found"));
+  }
+  
+  @Test (expected = IllegalArgumentException.class)
+  public void notEnoughMetrics() throws Exception {
+    oneExtraSameE();
+    expressions = Arrays.asList(
+        Expression.Builder().setId("e").setExpression("a + b + c").build());
+    String json = JSON.serializeToString(getDefaultQueryBuilder());
+    final QueryRpc rpc = new QueryRpc();
+    final HttpQuery query = NettyMocks.postQuery(tsdb, 
+        "/api/query/exp", json);
+    query.getQueryBaseRoute(); // to the correct serializer
+    NettyMocks.mockChannelFuture(query);
+    
+    rpc.execute(tsdb, query);
+  }
+
+  protected Query.Builder getDefaultQueryBuilder() {
+    return Query.Builder().setExpressions(expressions).setFilters(filters)
+        .setMetrics(metrics).setName("q1").setTime(time).setOutputs(outputs);
+  }
+}
diff --git a/test/tsd/TestQueryRpc.java b/test/tsd/TestQueryRpc.java
index a51b5ac5db..0741efb487 100644
--- a/test/tsd/TestQueryRpc.java
+++ b/test/tsd/TestQueryRpc.java
@@ -23,12 +23,14 @@
 
 import java.lang.reflect.Method;
 import java.nio.charset.Charset;
+import java.util.List;
 
 import net.opentsdb.core.DataPoints;
 import net.opentsdb.core.Query;
 import net.opentsdb.core.TSDB;
 import net.opentsdb.core.TSQuery;
 import net.opentsdb.core.TSSubQuery;
+import net.opentsdb.query.expression.ExpressionTree;
 import net.opentsdb.query.filter.TagVLiteralOrFilter;
 import net.opentsdb.query.filter.TagVRegexFilter;
 import net.opentsdb.query.filter.TagVWildcardFilter;
@@ -62,12 +64,13 @@ public final class TestQueryRpc {
   private QueryRpc rpc;
   private Query empty_query = mock(Query.class);
   private Query query_result;
+  private List<ExpressionTree> expressions;
   
   private static final Method parseQuery;
   static {
     try {
       parseQuery = QueryRpc.class.getDeclaredMethod("parseQuery", 
-          TSDB.class, HttpQuery.class);
+          TSDB.class, HttpQuery.class, List.class);
       parseQuery.setAccessible(true);
     } catch (Exception e) {
       throw new RuntimeException("Failed in static initializer", e);
@@ -80,6 +83,7 @@ public void before() throws Exception {
     empty_query = mock(Query.class);
     query_result = mock(Query.class);
     rpc = new QueryRpc();
+    expressions = null;
     
     when(tsdb.newQuery()).thenReturn(query_result);
     when(empty_query.run()).thenReturn(new DataPoints[0]);
@@ -93,7 +97,7 @@ public void before() throws Exception {
   public void parseQueryMType() throws Exception {
     HttpQuery query = NettyMocks.getQuery(tsdb, 
       "/api/query?start=1h-ago&m=sum:sys.cpu.0");
-    TSQuery tsq = (TSQuery) parseQuery.invoke(rpc, tsdb, query);
+    TSQuery tsq = (TSQuery) parseQuery.invoke(rpc, tsdb, query, expressions);
     assertNotNull(tsq);
     assertEquals("1h-ago", tsq.getStart());
     assertNotNull(tsq.getQueries());
@@ -107,7 +111,7 @@ public void parseQueryMType() throws Exception {
   public void parseQueryMTypeWEnd() throws Exception {
     HttpQuery query = NettyMocks.getQuery(tsdb, 
       "/api/query?start=1h-ago&end=5m-ago&m=sum:sys.cpu.0");
-    TSQuery tsq = (TSQuery) parseQuery.invoke(rpc, tsdb, query);
+    TSQuery tsq = (TSQuery) parseQuery.invoke(rpc, tsdb, query, expressions);
     assertEquals("5m-ago", tsq.getEnd());
   }
   
@@ -115,7 +119,7 @@ public void parseQueryMTypeWEnd() throws Exception {
   public void parseQuery2MType() throws Exception {
     HttpQuery query = NettyMocks.getQuery(tsdb, 
       "/api/query?start=1h-ago&m=sum:sys.cpu.0&m=avg:sys.cpu.1");
-    TSQuery tsq = (TSQuery) parseQuery.invoke(rpc, tsdb, query);
+    TSQuery tsq = (TSQuery) parseQuery.invoke(rpc, tsdb, query, expressions);
     assertNotNull(tsq.getQueries());
     assertEquals(2, tsq.getQueries().size());
     TSSubQuery sub1 = tsq.getQueries().get(0);
@@ -132,7 +136,7 @@ public void parseQuery2MType() throws Exception {
   public void parseQueryMTypeWRate() throws Exception {
     HttpQuery query = NettyMocks.getQuery(tsdb, 
       "/api/query?start=1h-ago&m=sum:rate:sys.cpu.0");
-    TSQuery tsq = (TSQuery) parseQuery.invoke(rpc, tsdb, query);
+    TSQuery tsq = (TSQuery) parseQuery.invoke(rpc, tsdb, query, expressions);
     TSSubQuery sub = tsq.getQueries().get(0);
     assertTrue(sub.getRate());
   }
@@ -141,7 +145,7 @@ public void parseQueryMTypeWRate() throws Exception {
   public void parseQueryMTypeWDS() throws Exception {
     HttpQuery query = NettyMocks.getQuery(tsdb, 
       "/api/query?start=1h-ago&m=sum:1h-avg:sys.cpu.0");
-    TSQuery tsq = (TSQuery) parseQuery.invoke(rpc, tsdb, query);
+    TSQuery tsq = (TSQuery) parseQuery.invoke(rpc, tsdb, query, expressions);
     TSSubQuery sub = tsq.getQueries().get(0);
     assertEquals("1h-avg", sub.getDownsample());
   }
@@ -150,7 +154,7 @@ public void parseQueryMTypeWDS() throws Exception {
   public void parseQueryMTypeWDSAndFill() throws Exception {
     HttpQuery query = NettyMocks.getQuery(tsdb, 
       "/api/query?start=1h-ago&m=sum:1h-avg-lerp:sys.cpu.0");
-    TSQuery tsq = (TSQuery) parseQuery.invoke(rpc, tsdb, query);
+    TSQuery tsq = (TSQuery) parseQuery.invoke(rpc, tsdb, query, expressions);
     TSSubQuery sub = tsq.getQueries().get(0);
     assertEquals("1h-avg-lerp", sub.getDownsample());
   }
@@ -159,7 +163,7 @@ public void parseQueryMTypeWDSAndFill() throws Exception {
   public void parseQueryMTypeWRateAndDS() throws Exception {
     HttpQuery query = NettyMocks.getQuery(tsdb, 
       "/api/query?start=1h-ago&m=sum:1h-avg:rate:sys.cpu.0");
-    TSQuery tsq = (TSQuery) parseQuery.invoke(rpc, tsdb, query);
+    TSQuery tsq = (TSQuery) parseQuery.invoke(rpc, tsdb, query, expressions);
     TSSubQuery sub = tsq.getQueries().get(0);
     assertTrue(sub.getRate());
     assertEquals("1h-avg", sub.getDownsample());
@@ -169,7 +173,7 @@ public void parseQueryMTypeWRateAndDS() throws Exception {
   public void parseQueryMTypeWTag() throws Exception {
     HttpQuery query = NettyMocks.getQuery(tsdb, 
       "/api/query?start=1h-ago&m=sum:sys.cpu.0{host=web01}");
-    TSQuery tsq = (TSQuery) parseQuery.invoke(rpc, tsdb, query);
+    TSQuery tsq = (TSQuery) parseQuery.invoke(rpc, tsdb, query, expressions);
     TSSubQuery sub = tsq.getQueries().get(0);
     assertNotNull(sub.getTags());
     assertEquals("literal_or(web01)", sub.getTags().get("host"));
@@ -180,7 +184,7 @@ public void parseQueryMTypeWGroupByRegex() throws Exception {
     HttpQuery query = NettyMocks.getQuery(tsdb, 
       "/api/query?start=1h-ago&m=sum:sys.cpu.0{host=" + 
           TagVRegexFilter.FILTER_NAME + "(something(foo|bar))}");
-    TSQuery tsq = (TSQuery) parseQuery.invoke(rpc, tsdb, query);
+    TSQuery tsq = (TSQuery) parseQuery.invoke(rpc, tsdb, query, expressions);
     TSSubQuery sub = tsq.getQueries().get(0);
     sub.validateAndSetQuery();
     assertEquals(1, sub.getFilters().size());
@@ -192,7 +196,7 @@ public void parseQueryMTypeWGroupByWildcardExplicit() throws Exception {
     HttpQuery query = NettyMocks.getQuery(tsdb, 
       "/api/query?start=1h-ago&m=sum:sys.cpu.0{host=" + 
           TagVWildcardFilter.FILTER_NAME + "(*quirm)}");
-    TSQuery tsq = (TSQuery) parseQuery.invoke(rpc, tsdb, query);
+    TSQuery tsq = (TSQuery) parseQuery.invoke(rpc, tsdb, query, expressions);
     TSSubQuery sub = tsq.getQueries().get(0);
     sub.validateAndSetQuery();
     assertEquals(1, sub.getFilters().size());
@@ -203,7 +207,7 @@ public void parseQueryMTypeWGroupByWildcardExplicit() throws Exception {
   public void parseQueryMTypeWGroupByWildcardImplicit() throws Exception {
     HttpQuery query = NettyMocks.getQuery(tsdb, 
       "/api/query?start=1h-ago&m=sum:sys.cpu.0{host=*quirm}");
-    TSQuery tsq = (TSQuery) parseQuery.invoke(rpc, tsdb, query);
+    TSQuery tsq = (TSQuery) parseQuery.invoke(rpc, tsdb, query, expressions);
     TSSubQuery sub = tsq.getQueries().get(0);
     sub.validateAndSetQuery();
     assertEquals(1, sub.getFilters().size());
@@ -214,7 +218,7 @@ public void parseQueryMTypeWGroupByWildcardImplicit() throws Exception {
   public void parseQueryMTypeWWildcardFilterExplicit() throws Exception {
     HttpQuery query = NettyMocks.getQuery(tsdb, 
       "/api/query?start=1h-ago&m=sum:sys.cpu.0{}{host=wildcard(*quirm)}");
-    TSQuery tsq = (TSQuery) parseQuery.invoke(rpc, tsdb, query);
+    TSQuery tsq = (TSQuery) parseQuery.invoke(rpc, tsdb, query, expressions);
     TSSubQuery sub = tsq.getQueries().get(0);
     sub.validateAndSetQuery();
     assertEquals(1, sub.getFilters().size());
@@ -225,7 +229,7 @@ public void parseQueryMTypeWWildcardFilterExplicit() throws Exception {
   public void parseQueryMTypeWWildcardFilterImplicit() throws Exception {
     HttpQuery query = NettyMocks.getQuery(tsdb, 
       "/api/query?start=1h-ago&m=sum:sys.cpu.0{}{host=*quirm}");
-    TSQuery tsq = (TSQuery) parseQuery.invoke(rpc, tsdb, query);
+    TSQuery tsq = (TSQuery) parseQuery.invoke(rpc, tsdb, query, expressions);
     TSSubQuery sub = tsq.getQueries().get(0);
     sub.validateAndSetQuery();
     assertEquals(1, sub.getFilters().size());
@@ -236,7 +240,7 @@ public void parseQueryMTypeWWildcardFilterImplicit() throws Exception {
   public void parseQueryMTypeWGroupByAndWildcardFilterExplicit() throws Exception {
     HttpQuery query = NettyMocks.getQuery(tsdb, 
       "/api/query?start=1h-ago&m=sum:sys.cpu.0{colo=lga}{host=wildcard(*quirm)}");
-    TSQuery tsq = (TSQuery) parseQuery.invoke(rpc, tsdb, query);
+    TSQuery tsq = (TSQuery) parseQuery.invoke(rpc, tsdb, query, expressions);
     TSSubQuery sub = tsq.getQueries().get(0);
     sub.validateAndSetQuery();
     assertTrue(sub.getFilters().get(0) instanceof TagVWildcardFilter);
@@ -248,7 +252,7 @@ public void parseQueryMTypeWGroupByAndWildcardFilterSameTagK() throws Exception
     HttpQuery query = NettyMocks.getQuery(tsdb, 
       "/api/query?start=1h-ago&m=sum:sys.cpu.0{host=quirm|tsort}"
       + "{host=wildcard(*quirm)}");
-    TSQuery tsq = (TSQuery) parseQuery.invoke(rpc, tsdb, query);
+    TSQuery tsq = (TSQuery) parseQuery.invoke(rpc, tsdb, query, expressions);
     TSSubQuery sub = tsq.getQueries().get(0);
     sub.validateAndSetQuery();
     assertTrue(sub.getFilters().get(0) instanceof TagVWildcardFilter);
@@ -261,7 +265,7 @@ public void parseQueryMTypeWGroupByFilterAndWildcardFilterSameTagK()
     HttpQuery query = NettyMocks.getQuery(tsdb, 
       "/api/query?start=1h-ago&m=sum:sys.cpu.0{host=wildcard(*tsort)}"
       + "{host=wildcard(*quirm)}");
-    TSQuery tsq = (TSQuery) parseQuery.invoke(rpc, tsdb, query);
+    TSQuery tsq = (TSQuery) parseQuery.invoke(rpc, tsdb, query, expressions);
     TSSubQuery sub = tsq.getQueries().get(0);
     sub.validateAndSetQuery();
     assertEquals(2, sub.getFilters().size());
@@ -274,7 +278,7 @@ public void parseQueryMTypeWGroupByFilterMissingClose() throws Exception {
     HttpQuery query = NettyMocks.getQuery(tsdb, 
       "/api/query?start=1h-ago&m=sum:sys.cpu.0{host=wildcard(*tsort)}"
       + "{host=wildcard(*quirm)");
-    parseQuery.invoke(rpc, tsdb, query);
+    parseQuery.invoke(rpc, tsdb, query, expressions);
   }
   
   @Test (expected = IllegalArgumentException.class)
@@ -282,7 +286,7 @@ public void parseQueryMTypeWGroupByFilterMissingEquals() throws Exception {
     HttpQuery query = NettyMocks.getQuery(tsdb, 
       "/api/query?start=1h-ago&m=sum:sys.cpu.0{host=wildcard(*tsort)}"
       + "{hostwildcard(*quirm)}");
-    parseQuery.invoke(rpc, tsdb, query);
+    parseQuery.invoke(rpc, tsdb, query, expressions);
   }
   
   @Test (expected = IllegalArgumentException.class)
@@ -290,24 +294,73 @@ public void parseQueryMTypeWGroupByNoSuchFilter() throws Exception {
     HttpQuery query = NettyMocks.getQuery(tsdb, 
       "/api/query?start=1h-ago&m=sum:sys.cpu.0{host=nosuchfilter(*tsort)}"
       + "{host=dummyfilter(*quirm)}");
-    parseQuery.invoke(rpc, tsdb, query);
+    parseQuery.invoke(rpc, tsdb, query, expressions);
   }
   
   @Test
   public void parseQueryMTypeWEmptyFilterBrackets() throws Exception {
     HttpQuery query = NettyMocks.getQuery(tsdb, 
       "/api/query?start=1h-ago&m=sum:sys.cpu.0{}{}");
-    TSQuery tsq = (TSQuery) parseQuery.invoke(rpc, tsdb, query);
+    TSQuery tsq = (TSQuery) parseQuery.invoke(rpc, tsdb, query, expressions);
     TSSubQuery sub = tsq.getQueries().get(0);
     sub.validateAndSetQuery();
     assertEquals(0, sub.getFilters().size());
   }
   
+  @Test
+  public void parseQueryMTypeWExplicit() throws Exception {
+    HttpQuery query = NettyMocks.getQuery(tsdb, 
+      "/api/query?start=1h-ago&m=sum:explicit_tags:sys.cpu.0{host=web01}");
+    TSQuery tsq = (TSQuery) parseQuery.invoke(rpc, tsdb, query, expressions);
+    TSSubQuery sub = tsq.getQueries().get(0);
+    assertNotNull(sub.getTags());
+    assertEquals("literal_or(web01)", sub.getTags().get("host"));
+    assertTrue(sub.getExplicitTags());
+  }
+  
+  @Test
+  public void parseQueryMTypeWExplicitAndRate() throws Exception {
+    HttpQuery query = NettyMocks.getQuery(tsdb, 
+      "/api/query?start=1h-ago&m=sum:explicit_tags:rate:sys.cpu.0{host=web01}");
+    TSQuery tsq = (TSQuery) parseQuery.invoke(rpc, tsdb, query, expressions);
+    TSSubQuery sub = tsq.getQueries().get(0);
+    assertNotNull(sub.getTags());
+    assertEquals("literal_or(web01)", sub.getTags().get("host"));
+    assertTrue(sub.getRate());
+    assertTrue(sub.getExplicitTags());
+  }
+  
+  @Test
+  public void parseQueryMTypeWExplicitAndRateAndDS() throws Exception {
+    HttpQuery query = NettyMocks.getQuery(tsdb, 
+      "/api/query?start=1h-ago&m=sum:explicit_tags:rate:1m-sum:sys.cpu.0{host=web01}");
+    TSQuery tsq = (TSQuery) parseQuery.invoke(rpc, tsdb, query, expressions);
+    TSSubQuery sub = tsq.getQueries().get(0);
+    assertNotNull(sub.getTags());
+    assertEquals("literal_or(web01)", sub.getTags().get("host"));
+    assertTrue(sub.getRate());
+    assertTrue(sub.getExplicitTags());
+    assertEquals("1m-sum", sub.getDownsample());
+  }
+  
+  @Test
+  public void parseQueryMTypeWExplicitAndDSAndRate() throws Exception {
+    HttpQuery query = NettyMocks.getQuery(tsdb, 
+      "/api/query?start=1h-ago&m=sum:explicit_tags:1m-sum:rate:sys.cpu.0{host=web01}");
+    TSQuery tsq = (TSQuery) parseQuery.invoke(rpc, tsdb, query, expressions);
+    TSSubQuery sub = tsq.getQueries().get(0);
+    assertNotNull(sub.getTags());
+    assertEquals("literal_or(web01)", sub.getTags().get("host"));
+    assertTrue(sub.getRate());
+    assertTrue(sub.getExplicitTags());
+    assertEquals("1m-sum", sub.getDownsample());
+  }
+  
   @Test
   public void parseQueryTSUIDType() throws Exception {
     HttpQuery query = NettyMocks.getQuery(tsdb, 
       "/api/query?start=1h-ago&tsuid=sum:010101");
-    TSQuery tsq = (TSQuery) parseQuery.invoke(rpc, tsdb, query);
+    TSQuery tsq = (TSQuery) parseQuery.invoke(rpc, tsdb, query, expressions);
     assertNotNull(tsq);
     assertEquals("1h-ago", tsq.getStart());
     assertNotNull(tsq.getQueries());
@@ -322,7 +375,7 @@ public void parseQueryTSUIDType() throws Exception {
   public void parseQueryTSUIDTypeMulti() throws Exception {
     HttpQuery query = NettyMocks.getQuery(tsdb, 
       "/api/query?start=1h-ago&tsuid=sum:010101,020202");
-    TSQuery tsq = (TSQuery) parseQuery.invoke(rpc, tsdb, query);
+    TSQuery tsq = (TSQuery) parseQuery.invoke(rpc, tsdb, query, expressions);
     assertNotNull(tsq);
     assertEquals("1h-ago", tsq.getStart());
     assertNotNull(tsq.getQueries());
@@ -338,7 +391,7 @@ public void parseQueryTSUIDTypeMulti() throws Exception {
   public void parseQuery2TSUIDType() throws Exception {
     HttpQuery query = NettyMocks.getQuery(tsdb, 
       "/api/query?start=1h-ago&tsuid=sum:010101&tsuid=avg:020202");
-    TSQuery tsq = (TSQuery) parseQuery.invoke(rpc, tsdb, query);
+    TSQuery tsq = (TSQuery) parseQuery.invoke(rpc, tsdb, query, expressions);
     assertNotNull(tsq);
     assertEquals("1h-ago", tsq.getStart());
     assertNotNull(tsq.getQueries());
@@ -359,7 +412,7 @@ public void parseQuery2TSUIDType() throws Exception {
   public void parseQueryTSUIDTypeWRate() throws Exception {
     HttpQuery query = NettyMocks.getQuery(tsdb, 
       "/api/query?start=1h-ago&tsuid=sum:rate:010101");
-    TSQuery tsq = (TSQuery) parseQuery.invoke(rpc, tsdb, query);
+    TSQuery tsq = (TSQuery) parseQuery.invoke(rpc, tsdb, query, expressions);
     assertNotNull(tsq);
     assertEquals("1h-ago", tsq.getStart());
     assertNotNull(tsq.getQueries());
@@ -375,7 +428,7 @@ public void parseQueryTSUIDTypeWRate() throws Exception {
   public void parseQueryTSUIDTypeWDS() throws Exception {
     HttpQuery query = NettyMocks.getQuery(tsdb, 
       "/api/query?start=1h-ago&tsuid=sum:1m-sum:010101");
-    TSQuery tsq = (TSQuery) parseQuery.invoke(rpc, tsdb, query);
+    TSQuery tsq = (TSQuery) parseQuery.invoke(rpc, tsdb, query, expressions);
     assertNotNull(tsq);
     assertEquals("1h-ago", tsq.getStart());
     assertNotNull(tsq.getQueries());
@@ -391,7 +444,7 @@ public void parseQueryTSUIDTypeWDS() throws Exception {
   public void parseQueryTSUIDTypeWRateAndDS() throws Exception {
     HttpQuery query = NettyMocks.getQuery(tsdb, 
       "/api/query?start=1h-ago&tsuid=sum:1m-sum:rate:010101");
-    TSQuery tsq = (TSQuery) parseQuery.invoke(rpc, tsdb, query);
+    TSQuery tsq = (TSQuery) parseQuery.invoke(rpc, tsdb, query, expressions);
     assertNotNull(tsq);
     assertEquals("1h-ago", tsq.getStart());
     assertNotNull(tsq.getQueries());
@@ -408,7 +461,7 @@ public void parseQueryTSUIDTypeWRateAndDS() throws Exception {
   public void parseQueryWPadding() throws Exception {
     HttpQuery query = NettyMocks.getQuery(tsdb, 
       "/api/query?start=1h-ago&m=sum:sys.cpu.0&padding");
-    TSQuery tsq = (TSQuery) parseQuery.invoke(rpc, tsdb, query);
+    TSQuery tsq = (TSQuery) parseQuery.invoke(rpc, tsdb, query, expressions);
     assertNotNull(tsq);
     assertTrue(tsq.getPadding());
   }
@@ -417,14 +470,14 @@ public void parseQueryWPadding() throws Exception {
   public void parseQueryStartMissing() throws Exception {
     HttpQuery query = NettyMocks.getQuery(tsdb, 
       "/api/query?end=1h-ago&m=sum:sys.cpu.0");
-    parseQuery.invoke(rpc, tsdb, query);
+    parseQuery.invoke(rpc, tsdb, query, expressions);
   }
   
   @Test (expected = BadRequestException.class)
   public void parseQueryNoSubQuery() throws Exception {
     HttpQuery query = NettyMocks.getQuery(tsdb, 
       "/api/query?start=1h-ago");
-    parseQuery.invoke(rpc, tsdb, query);
+    parseQuery.invoke(rpc, tsdb, query, expressions);
   }
   
   @Test
@@ -519,8 +572,9 @@ public void executeWithBadDSFill() throws Exception {
       rpc.execute(tsdb, query);
       fail("expected BadRequestException");
     } catch (final BadRequestException exn) {
+      System.out.println(exn.getMessage());
       assertTrue(exn.getMessage().startsWith(
-          "No such fill policy: 'badbadbad': must be one of:"));
+          "Unrecognized fill policy: badbadbad"));
     }
   }
   
@@ -535,5 +589,38 @@ public void deleteDatapointsBadRequest() throws Exception {
     assertTrue(json.contains("Deleting data is not enabled"));
   }
   
+  @Test
+  public void gexp() throws Exception {
+    final DataPoints[] datapoints = new DataPoints[1];
+    datapoints[0] = new MockDataPoints().getMock();
+    when(query_result.runAsync()).thenReturn(
+        Deferred.fromResult(datapoints));
+    
+    final HttpQuery query = NettyMocks.getQuery(tsdb, 
+        "/api/query/gexp?start=1h-ago&exp=scale(sum:sys.cpu.user,1)");
+    NettyMocks.mockChannelFuture(query);
+    rpc.execute(tsdb, query);
+    assertEquals(query.response().getStatus(), HttpResponseStatus.OK);
+    final String json = 
+        query.response().getContent().toString(Charset.forName("UTF-8"));
+    assertTrue(json.contains("\"metric\":\"system.cpu.user\""));
+  }
+  
+  @Test
+  public void gexpBadExpression() throws Exception {
+    final DataPoints[] datapoints = new DataPoints[1];
+    datapoints[0] = new MockDataPoints().getMock();
+    when(query_result.runAsync()).thenReturn(
+        Deferred.fromResult(datapoints));
+    
+    final HttpQuery query = NettyMocks.getQuery(tsdb, 
+        "/api/query/gexp?start=1h-ago&exp=scale(sum:sys.cpu.user,notanumber)");
+    rpc.execute(tsdb, query);
+    assertEquals(query.response().getStatus(), HttpResponseStatus.BAD_REQUEST);
+    final String json = 
+        query.response().getContent().toString(Charset.forName("UTF-8"));
+    assertTrue(json.contains("factor"));
+  }
+  
   //TODO(cl) add unit tests for the rate options parsing
 }
\ No newline at end of file
diff --git a/test/tsd/TestRpcManager.java b/test/tsd/TestRpcManager.java
index 58a8193487..fc062bc506 100644
--- a/test/tsd/TestRpcManager.java
+++ b/test/tsd/TestRpcManager.java
@@ -46,6 +46,12 @@ public class TestRpcManager {
   @Before
   public void before() {
     Config config = mock(Config.class);
+    when(config.getString("tsd.core.enable_api"))
+      .thenReturn("true");
+    when(config.getString("tsd.core.enable_ui"))
+      .thenReturn("true");
+    when(config.getString("tsd.no_diediedie"))
+      .thenReturn("false");
     TSDB tsdb = mock(TSDB.class);
     when(tsdb.getConfig()).thenReturn(config);
     mock_tsdb_no_plugins = tsdb;
@@ -62,10 +68,16 @@ public void after() throws Exception {
   public void loadHttpRpcPlugins() throws Exception {
     Config config = mock(Config.class);
     when(config.hasProperty("tsd.http.rpc.plugins"))
-    .thenReturn(true);
+      .thenReturn(true);
     when(config.getString("tsd.http.rpc.plugins"))
       .thenReturn("net.opentsdb.tsd.DummyHttpRpcPlugin");
-    
+    when(config.getString("tsd.core.enable_api"))
+      .thenReturn("true");
+    when(config.getString("tsd.core.enable_ui"))
+      .thenReturn("true");
+    when(config.getString("tsd.no_diediedie"))
+     .thenReturn("false");
+
     TSDB tsdb = mock(TSDB.class);
     when(tsdb.getConfig()).thenReturn(config);
     
@@ -80,17 +92,22 @@ public void loadHttpRpcPlugins() throws Exception {
   public void loadRpcPlugin() throws Exception {
     Config config = mock(Config.class);
     when(config.hasProperty("tsd.rpc.plugins"))
-    .thenReturn(true);
+      .thenReturn(true);
     when(config.getString("tsd.rpc.plugins"))
       .thenReturn("net.opentsdb.tsd.DummyRpcPlugin");
-    
     when(config.hasProperty("tsd.rpcplugin.DummyRPCPlugin.hosts"))
-    .thenReturn(true);
+      .thenReturn(true);
     when(config.getString("tsd.rpcplugin.DummyRPCPlugin.hosts"))
       .thenReturn("blah");
     when(config.getInt("tsd.rpcplugin.DummyRPCPlugin.port"))
       .thenReturn(1000);
-    
+    when(config.getString("tsd.core.enable_api"))
+      .thenReturn("true");
+    when(config.getString("tsd.core.enable_ui"))
+      .thenReturn("true");
+    when(config.getString("tsd.no_diediedie"))
+      .thenReturn("false");
+
     TSDB tsdb = mock(TSDB.class);
     when(tsdb.getConfig()).thenReturn(config);
     
diff --git a/test/tsd/TestSearchRpc.java b/test/tsd/TestSearchRpc.java
index a881b59990..3ba1ea7d74 100644
--- a/test/tsd/TestSearchRpc.java
+++ b/test/tsd/TestSearchRpc.java
@@ -13,10 +13,6 @@
 package net.opentsdb.tsd;
 
 import static org.mockito.Matchers.any;
-import static org.mockito.Matchers.anyChar;
-import static org.mockito.Matchers.anyList;
-import static org.mockito.Matchers.anyString;
-import static org.mockito.Mockito.doAnswer;
 import static org.mockito.Mockito.when;
 import static org.powermock.api.mockito.PowerMockito.mock;
 import static org.junit.Assert.assertEquals;
@@ -45,9 +41,7 @@
 import net.opentsdb.uid.UniqueId;
 import net.opentsdb.uid.UniqueId.UniqueIdType;
 import net.opentsdb.utils.Config;
-import net.opentsdb.utils.Pair;
 
-import org.hbase.async.Bytes;
 import org.jboss.netty.handler.codec.http.DefaultHttpRequest;
 import org.jboss.netty.handler.codec.http.HttpMethod;
 import org.jboss.netty.handler.codec.http.HttpRequest;
@@ -105,7 +99,8 @@ public void searchTSMeta_Summary() throws Exception {
     rpc.execute(tsdb, query);
     assertEquals(HttpResponseStatus.OK, query.response().getStatus());
     final String result = query.response().getContent().toString(UTF);
-    assertTrue(result.contains("\"results\":[{\"tags\""));
+    assertTrue(result.contains("\"host\":\"web01\""));
+    assertTrue(result.contains("\"metric\":\"sys.cpu.0\""));
     assertEquals(1, search_query.getResults().size());
   }
   
diff --git a/test/tsd/TestStatsRpc.java b/test/tsd/TestStatsRpc.java
index fa90729245..cad88aee7a 100644
--- a/test/tsd/TestStatsRpc.java
+++ b/test/tsd/TestStatsRpc.java
@@ -13,6 +13,7 @@
 package net.opentsdb.tsd;
 
 import static org.junit.Assert.assertEquals;
+import static org.junit.Assert.assertFalse;
 import static org.junit.Assert.assertNotNull;
 import static org.junit.Assert.assertTrue;
 import static org.mockito.Mockito.mock;
@@ -21,6 +22,7 @@
 import java.nio.charset.Charset;
 
 import net.opentsdb.core.TSDB;
+import net.opentsdb.stats.StatsCollector;
 import net.opentsdb.utils.Config;
 
 import org.hbase.async.HBaseClient;
@@ -45,6 +47,36 @@ public void before() throws Exception {
     when(tsdb.getClient()).thenReturn(client);
   }
 
+// TODO - revisit these as the one without port is failing intermittently.
+//  @Test
+//  public void statsWithOutPort() throws Exception {
+//    when(tsdb.getConfig().getBoolean("tsd.core.stats_with_port"))
+//    .thenReturn(false);
+//    final StatsRpc rpc = new StatsRpc();
+//    HttpQuery query = NettyMocks.getQuery(tsdb, "/api/stats");
+//    rpc.execute(tsdb, query);
+//    assertEquals(HttpResponseStatus.OK, query.response().getStatus());
+//    final String json = 
+//        query.response().getContent().toString(Charset.forName("UTF-8"));
+//    assertFalse(json.contains("port=4242"));
+//  }
+//  
+//  @Test
+//  public void statsWithPort() throws Exception {
+//    when(tsdb.getConfig().getBoolean("tsd.core.stats_with_port"))
+//      .thenReturn(true);
+//    when(tsdb.getConfig().getString("tsd.network.port"))
+//      .thenReturn("4242");
+//    StatsCollector.setGlobalTags(tsdb.getConfig());
+//    final StatsRpc rpc = new StatsRpc();
+//    HttpQuery query = NettyMocks.getQuery(tsdb, "/api/stats");
+//    rpc.execute(tsdb, query);
+//    assertEquals(HttpResponseStatus.OK, query.response().getStatus());
+//    final String json = 
+//        query.response().getContent().toString(Charset.forName("UTF-8"));
+//    assertTrue(json.contains("port=4242"));
+//  }
+  
   @Test
   public void printThreadStats() throws Exception {
     final StatsRpc rpc = new StatsRpc();
diff --git a/test/tsd/TestUniqueIdRpc.java b/test/tsd/TestUniqueIdRpc.java
index 266e11dd0d..6969b8f565 100644
--- a/test/tsd/TestUniqueIdRpc.java
+++ b/test/tsd/TestUniqueIdRpc.java
@@ -14,6 +14,7 @@
 
 import static org.junit.Assert.assertEquals;
 import static org.junit.Assert.assertTrue;
+import static org.mockito.Mockito.doThrow;
 import static org.mockito.Mockito.when;
 import static org.powermock.api.mockito.PowerMockito.mock;
 
@@ -531,6 +532,159 @@ public void stringToUniqueIdTypeEmpty() throws Exception {
     UniqueId.stringToUniqueIdType("Not a type");
   }
 
+  // Test /api/uid/rename ----------------------
+
+  @Test (expected = BadRequestException.class)
+  public void renameBadMethod() throws Exception {
+    HttpQuery query = NettyMocks.putQuery(tsdb, "/api/uid/rename", "");
+    rpc.execute(tsdb, query);
+  }
+
+  @Test
+  public void renamePostMetric() throws Exception {
+    HttpQuery query = NettyMocks.postQuery(tsdb, "/api/uid/rename",
+        "{\"metric\":\"sys.cpu.1\",\"name\":\"sys.cpu.2\"}");
+    rpc.execute(tsdb, query);
+    assertEquals(HttpResponseStatus.OK, query.response().getStatus());
+    assertEquals("{\"result\":\"true\"}",
+        query.response().getContent().toString(Charset.forName("UTF-8")));
+  }
+
+  @Test
+  public void renamePostTagk() throws Exception {
+    HttpQuery query = NettyMocks.postQuery(tsdb, "/api/uid/rename",
+        "{\"tagk\":\"datacenter\",\"name\":\"datacluster\"}");
+    rpc.execute(tsdb, query);
+    assertEquals(HttpResponseStatus.OK, query.response().getStatus());
+    assertEquals("{\"result\":\"true\"}",
+        query.response().getContent().toString(Charset.forName("UTF-8")));
+  }
+
+  @Test
+  public void renamePostTagv() throws Exception {
+    HttpQuery query = NettyMocks.postQuery(tsdb, "/api/uid/rename",
+        "{\"tagv\":\"localhost\",\"name\":\"127.0.0.1\"}");
+    rpc.execute(tsdb, query);
+    assertEquals(HttpResponseStatus.OK, query.response().getStatus());
+    assertEquals("{\"result\":\"true\"}",
+        query.response().getContent().toString(Charset.forName("UTF-8")));
+  }
+
+  @Test (expected = BadRequestException.class)
+  public void renamePostNoName() throws Exception {
+    HttpQuery query = NettyMocks.postQuery(tsdb, "/api/uid/rename",
+        "{\"tagk\":\"localhost\",\"not_name\":\"127.0.0.1\"}");
+    rpc.execute(tsdb, query);
+  }
+
+  @Test (expected = BadRequestException.class)
+  public void renamePostNoType() throws Exception {
+    HttpQuery query = NettyMocks.postQuery(tsdb, "/api/uid/rename",
+        "{\"name\":\"127.0.0.1\"}");
+    rpc.execute(tsdb, query);
+  }
+
+  @Test (expected = BadRequestException.class)
+  public void renamePostNotJSON() throws Exception {
+    HttpQuery query = NettyMocks.postQuery(tsdb, "/api/uid/rename", "Not JSON");
+    rpc.execute(tsdb, query);
+  }
+
+  @Test (expected = BadRequestException.class)
+  public void renamePostZeroLengthContent() throws Exception {
+    HttpQuery query = NettyMocks.postQuery(tsdb, "/api/uid/rename", "");
+    rpc.execute(tsdb, query);
+  }
+
+  @Test (expected = BadRequestException.class)
+  public void renamePostEmptyJSON() throws Exception {
+    HttpQuery query = NettyMocks.postQuery(tsdb, "/api/uid/rename", "{}");
+    rpc.execute(tsdb, query);
+  }
+
+  @Test
+  public void renameQsMetric() throws Exception {
+    HttpQuery query = NettyMocks.getQuery(tsdb,
+        "/api/uid/rename?metric=sys.cpu.1&name=sys.cpu.2");
+    rpc.execute(tsdb, query);
+    assertEquals(HttpResponseStatus.OK, query.response().getStatus());
+    assertEquals("{\"result\":\"true\"}",
+        query.response().getContent().toString(Charset.forName("UTF-8")));
+  }
+
+  @Test
+  public void renameQsTagk() throws Exception {
+    HttpQuery query = NettyMocks.getQuery(tsdb,
+        "/api/uid/rename?tagk=datacenter&name=datacluster");
+    rpc.execute(tsdb, query);
+    assertEquals(HttpResponseStatus.OK, query.response().getStatus());
+    assertEquals("{\"result\":\"true\"}",
+        query.response().getContent().toString(Charset.forName("UTF-8")));
+  }
+
+  @Test
+  public void renameQsTagv() throws Exception {
+    HttpQuery query = NettyMocks.getQuery(tsdb,
+        "/api/uid/rename?tagv=localhost&name=127.0.0.1");
+    rpc.execute(tsdb, query);
+    assertEquals(HttpResponseStatus.OK, query.response().getStatus());
+    assertEquals("{\"result\":\"true\"}",
+        query.response().getContent().toString(Charset.forName("UTF-8")));
+  }
+
+  @Test
+  public void renameQsSkipUnsupportedParam() throws Exception {
+    HttpQuery query = NettyMocks.getQuery(tsdb,
+        "/api/uid/rename?tagv=localhost&name=127.0.0.1&drop=db");
+    rpc.execute(tsdb, query);
+    assertEquals(HttpResponseStatus.OK, query.response().getStatus());
+    assertEquals("{\"result\":\"true\"}",
+        query.response().getContent().toString(Charset.forName("UTF-8")));
+  }
+
+  @Test (expected = BadRequestException.class)
+  public void renameQsMissingType() throws Exception {
+    HttpQuery query = NettyMocks.getQuery(tsdb,
+        "/api/uid/rename?name=127.0.0.1");
+    rpc.execute(tsdb, query);
+  }
+
+  @Test (expected = BadRequestException.class)
+  public void renameQsMissingName() throws Exception {
+    HttpQuery query = NettyMocks.getQuery(tsdb,
+        "/api/uid/rename?metric=sys.cpu.1");
+    rpc.execute(tsdb, query);
+  }
+
+  @Test (expected = BadRequestException.class)
+  public void renameQsNoParamValue() throws Exception {
+    HttpQuery query = NettyMocks.getQuery(tsdb,
+        "/api/uid/rename?metric=&name=sys.cpu.2");
+    rpc.execute(tsdb, query);
+  }
+
+  @Test (expected = BadRequestException.class)
+  public void renameQsNoParam() throws Exception {
+    HttpQuery query = NettyMocks.getQuery(tsdb,
+        "/api/uid/rename?");
+    rpc.execute(tsdb, query);
+  }
+
+  @Test
+  public void renameRenameException() throws Exception {
+    final String message = "New name already exists";
+    doThrow(new IllegalArgumentException(message)).when(tsdb).renameUid("tagv",
+        "localhost", "localhost");
+    HttpQuery query = NettyMocks.getQuery(tsdb,
+        "/api/uid/rename?tagv=localhost&name=localhost");
+    rpc.execute(tsdb, query);
+    assertEquals(HttpResponseStatus.BAD_REQUEST, query.response().getStatus());
+    final String json = query.response().getContent()
+        .toString(Charset.forName("UTF-8"));
+    assertTrue(json.contains("\"error\":\"" + message + "\""));
+    assertTrue(json.contains("\"result\":\"false\""));
+  }
+
   // Teset /api/uid/uidmeta --------------------
   
   @Test
diff --git a/test/uid/TestUniqueId.java b/test/uid/TestUniqueId.java
index a35aeeae3c..0b0393f855 100644
--- a/test/uid/TestUniqueId.java
+++ b/test/uid/TestUniqueId.java
@@ -22,11 +22,14 @@
 
 import net.opentsdb.core.Const;
 import net.opentsdb.core.TSDB;
+import net.opentsdb.core.BaseTsdbTest.UnitTestException;
 import net.opentsdb.storage.MockBase;
+import net.opentsdb.uid.UniqueId.UniqueIdType;
 import net.opentsdb.utils.Config;
 
 import org.hbase.async.AtomicIncrementRequest;
 import org.hbase.async.Bytes;
+import org.hbase.async.DeleteRequest;
 import org.hbase.async.GetRequest;
 import org.hbase.async.HBaseClient;
 import org.hbase.async.HBaseException;
@@ -36,18 +39,15 @@
 import org.junit.Test;
 import org.junit.runner.RunWith;
 
-import static org.junit.Assert.assertArrayEquals;
-import static org.junit.Assert.assertEquals;
-import static org.junit.Assert.assertNotNull;
-import static org.junit.Assert.assertSame;
-import static org.junit.Assert.fail;
-
 import org.mockito.ArgumentMatcher;
 import org.mockito.InOrder;
 import org.mockito.invocation.InvocationOnMock;
 import org.mockito.stubbing.Answer;
 
+import static org.junit.Assert.*;
 import static org.mockito.Matchers.any;
+import static org.mockito.Matchers.anyMapOf;
+import static org.mockito.Matchers.anyString;
 import static org.mockito.Mockito.anyInt;
 import static org.mockito.Mockito.argThat;
 import static org.mockito.Mockito.eq;
@@ -266,7 +266,7 @@ public void getOrCreateIdWithExistingId() {
   }
 
   @Test  // Test the creation of an ID with no problem.
-  public void getOrCreateIdAssignIdWithSuccess() {
+  public void getOrCreateIdAssignFilterOK() {
     uid = new UniqueId(client, table, METRIC, 3);
     final byte[] id = { 0, 0, 5 };
     final Config config = mock(Config.class);
@@ -274,6 +274,12 @@ public void getOrCreateIdAssignIdWithSuccess() {
     final TSDB tsdb = mock(TSDB.class);
     when(tsdb.getConfig()).thenReturn(config);
     uid.setTSDB(tsdb);
+    final UniqueIdFilterPlugin filter = mock(UniqueIdFilterPlugin.class);
+    when(filter.fillterUIDAssignments()).thenReturn(true);
+    when(filter.allowUIDAssignment(any(UniqueIdType.class), anyString(), 
+        anyString(), anyMapOf(String.class, String.class)))
+      .thenReturn(Deferred.fromResult(true));
+    when(tsdb.getUidFilter()).thenReturn(filter);
     
     when(client.get(anyGet()))      // null  =>  ID doesn't exist.
       .thenReturn(Deferred.<ArrayList<KeyValue>>fromResult(null));
@@ -296,6 +302,216 @@ public void getOrCreateIdAssignIdWithSuccess() {
     verify(client).atomicIncrement(incrementForRow(MAXID));
     // Reverse + forward mappings.
     verify(client, times(2)).compareAndSet(anyPut(), emptyArray());
+    verify(filter, times(1)).allowUIDAssignment(any(UniqueIdType.class), anyString(), 
+        anyString(), anyMapOf(String.class, String.class));
+  }
+
+  @Test (expected = FailedToAssignUniqueIdException.class)
+  public void getOrCreateIdAssignFilterBlocked() {
+    uid = new UniqueId(client, table, METRIC, 3);
+    final Config config = mock(Config.class);
+    when(config.enable_realtime_uid()).thenReturn(false);
+    final TSDB tsdb = mock(TSDB.class);
+    when(tsdb.getConfig()).thenReturn(config);
+    uid.setTSDB(tsdb);
+    final UniqueIdFilterPlugin filter = mock(UniqueIdFilterPlugin.class);
+    when(filter.fillterUIDAssignments()).thenReturn(true);
+    when(filter.allowUIDAssignment(any(UniqueIdType.class), anyString(), 
+        anyString(), anyMapOf(String.class, String.class)))
+      .thenReturn(Deferred.fromResult(false));
+    when(tsdb.getUidFilter()).thenReturn(filter);
+    
+    when(client.get(anyGet()))      // null  =>  ID doesn't exist.
+            .thenReturn(Deferred.<ArrayList<KeyValue>>fromResult(null));
+    // Watch this! ______,^   I'm writing C++ in Java!
+
+    when(client.atomicIncrement(incrementForRow(MAXID)))
+            .thenReturn(Deferred.fromResult(5L));
+
+    when(client.compareAndSet(anyPut(), emptyArray()))
+            .thenReturn(Deferred.fromResult(true))
+            .thenReturn(Deferred.fromResult(true));
+
+    uid.getOrCreateId("foo");
+  }
+
+  @Test(expected = RuntimeException.class)
+  public void getOrCreateIdAssignFilterReturnException() {
+    uid = new UniqueId(client, table, METRIC, 3);
+    final Config config = mock(Config.class);
+    when(config.enable_realtime_uid()).thenReturn(false);
+    final TSDB tsdb = mock(TSDB.class);
+    when(tsdb.getConfig()).thenReturn(config);
+    uid.setTSDB(tsdb);
+    final UniqueIdFilterPlugin filter = mock(UniqueIdFilterPlugin.class);
+    when(filter.fillterUIDAssignments()).thenReturn(true);
+    when(filter.allowUIDAssignment(any(UniqueIdType.class), anyString(), 
+        anyString(), anyMapOf(String.class, String.class)))
+      .thenReturn(Deferred.<Boolean>fromError(new UnitTestException()));
+    when(tsdb.getUidFilter()).thenReturn(filter);
+
+    when(client.get(anyGet()))      // null  =>  ID doesn't exist.
+            .thenReturn(Deferred.<ArrayList<KeyValue>>fromResult(null));
+    // Watch this! ______,^   I'm writing C++ in Java!
+
+    when(client.atomicIncrement(incrementForRow(MAXID)))
+            .thenReturn(Deferred.fromResult(5L));
+
+    when(client.compareAndSet(anyPut(), emptyArray()))
+            .thenReturn(Deferred.fromResult(true))
+            .thenReturn(Deferred.fromResult(true));
+
+    uid.getOrCreateId("foo");
+  }
+  
+  @Test(expected = RuntimeException.class)
+  public void getOrCreateIdAssignFilterThrowsException() {
+    uid = new UniqueId(client, table, METRIC, 3);
+    final Config config = mock(Config.class);
+    when(config.enable_realtime_uid()).thenReturn(false);
+    final TSDB tsdb = mock(TSDB.class);
+    when(tsdb.getConfig()).thenReturn(config);
+    uid.setTSDB(tsdb);
+    final UniqueIdFilterPlugin filter = mock(UniqueIdFilterPlugin.class);
+    when(filter.fillterUIDAssignments()).thenReturn(true);
+    when(filter.allowUIDAssignment(any(UniqueIdType.class), anyString(), 
+        anyString(), anyMapOf(String.class, String.class)))
+      .thenThrow(new UnitTestException());
+    when(tsdb.getUidFilter()).thenReturn(filter);
+
+    when(client.get(anyGet()))      // null  =>  ID doesn't exist.
+            .thenReturn(Deferred.<ArrayList<KeyValue>>fromResult(null));
+    // Watch this! ______,^   I'm writing C++ in Java!
+
+    when(client.atomicIncrement(incrementForRow(MAXID)))
+            .thenReturn(Deferred.fromResult(5L));
+
+    when(client.compareAndSet(anyPut(), emptyArray()))
+            .thenReturn(Deferred.fromResult(true))
+            .thenReturn(Deferred.fromResult(true));
+
+    uid.getOrCreateId("foo");
+  }
+
+  @Test
+  public void getOrCreateIdAsyncAssignFilterOK() throws Exception {
+    uid = new UniqueId(client, table, METRIC, 3);
+    final byte[] id = { 0, 0, 5 };
+    final Config config = mock(Config.class);
+    when(config.enable_realtime_uid()).thenReturn(false);
+    final TSDB tsdb = mock(TSDB.class);
+    when(tsdb.getConfig()).thenReturn(config);
+    uid.setTSDB(tsdb);
+    final UniqueIdFilterPlugin filter = mock(UniqueIdFilterPlugin.class);
+    when(filter.fillterUIDAssignments()).thenReturn(true);
+    when(filter.allowUIDAssignment(any(UniqueIdType.class), anyString(), 
+        anyString(), anyMapOf(String.class, String.class)))
+      .thenReturn(Deferred.fromResult(true));
+    when(tsdb.getUidFilter()).thenReturn(filter);
+    when(client.get(anyGet()))      // null  =>  ID doesn't exist.
+      .thenReturn(Deferred.<ArrayList<KeyValue>>fromResult(null));
+    // Watch this! ______,^   I'm writing C++ in Java!
+
+    when(client.atomicIncrement(incrementForRow(MAXID)))
+      .thenReturn(Deferred.fromResult(5L));
+
+    when(client.compareAndSet(anyPut(), emptyArray()))
+      .thenReturn(Deferred.fromResult(true))
+      .thenReturn(Deferred.fromResult(true));
+
+    assertArrayEquals(id, uid.getOrCreateIdAsync("foo").join());
+    // Should be a cache hit since we created that entry.
+    assertArrayEquals(id, uid.getOrCreateIdAsync("foo").join());
+    // Should be a cache hit too for the same reason.
+    assertEquals("foo", uid.getName(id));
+    
+    verify(client).get(anyGet()); // Initial Get.
+    verify(client).atomicIncrement(incrementForRow(MAXID));
+    // Reverse + forward mappings.
+    verify(client, times(2)).compareAndSet(anyPut(), emptyArray());
+    verify(filter, times(1)).allowUIDAssignment(any(UniqueIdType.class), anyString(), 
+        anyString(), anyMapOf(String.class, String.class));
+  }
+  
+  @Test (expected = FailedToAssignUniqueIdException.class)
+  public void getOrCreateIdAsyncAssignFilterBlocked() throws Exception {
+    uid = new UniqueId(client, table, METRIC, 3);
+    final Config config = mock(Config.class);
+    when(config.enable_realtime_uid()).thenReturn(false);
+    final TSDB tsdb = mock(TSDB.class);
+    when(tsdb.getConfig()).thenReturn(config);
+    uid.setTSDB(tsdb);
+    final UniqueIdFilterPlugin filter = mock(UniqueIdFilterPlugin.class);
+    when(filter.fillterUIDAssignments()).thenReturn(true);
+    when(filter.allowUIDAssignment(any(UniqueIdType.class), anyString(), 
+        anyString(), anyMapOf(String.class, String.class)))
+      .thenReturn(Deferred.fromResult(false));
+    when(tsdb.getUidFilter()).thenReturn(filter);
+    when(client.get(anyGet()))      // null  =>  ID doesn't exist.
+      .thenReturn(Deferred.<ArrayList<KeyValue>>fromResult(null));
+
+    when(client.atomicIncrement(incrementForRow(MAXID)))
+      .thenReturn(Deferred.fromResult(5L));
+
+    when(client.compareAndSet(anyPut(), emptyArray()))
+      .thenReturn(Deferred.fromResult(true))
+      .thenReturn(Deferred.fromResult(true));
+
+    uid.getOrCreateIdAsync("foo").join();
+  }
+  
+  @Test (expected = UnitTestException.class)
+  public void getOrCreateIdAsyncAssignFilterReturnException() throws Exception {
+    uid = new UniqueId(client, table, METRIC, 3);
+    final Config config = mock(Config.class);
+    when(config.enable_realtime_uid()).thenReturn(false);
+    final TSDB tsdb = mock(TSDB.class);
+    when(tsdb.getConfig()).thenReturn(config);
+    uid.setTSDB(tsdb);
+    final UniqueIdFilterPlugin filter = mock(UniqueIdFilterPlugin.class);
+    when(filter.fillterUIDAssignments()).thenReturn(true);
+    when(filter.allowUIDAssignment(any(UniqueIdType.class), anyString(), 
+        anyString(), anyMapOf(String.class, String.class)))
+      .thenReturn(Deferred.<Boolean>fromError(new UnitTestException()));
+    when(tsdb.getUidFilter()).thenReturn(filter);
+    when(client.get(anyGet()))      // null  =>  ID doesn't exist.
+      .thenReturn(Deferred.<ArrayList<KeyValue>>fromResult(null));
+
+    when(client.atomicIncrement(incrementForRow(MAXID)))
+      .thenReturn(Deferred.fromResult(5L));
+
+    when(client.compareAndSet(anyPut(), emptyArray()))
+      .thenReturn(Deferred.fromResult(true))
+      .thenReturn(Deferred.fromResult(true));
+
+    uid.getOrCreateIdAsync("foo").join();
+  }
+  
+  @Test (expected = UnitTestException.class)
+  public void getOrCreateIdAsyncAssignFilterThrowsException() throws Exception {
+    uid = new UniqueId(client, table, METRIC, 3);
+    final Config config = mock(Config.class);
+    when(config.enable_realtime_uid()).thenReturn(false);
+    final TSDB tsdb = mock(TSDB.class);
+    when(tsdb.getConfig()).thenReturn(config);
+    uid.setTSDB(tsdb);
+    final UniqueIdFilterPlugin filter = mock(UniqueIdFilterPlugin.class);
+    when(filter.fillterUIDAssignments()).thenReturn(true);
+    when(filter.allowUIDAssignment(any(UniqueIdType.class), anyString(), 
+        anyString(),anyMapOf(String.class, String.class)))
+      .thenThrow(new UnitTestException());
+    when(tsdb.getUidFilter()).thenReturn(filter);
+    when(client.get(anyGet()))      // null  =>  ID doesn't exist.
+      .thenReturn(Deferred.<ArrayList<KeyValue>>fromResult(null));
+
+    when(client.atomicIncrement(incrementForRow(MAXID)))
+      .thenReturn(Deferred.fromResult(5L));
+
+    when(client.compareAndSet(anyPut(), emptyArray()))
+      .thenReturn(Deferred.fromResult(true))
+      .thenReturn(Deferred.fromResult(true));
+
+    uid.getOrCreateIdAsync("foo").join();
   }
   
   @Test  // Test the creation of an ID when unable to increment MAXID
@@ -823,7 +1039,6 @@ public void getTagPairsFromTSUIDString() {
     assertArrayEquals(new byte[] { 0, 0, 3, 0, 0, 4 }, tags.get(1));
   }
   
-  
   @Test
   public void getTagPairsFromTSUIDStringNonStandardWidth() {
     PowerMockito.mockStatic(TSDB.class);
@@ -879,7 +1094,6 @@ public void getTagPairsFromTSUIDBytes() {
     assertArrayEquals(new byte[] { 0, 0, 3, 0, 0, 4 }, tags.get(1));
   }
   
-  
   @Test
   public void getTagPairsFromTSUIDBytesNonStandardWidth() {
     PowerMockito.mockStatic(TSDB.class);
@@ -1062,6 +1276,82 @@ public void longToUIDTooBig() throws Exception {
     UniqueId.longToUID(257, (short)1);
   }
 
+  @Test
+  public void rename() throws Exception {
+    uid = new UniqueId(client, table, METRIC, 3);
+    final byte[] foo_id = { 0, 'a', 0x42 };
+    final byte[] foo_name = { 'f', 'o', 'o' };
+
+    ArrayList<KeyValue> kvs = new ArrayList<KeyValue>(1);
+    kvs.add(new KeyValue(foo_name, ID, METRIC_ARRAY, foo_id));
+    when(client.get(anyGet()))
+        .thenReturn(Deferred.fromResult(kvs))
+        .thenReturn(Deferred.<ArrayList<KeyValue>>fromResult(null));
+    when(client.put(anyPut())).thenAnswer(answerTrue());
+    when(client.delete(anyDelete())).thenAnswer(answerTrue());
+
+    uid.rename("foo", "bar");
+  }
+
+  @Test (expected = IllegalArgumentException.class)
+  public void renameNewNameExists() throws Exception {
+    uid = new UniqueId(client, table, METRIC, 3);
+    final byte[] foo_id = { 0, 'a', 0x42 };
+    final byte[] foo_name = { 'f', 'o', 'o' };
+    final byte[] bar_id = { 1, 'b', 0x43 };
+    final byte[] bar_name = { 'b', 'a', 'r' };
+
+    ArrayList<KeyValue> foo_kvs = new ArrayList<KeyValue>(1);
+    ArrayList<KeyValue> bar_kvs = new ArrayList<KeyValue>(1);
+    foo_kvs.add(new KeyValue(foo_name, ID, METRIC_ARRAY, foo_id));
+    bar_kvs.add(new KeyValue(bar_name, ID, METRIC_ARRAY, bar_id));
+    when(client.get(anyGet()))
+        .thenReturn(Deferred.fromResult(foo_kvs))
+        .thenReturn(Deferred.fromResult(bar_kvs));
+    when(client.put(anyPut())).thenAnswer(answerTrue());
+    when(client.delete(anyDelete())).thenAnswer(answerTrue());
+
+    uid.rename("foo", "bar");
+  }
+
+  @Test (expected = IllegalStateException.class)
+  public void renameRaceCondition() throws Exception {
+    // Simulate a race between client A(default) and client B.
+    // A and B rename same UID to different name.
+    // B waits till A start to invoke PutRequest to start.
+
+    uid = new UniqueId(client, table, METRIC, 3);
+    HBaseClient client_b = mock(HBaseClient.class);
+    final UniqueId uid_b = new UniqueId(client_b, table, METRIC, 3);
+
+    final byte[] foo_id = { 0, 'a', 0x42 };
+    final byte[] foo_name = { 'f', 'o', 'o' };
+
+    ArrayList<KeyValue> kvs = new ArrayList<KeyValue>(1);
+    kvs.add(new KeyValue(foo_name, ID, METRIC_ARRAY, foo_id));
+
+    when(client_b.get(anyGet()))
+        .thenReturn(Deferred.fromResult(kvs))
+        .thenReturn(Deferred.<ArrayList<KeyValue>>fromResult(null));
+    when(client_b.put(anyPut())).thenAnswer(answerTrue());
+    when(client_b.delete(anyDelete())).thenAnswer(answerTrue());
+
+    final Answer<Deferred<Boolean>> the_race = new Answer<Deferred<Boolean>>() {
+      public Deferred<Boolean> answer(final InvocationOnMock inv) throws Exception {
+        uid_b.rename("foo", "xyz");
+        return Deferred.fromResult(true);
+      }
+    };
+
+    when(client.get(anyGet()))
+        .thenReturn(Deferred.fromResult(kvs))
+        .thenReturn(Deferred.<ArrayList<KeyValue>>fromResult(null));
+    when(client.put(anyPut())).thenAnswer(the_race);
+    when(client.delete(anyDelete())).thenAnswer(answerTrue());
+
+    uid.rename("foo", "bar");
+  }
+
   @Test
   public void deleteCached() throws Exception {
     setupStorage();
@@ -1180,6 +1470,8 @@ public void deleteNoSuchUniqueName() throws Exception {
   // ----------------- //
 
   private void setupStorage() throws Exception {
+    final Config config = mock(Config.class);
+    when(tsdb.getConfig()).thenReturn(config);
     when(tsdb.getClient()).thenReturn(client);
     storage = new MockBase(tsdb, client, true, true, true, true);
     
@@ -1220,6 +1512,18 @@ private static PutRequest anyPut() {
     return any(PutRequest.class);
   }
   
+  private static DeleteRequest anyDelete() {
+    return any(DeleteRequest.class);
+  }
+
+  private static Answer<Deferred<Boolean>> answerTrue() {
+    return new Answer<Deferred<Boolean>>() {
+      public Deferred<Boolean> answer(final InvocationOnMock inv) {
+        return Deferred.fromResult(true);
+      }
+    };
+  }
+
   @SuppressWarnings("unchecked")
   private static Callback<byte[], ArrayList<KeyValue>> anyByteCB() {
     return any(Callback.class);
diff --git a/test/uid/TestUniqueIdWhitelistFilter.java b/test/uid/TestUniqueIdWhitelistFilter.java
new file mode 100644
index 0000000000..c07f9c26e2
--- /dev/null
+++ b/test/uid/TestUniqueIdWhitelistFilter.java
@@ -0,0 +1,165 @@
+// This file is part of OpenTSDB.
+// Copyright (C) 2016  The OpenTSDB Authors.
+//
+// This program is free software: you can redistribute it and/or modify it
+// under the terms of the GNU Lesser General Public License as published by
+// the Free Software Foundation, either version 2.1 of the License, or (at your
+// option) any later version.  This program is distributed in the hope that it
+// will be useful, but WITHOUT ANY WARRANTY; without even the implied warranty
+// of MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser
+// General Public License for more details.  You should have received a copy
+// of the GNU Lesser General Public License along with this program.  If not,
+// see <http://www.gnu.org/licenses/>.
+package net.opentsdb.uid;
+
+import static org.junit.Assert.assertEquals;
+import static org.junit.Assert.assertFalse;
+import static org.junit.Assert.assertNull;
+import static org.junit.Assert.assertTrue;
+import static org.mockito.Mockito.when;
+
+import org.junit.Before;
+import org.junit.Test;
+import org.junit.runner.RunWith;
+import org.powermock.api.mockito.PowerMockito;
+import org.powermock.core.classloader.annotations.PowerMockIgnore;
+import org.powermock.core.classloader.annotations.PrepareForTest;
+import org.powermock.modules.junit4.PowerMockRunner;
+
+import net.opentsdb.core.TSDB;
+import net.opentsdb.uid.UniqueId.UniqueIdType;
+import net.opentsdb.utils.Config;
+
+@RunWith(PowerMockRunner.class)
+//"Classloader hell"...  It's real.  Tell PowerMock to ignore these classes
+//because they fiddle with the class loader.  We don't test them anyway.
+@PowerMockIgnore({"javax.management.*", "javax.xml.*",
+               "ch.qos.*", "org.slf4j.*", "com.sum.*", "org.xml.*"})
+@PrepareForTest({ TSDB.class, Config.class })
+public class TestUniqueIdWhitelistFilter {
+
+  private TSDB tsdb;
+  private Config config;
+  private UniqueIdWhitelistFilter filter;
+  
+  @Before
+  public void before() throws Exception {
+    tsdb = PowerMockito.mock(TSDB.class);
+    config = new Config(false);
+    when(tsdb.getConfig()).thenReturn(config);
+    filter = new UniqueIdWhitelistFilter();
+    
+    config.overrideConfig("tsd.uidfilter.whitelist.metric_patterns", ".*");
+    config.overrideConfig("tsd.uidfilter.whitelist.tagk_patterns", ".*");
+    config.overrideConfig("tsd.uidfilter.whitelist.tagv_patterns", ".*");
+  }
+  
+  @Test
+  public void ctor() throws Exception {
+    assertNull(filter.metricPatterns());
+    assertNull(filter.tagkPatterns());
+    assertNull(filter.tagvPatterns());
+  }
+  
+  @Test
+  public void initalize() throws Exception {
+    filter.initialize(tsdb);
+    assertEquals(1, filter.metricPatterns().size());
+    assertEquals(".*", filter.metricPatterns().get(0).pattern());
+    assertEquals(1, filter.tagkPatterns().size());
+    assertEquals(".*", filter.tagkPatterns().get(0).pattern());
+    assertEquals(1, filter.tagvPatterns().size());
+    assertEquals(".*", filter.tagvPatterns().get(0).pattern());
+  }
+  
+  @Test
+  public void initalizeMultiplePatterns() throws Exception {
+    config.overrideConfig("tsd.uidfilter.whitelist.metric_patterns", ".*,^test.*");
+    config.overrideConfig("tsd.uidfilter.whitelist.tagk_patterns", ".*,^test.*");
+    config.overrideConfig("tsd.uidfilter.whitelist.tagv_patterns", ".*,^test.*");
+    filter.initialize(tsdb);
+    assertEquals(2, filter.metricPatterns().size());
+    assertEquals(".*", filter.metricPatterns().get(0).pattern());
+    assertEquals("^test.*", filter.metricPatterns().get(1).pattern());
+    assertEquals(2, filter.tagkPatterns().size());
+    assertEquals(".*", filter.tagkPatterns().get(0).pattern());
+    assertEquals("^test.*", filter.tagkPatterns().get(1).pattern());
+    assertEquals(2, filter.tagvPatterns().size());
+    assertEquals(".*", filter.tagvPatterns().get(0).pattern());
+    assertEquals("^test.*", filter.tagvPatterns().get(1).pattern());
+  }
+  
+  @Test
+  public void initalizeMultiplePatternsAlternateDelimiter() throws Exception {
+    config.overrideConfig("tsd.uidfilter.whitelist.delimiter", "\\|");
+    config.overrideConfig("tsd.uidfilter.whitelist.metric_patterns", ".*|^test.*");
+    config.overrideConfig("tsd.uidfilter.whitelist.tagk_patterns", ".*|^test.*");
+    config.overrideConfig("tsd.uidfilter.whitelist.tagv_patterns", ".*|^test.*");
+    filter.initialize(tsdb);
+    assertEquals(2, filter.metricPatterns().size());
+    assertEquals(".*", filter.metricPatterns().get(0).pattern());
+    assertEquals("^test.*", filter.metricPatterns().get(1).pattern());
+    assertEquals(2, filter.tagkPatterns().size());
+    assertEquals(".*", filter.tagkPatterns().get(0).pattern());
+    assertEquals("^test.*", filter.tagkPatterns().get(1).pattern());
+    assertEquals(2, filter.tagvPatterns().size());
+    assertEquals(".*", filter.tagvPatterns().get(0).pattern());
+    assertEquals("^test.*", filter.tagvPatterns().get(1).pattern());
+  }
+  
+  @Test (expected = IllegalArgumentException.class)
+  public void initalizeBadRegex() throws Exception {
+    config.overrideConfig("tsd.uidfilter.whitelist.metric_patterns", "grp[start");
+    filter.initialize(tsdb);
+  }
+
+  @Test
+  public void shutdown() throws Exception {
+    assertNull(filter.shutdown().join());
+  }
+  
+  @Test
+  public void allowUIDAssignment() throws Exception {
+    config.overrideConfig("tsd.uidfilter.whitelist.metric_patterns", "^test.*");
+    config.overrideConfig("tsd.uidfilter.whitelist.tagk_patterns", "^test.*");
+    config.overrideConfig("tsd.uidfilter.whitelist.tagv_patterns", "^test.*");
+    filter.initialize(tsdb);
+    assertTrue(filter.allowUIDAssignment(UniqueIdType.METRIC, "test_metric", 
+        null, null).join());
+    assertFalse(filter.allowUIDAssignment(UniqueIdType.METRIC, "metric", 
+        null, null).join());
+    assertTrue(filter.allowUIDAssignment(UniqueIdType.TAGK, "test_tagk", 
+        null, null).join());
+    assertFalse(filter.allowUIDAssignment(UniqueIdType.TAGK, "tagk", 
+        null, null).join());
+    assertTrue(filter.allowUIDAssignment(UniqueIdType.TAGV, "test_tagv", 
+        null, null).join());
+    assertFalse(filter.allowUIDAssignment(UniqueIdType.TAGV, "tagv", 
+        null, null).join());
+  }
+  
+  @Test
+  public void allowUIDAssignmentMultiplePaterns() throws Exception {
+    config.overrideConfig("tsd.uidfilter.whitelist.metric_patterns", ".*,^test.*");
+    config.overrideConfig("tsd.uidfilter.whitelist.tagk_patterns", ".*,^test.*");
+    config.overrideConfig("tsd.uidfilter.whitelist.tagv_patterns", ".*,^test.*");
+    filter.initialize(tsdb);
+    assertTrue(filter.allowUIDAssignment(UniqueIdType.METRIC, "test_metric", 
+        null, null).join());
+    assertFalse(filter.allowUIDAssignment(UniqueIdType.METRIC, "metric", 
+        null, null).join());
+    assertTrue(filter.allowUIDAssignment(UniqueIdType.TAGK, "test_tagk", 
+        null, null).join());
+    assertFalse(filter.allowUIDAssignment(UniqueIdType.TAGK, "tagk", 
+        null, null).join());
+    assertTrue(filter.allowUIDAssignment(UniqueIdType.TAGV, "test_tagv", 
+        null, null).join());
+    assertFalse(filter.allowUIDAssignment(UniqueIdType.TAGV, "tagv", 
+        null, null).join());
+  }
+  
+  @Test
+  public void fillterUIDAssignments() throws Exception {
+    assertTrue(filter.fillterUIDAssignments());
+  }
+}
diff --git a/test/utils/TestByteSet.java b/test/utils/TestByteSet.java
new file mode 100644
index 0000000000..5cd83a240c
--- /dev/null
+++ b/test/utils/TestByteSet.java
@@ -0,0 +1,71 @@
+// This file is part of OpenTSDB.
+// Copyright (C) 2015  The OpenTSDB Authors.
+//
+// This program is free software: you can redistribute it and/or modify it
+// under the terms of the GNU Lesser General Public License as published by
+// the Free Software Foundation, either version 2.1 of the License, or (at your
+// option) any later version.  This program is distributed in the hope that it
+// will be useful, but WITHOUT ANY WARRANTY; without even the implied warranty
+// of MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser
+// General Public License for more details.  You should have received a copy
+// of the GNU Lesser General Public License along with this program.  If not,
+// see <http://www.gnu.org/licenses/>.
+package net.opentsdb.utils;
+
+import static org.junit.Assert.assertArrayEquals;
+import static org.junit.Assert.assertEquals;
+import static org.junit.Assert.assertFalse;
+import static org.junit.Assert.assertNotNull;
+import static org.junit.Assert.assertTrue;
+
+import java.util.Iterator;
+
+import org.junit.Test;
+
+public class TestByteSet {
+
+  private static final byte[] V1 = new byte[] { 0, 0, 1 };
+  private static final byte[] V2 = new byte[] { 0, 0, 2 };
+  private static final byte[] V3 = new byte[] { 0, 0, 3 };
+  private static final byte[] V4 = new byte[] { 0, 0, 4 };
+  
+  @Test
+  public void ctor() {
+    final ByteSet set = new ByteSet();
+    assertNotNull(set);
+    assertEquals(0, set.size());
+    assertTrue(set.isEmpty());
+  }
+  
+  @Test
+  public void goodOperations() {
+    final ByteSet set = new ByteSet();
+    set.add(V3);
+    set.add(V2);
+    set.add(V1);
+    
+    assertEquals(3, set.size());
+    assertFalse(set.isEmpty());
+    
+    // should come out in order
+    final Iterator<byte[]> it = set.iterator();
+    assertArrayEquals(V1, it.next());
+    assertArrayEquals(V2, it.next());
+    assertArrayEquals(V3, it.next());
+    assertFalse(it.hasNext());
+    
+    assertEquals("[[0, 0, 1],[0, 0, 2],[0, 0, 3]]", set.toString());
+    
+    assertTrue(set.contains(V1));
+    assertFalse(set.contains(V4));
+    
+    assertTrue(set.remove(V1));
+    assertFalse(set.contains(V1));
+    assertFalse(set.remove(V4));
+    
+    set.clear();
+    assertFalse(set.contains(V2));
+    assertFalse(set.contains(V3));
+    assertTrue(set.isEmpty());
+  }
+}
diff --git a/test/utils/TestDateTime.java b/test/utils/TestDateTime.java
index f5d75f6c25..b21bb25866 100644
--- a/test/utils/TestDateTime.java
+++ b/test/utils/TestDateTime.java
@@ -21,19 +21,39 @@
 import static org.mockito.Mockito.when;
 
 import java.text.SimpleDateFormat;
+import java.util.Calendar;
 import java.util.TimeZone;
 
 import org.junit.Before;
 import org.junit.Test;
 import org.junit.runner.RunWith;
 import org.powermock.api.mockito.PowerMockito;
+import org.powermock.core.classloader.annotations.PowerMockIgnore;
 import org.powermock.core.classloader.annotations.PrepareForTest;
 import org.powermock.modules.junit4.PowerMockRunner;
 
+//"Classloader hell"...  It's real.  Tell PowerMock to ignore these classes
+//because they fiddle with the class loader.  We don't test them anyway.
+@PowerMockIgnore({"javax.management.*", "javax.xml.*",
+             "ch.qos.*", "org.slf4j.*",
+             "com.sum.*", "org.xml.*"})
 @RunWith(PowerMockRunner.class)
 @PrepareForTest({ DateTime.class, System.class })
 public final class TestDateTime {
 
+  //30 minute offset
+  final static TimeZone AF = DateTime.timezones.get("Asia/Kabul");
+  // 45 minute offset w DST
+  final static TimeZone NZ = DateTime.timezones.get("Pacific/Chatham");
+  // 12h offset w/o DST
+  final static TimeZone TV = DateTime.timezones.get("Pacific/Funafuti");
+  // 12h offset w DST
+  final static TimeZone FJ = DateTime.timezones.get("Pacific/Fiji");
+  // Fri, 15 May 2015 14:21:13.432 UTC
+  final static long NON_DST_TS = 1431699673432L;
+  // Tue, 15 Dec 2015 04:02:25.123 UTC
+  final static long DST_TS = 1450152145123L;
+ 
   @Before
   public void before() {
     PowerMockito.mockStatic(System.class);
@@ -50,6 +70,12 @@ public void getTimezoneNull() {
     assertNull(DateTime.timezones.get("Nothere"));
   }
   
+  @Test
+  public void parseDateTimeStringNow() {
+    long t = DateTime.parseDateTimeString("now", null);
+    assertEquals(t, 1357300800000L);
+  }
+
   @Test
   public void parseDateTimeStringRelativeS() {
     long t = DateTime.parseDateTimeString("60s-ago", null);
@@ -159,6 +185,18 @@ public void parseDateTimeStringUnixMS() {
     long t = DateTime.parseDateTimeString("1355961603418", null);
     assertEquals(1355961603418L, t);
   }
+
+  @Test
+  public void parseDateTimeStringShortExplicitMS() {
+    long t = DateTime.parseDateTimeString("123123ms", null);
+    assertEquals(123123L, t);
+  }
+
+  @Test
+  public void parseDateTimeStringExplicitMS() {
+    long t = DateTime.parseDateTimeString("1234567890123ms", null);
+    assertEquals(1234567890123L, t);
+  }
   
   @Test
   public void parseDateTimeStringUnixMSDot() {
@@ -415,6 +453,474 @@ public void nanoTime() {
     assertEquals(1388534400000000000L, DateTime.nanoTime());
   }
 
+  @Test
+  public void previousIntervalMilliseconds() {
+    // interval 1
+    assertEquals(DST_TS, DateTime.previousInterval(DST_TS, 
+        1, Calendar.MILLISECOND).getTimeInMillis());
+    assertEquals(NON_DST_TS, DateTime.previousInterval(NON_DST_TS, 
+        1, Calendar.MILLISECOND).getTimeInMillis());
+    
+    // interval 100
+    assertEquals(1450152145100L, DateTime.previousInterval(DST_TS, 
+        100, Calendar.MILLISECOND).getTimeInMillis());
+    assertEquals(1450152145000L, DateTime.previousInterval(1450152145000L, 
+        100, Calendar.MILLISECOND).getTimeInMillis());
+    
+    // odd interval
+    assertEquals(1450152144769L, DateTime.previousInterval(DST_TS, 
+        799, Calendar.MILLISECOND).getTimeInMillis());
+    
+    // TZs - all the same for ms
+    assertEquals(1450152145100L, DateTime.previousInterval(DST_TS, 
+        100, Calendar.MILLISECOND, AF).getTimeInMillis());
+    assertEquals(1431699673400L, DateTime.previousInterval(NON_DST_TS, 
+        100, Calendar.MILLISECOND, AF).getTimeInMillis());
+    assertEquals(1450152145100L, DateTime.previousInterval(DST_TS, 
+        100, Calendar.MILLISECOND, NZ).getTimeInMillis());
+    assertEquals(1431699673400L, DateTime.previousInterval(NON_DST_TS, 
+        100, Calendar.MILLISECOND, NZ).getTimeInMillis());
+    assertEquals(1450152145100L, DateTime.previousInterval(DST_TS, 
+        100, Calendar.MILLISECOND, TV).getTimeInMillis());
+    assertEquals(1431699673400L, DateTime.previousInterval(NON_DST_TS, 
+        100, Calendar.MILLISECOND, TV).getTimeInMillis());
+    assertEquals(1450152145100L, DateTime.previousInterval(DST_TS, 
+        100, Calendar.MILLISECOND, FJ).getTimeInMillis());
+    assertEquals(1431699673400L, DateTime.previousInterval(NON_DST_TS, 
+        100, Calendar.MILLISECOND, FJ).getTimeInMillis());
+    
+    // multiples
+    assertEquals(1450152120000L, DateTime.previousInterval(DST_TS, 
+        60000, Calendar.MILLISECOND).getTimeInMillis());
+    assertEquals(1431699660000L, DateTime.previousInterval(NON_DST_TS, 
+        60000, Calendar.MILLISECOND).getTimeInMillis());
+  }
+  
+  @Test
+  public void previousIntervalSeconds() {
+    // interval 1
+    assertEquals(1450152145000L, DateTime.previousInterval(DST_TS, 
+        1, Calendar.SECOND).getTimeInMillis());
+    assertEquals(1431699673000L, DateTime.previousInterval(NON_DST_TS, 
+        1, Calendar.SECOND).getTimeInMillis());
+    
+    // interval 30
+    assertEquals(1450152120000L, DateTime.previousInterval(DST_TS, 
+        30, Calendar.SECOND).getTimeInMillis());
+    assertEquals(1431699660000L, DateTime.previousInterval(NON_DST_TS, 
+        30, Calendar.SECOND).getTimeInMillis());
+    assertEquals(1450152120000L, DateTime.previousInterval(1450152120000L, 
+        30, Calendar.SECOND).getTimeInMillis());
+        
+    // odd interval
+    assertEquals(1431699647000L, DateTime.previousInterval(NON_DST_TS, 
+        29, Calendar.SECOND).getTimeInMillis());
+    assertEquals(1450152145000L, DateTime.previousInterval(DST_TS, 
+        29, Calendar.SECOND).getTimeInMillis());
+    
+    // TZs - all the same for seconds
+    assertEquals(1450152120000L, DateTime.previousInterval(DST_TS, 
+        30, Calendar.SECOND, AF).getTimeInMillis());
+    assertEquals(1431699660000L, DateTime.previousInterval(NON_DST_TS, 
+        30, Calendar.SECOND, AF).getTimeInMillis());
+    assertEquals(1450152120000L, DateTime.previousInterval(DST_TS, 
+        30, Calendar.SECOND, NZ).getTimeInMillis());
+    assertEquals(1431699660000L, DateTime.previousInterval(NON_DST_TS, 
+        30, Calendar.SECOND, NZ).getTimeInMillis());
+    assertEquals(1450152120000L, DateTime.previousInterval(DST_TS, 
+        30, Calendar.SECOND, TV).getTimeInMillis());
+    assertEquals(1431699660000L, DateTime.previousInterval(NON_DST_TS, 
+        30, Calendar.SECOND, TV).getTimeInMillis());
+    assertEquals(1450152120000L, DateTime.previousInterval(DST_TS, 
+        30, Calendar.SECOND, FJ).getTimeInMillis());
+    assertEquals(1431699660000L, DateTime.previousInterval(NON_DST_TS, 
+        30, Calendar.SECOND, FJ).getTimeInMillis());
+    
+    // multiples
+    assertEquals(1450152000000L, DateTime.previousInterval(DST_TS, 
+        60000, Calendar.SECOND).getTimeInMillis());
+    assertEquals(1431698400000L, DateTime.previousInterval(NON_DST_TS, 
+        60000, Calendar.SECOND).getTimeInMillis());
+  }
+  
+  @Test
+  public void previousIntervalMinutes() {
+    // interval 1
+    assertEquals(1450152120000L, DateTime.previousInterval(DST_TS, 
+        1, Calendar.MINUTE).getTimeInMillis());
+    assertEquals(1431699660000L, DateTime.previousInterval(NON_DST_TS, 
+        1, Calendar.MINUTE).getTimeInMillis());
+    
+    // interval 30
+    assertEquals(1450152000000L, DateTime.previousInterval(DST_TS, 
+        30, Calendar.MINUTE).getTimeInMillis());
+    assertEquals(1431698400000L, DateTime.previousInterval(NON_DST_TS, 
+        30, Calendar.MINUTE).getTimeInMillis());
+    assertEquals(1431698400000L, DateTime.previousInterval(1431698400000L, 
+        30, Calendar.MINUTE).getTimeInMillis());
+        
+    // odd interval
+    assertEquals(1431698460000L, DateTime.previousInterval(NON_DST_TS, 
+        29, Calendar.MINUTE).getTimeInMillis());
+    assertEquals(1450151520000L, DateTime.previousInterval(DST_TS, 
+        29, Calendar.MINUTE).getTimeInMillis());
+    
+    // TZs
+    assertEquals(1450152000000L, DateTime.previousInterval(DST_TS, 
+        30, Calendar.MINUTE, AF).getTimeInMillis());
+    assertEquals(1431698400000L, DateTime.previousInterval(NON_DST_TS, 
+        30, Calendar.MINUTE, AF).getTimeInMillis());
+    // 15 min diff
+    assertEquals(1450152000000L, DateTime.previousInterval(DST_TS, 
+        15, Calendar.MINUTE, AF).getTimeInMillis());
+    assertEquals(1431699300000L, DateTime.previousInterval(NON_DST_TS, 
+        15, Calendar.MINUTE, AF).getTimeInMillis());
+    // outliers @ 45 minutes
+    assertEquals(1450151100000L, DateTime.previousInterval(DST_TS, 
+        30, Calendar.MINUTE, NZ).getTimeInMillis());
+    assertEquals(1431699300000L, DateTime.previousInterval(NON_DST_TS, 
+        30, Calendar.MINUTE, NZ).getTimeInMillis());
+    // back to normal
+    assertEquals(1450152000000L, DateTime.previousInterval(DST_TS, 
+        30, Calendar.MINUTE, TV).getTimeInMillis());
+    assertEquals(1431698400000L, DateTime.previousInterval(NON_DST_TS, 
+        30, Calendar.MINUTE, TV).getTimeInMillis());
+    assertEquals(1450152000000L, DateTime.previousInterval(DST_TS, 
+        30, Calendar.MINUTE, FJ).getTimeInMillis());
+    assertEquals(1431698400000L, DateTime.previousInterval(NON_DST_TS, 
+        30, Calendar.MINUTE, FJ).getTimeInMillis());
+    
+    // multiples
+    assertEquals(1450152000000L, DateTime.previousInterval(DST_TS, 
+        120, Calendar.MINUTE).getTimeInMillis());
+    assertEquals(1431698400000L, DateTime.previousInterval(NON_DST_TS, 
+        120, Calendar.MINUTE).getTimeInMillis());
+  }
+  
+  @Test
+  public void previousIntervalHours() {
+    // interval 1
+    assertEquals(1450152000000L, DateTime.previousInterval(DST_TS, 
+        1, Calendar.HOUR_OF_DAY).getTimeInMillis());
+    assertEquals(1431698400000L, DateTime.previousInterval(NON_DST_TS, 
+        1, Calendar.HOUR_OF_DAY).getTimeInMillis());
+    
+    // interval 12
+    assertEquals(1450137600000L, DateTime.previousInterval(DST_TS, 
+        12, Calendar.HOUR_OF_DAY).getTimeInMillis());
+    assertEquals(1431691200000L, DateTime.previousInterval(NON_DST_TS, 
+        12, Calendar.HOUR_OF_DAY).getTimeInMillis());
+    assertEquals(1450137600000L, DateTime.previousInterval(1450137600000L, 
+        12, Calendar.HOUR_OF_DAY).getTimeInMillis());
+        
+    // odd interval
+    assertEquals(1431680400000L, DateTime.previousInterval(NON_DST_TS, 
+        15, Calendar.HOUR_OF_DAY).getTimeInMillis());
+    assertEquals(1450116000000L, DateTime.previousInterval(DST_TS, 
+        15, Calendar.HOUR_OF_DAY).getTimeInMillis());
+    
+    // TZs - 30m offset here
+    assertEquals(1450121400000L, DateTime.previousInterval(DST_TS, 
+        12, Calendar.HOUR_OF_DAY, AF).getTimeInMillis());
+    assertEquals(1431675000000L, DateTime.previousInterval(NON_DST_TS, 
+        12, Calendar.HOUR_OF_DAY, AF).getTimeInMillis());
+    // outliers @ 45 minutes
+    assertEquals(1450131300000L, DateTime.previousInterval(DST_TS, 
+        12, Calendar.HOUR_OF_DAY, NZ).getTimeInMillis());
+    assertEquals(1431688500000L, DateTime.previousInterval(NON_DST_TS, 
+        12, Calendar.HOUR_OF_DAY, NZ).getTimeInMillis());
+    // back to normal
+    assertEquals(1450137600000L, DateTime.previousInterval(DST_TS, 
+        12, Calendar.HOUR_OF_DAY, TV).getTimeInMillis());
+    assertEquals(1431691200000L, DateTime.previousInterval(NON_DST_TS, 
+        12, Calendar.HOUR_OF_DAY, TV).getTimeInMillis());
+    assertEquals(1450134000000L, DateTime.previousInterval(DST_TS, 
+        12, Calendar.HOUR_OF_DAY, FJ).getTimeInMillis());
+    assertEquals(1431691200000L, DateTime.previousInterval(NON_DST_TS, 
+        12, Calendar.HOUR_OF_DAY, FJ).getTimeInMillis());
+    
+    // multiples
+    assertEquals(1450094400000L, DateTime.previousInterval(DST_TS, 
+        36, Calendar.HOUR_OF_DAY).getTimeInMillis());
+    assertEquals(1431604800000L, DateTime.previousInterval(NON_DST_TS, 
+        36, Calendar.HOUR_OF_DAY).getTimeInMillis());
+  }
+  
+  @Test
+  public void previousIntervalDays() {
+    // interval 1
+    assertEquals(1450137600000L, DateTime.previousInterval(DST_TS, 
+        1, Calendar.DAY_OF_MONTH).getTimeInMillis());
+    assertEquals(1431648000000L, DateTime.previousInterval(NON_DST_TS, 
+        1, Calendar.DAY_OF_MONTH).getTimeInMillis());
+    
+    // interval 7 - since days aren't consistent, the only thing we can
+    // do is pick a starting day, i.e. start of the year
+    assertEquals(1449705600000L, DateTime.previousInterval(DST_TS, 
+        7, Calendar.DAY_OF_MONTH).getTimeInMillis());
+    assertEquals(1431561600000L, DateTime.previousInterval(NON_DST_TS, 
+        7, Calendar.DAY_OF_MONTH).getTimeInMillis());
+    assertEquals(1449705600000L, DateTime.previousInterval(1449705600000L, 
+        7, Calendar.DAY_OF_MONTH).getTimeInMillis());
+    
+    // leap year
+    assertEquals(1330473600000L, DateTime.previousInterval(1330516800000L,  
+        1, Calendar.DAY_OF_MONTH).getTimeInMillis());
+    
+    // TZs - 30m offset here
+    assertEquals(1450121400000L, DateTime.previousInterval(DST_TS, 
+        1, Calendar.DAY_OF_MONTH, AF).getTimeInMillis());
+    assertEquals(1431631800000L, DateTime.previousInterval(NON_DST_TS, 
+        1, Calendar.DAY_OF_MONTH, AF).getTimeInMillis());
+    // outliers @ 45 minutes
+    assertEquals(1450088100000L, DateTime.previousInterval(DST_TS, 
+        1, Calendar.DAY_OF_MONTH, NZ).getTimeInMillis());
+    assertEquals(1431688500000L, DateTime.previousInterval(NON_DST_TS, 
+        1, Calendar.DAY_OF_MONTH, NZ).getTimeInMillis());
+    // back to normal
+    assertEquals(1450094400000L, DateTime.previousInterval(DST_TS, 
+        1, Calendar.DAY_OF_MONTH, TV).getTimeInMillis());
+    assertEquals(1431691200000L, DateTime.previousInterval(NON_DST_TS, 
+        1, Calendar.DAY_OF_MONTH, TV).getTimeInMillis());
+    assertEquals(1450090800000L, DateTime.previousInterval(DST_TS, 
+        1, Calendar.DAY_OF_MONTH, FJ).getTimeInMillis());
+    assertEquals(1431691200000L, DateTime.previousInterval(NON_DST_TS, 
+        1, Calendar.DAY_OF_MONTH, FJ).getTimeInMillis());
+    
+    // multiples
+    assertEquals(1445990400000L, DateTime.previousInterval(DST_TS, 
+        60, Calendar.DAY_OF_MONTH).getTimeInMillis());
+    assertEquals(1430438400000L, DateTime.previousInterval(NON_DST_TS, 
+        60, Calendar.DAY_OF_MONTH).getTimeInMillis());
+  }
+  
+  @Test
+  public void previousIntervalWeeks() {
+    // interval 1 DST_TS starts on 13th of Dec, NON starts on the 10th of May
+    assertEquals(1449964800000L, DateTime.previousInterval(DST_TS, 
+        1, Calendar.DAY_OF_WEEK).getTimeInMillis());
+    assertEquals(1431216000000L, DateTime.previousInterval(NON_DST_TS, 
+        1, Calendar.DAY_OF_WEEK).getTimeInMillis());
+    
+    // interval 2
+    assertEquals(1449964800000L, DateTime.previousInterval(DST_TS, 
+        2, Calendar.DAY_OF_WEEK).getTimeInMillis());
+    assertEquals(1431216000000L, DateTime.previousInterval(NON_DST_TS, 
+        2, Calendar.DAY_OF_WEEK).getTimeInMillis());
+    assertEquals(1435449600000L, DateTime.previousInterval(1435795200000L, 
+        2, Calendar.DAY_OF_WEEK).getTimeInMillis());
+    
+    // TZs - 30m offset here
+    assertEquals(1449948600000L, DateTime.previousInterval(DST_TS, 
+        1, Calendar.DAY_OF_WEEK, AF).getTimeInMillis());
+    assertEquals(1431199800000L, DateTime.previousInterval(NON_DST_TS, 
+        1, Calendar.DAY_OF_WEEK, AF).getTimeInMillis());
+    // outliers @ 45 minutes
+    assertEquals(1449915300000L, DateTime.previousInterval(DST_TS, 
+        1, Calendar.DAY_OF_WEEK, NZ).getTimeInMillis());
+    assertEquals(1431170100000L, DateTime.previousInterval(NON_DST_TS, 
+        1, Calendar.DAY_OF_WEEK, NZ).getTimeInMillis());
+    // back to normal
+    assertEquals(1449921600000L, DateTime.previousInterval(DST_TS, 
+        1, Calendar.DAY_OF_WEEK, TV).getTimeInMillis());
+    assertEquals(1431172800000L, DateTime.previousInterval(NON_DST_TS, 
+        1, Calendar.DAY_OF_WEEK, TV).getTimeInMillis());
+    assertEquals(1449918000000L, DateTime.previousInterval(DST_TS, 
+        1, Calendar.DAY_OF_WEEK, FJ).getTimeInMillis());
+    assertEquals(1431172800000L, DateTime.previousInterval(NON_DST_TS, 
+        1, Calendar.DAY_OF_WEEK, FJ).getTimeInMillis());
+    
+    // multiples - still from start of the week
+    assertEquals(1449964800000L, DateTime.previousInterval(DST_TS, 
+        104, Calendar.DAY_OF_WEEK).getTimeInMillis());
+    assertEquals(1431216000000L, DateTime.previousInterval(NON_DST_TS, 
+        104, Calendar.DAY_OF_WEEK).getTimeInMillis());
+  }
+  
+  @Test
+  public void previousIntervalWeekOfYear() {
+    // interval 1 DST_TS starts on 10th of Dec, NON starts on the 14th of May
+    assertEquals(1449705600000L, DateTime.previousInterval(DST_TS, 
+        1, Calendar.WEEK_OF_YEAR).getTimeInMillis());
+    assertEquals(1431561600000L, DateTime.previousInterval(NON_DST_TS, 
+        1, Calendar.WEEK_OF_YEAR).getTimeInMillis());
+    
+    // interval 26
+    assertEquals(1435795200000L, DateTime.previousInterval(DST_TS, 
+        26, Calendar.WEEK_OF_YEAR).getTimeInMillis());
+    assertEquals(1420070400000L, DateTime.previousInterval(NON_DST_TS, 
+        26, Calendar.WEEK_OF_YEAR).getTimeInMillis());
+    assertEquals(1435795200000L, DateTime.previousInterval(1435795200000L, 
+        26, Calendar.WEEK_OF_YEAR).getTimeInMillis());
+    
+    // TZs - 30m offset here
+    assertEquals(1449689400000L, DateTime.previousInterval(DST_TS, 
+        1, Calendar.WEEK_OF_YEAR, AF).getTimeInMillis());
+    assertEquals(1431545400000L, DateTime.previousInterval(NON_DST_TS, 
+        1, Calendar.WEEK_OF_YEAR, AF).getTimeInMillis());
+    // outliers @ 45 minutes
+    assertEquals(1449656100000L, DateTime.previousInterval(DST_TS, 
+        1, Calendar.WEEK_OF_YEAR, NZ).getTimeInMillis());
+    assertEquals(1431515700000L, DateTime.previousInterval(NON_DST_TS, 
+        1, Calendar.WEEK_OF_YEAR, NZ).getTimeInMillis());
+    // back to normal
+    assertEquals(1449662400000L, DateTime.previousInterval(DST_TS, 
+        1, Calendar.WEEK_OF_YEAR, TV).getTimeInMillis());
+    assertEquals(1431518400000L, DateTime.previousInterval(NON_DST_TS, 
+        1, Calendar.WEEK_OF_YEAR, TV).getTimeInMillis());
+    assertEquals(1449658800000L, DateTime.previousInterval(DST_TS, 
+        1, Calendar.WEEK_OF_YEAR, FJ).getTimeInMillis());
+    assertEquals(1431518400000L, DateTime.previousInterval(NON_DST_TS, 
+        1, Calendar.WEEK_OF_YEAR, FJ).getTimeInMillis());
+    
+    // multiples
+    assertEquals(1420070400000L, DateTime.previousInterval(DST_TS, 
+        104, Calendar.WEEK_OF_YEAR).getTimeInMillis());
+    assertEquals(1420070400000L, DateTime.previousInterval(NON_DST_TS, 
+        104, Calendar.WEEK_OF_YEAR).getTimeInMillis());
+  }
+  
+  @Test
+  public void previousIntervalMonths() {
+    // interval 1
+    assertEquals(1448928000000L, DateTime.previousInterval(DST_TS, 
+        1, Calendar.MONTH).getTimeInMillis());
+    assertEquals(1430438400000L, DateTime.previousInterval(NON_DST_TS, 
+        1, Calendar.MONTH).getTimeInMillis());
+    
+    // interval 3 (quarters)
+    assertEquals(1443657600000L, DateTime.previousInterval(DST_TS, 
+        3, Calendar.MONTH).getTimeInMillis());
+    assertEquals(1427846400000L, DateTime.previousInterval(NON_DST_TS, 
+        3, Calendar.MONTH).getTimeInMillis());
+    assertEquals(1443657600000L, DateTime.previousInterval(1443657600000L, 
+        3, Calendar.MONTH).getTimeInMillis());
+    
+    // odd intervals
+    assertEquals(1446336000000L, DateTime.previousInterval(DST_TS, 
+        5, Calendar.MONTH).getTimeInMillis());
+    assertEquals(1420070400000L, DateTime.previousInterval(NON_DST_TS, 
+        5, Calendar.MONTH).getTimeInMillis());
+    
+    // TZs - 30m offset here
+    assertEquals(1448911800000L, DateTime.previousInterval(DST_TS, 
+        1, Calendar.MONTH, AF).getTimeInMillis());
+    assertEquals(1430422200000L, DateTime.previousInterval(NON_DST_TS, 
+        1, Calendar.MONTH, AF).getTimeInMillis());
+    // outliers @ 45 minutes
+    assertEquals(1448878500000L, DateTime.previousInterval(DST_TS, 
+        1, Calendar.MONTH, NZ).getTimeInMillis());
+    assertEquals(1430392500000L, DateTime.previousInterval(NON_DST_TS, 
+        1, Calendar.MONTH, NZ).getTimeInMillis());
+    // back to normal
+    assertEquals(1448884800000L, DateTime.previousInterval(DST_TS, 
+        1, Calendar.MONTH, TV).getTimeInMillis());
+    assertEquals(1430395200000L, DateTime.previousInterval(NON_DST_TS, 
+        1, Calendar.MONTH, TV).getTimeInMillis());
+    assertEquals(1448881200000L, DateTime.previousInterval(DST_TS, 
+        1, Calendar.MONTH, FJ).getTimeInMillis());
+    assertEquals(1430395200000L, DateTime.previousInterval(NON_DST_TS, 
+        1, Calendar.MONTH, FJ).getTimeInMillis());
+    
+    // multiples
+    assertEquals(1420070400000L, DateTime.previousInterval(DST_TS, 
+        24, Calendar.MONTH).getTimeInMillis());
+    assertEquals(1420070400000L, DateTime.previousInterval(NON_DST_TS, 
+        24, Calendar.MONTH).getTimeInMillis());
+  }
+  
+  @Test
+  public void previousIntervalYears() {
+    // interval 1
+    assertEquals(1420070400000L, DateTime.previousInterval(DST_TS, 
+        1, Calendar.YEAR).getTimeInMillis());
+    assertEquals(1420070400000L, DateTime.previousInterval(NON_DST_TS, 
+        1, Calendar.YEAR).getTimeInMillis());
+    
+    // interval 5
+    assertEquals(1420070400000L, DateTime.previousInterval(DST_TS, 
+        5, Calendar.YEAR).getTimeInMillis());
+    assertEquals(1420070400000L, DateTime.previousInterval(NON_DST_TS, 
+        5, Calendar.YEAR).getTimeInMillis());
+    assertEquals(1420070400000L, DateTime.previousInterval(1420070400000L, 
+        5, Calendar.YEAR).getTimeInMillis());
+    
+    // TZs - 30m offset here
+    assertEquals(1420054200000L, DateTime.previousInterval(DST_TS, 
+        1, Calendar.YEAR, AF).getTimeInMillis());
+    assertEquals(1420054200000L, DateTime.previousInterval(NON_DST_TS, 
+        1, Calendar.YEAR, AF).getTimeInMillis());
+    // outliers @ 45 minutes
+    assertEquals(1420020900000L, DateTime.previousInterval(DST_TS, 
+        1, Calendar.YEAR, NZ).getTimeInMillis());
+    assertEquals(1420020900000L, DateTime.previousInterval(NON_DST_TS, 
+        1, Calendar.YEAR, NZ).getTimeInMillis());
+    // back to normal
+    assertEquals(1420027200000L, DateTime.previousInterval(DST_TS, 
+        1, Calendar.YEAR, TV).getTimeInMillis());
+    assertEquals(1420027200000L, DateTime.previousInterval(NON_DST_TS, 
+        1, Calendar.YEAR, TV).getTimeInMillis());
+    assertEquals(1420023600000L, DateTime.previousInterval(DST_TS, 
+        1, Calendar.YEAR, FJ).getTimeInMillis());
+    assertEquals(1420023600000L, DateTime.previousInterval(NON_DST_TS, 
+        1, Calendar.YEAR, FJ).getTimeInMillis());
+  }
+  
+  @Test (expected = IllegalArgumentException.class)
+  public void previousIntervalNegativeTs() {
+    DateTime.previousInterval(-42, 1, Calendar.MINUTE);
+  }
+  
+  @Test (expected = IllegalArgumentException.class)
+  public void previousIntervalNegativeInterval() {
+    DateTime.previousInterval(1355961600000L, -1, Calendar.MINUTE);
+  }
+  
+  @Test (expected = IllegalArgumentException.class)
+  public void previousIntervalZeroInterval() {
+    DateTime.previousInterval(1355961600000L, 0, Calendar.MINUTE);
+  }
+  
+  @Test (expected = IllegalArgumentException.class)
+  public void previousIntervalNegativeUnit() {
+    DateTime.previousInterval(1355961600000L, 1, -1);
+  }
+  
+  @Test (expected = IllegalArgumentException.class)
+  public void previousIntervalUnsupportedUnit() {
+    DateTime.previousInterval(1355961600000L, 1, Calendar.HOUR);
+  }
+  
+  @Test (expected = IllegalArgumentException.class)
+  public void previousIntervalMassiveUnit() {
+    DateTime.previousInterval(1355961600000L, 1, 6048);
+  }
+  
+  @Test
+  public void unitsToCalendarType() {
+    assertEquals(Calendar.MILLISECOND, DateTime.unitsToCalendarType("ms"));
+    assertEquals(Calendar.SECOND, DateTime.unitsToCalendarType("s"));
+    assertEquals(Calendar.MINUTE, DateTime.unitsToCalendarType("m"));
+    assertEquals(Calendar.HOUR_OF_DAY, DateTime.unitsToCalendarType("h"));
+    assertEquals(Calendar.DAY_OF_MONTH, DateTime.unitsToCalendarType("d"));
+    assertEquals(Calendar.DAY_OF_WEEK, DateTime.unitsToCalendarType("w"));
+    assertEquals(Calendar.MONTH, DateTime.unitsToCalendarType("n"));
+    assertEquals(Calendar.YEAR, DateTime.unitsToCalendarType("y"));
+    try {
+      DateTime.unitsToCalendarType("j");
+      fail("Expected IllegalArgumentException");
+    } catch (IllegalArgumentException e) { }
+    try {
+      DateTime.unitsToCalendarType(null);
+      fail("Expected IllegalArgumentException");
+    } catch (IllegalArgumentException e) { }
+    try {
+      DateTime.unitsToCalendarType("");
+      fail("Expected IllegalArgumentException");
+    } catch (IllegalArgumentException e) { }
+  }
+
+  
   @Test
   public void msFromNano() {
     assertEquals(0, DateTime.msFromNano(0), 0.0001);
diff --git a/third_party/alpn-boot/alpn-boot-7.0.0.v20140317.jar.md5 b/third_party/alpn-boot/alpn-boot-7.0.0.v20140317.jar.md5
new file mode 100644
index 0000000000..6e005e9074
--- /dev/null
+++ b/third_party/alpn-boot/alpn-boot-7.0.0.v20140317.jar.md5
@@ -0,0 +1 @@
+81e4f665ff2bf40720f9b345cee6b429
diff --git a/third_party/alpn-boot/alpn-boot-7.1.0.v20141016.jar.md5 b/third_party/alpn-boot/alpn-boot-7.1.0.v20141016.jar.md5
new file mode 100644
index 0000000000..529b4c8b5d
--- /dev/null
+++ b/third_party/alpn-boot/alpn-boot-7.1.0.v20141016.jar.md5
@@ -0,0 +1 @@
+b1569a1f34a0ca61d34c3c3e5020a8ef
diff --git a/third_party/alpn-boot/alpn-boot-7.1.1.v20141016.jar.md5 b/third_party/alpn-boot/alpn-boot-7.1.1.v20141016.jar.md5
new file mode 100644
index 0000000000..d125a86172
--- /dev/null
+++ b/third_party/alpn-boot/alpn-boot-7.1.1.v20141016.jar.md5
@@ -0,0 +1 @@
+d9add9c8eb6c087e408b076e6d823ddd
diff --git a/third_party/alpn-boot/alpn-boot-7.1.2.v20141202.jar.md5 b/third_party/alpn-boot/alpn-boot-7.1.2.v20141202.jar.md5
new file mode 100644
index 0000000000..2ea2c00f10
--- /dev/null
+++ b/third_party/alpn-boot/alpn-boot-7.1.2.v20141202.jar.md5
@@ -0,0 +1 @@
+391f659c583e2ea0f05515a6f6147620
diff --git a/third_party/alpn-boot/alpn-boot-7.1.3.v20150130.jar.md5 b/third_party/alpn-boot/alpn-boot-7.1.3.v20150130.jar.md5
new file mode 100644
index 0000000000..b51d10325d
--- /dev/null
+++ b/third_party/alpn-boot/alpn-boot-7.1.3.v20150130.jar.md5
@@ -0,0 +1 @@
+b10366c9301e954bcedbf9130b6381c7
diff --git a/third_party/alpn-boot/alpn-boot-8.0.0.v20140317.jar.md5 b/third_party/alpn-boot/alpn-boot-8.0.0.v20140317.jar.md5
new file mode 100644
index 0000000000..b34b6459eb
--- /dev/null
+++ b/third_party/alpn-boot/alpn-boot-8.0.0.v20140317.jar.md5
@@ -0,0 +1 @@
+de73395f7e20619699a07063e640d5f7
diff --git a/third_party/alpn-boot/alpn-boot-8.1.0.v20141016.jar.md5 b/third_party/alpn-boot/alpn-boot-8.1.0.v20141016.jar.md5
new file mode 100644
index 0000000000..89c8317c71
--- /dev/null
+++ b/third_party/alpn-boot/alpn-boot-8.1.0.v20141016.jar.md5
@@ -0,0 +1 @@
+d4a325fdb7e86bd0d9ac583998165a84
diff --git a/third_party/alpn-boot/alpn-boot-8.1.1.v20141016.jar.md5 b/third_party/alpn-boot/alpn-boot-8.1.1.v20141016.jar.md5
new file mode 100644
index 0000000000..5993e27253
--- /dev/null
+++ b/third_party/alpn-boot/alpn-boot-8.1.1.v20141016.jar.md5
@@ -0,0 +1 @@
+4655c087dda15743449ff31717d98e50
diff --git a/third_party/alpn-boot/alpn-boot-8.1.2.v20141202.jar.md5 b/third_party/alpn-boot/alpn-boot-8.1.2.v20141202.jar.md5
new file mode 100644
index 0000000000..01c9bb0cef
--- /dev/null
+++ b/third_party/alpn-boot/alpn-boot-8.1.2.v20141202.jar.md5
@@ -0,0 +1 @@
+9689564f4d7cc15918568f7006b85bf5
diff --git a/third_party/alpn-boot/alpn-boot-8.1.3.v20150130.jar.md5 b/third_party/alpn-boot/alpn-boot-8.1.3.v20150130.jar.md5
new file mode 100644
index 0000000000..a964d2acca
--- /dev/null
+++ b/third_party/alpn-boot/alpn-boot-8.1.3.v20150130.jar.md5
@@ -0,0 +1 @@
+a5803d4ff6ce36d15c750104a117dfb1
diff --git a/third_party/alpn-boot/alpn-boot-8.1.4.v20150727.jar.md5 b/third_party/alpn-boot/alpn-boot-8.1.4.v20150727.jar.md5
new file mode 100644
index 0000000000..c830ed3e9f
--- /dev/null
+++ b/third_party/alpn-boot/alpn-boot-8.1.4.v20150727.jar.md5
@@ -0,0 +1 @@
+1543b3403ae451ca2ec0944de403f6cc
diff --git a/third_party/alpn-boot/alpn-boot-8.1.5.v20150921.jar.md5 b/third_party/alpn-boot/alpn-boot-8.1.5.v20150921.jar.md5
new file mode 100644
index 0000000000..38a5c04b33
--- /dev/null
+++ b/third_party/alpn-boot/alpn-boot-8.1.5.v20150921.jar.md5
@@ -0,0 +1 @@
+b05ac69bd8697c4bfc4cf896dea63c94
diff --git a/third_party/alpn-boot/alpn-boot-8.1.6.v20151105.jar.md5 b/third_party/alpn-boot/alpn-boot-8.1.6.v20151105.jar.md5
new file mode 100644
index 0000000000..209c34b148
--- /dev/null
+++ b/third_party/alpn-boot/alpn-boot-8.1.6.v20151105.jar.md5
@@ -0,0 +1 @@
+0f7bbc8e3da3948082c4d3a510d6fe43
\ No newline at end of file
diff --git a/third_party/alpn-boot/alpn-boot-8.1.7.v20160121.jar.md5 b/third_party/alpn-boot/alpn-boot-8.1.7.v20160121.jar.md5
new file mode 100644
index 0000000000..a70c6c1356
--- /dev/null
+++ b/third_party/alpn-boot/alpn-boot-8.1.7.v20160121.jar.md5
@@ -0,0 +1 @@
+4af7a18a9b4549a1796b182dabca9062
\ No newline at end of file
diff --git a/third_party/alpn-boot/include.mk b/third_party/alpn-boot/include.mk
new file mode 100644
index 0000000000..a949d1da29
--- /dev/null
+++ b/third_party/alpn-boot/include.mk
@@ -0,0 +1,69 @@
+# Copyright (C) 2015  The OpenTSDB Authors.
+#
+# This library is free software: you can redistribute it and/or modify it
+# under the terms of the GNU Lesser General Public License as published
+# by the Free Software Foundation, either version 2.1 of the License, or
+# (at your option) any later version.
+#
+# This library is distributed in the hope that it will be useful,
+# but WITHOUT ANY WARRANTY; without even the implied warranty of
+# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+# GNU Lesser General Public License for more details.
+#
+# You should have received a copy of the GNU Lesser General Public License
+# along with this library.  If not, see <http://www.gnu.org/licenses/>.
+
+# ALPN_BOOT_VERSION := 7.1.3.v20150130
+
+ALPN_BOOT_VERSION = $(shell version= ;\
+  if [[ "@JAVA@" ]]; then \
+    version=$$("@JAVA@" -version 2>&1 | awk -F '"' '/version/ {print $$2}'); \
+  else\
+    echo "Failed to parse Java version";\
+    exit 1;\
+  fi; \
+  if [[ $$version =~ ^([0-9]+\.[0-9]+)\.([0-9])[_Uu]([0-9]+) ]]; then \
+    major=$${BASH_REMATCH[1]};\
+    minor=$${BASH_REMATCH[2]}; \
+    sub=$${BASH_REMATCH[3]}; \
+  if [[ $$major = "1.7" ]]; then \
+    if [[ $$sub -lt 71 ]]; then \
+      echo "7.1.0.v20141016"; \
+    elif [[ $$sub -lt 75 ]]; then \
+      echo "7.1.2.v20141202"; \
+    else \
+       echo "7.1.3.v20150130"; \
+    fi \
+  elif [[ $$major = "1.8" ]]; then \
+    if [[ $$sub -lt 25 ]]; then \
+      echo "8.1.0.v20141016"; \
+    elif [[ $$sub -lt 31 ]]; then \
+      echo "8.1.2.v20141202"; \
+    elif [[ $$sub -lt 51 ]]; then \
+       echo "8.1.3.v20150130"; \
+    elif [[ $$sub -lt 60 ]]; then \
+      echo "8.1.4.v20150727"; \
+    elif [[ $$sub -lt 65 ]]; then \
+      echo "8.1.5.v20150921"; \
+    elif [[ $$sub -lt 71 ]]; then \
+      echo "8.1.6.v20151105"; \
+    else \
+      echo "8.1.7.v20160121"; \
+    fi \
+  else \
+    echo "Unsupported major Java version: $$major"; \
+    exit 1; \
+  fi \
+  else \
+  echo "Possibly invalid Java version (couldn't parse): $$version"; \
+  exit 1; \
+  fi)
+
+
+ALPN_BOOT := third_party/alpn-boot/alpn-boot-$(ALPN_BOOT_VERSION).jar
+ALBPN_BOOT_BASE_URL := http://central.maven.org/maven2/org/mortbay/jetty/alpn/alpn-boot/$(ALPN_BOOT_VERSION)
+
+$(ALPN_BOOT): $(ALPN_BOOT).md5
+	set dummy "$(ALBPN_BOOT_BASE_URL)" "$(ALPN_BOOT)"; shift; $(FETCH_DEPENDENCY)
+
+THIRD_PARTY += $(ALPN_BOOT)
diff --git a/third_party/asyncbigtable/asyncbigtable-0.2.1-20151029.214823-2-jar-with-dependencies.jar.md5 b/third_party/asyncbigtable/asyncbigtable-0.2.1-20151029.214823-2-jar-with-dependencies.jar.md5
new file mode 100644
index 0000000000..dbfa539ba6
--- /dev/null
+++ b/third_party/asyncbigtable/asyncbigtable-0.2.1-20151029.214823-2-jar-with-dependencies.jar.md5
@@ -0,0 +1 @@
+e07097fbc7023fd0ee108368a7ad7c73
\ No newline at end of file
diff --git a/third_party/asyncbigtable/asyncbigtable-0.2.1-20160228.235952-3-jar-with-dependencies.jar.md5 b/third_party/asyncbigtable/asyncbigtable-0.2.1-20160228.235952-3-jar-with-dependencies.jar.md5
new file mode 100644
index 0000000000..78c394f1d3
--- /dev/null
+++ b/third_party/asyncbigtable/asyncbigtable-0.2.1-20160228.235952-3-jar-with-dependencies.jar.md5
@@ -0,0 +1 @@
+512cc4c7ba345a11aa8d6662d03bb3ed
diff --git a/third_party/asyncbigtable/include.mk b/third_party/asyncbigtable/include.mk
new file mode 100644
index 0000000000..8549f1451c
--- /dev/null
+++ b/third_party/asyncbigtable/include.mk
@@ -0,0 +1,23 @@
+# Copyright (C) 2015 The OpenTSDB Authors.
+#
+# This library is free software: you can redistribute it and/or modify it
+# under the terms of the GNU Lesser General Public License as published
+# by the Free Software Foundation, either version 2.1 of the License, or
+# (at your option) any later version.
+#
+# This library is distributed in the hope that it will be useful,
+# but WITHOUT ANY WARRANTY; without even the implied warranty of
+# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+# GNU Lesser General Public License for more details.
+#
+# You should have received a copy of the GNU Lesser General Public License
+# along with this library.  If not, see <http://www.gnu.org/licenses/>.
+
+ASYNCBIGTABLE_VERSION := 0.2.1-20160228.235952-3
+ASYNCBIGTABLE := third_party/asyncbigtable/asyncbigtable-$(ASYNCBIGTABLE_VERSION)-jar-with-dependencies.jar
+ASYNCBIGTABLE_BASE_URL := https://oss.sonatype.org/content/repositories/snapshots/com/pythian/opentsdb/asyncbigtable/0.2.1-SNAPSHOT/
+
+$(ASYNCBIGTABLE): $(ASYNCBIGTABLE).md5
+	set dummy "$(ASYNCBIGTABLE_BASE_URL)" "$(ASYNCBIGTABLE)"; shift; $(FETCH_DEPENDENCY)
+
+THIRD_PARTY += $(ASYNCBIGTABLE)
\ No newline at end of file
diff --git a/third_party/asynccassandra/asynccassandra-0.0.1-20151104.191228-3-jar-with-dependencies.jar.md5 b/third_party/asynccassandra/asynccassandra-0.0.1-20151104.191228-3-jar-with-dependencies.jar.md5
new file mode 100644
index 0000000000..6469b18da4
--- /dev/null
+++ b/third_party/asynccassandra/asynccassandra-0.0.1-20151104.191228-3-jar-with-dependencies.jar.md5
@@ -0,0 +1 @@
+0dd29195cdb9ca4467d0fc32bfffb98c
\ No newline at end of file
diff --git a/third_party/asynccassandra/asynccassandra-0.0.1-20160229.001338-4-jar-with-dependencies.jar.md5 b/third_party/asynccassandra/asynccassandra-0.0.1-20160229.001338-4-jar-with-dependencies.jar.md5
new file mode 100644
index 0000000000..cbd7d36bb3
--- /dev/null
+++ b/third_party/asynccassandra/asynccassandra-0.0.1-20160229.001338-4-jar-with-dependencies.jar.md5
@@ -0,0 +1 @@
+cb857f54223905d744fafa475d82623f
\ No newline at end of file
diff --git a/third_party/asynccassandra/include.mk b/third_party/asynccassandra/include.mk
new file mode 100644
index 0000000000..f98aab5050
--- /dev/null
+++ b/third_party/asynccassandra/include.mk
@@ -0,0 +1,23 @@
+# Copyright (C) 2015 The OpenTSDB Authors.
+#
+# This library is free software: you can redistribute it and/or modify it
+# under the terms of the GNU Lesser General Public License as published
+# by the Free Software Foundation, either version 2.1 of the License, or
+# (at your option) any later version.
+#
+# This library is distributed in the hope that it will be useful,
+# but WITHOUT ANY WARRANTY; without even the implied warranty of
+# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+# GNU Lesser General Public License for more details.
+#
+# You should have received a copy of the GNU Lesser General Public License
+# along with this library.  If not, see <http://www.gnu.org/licenses/>.
+
+ASYNCCASSANDRA_VERSION := 0.0.1-20160229.001338-4
+ASYNCCASSANDRA := third_party/asynccassandra/asynccassandra-$(ASYNCCASSANDRA_VERSION)-jar-with-dependencies.jar
+ASYNCCASSANDRA_BASE_URL := https://oss.sonatype.org/content/repositories/snapshots/net/opentsdb/asynccassandra/0.0.1-SNAPSHOT/
+
+$(ASYNCCASSANDRA): $(ASYNCCASSANDRA).md5
+	set dummy "$(ASYNCCASSANDRA_BASE_URL)" "$(ASYNCCASSANDRA)"; shift; $(FETCH_DEPENDENCY)
+
+THIRD_PARTY += $(ASYNCCASSANDRA)
diff --git a/third_party/gwt/gwt-dev-2.6.1.jar.md5 b/third_party/gwt/gwt-dev-2.6.1.jar.md5
new file mode 100644
index 0000000000..b5847e6a60
--- /dev/null
+++ b/third_party/gwt/gwt-dev-2.6.1.jar.md5
@@ -0,0 +1 @@
+2f8df1f3b021315775506a1e0a4ee4b8
diff --git a/third_party/gwt/gwt-user-2.6.1.jar.md5 b/third_party/gwt/gwt-user-2.6.1.jar.md5
new file mode 100644
index 0000000000..822626d3e7
--- /dev/null
+++ b/third_party/gwt/gwt-user-2.6.1.jar.md5
@@ -0,0 +1 @@
+ce17f82bb92e3a7416a9be5659cbcc89
diff --git a/third_party/include.mk b/third_party/include.mk
index 56649734d1..dc2f22d20b 100644
--- a/third_party/include.mk
+++ b/third_party/include.mk
@@ -21,18 +21,39 @@ THIRD_PARTY =
 include third_party/guava/include.mk
 include third_party/gwt/include.mk
 include third_party/hamcrest/include.mk
-include third_party/hbase/include.mk
 include third_party/jackson/include.mk
+include third_party/javacc/include.mk
 include third_party/javassist/include.mk
+include third_party/jexl/include.mk
+include third_party/jgrapht/include.mk
 include third_party/junit/include.mk
 include third_party/logback/include.mk
 include third_party/mockito/include.mk
 include third_party/netty/include.mk
 include third_party/objenesis/include.mk
 include third_party/powermock/include.mk
-include third_party/protobuf/include.mk
 include third_party/slf4j/include.mk
 include third_party/suasync/include.mk
 include third_party/validation-api/include.mk
-include third_party/zookeeper/include.mk
 include third_party/apache/include.mk
+
+if BIGTABLE
+include third_party/alpn-boot/include.mk
+include third_party/asyncbigtable/include.mk
+ASYNCCASSANDRA_VERSION = 0.0
+ASYNCHBASE_VERSION = 0.0
+ZOOKEEPER_VERSION = 0.0
+else
+if CASSANDRA
+include third_party/asynccassandra/include.mk
+ASYNCBIGTABLE_VERSION = 0.0
+ASYNCHBASE_VERSION = 0.0
+ZOOKEEPER_VERSION = 0.0
+else
+include third_party/hbase/include.mk
+include third_party/protobuf/include.mk
+include third_party/zookeeper/include.mk
+ASYNCBIGTABLE_VERSION = 0.0
+ASYNCCASSANDRA_VERSION = 0.0
+endif
+endif
\ No newline at end of file
diff --git a/third_party/javacc/include.mk b/third_party/javacc/include.mk
new file mode 100644
index 0000000000..2c7f29785a
--- /dev/null
+++ b/third_party/javacc/include.mk
@@ -0,0 +1,23 @@
+# Copyright (C) 2015  The OpenTSDB Authors.
+#
+# This library is free software: you can redistribute it and/or modify it
+# under the terms of the GNU Lesser General Public License as published
+# by the Free Software Foundation, either version 2.1 of the License, or
+# (at your option) any later version.
+#
+# This library is distributed in the hope that it will be useful,
+# but WITHOUT ANY WARRANTY; without even the implied warranty of
+# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+# GNU Lesser General Public License for more details.
+#
+# You should have received a copy of the GNU Lesser General Public License
+# along with this library.  If not, see <http://www.gnu.org/licenses/>.
+
+JAVACC_VERSION := 6.1.2
+JAVACC := third_party/javacc/javacc-$(JAVACC_VERSION).jar
+JAVACC_BASE_URL := http://central.maven.org/maven2/net/java/dev/javacc/javacc/$(JAVACC_VERSION)
+
+$(JAVACC): $(JAVACC).md5
+	set dummy "$(JAVACC_BASE_URL)" "$(JAVACC)"; shift; $(FETCH_DEPENDENCY)
+
+THIRD_PARTY += $(JAVACC)
diff --git a/third_party/javacc/javacc-6.1.2.jar.md5 b/third_party/javacc/javacc-6.1.2.jar.md5
new file mode 100644
index 0000000000..84d9e28cfc
--- /dev/null
+++ b/third_party/javacc/javacc-6.1.2.jar.md5
@@ -0,0 +1 @@
+c74b2df75b4c46209d6da22bf4dad976
diff --git a/third_party/jexl/commons-jexl-2.1.1.jar.md5 b/third_party/jexl/commons-jexl-2.1.1.jar.md5
new file mode 100644
index 0000000000..866f0e175a
--- /dev/null
+++ b/third_party/jexl/commons-jexl-2.1.1.jar.md5
@@ -0,0 +1 @@
+4ad8f5c161dd3a50e190334555675db9
diff --git a/third_party/jexl/commons-logging-1.1.1.jar.md5 b/third_party/jexl/commons-logging-1.1.1.jar.md5
new file mode 100644
index 0000000000..00979c8fe9
--- /dev/null
+++ b/third_party/jexl/commons-logging-1.1.1.jar.md5
@@ -0,0 +1 @@
+ed448347fc0104034aa14c8189bf37de
diff --git a/third_party/jexl/include.mk b/third_party/jexl/include.mk
new file mode 100644
index 0000000000..b78ce1e8ee
--- /dev/null
+++ b/third_party/jexl/include.mk
@@ -0,0 +1,33 @@
+# Copyright (C) 2015  The OpenTSDB Authors.
+#
+# This library is free software: you can redistribute it and/or modify it
+# under the terms of the GNU Lesser General Public License as published
+# by the Free Software Foundation, either version 2.1 of the License, or
+# (at your option) any later version.
+#
+# This library is distributed in the hope that it will be useful,
+# but WITHOUT ANY WARRANTY; without even the implied warranty of
+# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+# GNU Lesser General Public License for more details.
+#
+# You should have received a copy of the GNU Lesser General Public License
+# along with this library.  If not, see <http://www.gnu.org/licenses/>.
+
+JEXL_VERSION := 2.1.1
+JEXL := third_party/jexl/commons-jexl-$(JEXL_VERSION).jar
+JEXL_BASE_URL := http://central.maven.org/maven2/org/apache/commons/commons-jexl/$(JEXL_VERSION)
+
+$(JEXL): $(JEXL).md5
+	set dummy "$(JEXL_BASE_URL)" "$(JEXL)"; shift; $(FETCH_DEPENDENCY)
+
+THIRD_PARTY += $(JEXL)
+
+# In here as Jexl depends on it and no one else (for now, I hope)
+COMMONS_LOGGING_VERSION := 1.1.1
+COMMONS_LOGGING := third_party/jexl/commons-logging-$(COMMONS_LOGGING_VERSION).jar
+COMMONS_LOGGING_BASE_URL := http://central.maven.org/maven2/commons-logging/commons-logging/$(COMMONS_LOGGING_VERSION)
+
+$(COMMONS_LOGGING): $(COMMONS_LOGGING).md5
+	set dummy "$(COMMONS_LOGGING_BASE_URL)" "$(COMMONS_LOGGING)"; shift; $(FETCH_DEPENDENCY)
+
+THIRD_PARTY += $(COMMONS_LOGGING)
\ No newline at end of file
diff --git a/third_party/jgrapht/include.mk b/third_party/jgrapht/include.mk
new file mode 100644
index 0000000000..11647e3bcc
--- /dev/null
+++ b/third_party/jgrapht/include.mk
@@ -0,0 +1,23 @@
+# Copyright (C) 2015  The OpenTSDB Authors.
+#
+# This library is free software: you can redistribute it and/or modify it
+# under the terms of the GNU Lesser General Public License as published
+# by the Free Software Foundation, either version 2.1 of the License, or
+# (at your option) any later version.
+#
+# This library is distributed in the hope that it will be useful,
+# but WITHOUT ANY WARRANTY; without even the implied warranty of
+# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+# GNU Lesser General Public License for more details.
+#
+# You should have received a copy of the GNU Lesser General Public License
+# along with this library.  If not, see <http://www.gnu.org/licenses/>.
+
+JGRAPHT_VERSION := 0.9.1
+JGRAPHT := third_party/jgrapht/jgrapht-core-$(JGRAPHT_VERSION).jar
+JGRAPHT_BASE_URL := http://central.maven.org/maven2/org/jgrapht/jgrapht-core/$(JGRAPHT_VERSION)
+
+$(JGRAPHT): $(JGRAPHT).md5
+	set dummy "$(JGRAPHT_BASE_URL)" "$(JGRAPHT)"; shift; $(FETCH_DEPENDENCY)
+
+THIRD_PARTY += $(JGRAPHT)
diff --git a/third_party/jgrapht/jgrapht-core-0.9.1.jar.md5 b/third_party/jgrapht/jgrapht-core-0.9.1.jar.md5
new file mode 100644
index 0000000000..a0089aa304
--- /dev/null
+++ b/third_party/jgrapht/jgrapht-core-0.9.1.jar.md5
@@ -0,0 +1 @@
+86e15da146c96430aef3e1de36df52c8
diff --git a/third_party/zookeeper/include.mk b/third_party/zookeeper/include.mk
index 514b9dc5ed..7fc7695f4f 100644
--- a/third_party/zookeeper/include.mk
+++ b/third_party/zookeeper/include.mk
@@ -13,7 +13,7 @@
 # You should have received a copy of the GNU Lesser General Public License
 # along with this library.  If not, see <http://www.gnu.org/licenses/>.
 
-ZOOKEEPER_VERSION := 3.4.5
+ZOOKEEPER_VERSION := 3.4.6
 ZOOKEEPER := third_party/zookeeper/zookeeper-$(ZOOKEEPER_VERSION).jar
 ZOOKEEPER_BASE_URL := http://central.maven.org/maven2/org/apache/zookeeper/zookeeper/$(ZOOKEEPER_VERSION)
 
diff --git a/third_party/zookeeper/zookeeper-3.4.6.jar.md5 b/third_party/zookeeper/zookeeper-3.4.6.jar.md5
new file mode 100644
index 0000000000..ce5652c709
--- /dev/null
+++ b/third_party/zookeeper/zookeeper-3.4.6.jar.md5
@@ -0,0 +1 @@
+7d01d317c717268725896cfb81b18152
\ No newline at end of file
diff --git a/tools/check_tsd b/tools/check_tsd
index 237ec0e534..0159db4d82 100755
--- a/tools/check_tsd
+++ b/tools/check_tsd
@@ -29,6 +29,13 @@ import sys
 import time
 from optparse import OptionParser
 
+AGGREGATORS = ('avg', 'count', 'dev',
+        'ep50r3', 'ep50r7', 'ep75r3', 'ep75r7', 'ep90r3', 'ep90r7', 'ep95r3', 'ep95r7',
+        'ep99r3', 'ep99r7', 'ep999r3', 'ep999r7',
+        'mimmin', 'mimmax', 'min', 'max', 'none',
+        'p50', 'p75', 'p90', 'p95', 'p99', 'p999',
+        'sum', 'zimsum')
+
 def main(argv):
     """Pulls data out of the TSDB and do very simple alerting from Nagios."""
 
@@ -71,6 +78,12 @@ def main(argv):
     parser.add_option('-P', '--percent-over', dest='percent_over', default=0,
             metavar='PERCENT', type='float', help='Only alarm if PERCENT of the data'
             ' points violate the threshold.')
+    parser.add_option('-N', '--now', type='int', default=None,
+            metavar='UTC',
+            help='Set unix timestamp for "now", for testing')
+    parser.add_option('-B', '--bad_percent', dest='bad_percent', default=None,
+            metavar='PERCENT', type='float', help='Ignore alarm if PERCENT of the data'
+            ' points is bad')
     parser.add_option('-S', '--ssl', default=False, action='store_true',
             help='Make queries to OpenTSDB via SSL (https)')
     (options, args) = parser.parse_args(args=argv[1:])
@@ -78,9 +91,9 @@ def main(argv):
     # argument validation
     if options.comparator not in ('gt', 'ge', 'lt', 'le', 'eq', 'ne'):
         parser.error("Comparator '%s' not valid." % options.comparator)
-    elif options.downsample not in ('none', 'avg', 'min', 'sum', 'max'):
+    elif options.downsample not in ('none',)+AGGREGATORS:
         parser.error("Downsample '%s' not valid." % options.downsample)
-    elif options.aggregator not in ('avg', 'min', 'sum', 'max'):
+    elif options.aggregator not in AGGREGATORS:
         parser.error("Aggregator '%s' not valid." % options.aggregator)
     elif not options.metric:
         parser.error('You must specify a metric (option -m).')
@@ -118,8 +131,16 @@ def main(argv):
         rate = 'rate:'
     else:
         rate = ''
-    url = ('/q?start=%ss-ago&m=%s:%s%s%s%s&ascii&nagios'
-           % (options.duration, options.aggregator, downsampling, rate,
+
+    if options.now:
+        now = options.now
+        start = '%s' % (now - int(options.duration))
+    else:
+        now = int(time.time())
+        start = '%ss-ago' % options.duration
+
+    url = ('/q?start=%s&m=%s:%s%s%s%s&ascii&nagios'
+           % (start, options.aggregator, downsampling, rate,
               options.metric, tags))
     tsd = '%s:%d' % (options.host, options.port)
     if options.ssl:  # Pick the class to instantiate first.
@@ -139,7 +160,7 @@ def main(argv):
         peer = conn.sock.getpeername()
         print ('Connected to %s:%d' % (peer[0], peer[1]))
         conn.set_debuglevel(1)
-    now = int(time.time())
+
     try:
       conn.request('GET', url)
       res = conn.getresponse()
@@ -159,8 +180,6 @@ def main(argv):
         return 2
 
     # but we won!
-    if options.verbose:
-        print (datapoints)
     datapoints = datapoints.splitlines()
 
     def no_data_point():
@@ -182,12 +201,20 @@ def main(argv):
     nbad = 0       # How many bad values have we seen?
     ncrit = 0      # How many critical values have we seen?
     nwarn = 0      # How many warning values have we seen?
-    for datapoint in datapoints:
-        datapoint = datapoint.split()
+    for datapoint_str in datapoints:
+        datapoint = datapoint_str.split()
         ts = int(datapoint[1])
         delta = now - ts
         if delta > options.duration or delta <= options.ignore_recent:
+            if options.verbose:
+                print "%s (ignored, delta %ds)" % (datapoint_str, delta)
+            if delta < 0:
+                break # Skip the rest, we got what we came for.
             continue  # Ignore data points outside of our range.
+
+        if options.verbose:
+            print datapoint_str
+
         npoints += 1
         val = datapoint[2]
         if '.' in val:
@@ -228,13 +255,6 @@ def main(argv):
 
     bad_pct = nbad * 100.0 / npoints
 
-    if options.bad_percent is not None and rv > 0 \
-        and bad_pct < options.bad_percent:
-            if options.verbose:
-                print 'ignoring alarm, less than %.1f%% bad values (found %.1f%%)' % \
-                    (options.bad_percent, bad_pct)
-            rv = 0
-
     # in nrpe, pipe character is something special, but it's used in tag
     # searches.  Translate it to something else for the purposes of output.
     ttags = tags.replace("|",":")
diff --git a/tools/docker/Dockerfile b/tools/docker/Dockerfile
new file mode 100644
index 0000000000..c9410133e1
--- /dev/null
+++ b/tools/docker/Dockerfile
@@ -0,0 +1,43 @@
+FROM java:openjdk-8-alpine
+
+MAINTAINER jonathan.creasy@gmail.com
+
+ENV       VERSION 2.3.0-RC1
+ENV       WORKDIR /usr/share/opentsdb
+ENV       LOGDIR  /var/log/opentsdb
+ENV       DATADIR /data/opentsdb
+ENV       ETCDIR /etc/opentsdb
+
+RUN       mkdir -p $WORKDIR/static
+RUN       mkdir -p $WORKDIR/libs
+RUN       mkdir -p $WORKDIR/third_party
+RUN       mkdir -p $WORKDIR/resources
+RUN       mkdir -p $DATADIR/cache
+RUN       mkdir -p $LOGDIR
+RUN       mkdir -p $ETCDIR
+
+ENV       CONFIG $ETCDIR/opentsdb.conf
+ENV       STATICROOT $WORKDIR/static
+ENV       CACHEDIR $DATADIR/cache
+
+ENV       CLASSPATH  $WORKDIR:$WORKDIR/tsdb-$VERSION.jar:$WORKDIR/libs/*:$WORKDIR/logback.xml
+ENV       CLASS net.opentsdb.tools.TSDMain
+
+# It is expected these might need to be passed in with the -e flag
+ENV       JAVA_OPTS="-Xms512m -Xmx2048m"
+ENV       ZKQUORUM zookeeper:2181
+ENV       ZKBASEDIR /hbase
+ENV       TSDB_OPTS "--read-only --disable-ui"
+ENV       TSDB_PORT  4244
+
+WORKDIR   $WORKDIR
+
+ADD       libs $WORKDIR/libs
+ADD       logback.xml $WORKDIR
+ADD       tsdb-$VERSION.jar $WORKDIR
+ADD       opentsdb.conf $ETCDIR/opentsdb.conf
+
+VOLUME    ["/etc/openstsdb"]
+VOLUME    ["/data/opentsdb"]
+
+ENTRYPOINT java -enableassertions -enablesystemassertions -classpath ${CLASSPATH} ${CLASS} --config=${CONFIG} --staticroot=${STATICROOT} --cachedir=${CACHEDIR} --port=${TSDB_PORT} --zkquorum=${ZKQUORUM} --zkbasedir=${ZKBASEDIR} ${TSDB_OPTS}
diff --git a/tools/docker/docker.sh b/tools/docker/docker.sh
new file mode 100755
index 0000000000..17686a0e61
--- /dev/null
+++ b/tools/docker/docker.sh
@@ -0,0 +1,16 @@
+#!/bin/bash -x
+BUILDROOT=./build;
+TOOLS=./tools
+DOCKER=$BUILDROOT/docker;
+rm -r $DOCKER;
+mkdir -p $DOCKER;
+SOURCE_PATH=$BUILDROOT;
+DEST_PATH=$DOCKER/libs;
+mkdir -p $DEST_PATH;
+cp ${TOOLS}/docker/Dockerfile ${DOCKER};
+cp ${BUILDROOT}/../src/opentsdb.conf ${DOCKER};
+cp ${BUILDROOT}/../src/logback.xml ${DOCKER};
+#cp ${BUILDROOT}/../src/mygnuplot.sh ${DOCKER};
+cp ${SOURCE_PATH}/tsdb-2.3.0-RC1.jar ${DOCKER};
+cp ${SOURCE_PATH}/third_party/*/*.jar ${DEST_PATH};
+docker build -t opentsdb/opentsdb $DOCKER
diff --git a/tools/osx_full_stack_install.sh b/tools/osx_full_stack_install.sh
new file mode 100644
index 0000000000..e409f03c7a
--- /dev/null
+++ b/tools/osx_full_stack_install.sh
@@ -0,0 +1,93 @@
+#!/bin/bash
+#
+# Script which installs HBase, OpenTSDB and TCollector on OSX
+#
+# This file is part of OpenTSDB.
+# Copyright (C) 2010-2012  The OpenTSDB Authors.
+#
+# This program is free software: you can redistribute it and/or modify it
+# under the terms of the GNU Lesser General Public License as published by
+# the Free Software Foundation, either version 2.1 of the License, or (at your
+# option) any later version.  This program is distributed in the hope that it
+# will be useful, but WITHOUT ANY WARRANTY; without even the implied warranty
+# of MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser
+# General Public License for more details.  You should have received a copy
+# of the GNU Lesser General Public License along with this program.  If not,
+# see <http://www.gnu.org/licenses/>.
+#
+#
+if [ $# -eq 0 ]
+  then
+    echo "No arguments supplied, please suggest an installation path, ex. $HOME"
+    exit 1;
+fi
+BASE_DIR=$1
+SUBBASE_DIR=opentsdb_stack;
+if [ ! -d "${BASE_DIR}" ] ; then
+    echo "$BASE_DIR is not a directory";
+    exit 1;
+fi
+export INSTALL_DIR=$BASE_DIR/$SUBBASE_DIR;
+/bin/echo "Installing into $INSTALL_DIR";
+/bin/mkdir -p $INSTALL_DIR;
+cd $INSTALL_DIR;
+/usr/bin/curl -q http://mirror.cogentco.com/pub/apache/hbase/1.1.2/hbase-1.1.2-bin.tar.gz -o $INSTALL_DIR/hbase-1.1.2-bin.tar.gz 2>/dev/null;
+/usr/bin/tar -xzvf hbase-1.1.2-bin.tar.gz -C $INSTALL_DIR/;
+cd $INSTALL_DIR/hbase-1.1.2;
+/bin/mkdir -p $INSTALL_DIR/data/hbase;
+/bin/mkdir -p $INSTALL_DIR/data/zookeeper;
+/bin/cat <<EOF > conf/hbase-site.xml
+<?xml version="1.0"?>
+<?xml-stylesheet type="text/xsl" href="configuration.xsl"?>
+<!--
+/**
+ *
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * "License"); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+-->
+<configuration>
+  <property>
+    <name>hbase.rootdir</name>
+    <value>file://$INSTALL_DIR/data/hbase</value>
+  </property>
+  <property>
+    <name>hbase.zookeeper.property.dataDir</name>
+    <value>$INSTALL_DIR/data/zookeeper</value>
+  </property>
+</configuration>
+EOF
+$INSTALL_DIR/hbase-1.1.2/bin/start-hbase.sh;
+cd $INSTALL_DIR
+/usr/bin/git clone https://github.com/OpenTSDB/opentsdb.git;
+cd opentsdb
+$INSTALL_DIR/opentsdb/build.sh clean; $INSTALL_DIR/opentsdb/build.sh;
+/bin/mkdir $INSTALL_DIR/opentsdb/build/cache;
+export HBASE_HOME=$INSTALL_DIR/hbase-1.1.2;
+export COMPRESSION=NONE;
+$INSTALL_DIR/opentsdb/src/create_table.sh;
+$INSTALL_DIR/opentsdb/build/tsdb tsd --config=$INSTALL_DIR/opentsdb/src/opentsdb.conf --staticroot=$INSTALL_DIR/opentsdb/build/staticroot --cachedir=$INSTALL_DIR/opentsdb/build/cache --port=4242 --zkquorum=localhost:2181 --zkbasedir=/hbase --auto-metric &
+cd $INSTALL_DIR
+/usr/bin/git clone https://github.com/OpenTSDB/tcollector.git;
+cd $INSTALL_DIR/tcollector/tcollector
+/bin/rm -rf $INSTALL_DIR/tcollector/collectors/0/*;
+/usr/bin/curl -q https://raw.githubusercontent.com/aalpern/tcollector-osx/master/dfstat.py -o $INSTALL_DIR/tcollector/collectors/0/dfstat.py 2>/dev/null;
+/usr/bin/curl -q https://raw.githubusercontent.com/aalpern/tcollector-osx/master/iostat.py -o $INSTALL_DIR/tcollector/collectors/0/iostat.py 2>/dev/null;
+/usr/bin/curl -q https://raw.githubusercontent.com/aalpern/tcollector-osx/master/vmstat.py -o $INSTALL_DIR/tcollector/collectors/0/vmstat.py 2>/dev/null;
+/bin/chmod a+x collectors/0/*.py;
+$INSTALL_DIR/tcollector/tcollector.py -L localhost:4242 -t host=`hostname` -t domain=dev -P $INSTALL_DIR/tcollector/tcollector.pid --logfile $INSTALL_DIR/tcollector/tcollector.log &
+/bin/sleep 30;
+/usr/bin/open http://localhost:4242/#start=10m-ago\&m=sum:df.inodes.free\&autoreload=15;
diff --git a/tsdb.in b/tsdb.in
index d96c53d540..534deb03c1 100644
--- a/tsdb.in
+++ b/tsdb.in
@@ -106,4 +106,14 @@ shift
 JAVA=${JAVA-'java'}
 JVMARGS=${JVMARGS-'-enableassertions -enablesystemassertions'}
 test -r "$localdir/tsdb.local" && . "$localdir/tsdb.local"
-exec $JAVA $JVMARGS -classpath "$CLASSPATH" net.opentsdb.tools.$MAINCLASS "$@"
+
+if [[ $CLASSPATH == *"asyncbigtable"* ]]
+then
+  USE_BIGTABLE=1
+  echo "Running OpenTSDB with Bigtable support"
+
+  ALPN_BOOT_JAR=$(find $localdir -name alpn-boot\*.jar)
+  exec $JAVA $JVMARGS -classpath "$CLASSPATH:$HBASE_CONF" -Xbootclasspath/p:$ALPN_BOOT_JAR net.opentsdb.tools.$MAINCLASS "$@"
+else
+  exec $JAVA $JVMARGS -classpath "$CLASSPATH" net.opentsdb.tools.$MAINCLASS "$@"
+fi
